\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{blindtext}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{cancel}
\usepackage[left=2cm,top=2cm,right=2cm,bottom=2cm]{geometry}
\usepackage[all]{xy}
\usepackage{cancel}
\usepackage{pictexwd}
\usepackage{parskip}
\usepackage{pgfplots}
\pgfplotsset{compat=1.15}
\usepackage{mathrsfs}
\usepackage{vmargin}
\usepackage{hyperref}

\DeclarePairedDelimiter\Floor\lfloor\rfloor
\DeclarePairedDelimiter\Ceil\lceil\rceil


\newtheorem{theorem}{Teorema}[section]
\newtheorem{definicion}[theorem]{Definición}
\newtheorem{proposition}[theorem]{Proposición}
\newtheorem{lemma}{Lema}[theorem]
\newtheorem{definition}[theorem]{Definición}
\newtheorem{example}{Ejemplo}[theorem]
\newtheorem{corolario}{Corolario}[theorem]
\newtheorem{observation}{Observación}[theorem]
\newtheorem{properties}{Propiedades}[theorem]
\providecommand{\abs}[1]{\lvert#1\rvert}
\providecommand{\norm}[1]{\lVert#1\rVert}


\author{Pablo Pallàs}
\title{Introducción a la Teoría de Galois}
\setlength{\parindent}{10pt}
\begin{document}
\rmfamily
\maketitle
\tableofcontents
\parindent= 0cm


\section{Introducción y contexto}
\section{Grupos}

\subsection{Generalidades de grupos}

Supongamos que $G$ es un conjunto no vacío. Entonces definimos una \textbf{operación binaria} en $G$ como una aplicación $G \times G \longrightarrow G$. Usaremos esta operación:
 $$\begin{array}{rccl}
&G \times G&\longrightarrow &G \\
&(x,y)& \longmapsto &x\cdot y = xy
\end{array}
$$
y notar que no todas las operaciones binarias van a ser de interés para nuestros propósitos. Para que lo sean:

\begin{definition}Diremos que $G$ es un \textbf{grupo} con una operación $\cdot$ y lo denotaremos $(G,\cdot)$ si se satisfacen las siguientes condiciones:
\begin{enumerate}
 \renewcommand{\theenumi}{\roman{enumi}} %Números arábigos
\item $(x\cdot y)\cdot z = x\cdot(y\cdot z)$ $\forall x,y,z \in G$. 
\item Existe un elemento $1 \in G$, que denotaremos $e$, tal que $e\cdot x = x \cdot e = x$.
\item $\forall x \in G$ existe $y \in G$ tal que $x\cdot y = y \cdot x = e$.
\end{enumerate}

A esta operación se le suele llamar \textbf{producto}.

Si $G$ es un grupo, el elemento neutro es único, ya que si tenemos $e,e'\in G$ dos elementos neutros de $G$ entonces $$e=e\cdot e' = e'.$$
También el elemento inverso de un $x\in G$ cualquiera es único, ya que si $y,z \in G$ son inversos de $x$ entonces $$y = y \cdot e = y \cdot (x \cdot z) = (y \cdot x) \cdot z = e \cdot z = z.$$
Al inverso de un $x \in G$ lo denotaremos por $x^{-1}$ y al producto lo podremos denotar por $xy$ en vez de $x \cdot y$, con $x,y \in G$.
\end{definition}

\begin{definition}Diremos que un grupo $G$ es \textbf{finito} si $G$ es un conjunto finito. En ese caso, llamaremos \textbf{orden} de $G$ a su número de elementos, y lo denotaremos por $|G|$.
\end{definition}

\begin{example} Algunos ejemplos de grupos:
\begin{enumerate}
\item $\mathbb{Z}, \mathbb{Q}, \mathbb{R}, \mathbb{C}$ son grupos con la suma usual. También lo son $\mathbb{Q}^*, \mathbb{R}^*, \mathbb{C}^*$ con la multiplicación usual.
\item Dado un conjunto no vacío $\Omega$, consideramos $S_{\Omega}$ el conjunto de las aplicaciones biyectivas $\alpha \colon \Omega \longrightarrow \Omega$. Si $\alpha, \beta \in S_{\Omega}$ podemos componerlas y $\alpha \circ \beta \in S_{\Omega}$, así $S_{\Omega}$ es un grupo con la operación $$\alpha \beta = \alpha \circ \beta.$$ A este grupo lo denominaremos \textbf{grupo simétrico} sobre $\Omega$. Si $\Omega$ tiene $n$ elementos, entonces hay $n!$ aplicaciones biyectivas $\Omega \longrightarrow \Omega$, por lo que $|S_{\Omega}| = n!$. Cuando $\Omega = \lbrace 1, 2, \ldots, n \rbrace$ entonces escribiremos $S_{n}$.

Este tipo de grupos los estudiaremos en detalle más adelante. 

\item Dado $K = \mathbb{Q}, \mathbb{R}, \mathbb{C}$ o en general cualquier cuerpo, entonces el conjunto $GL_{n}(K)$ de matrices $n\times n$ con coeficientes en $K$ y cuyo determinante es no nulo es un grupo conocido como \textbf{grupo general lineal}.
\item Consideremos el siguiente subconjunto de los números complejos $$C = \lbrace a+bi \in \mathbb{C}: a^2+b^2 = 1 \rbrace,$$ formado por los elementos de la circunferencia de radio $1$. Entonces $C$ es un grupo con la multiplicación de números complejos. Es lo que conocemos como \textbf{grupo circular}. Si tenemos un $n$ entero positivo, el subconjunto de $C$ formado por las $n$ raíces $n-$ésimas de la unidad $$C_{n}= \lbrace \xi^k : k =0, \ldots, n-1 \rbrace,$$ con $\xi = \cos\left( \dfrac{2\pi}{n} \right) + i\sin\left(\dfrac{2\pi}{n}\right)$ es también un grupo con la misma multiplicación, de un tipo que veremos más tarde conocido como \textbf{grupo cíclico}.
\end{enumerate}
\end{example}
$\hfill \blacksquare$


En general, dado un grupo $G$, no será cierto que $xy = yx$ para cualesquiera $x,y \in G$. Por ejemplo, en $S_{3}$, si $\alpha, \beta \in S_{3}$ con $\alpha(1) = 2, \alpha (2)=3, \alpha (3) = 1$, $\beta (1)=2, \beta(2)=1, \beta (3) = 3$, entonces $\alpha \beta \neq \beta \alpha$. Aquellos grupos $G$ en los que sí se cumpla la igualdad, es decir $xy = yx$ $\forall x,y \in G$, los denominaremos \textbf{grupos abelianos}.

Cuando trabajemos con grupos abelianos será habitual emplear la notación aditiva y escribiremos $x+y$ en lugar de $xy$, $-x$ en lugar de $x^{-1}$ y el elemento neutro será $0$.

\begin{proposition}\label{eq:primGrup} Dado un grupo $G$ tenemos:
\begin{enumerate}
\item Dados $x,y \in G$, si $xy = e$ entonces $x = y^{-1}$, $y = x^{-1}$. En particular, $(xy)^{-1} = y^{-1}x^{-1}$.
\item La aplicación $$\begin{array}{rccl}
&G&\longrightarrow &G\\
&x& \longmapsto &x^{-1}
\end{array}
$$ es una biyección.
\item Dado un $g \in G$, las aplicaciones $$\begin{array}{rccl}
&G&\longrightarrow &G\\
&x& \longmapsto &xg
\end{array}
$$
$$\begin{array}{rccl}
&G&\longrightarrow &G\\
&x& \longmapsto &gx
\end{array}
$$ son biyectivas.
\end{enumerate}
\end{proposition}
\emph{Demostración: }Veamos: \begin{enumerate}
\item Si $xy = 1$ entonces $x^{-1} = x^{-1}e= x^{-1}(xy) = y$, y análogo con $y^{-1}$. Ahora, como $(xy) (y^{-1}x^{-1})=xex^{-1} = e$, de la primera parte ya se tiene.
\item Veamos que la aplicación es biyectiva. Si $x^{-1} = y^{-1}$, con $x,y \in G$, entonces $x = (x^{-1})^{-1} = (y^{-1})^{-1}=y$ y así es inyectiva. Ahora, dado un $z \in G$ tenemos que $z$ es el inverso de $z^{-1}$ y también es suprayectiva.
\item Veamos que la aplicación $$\begin{array}{rccl}
&G&\longrightarrow &G\\
&x& \longmapsto &xg
\end{array}
$$ es biyectiva. Si $xg = yg$, multiplicando por $g^{-1}$ a la derecha tenemos que $x = y$ y así es inyectiva. Si $z \in G$ entonces existirá un elemento $zg^{-1} \in G$ por ser $G$ grupo y la aplicación manda $zg^{-1}$ a $z$ y es suprayectiva también. Para ver la otra la demostración es completamente análoga.
\end{enumerate}

$\hfill \square$

Una vez definida una estructura algebtaica cualquiera siempre nos interesaremos por su subestructura. Esto es particularmente relevante en \textit{Teoría de grupos}.

\begin{definition}Sea $G$ un grupo. Un subconjunto $H$ de $G$ se dice \textbf{subgrupo} si es grupo con la restricción a $H$ de la operación de $G$. Lo denotaremos por $H \leq G$.
\end{definition}

\begin{example}Por ejemplo el subconjunto $SL_{n}(K)$ de matrices de determinante $1$ con coeficientes en $K$ es un subgrupo de $GL_n(K)$ conocido como \textbf{subgrupo especial lineal}.
\end{example}

Observar que un grupo $G$ siempre tiene al menos los subgrupos $ \lbrace 1 \rbrace$ y el propio $G$. Son los conocidos como \textbf{subgrupos triviales}. El resto de subgrupos, aquellos $H \leq G $ tales que $H \neq G$, son los llamados subgrupos \textbf{propios}.

\begin{proposition}Sea $G$ un grupo y sea $H$ un subconjunto no vacío de $G$. Entonces $H \leq G$ si y sólo si $xy^{-1} \in H$ para cualesquiera $x,y \in H$.
\end{proposition}
\emph{Demostración: }
Supongamos que $H \leq G$ y sean $x,y \in H$. Entonces $y^{-1} \in H$ y $xy^{-1} \in H$ por definición. Recíprocamente, supongamos que $xy^{-1} \in H$ $\forall x,y \in H$. Eligiendo cualquier $h \in H$ tenemos que $1 = h h^{-1} \in H$. Luego $y^{-1} = 1y^{-1} \in H$ $\forall y \in H$. Finalmente, si $x,y \in H$ entonces $xy = x(y^{-1})^{-1} \in H$. Así, $H$ es grupo.

$\hfill \square$

\begin{definition} Dados dos subgrupos $H$ y $K$ de un grupo $G$, se define $$HK = \lbrace hk : h \in H, k \in K \rbrace.$$ A este grupo lo llamaremos \textbf{grupo producto}. Igualmente también podremos definir su \textbf{intersección} como
$$H \cap K = \lbrace x: x\in H \wedge x \in K \rbrace.$$
\end{definition}

Si tenemos dos subgrupos cualesquiera $H$ y $K$ de $G$ está claro que $H \cap K$ es subgrupo también. Sin embargo, en general $HK$ no lo será.

\begin{proposition}\label{eq:progruesgru} Sean $H,K \leq G$. Entonces $HK \leq G$ si y sólo si $HK = KH$.
\end{proposition}
\emph{Demostración: }Supongamos que $HK$ es subgrupo de $G$. Si $x = hk \in HK$ entonces $k^{-1}h^{-1} = x^{-1} \in HK$, luego $k^{-1}h^{-1} = uv$ con $u \in H$, $v \in K$ y así $x = hk = (k^{-1}h^{-1})^{-1} = (uv)^{-1} = v^{-1}u^{-1} \in KH$ y esto prueba $HK \subseteq KH$.Sea ahora $y = kh \in KH$. Entonces $z = h^{-1}k^{-1} \in HK$, y como $HK$ es subgrupo $y = kh = (h^{-1}k^{-1})^{-1} = z^{-1} \in HK$, y así $KH \subseteq HK$.
 
Recíprocamente, supongamos que $HK = KH$. Evidentemente $HK$ es no vacío, pues $1 = 1 \cdot 1 \in HK$. Además, dados $x = h_{1}k_{1}$, $y = h_{2}k_{2}$, con $x,y \in HK$,$xy^{-1} = h_{1}k_{1}k_{2}^{-1}h_{2}^{-1} = h_{1}k_{3}h_{2}^{-1}$, con $k_{3} = k_{1}k_{2}^{-1} \in K$. Como $k_{3}h_{2}^{-1} \in KH = HK$, $k_{3}h_{2}^{-1} = h_{3}k$, con $h_{3} \in H$, $k \in K$. Así, $xy^{-1} = h_{1}h_{3}k = hk \in HK$, con $h = h_{1}h_{3} \in H$.

$\hfill \square$

\begin{definition}Si $S$ es un subconjunto no vacío de un grupo $G$, el conjunto $$\langle S \rangle = \lbrace s_{1}^{h_{1}} \ldots s_{n}^{h_{n}} : n \in \mathbb{N},\hspace{0.1cm} s_{i} \in S,\hspace{0.1cm} h_{i} \in \mathbb{Z}, \hspace{0.2cm} 1 \leq i \leq n \rbrace$$ es un subgrupo de $G$ que contiene a $S$, llamado \textbf{subgrupo generado por $S$}.


Si $\mathcal{F}$ es la familia de todos los subgrupos de $G$ que contienen a $S$, $$ \langle S \rangle = \bigcap_{H \in \mathcal{F}} H$$ y, en particular, $\langle S\rangle \subseteq H$ para cada $H \in \mathcal{F}$.
\end{definition}

\begin{definition}\label{eq:centro} Dado $H$ un subgrupo de un grupo $G$, llamaremos \textbf{centralizador} de $H$ en $G$ a $$C_{G}(H) = \lbrace x \in G : xg = gx \hspace{0.15cm} \forall g \in H\rbrace.$$
Al caso particular de $H = G$, es decir, al centralizador de $G$ en $G$ lo denotaremos por $Z(G)$ y lo llamaremos \textbf{centro} de $G$. Así, $$Z(G) = \lbrace x \in G : xg = gx \hspace{0.15cm} \forall g \in G\rbrace.$$
Como consecuencia se tiene que $G$ es abeliano si y sólo si $G = Z(G)$. Además, el centro es un subgrupo de $G$. De hecho, más en general todavía: se tiene que $C_{G}(H)$ es un subgrupo de $G$
\end{definition}
\emph{Demostración: } Demostraremos esto último. Como $1_{G} \in C_{G}(H),$ éste es no vacío. Sean $x,y \in C_{G}(H),\hspace{0.1cm} g \in H$. Como $x\in C_{G}(H),\hspace{0.1cm} xg = gx$. Como $y \in C_{G}(H), \hspace{0.1cm} g^{-1} \in H,\hspace{0.1cm} yg^{-1} = g^{-1}y$. Por lo tanto, \begin{center}$(xy^{-1})g = x(y^{-1}g) = x(g^{-1}y)^{-1} = x(yg^{-1})^{-1} = x(gy^{-1}) = (xg)y^{-1} = (gx)y^{-1} = g(xy^{-1})$\end{center} luego $xy^{-1} \in C_{G}(H)$. Así, $C_{G}(H)$ es un subgrupo de $G$.

$\hfill \square$

\begin{definition} \label{eq:conjugado} Si $S$ es un subconjunto no vacío de un grupo $G$ y $g \in G$, se llama \textbf{conjugado de $S$ por $g$} al conjunto $$S^{g} = \lbrace gxg^{-1}: x \in S\rbrace$$ Diremos que $y \in S^{g} \Leftrightarrow g^{-1}yg \in S$. Ya que si $y \in S^{g} \Rightarrow y = gxg^{-1}\Rightarrow g^{-1}yg = x, \hspace{0.1cm} x \in S$.
\end{definition}

\begin{definition}\label{eq:normalizador} Dado $X$ un subconjunto no vacío de un grupo $G$, llamaremos \textbf{normalizador} de $X$ en $G$ a $$N_{G}(X) = \lbrace g \in G : X^{g} = X\rbrace,$$ que además es un subgrupo de $G$.
\end{definition}

\emph{Demostración: } Ya sabemos que $X^{1} = X$, por lo que $1 \in N_{G}(X)$ y así $N_{G}(X)$ es no vacío. Por otro lado, si $g,f \in N_{G}(X)$, $X^{gf^{-1}} = (X^{g})^{f^{-1}} = X^{f^{-1}}$ pues $g \in N_{G}(X)$. Además, $X = X^{1} = X^{ff^{-1}} = (X^{f})^{f^{-1}} = X^{f^{-1}}$, ya que $f \in N_{G}(X)$. Tenemos entonces que $X^{gf^{-1}} = X$, luego $gf^{-1} \in N_{G}(X)$.

$\hfill \square$

\begin{definition}Si $H \leq G$ y $x \in G$, llamamos a $$Hx = \lbrace hx : h \in H \rbrace$$ \textbf{clase a derecha} (o \textbf{coclase a derecha}) de $x$ módulo $H$. Análogamente, a $$xH = \lbrace xh : h \in H \rbrace$$ lo llamamos \textbf{clase a izquierda} (o \textbf{coclase a izquierda}) de $x$ módulo $H$. 
\end{definition}

En general, aunque ambos conjuntos contienen al elemento $x$, se tiene que $xH \neq Hx$. Más adelante veremos qué ocurre cuando estos conjuntos coinciden.

\begin{proposition}\label{eq:partiGrupo} Sea $H \leq G$ y $x,y \in G$. Entonces: \begin{enumerate}
\item $xH = H$ si y sólo si $x \in H$.
\item $xH = yH$ si y sólo si $x^{-1}y \in H$.
\item $xH \cap yH \neq 0$ si y sólo si $xH = yH$.
\end{enumerate}
\end{proposition}
\emph{Demostración: }\begin{enumerate}
\item Si $x \in H$ ya sabemos por~\ref{eq:primGrup} que $xH = H$. Recíprocamente, si $xH = H$ entonces $x = x1 \in xH = H$.
\item Sea $xH = yH$, entonces $y \in yH = xH$ luego $y = xh$ para algún $h \in H$. De aquí tenemos que $x^{-1}y = h \in H$. Recíprocamente, sea $x^{-1}y \in H$, luego $x^{-1}y = h \in H$ y se tiene que $y = xh$ y $x = yh^{-1}$. Sea $a \in xH$, entonces $a = xh'$, $h' ,\in H$. Ahora $a = xh' = yh^{-1}h' = y(h^{-1}h') \in yH$ ya que $h^{-1}h' \in H$. Así, $xH \subseteq yH$. Al revés es análogo. Así, $xH = yH$.
\item Sea $z \in (xH \cap yH)$. Entonces $z = xh \in xH$ y también $z= yh' \in yH$, luego $x^{-1}z \in H$ e $y^{-1}z \in H$. Como $H$ es grupo, $(y^{-1}z)^{-1} = z^{-1}y \in H$ y $(x^{-1}z)(z^{-1}y) = x^{-1}y \in H$. Ahora, por el apartado anterior $xH = yH$. El recíproco es evidente.
\end{enumerate}

$\hfill \square$

El resultado anterior es completamente análogo para las clases a derecha.

Con esto, es fácilmente comprobable que la relación en $G$ definida por: dados $x,y \in G$, entonces $x\sim_{H} y \Longleftrightarrow xH = yH$ es una relación de equivalencia, de hecho la clase de equivalencia de $x \in G$ es $xH$, es decir, una coclase a izquierda. Luego las coclases, tanto a izquierda como a derecha, forman una partición de $G$. Así, $G$ es unión disjunta de estas clases: $$G = \bigcup_{x \in R} xH,$$ con $R$ un conjunto de representantes de las clases de equivalencia.

\begin{definition}A los conjuntos de estas clases los llamaremos \textbf{conjuntos cocientes} definidos por las respectivas relaciones de equivalencia (a izquierda o derecha). Los denotaremos: $$G/\sim_{H} = \lbrace xH : x \in G \rbrace,$$ $$G/\sim^{H} = \lbrace Hx : x \in G \rbrace.$$
\end{definition}

\begin{proposition}[\textbf{\textit{Teorema de Lagrange y definición de índice}}]Sea $G$ un grupo finito y $H \leq G$. Sea $a$ el número de coclases a izquierda módulo $H$ y $b$ el número de coclases a derecha módulo $H$. Entonces $|G| = a|H| = b|H|$. Así, $a = b$. Tanto a $b$ como a $a$ lo llamaremos \textbf{índice} de $H$ en $G$ y se escribe como $[G:H]$.

Así, tenemos $$|G| = |H|\cdot \left[ G:H \right].$$
\end{proposition}
\begin{proof}
Sabemos que las coclases a izquierda (o derecha) forman una partición de $G$. Además, también sabemos por~~ que cada coclase $xH$ (o $Hx$) es biyectiva con $H$, luego $|xH| = |H| = |Hx|$. Así, $|G| = a|H| = b|H|$. Luego $a=b$.

Así, $|G| = [G:H]|H|$.

\end{proof}

Notar que, al ser grupos finitos podemos poner la anterior expresión como $$[G:H] = \dfrac{|G|}{|H|}.$$
Notar también que, si tenemos $H \leq K \leq G$ entonces, aplicando dos veces el \textit{Teorema de Lagrange} tenemos $$[G:H]=[G:K][K:H],$$ es lo que se conoce como \textbf{\textit{transitividad del índice}}.

Dentro de la \textbf{Teoría de grupos}, un concepto fundamental es el de subgrupo \textit{normal}.

\begin{definition} Un subgrupo $N$ de $G$ se dice \textbf{normal} si $$xN = Nx,$$ para todo $x \in G$. En ese caso, escribimos $N \unlhd G$. También denotaremos por $$G/N = \lbrace gN : g\in G\rbrace$$ al conjunto de las clases a izquierda de $G$ módulo $N$. Si el conjunto $G/N$ es finito, tenemos que $$|G/N| = [G:N].$$
\end{definition}

Notar que todo grupo posee al menos dos subgrupos normales, $1 \unlhd G$, $G \unlhd G$.

\begin{definition} Un grupo $G$ cuyos únicos subgrupos normales sean $\lbrace 1 \rbrace$ y él mismo se dice que es \textbf{simple}.
\end{definition}

\begin{theorem}[\textbf{\textit{Criterio de normalidad}}]
Sea $N$ un subgrupo de $G$. Entonces son equivalentes:
\begin{enumerate}
\item $N\unlhd G$.
\item $xN x^{-1} = N$ $\forall x \in G$.
\item $xNx^{-1} \subseteq N$ $\forall x \in G$.
\end{enumerate}
\end{theorem}
\emph{Demostración: }Veamos primero que $1.\Rightarrow 2.$, para ello notemos que si $y\in xNx^{-1}$ entonces $x^{-1}yx = n \in N$. Como $yx = xn \in xN = Nx$ existirá algún $n' \in N$ tal que $yx = n'x$, y simplificando tendremos que $y = n' \in N$, luego $xNx^{-1} subseteq N$. Como esto es válido para todo $x \in G$, en particular si aplicamos este contenido para $x^{-1}$ tenemos que $x^{-1}N(x^{-1})^{-1}= x^{-1}Nx \subseteq N$. Así, $N = xx^{-1}Nxx^{-1} = x(x^{-1}Nx)x^{-1} \subseteq xNx^{-1}$ y tenemos la igualdad. 

Es evidente que $2.\Rightarrow 3.$, así que veamos que $3.\Rightarrow 1.$ Sabiendo que $xNx^{-1} \subseteq N$ $\forall x\in G$, lo aplicamos a $x^{-1}$ y tenemos nuevamente que $N \subseteq xNx^{-1}$ $\forall x \in G$, así, tenemos la igualdad ($2.$) y de aquí sacamos que $xN = Nx$ y $N$ es normal.

$\hfill \square$

Los subgrupos normales son importantes porque nos permiten construir un nuevo tipo de grupo.

\begin{proposition}Supongamos que $N \unlhd G$. El conjunto $G/N$ de las coclases a izquierda módulo $N$ es un grupo con la operación de $G$ 
$$(xN)(yN)=xyN,$$ con $x,y \in G$. El elemento neutro del grupo $G/N$ es $N$ y $(xN)^{-1} = x^{-1}N$ para tod $x \in G$.
\end{proposition}
\emph{Demostración: }Tenemos que $$(xN)(yN)=x(Ny)N = x(yN)N = xyN.$$ Luego es una operación binaria. 

Veamos que la operación está bien definida: sean $xN = x'N$, $yN = y'N$, veamos que $xyN = x'y'N$. Por~\ref{eq:partiGrupo}, $x^{-1}x' \in N$, $y^{-1}y' \in N$. Ahora $(xy)^{-1}(x'y') = y^{-1}x^{-1}x'y' = y^{-1}x^{-1}x'yy^{-1}y'=y^{-1}(x^{-1}x')y(y^{-1}y') \in N$. Nuevamente por~\ref{eq:partiGrupo} se tiene.

Como $N = 1N$ por lo primero tenemos que $$(xN)N=xN = N(xN)$$ y así es el elemento neutro de $G/N$. También tenemmos que $$(xN)(x^{-1}N) = N = (x^{-1}N)(xN),$$ para todo $x	\in G$.

$\hfill \square$

\begin{definition}Dado $N \unlhd G$, llamaremos \textbf{grupo cociente} de $G$ por $N$ al grupo $G/N$.
\end{definition}

Notar que en un grupo abeliano $G$, todo subgrupo $H$ va a cumplir que $xH = Hx$, por lo que en un grupo abeliano todos sus subgrupos son normales.

\begin{proposition}Sea $N \unlhd G$ y $H \leq G$. Entonces $HN \leq G$.
\end{proposition}
\emph{Demostración: }Como $N$ es subgrupo normal: $$NH = \bigcup_{h\in H} hN = \bigcup_{h\in H} Nh = HN.$$ Aplicamos~\ref{eq:progruesgru} y ya está.

$\hfill \square$

\begin{proposition}\label{eq:ej218} Sea $N \unlhd G$, sean $H, K \leq G$ tales que $H \unlhd K$. Entonces $HN$ es subgrupo normal de $KN$.
\end{proposition}
\emph{Demostración: }Primeramente veamos que $NH=HN$ y así $NH$ es subgrupo de $G$:

En particular $NH$ es subgrupo de $NK$, pues $NH \subseteq NK$. Si $x \in NH$ escribiremos $x = nh, \hspace{0.1cm} n \in N, \hspace{0.1cm} h \in H$. Así $x \in Nh = hN \subseteq HN$, la igualdad $Nh = hN$ se tiene por ser $N$ subgrupo normal de $G$. Esto prueba el contenido $NH \subseteq HN$. El otro es análogo. De igual forma se prueba que $NK = KN$, luego $NK$ es subgrupo de $G$, y así es grupo. Ahora veamos la normalidad:

Veamos ahora que si $a \in NK$, entonces $a(NH) = (NH)a$. Como $a \in NK$ se escribirá $a = nk, \hspace{0.1cm} n \in N, \hspace{0.1cm} k \in K$. Si $x \in a(NH) = a(HN)$ se tendrá $x = ahn_{1}, \hspace{0.1cm} h \in H, \hspace{0.1cm} n_{1} \in N.$ Como $x \in (ah)N = N(ah)$ por ser $N$ subgrupo normal de $G$, tendremos entonces $x = n_{2}ah = n_{2}nkh, \hspace{0.1cm} n_{2} \in N.$ Como $kh \in kH = Hk$ por ser $H$ subgrupo normal de $K$, $x = n_{2}nh_{1}k, \hspace{0.1cm} h_{1} \in H,$ o también, $x = n_{2}nh_{1}n^{-1}nk = n_{2}nh_{1}n^{-1}a$. Ahora $h_{1}n^{-1} \in HN = NH$, con lo que se tiene $h_{1}n^{-1} = n_{3}h_{2}$, $n_{3} \in N$, $h_{2} \in H$. Finalmente, $x = n_{2}nn_{3}h_{2}a \in (NH)a$. Y así $a(NH) \subseteq (NH)a$. Para el otro contenido se procede de igual forma.

$\hfill \square$

Los homomorfismos son las aplicaciones que conservan la estructura de grupo.

\begin{definition}Dados $G$ y $H$ grupos, una aplicación $f \colon G \longrightarrow H$ es un \textbf{homomorfismo de grupos} si cumple $$f(xy) = f(x)f(y) \quad \forall x,y \in G.$$
\end{definition}

\begin{definition}Diremos que un homomorfismo de grupos $f \colon G \longrightarrow H$ es un \textbf{isomorfismo} si la aplicación $f$ es biyectiva. En tal caso diremos que $G$ es \textbf{isomorfo} a $H$ y lo denotaremos por $G \cong H$. Si $f$ es un isomorfismo y además es de la forma $f\colon G \longrightarrow G$ entonces diremos que $f$ es un \textbf{automorfismo}.
\end{definition}

\begin{example}\label{eq:ejsHoms} Algunos ejemplos importantes de homomorfismos:
\begin{enumerate}
\item La aplicación determinante $$\begin{array}{rccl}
&GL_n(K)&\longrightarrow &K^* \\
&A& \longmapsto &det(A)
\end{array}
$$
\item Dado un grupo $G$ y $N \unlhd G$, la aplicación $$\begin{array}{rccl}
&G&\longrightarrow &G/N \\
&g& \longmapsto &gN
\end{array}
$$ que se conoce como \textbf{proyección canónica}.
\item Dado $G = \langle x \rangle$ un grupo cíclico, la aplicación $$\begin{array}{rccl}
&\mathbb{Z}&\longrightarrow &G \\
&m& \longmapsto &x^m
\end{array}
$$
\end{enumerate}
\end{example}

$\hfill \blacksquare$

Más adelante veremos más desarrollados estos homomorfismos. Ahora veamos algunas de las propiedades fundamentales de los homomorfismos:

\begin{properties}\label{eq:propHoms} Consideremos un homomorfismo $f \colon G \longrightarrow H$. Entonces algunas propiedades sobre los homomorfismos de grupos que serán importantes tenerlas en cuenta son las siguientes:
\begin{enumerate}
\item $f(1_{G}) = 1_{H}$ ya que $1_{H}f(1_{G}) = f(1_{G}) = f(1_{G}1_{G}) = f(1_{G})f(1_{G}) \Longrightarrow 1_{H} = f(1_{G}).$
\item $f(a^{-1}) = (f(a))^{-1}$ para cada $a \in G$, puesto que $$f(a)f(a^{-1}) = f(aa^{-1}) = f(1_{G}) = 1_{H},$$ $$f(a^{-1})f(a) = f(a^{-1}a) = f(1_{G}) = 1_{H}.$$
\item $f(x^n) = f(x)^n$. Esto es así ya que $f(x^n) = f(x\overbrace{\cdots}^n x) = f(x) \overbrace{\cdots}^n f(x) = f(x)^n.$
\item $o(f(x))$ divide al orden de $x$. En efecto, si $o(x) = m$ como $x^{m} = 1_{G}$ se tiene que $1_{H} = f(1_{G}) = f(x^{m}) = f(x)^{m}$ y así $o(f(x))$ divide a $m$. 
\item Si $X$ es un subgrupo de $G$, su imagen $f(X)$ es un subgrupo de $H$.

En efecto, ya sabemos que $f(X)$ contiene el elemento neutro, $f(1_G)$. Ahora, sean $f(x), f(y) \in f(X)$, entonces $f(x) f(y)^{-1} = f(x)f(y^{-1}) = f(xy^{-1}) \in f(X)$ al ser $X$ subgrupo de $G$, luego $f(X)$ es subgrupo de $H$.
\item Si $Y$ es un subgrupo de $H$, $$f^{-1}(Y) = \lbrace x \in G : f(x) \in Y\rbrace$$ es un subgrupo de $G$. Además si $Y$ es subgrupo normal de $H$, $f^{-1}(Y)$ lo es de $G$.

En efecto, si $x,y \in f^{-1}(Y)$, entonces $f(x),f(y) \in Y$, de donde $f(xy^{-1}) = f(x)f(y)^{-1} \in Y$, luego $xy^{-1} \in f^{-1}(Y)$ y $f^{-1}(Y)$ es subgrupo. Para probar la normalidad de $f^{-1}(Y)$ tenemos que ver que $[f^{-1}(Y)]^a \subseteq f^{-1}(Y)$, con $a \in G$. Sea $x \in [f^{-1}(Y)]^a$, luego $a^{-1}xa \in f^{-1}(Y)$ y así $f(a^{-1}xa)=f(a)^{-1}f(x)f(a) \in Y$, por lo que $f(x) \in Y^{f(a)}$ y como $f(a)$ es un elemento de $H$ e $Y$ es normal entonces $f(x) \in Y$ y así $x \in f^{-1}(Y)$.
 
\item Si ahora además consideramos otro homomorfismo $g\colon H \longrightarrow  Z$, con $Z$ otro grupo, entonces,
$g \circ f\colon G \longrightarrow  Z$ también es homomorfismo, pues $$ (g \circ f)(xy) = g(f(xy)) = g(f(x)f(y)) = g(f(x))g(f(y)) = (g \circ f)(x) (g \circ f)(y).$$
\end{enumerate}
\end{properties}
$\hfill \blacksquare$

Notar que de lo último se puede ver que la composición de homomorfismos la hemos definido tal que $$(g \circ f)(x) = g(f(x)),$$ con $g,f$ sendos homomorfismos. Es importante aclararlo porque en otros textos es frecuente encontrar que actúan al revés, primero $g$ y luego $f$.

\begin{definition}Si $f \colon G \longrightarrow H$ es un homomorfismo de grupos, llamaremos \textbf{núcleo de $f$} a $$Ker f= \lbrace g \in G: f(g) = 1_H \rbrace.$$

De igual manera, llamaremos \textbf{imagen de $f$} al conjunto $$Im f = \lbrace f(x) : x \in G\rbrace.$$
\end{definition}

De hecho, en el ejemplo~\ref{eq:ejsHoms}($1.$) tenemos que $Ker(det) = SL_n(K)$ es el grupo especial lineal. Y en el ejemplo~\ref{eq:ejsHoms}($2.$) es el propio $N$.

\begin{proposition}Si consideramos $f \colon G \longrightarrow H$ un homomorfismo de grupos cualquiera, entonces $Ker f \unlhd G$. Además, $f$ es inyectiva si y sólo si $Ker f= \lbrace 1 \rbrace.$
\end{proposition}
\emph{Demostración: }Como $Ker f=f^{-1} (1_H)$, por~\ref{eq:propHoms}($4.$) tenemos que $Ker f$ es subgrupo de $G$. Probaremos ahora que, dados $x \in G$ y $z \in Ker f$, $xzx^{-1} \in Ker f$. Esto es claro, ya que $$f(xzx^{-1})=f(x)f(z)f(x)^{-1} = f(x)f(x)^{-1} = 1.$$

Ahora, si $f$ es inyectiva y $x \in Ker f$ entonces $f(x) = 1 = f(1)$, por lo que $x = 1$ y así $Ker f = \lbrace 1 \rbrace$. Recíprocamente, si $Ker f = \lbrace 1 \rbrace$ y $x,y \in G$ son tales que $f(x) = f(y)$, entonces $f(xy^{-1}) = f(x)f(y)^{-1} = 1$, luego $xy^{-1} \in Ker f = \lbrace 1 \rbrace$ y así $x=y$.

$\hfill \square$

\begin{definition}Sea $
\begin{array}{rccl}
f\colon G_{1} \longrightarrow  G_{2}
\end{array}
$ un homomorfismo entre dos grupos $G_{1}$ y $G_{2}$, diremos que $f$ es un \textbf{monomorfismo} si $f$ es inyectiva y \textbf{epimorfismo} si $f$ es sobreyectiva.
\end{definition}

\begin{theorem}[\textbf{\textit{Primer Teorema de Isomorfía}}]
Sea $f \colon G \longrightarrow H$ un homomorfismo de grupos. Entonces, la aplicación $$\begin{array}{rccl}
\bar{f} &G/Ker f&\longrightarrow &f(G) \\
&xKer f& \longmapsto &f(x)
\end{array}
$$
es un isomorfismo de grupos.
\end{theorem}
\emph{Demostración: }Sea $N = Ker f$. Sabemos por~\ref{eq:partiGrupo} que $xN = yN$ si y sólo si $x^{-1}y \in N$ si y sólo si $f(x^{-1}y)=1$ si y sólo si $f(x)^{-1}f(y) = 1$ si y sólo si $f(x)=f(y)$. Si leemos esto de izquierda a derecha estamos probando que la aplicación $\bar{f}$ está bien definida, es decir, que la imagen por $\bar{f}$ de un elemento $xN \in G/N$ no depende del representante que escojamos. Si lo leemos de derecha a izquierda estaremos probando que $\bar{f}$ es inyectiva. Si $y \in f(G)$ (imagen de $G$ por $f$) entonces $y=f(x)=\bar{f}(xKer f)$ con $x\in G$ y esto prueba la sobreyectividad. Además, es homomorfismo: $$\bar{f}(xNyN)= \bar{f}(xyN)=f(xy)=f(x)f(y) =\bar{f}(xN) \bar{f}(yN).$$ 

$\hfill \square$

Luego, dados dos grupos $G,H$, podemos expresar el \textit{Primer Teorema de Isomorfía} tal que así: $$G/Ker f \cong f(G).$$
Y notar que si $f$ es suprayectiva, entonces: $$G/Ker f \cong H.$$

\begin{proposition}\label{eq:lemIsom} Sea $N \unlhd G$ y sea $f \colon G \longrightarrow G/N$ el homomorfismo $f(g) = gN$. Si $H \leq G$, entonces $f(H) = f(NH)=NH/N \leq G/N$.
\end{proposition}
\emph{Demostración: }Si $H \leq G$ sabemos que $NH$ es subgrupo de $G$. Como $N \unlhd G$ y $N \subseteq NH$, tenemos que $N \unlhd NH$. Ahora, $$f(H) = \lbrace hN : h \in H \rbrace = \lbrace nhN :n, \in N, h \in H \rbrace = NH/N.$$ Por~\ref{eq:propHoms}($5.$), $NH/N$ es un subgrupo de $G/N$.

$\hfill \square$

\begin{theorem}[\textbf{\textit{Segundo Teorema de Isomorfía}}]
Sea $N \unlhd G$ y sea $H \leq G$. Entonces $H \cap N \unlhd H$ y $$H/H\cap N \cong NH/N.$$

\end{theorem}
\emph{Demostración: }Consideremos el siguiente homomorfismo de grupos: $$\begin{array}{rccl}
f\colon &G&\longrightarrow &G/N \\
&x& \longmapsto &xN
\end{array}
$$
y sea $g = \left.f \right|_H \colon H \longrightarrow G/N$ la restricción a $H$. Por el resultado anterior tenemos que $g(H) = f(H) = NH/N$. Notar que, como $N \unlhd G$ y $H \leq G$, $NH$ es grupo. El núcleo de $g$ es:
$$Ker g = \lbrace x \in H :xN = N \rbrace = N \cap H.$$ El resultado se sigue de aplicar el \textit{Primer Teorema de Isomorfía}.

$\hfill \square$

\begin{theorem}[\textbf{\textit{Tercer Teorema de Isomorfía}}]
Sea $G$ un grupo. Sean $N,M \unlhd G$ y $N \subseteq M$. Entonces $$G/M \cong (G/N)/(M/N).$$
\end{theorem}
\emph{Demostración: }Consideremos la aplicación suprayectiva $$\begin{array}{rccl}
f \colon &G/N&\longrightarrow &G/M\\
&gN& \longmapsto &gM
\end{array}
$$
Entonces $f$ está bien definida ya que si $gN = hN$ entonces $g^{-1}h \in N \subseteq M$ y así $gM =hM$. Es claro que es homomorfismo y el núcleo es $$Ker f = \lbrace gN \in G/N : gM = M \rbrace = \lbrace gN \in G/N : g \in M \rbrace = M/N.$$
El resultado se sigue de aplicar el \textit{Primer Teorema de Isomorfía}.

$\hfill \square$

También podemos estudiar los subgrupos de un grupo cociente $G/N$:

\begin{theorem}[\textbf{\textit{Teorema de la correspondencia}}]
Sea $N \unlhd G$. La aplicación $K \longrightarrow G/N$ es una biyección entre el conjunto $\lbrace K: N \subseteq K \leq G \rbrace$ y los subgrupos de $G/N$.
\end{theorem}
\emph{Demostración: }Sea $f \colon G \longrightarrow G/N$ el homomorfismo dado por $f(g) = gN$. Supongamos que $K$ es un subgrupo de $G$ que contiene a $N$. Por~\ref{eq:lemIsom}, $K/N = f(K)$ es un subgrupo de $G/N$. Supongamos que $J$ es otro subgrupo de $G$ que contiene a $N$ con $K/N = J/N$. Si $k \in K$, entonces $kN \in K/N = J/N$, por lo que existirá $j \in J$ tal que $kN = jN$. Así, $k \in jN \subseteq J$. Esto prueba que $K \subseteq J$. Análogamente, $J \subseteq K$ y tenemos que $K=J$. Esto prueba que la aplicación $K \longrightarrow K/N$ es inyectiva. Si $X \leq G/N$, entonces $f(f^{-1}(X)) = X$ pues $f$ es suprayectiva. Sea $K = f^{-1}(X)$. Sabemos que $K \leq G$ por~\ref{eq:propHoms}. Está claro que $N \subseteq K$ pues $f(n) = N \subseteq X$ para cada $n \in N$. Ahora, $X=f(K) = K/N$ y ya está.

$\hfill \square$

\begin{proposition}\label{eq:ej32} K es subgrupo normal de $G$ si y sólo si $K/H$ es subgrupo normal de $G/H$.\end{proposition}

\emph{Demostración: }Sea $K \unlhd G$. Dados $aH, bH$ con $(aH)(bH) \in K/H$, entonces $(ab)H \in K/H$, es decir, $ab \in K$. Como $K$ es normal, y $ab \in K$, deducimos que $ba \in K$, luego $(bH)(aH) = (ba)H \in K/H,$ y así $K/H$ es normal. Para el recíproco es análogo.

$\hfill \square$

\begin{definition}Un \textbf{automorfismo} $\alpha$ de $G$ es un isomorfismo $\alpha \colon G \longrightarrow G$. Denotaremos por $Aut(G)$ el conjunto de los automorfismos de $G$. Es claro que $Aut(G)$ es grupo con la operación composición de aplicaciones: $$\alpha \circ \beta = \alpha \beta.$$
\end{definition}

Aunque en general no es sencillo calcular el grupo de automorfismos de un grupo $G$, nosotros estudiaremos un caso más simple, para ello tenemos que:

\begin{definition} Dado $G$ un grupo y $x,g \in G$ tenemos que $$x^g=gxg^{-1}.$$ A este $x^g$ lo denominaremos \textbf{conjugado} de $x$ por $g$. Igualmente para conjuntos, que ya lo habíamos definido al principio para presentar el normalizador, si $X \subseteq G$ y $g \in G$ escribiremos $$X^g = \lbrace x^g:x \in X \rbrace.$$ También definimos la \textbf{aplicación conjugación por $g$} como $$\begin{array}{rccl}
\alpha_g \colon &G&\longrightarrow &G \\
&x& \longmapsto &x^g = gxg^{-1}
\end{array}
$$
\end{definition}

\begin{proposition}Sea $G$ un grupo y $g \in G$. Entonces:
\begin{enumerate}
\item La aplicación $\alpha_g$ es un automorfismo de $G$. En particular, si $x,y \in G$ entonces $(xy)^g = x^gy^g.$
\item Si $h \in G$, entonces $\alpha_h \alpha_g = \alpha_{hg}$. En particular, si $x \in G$ entonces $(x^g)^h = x^{hg}$.
\end{enumerate}
\end{proposition}
\emph{Demostración: }Veamos:
\begin{enumerate}
\item Tenemos que $\alpha_g \alpha_{g^{-1}} = \alpha_{g^{-1}} \alpha_g = 1$, luego $(\alpha_g)^{-1}=\alpha_{g^{-1}}$ y así $\alpha_g$ es biyectiva. Sean ahora $x,y \in G$, entonces: $$(xy)^g = g(xy)g^{-1} = gxg^{-1}gyg^{-1} = x^gy^g.$$ Luego $\alpha_g$ es un homomorfismo, y notar que $\alpha_1$ es la identidad.
\item Sea $h \in G$, entonces: $$(x^g)^h=h(gxg^{-1})h^{-1} = (hg)x(g^{-1}h^{-1}) = (hg)x(hg)^{-1} = x^{hg}.$$ Luego, $\alpha_h\alpha_g(x) =\alpha_h(\alpha_g(x)) = (x^g)^h = x^{hg} = \alpha_{hg}(x).$ Así, $\alpha_h\alpha_g = \alpha_{hg}$. 
\end{enumerate}

$\hfill \square$

Notar que cuando hacemos $(x^g)^h$ primero actúa $g$ y luego $h$, por eso $(x^g)^h = x^{hg}.$

Resulta que estos automorfismos especiales, las conjugaciones, forman un grupo y tienen características interesantes.

\begin{definition}Definimos $$Int (G) = \lbrace \alpha_g :g \in G \rbrace$$ como el conjunto de los \textbf{automorfismos internos} de $G$.
\end{definition}

\begin{proposition}Si $G$ es un grupo, entonces $Int(G) \unlhd Aut(G)$. Además, $$Int(G) \cong G/Z(G).$$
\end{proposition}
\emph{Demostración: }Sabemos que $\alpha_g\alpha_h = \alpha_{gh}$ y que $(\alpha_g)^{-1} = \alpha_{g^{-1}}$ por el resultado anterior. Así, tenemos que $Int(G) \leq Aut(G)$. Si $f \in Aut(G)$, veamos que $(\alpha_g)^f=\alpha_{f(g)}$: (recordar que $f$ es un automorfismo y $g \in G$) \begin{center}$((\alpha_g)^f)(x) = (f\alpha_g f^{-1})(x) = f(\alpha_g(f^{-1}(x))) = f(g(f^{-1}(x))g^{-1}) = f(g)xf(g^{-1}) =f(g)x(f(g))^{-1} =\alpha_{f(g)}(x) = x^{f(g)}.$\end{center}
Esto demuestra que $Int(G) \unlhd Aut(G)$. 

Ahora, si consideramos la aplicación $G \longrightarrow Int(G)$ dada por $g \longmapsto \alpha_g$, es evidentemente suprayectiva y homomorfismo. El núcleo de esta aplicación será el conjunto $\lbrace g \in G : \alpha_g = id \rbrace = \lbrace g \in G: gxg^{-1}=x\hspace{0.1cm} \forall x \in G \rbrace = \lbrace g \in G : gx = xg\hspace{0.1cm} \forall x \in G \rbrace$, y este conjunto es el centro $Z(G)$. El resultado se sigue de aplicar el \textit{Primer Teorema de Isomorfía}. 

$\hfill \square$

\begin{definition}Si consideramos un grupo $G$ y un $x\in G$, entonces $$\langle x \rangle = \lbrace x^k:k \in \mathbb{Z} \rbrace,$$ es un subgrupo de $G$ que lo denominaremos \textbf{subgrupo generado por $x$}. Es claro que si $H$ es un subgrupo de $G$ que contiene a $x$, entonces $\langle x \rangle \subseteq H$.
\end{definition}

Notar que, dado un grupo $G$ y un $x \in G$, si estamos utilizando la notación aditiva entonces: $$\langle x \rangle = \lbrace kx : k \in \mathbb{Z} \rbrace.$$

\begin{definition}Diremos que un grupo $G$ es \textbf{cíclico} si existe un $x \in G$ tal que $$\langle x \rangle = G.$$ A este elemento $x$ lo llamamos \textbf{generador} de $G$. En general, un grupo cíclico puede tener varios elementos generadores. Además, a un grupo cíclico de orden $n$ se le suele denotar $C_n$.
\end{definition}

Notar que, por ejemplo $$\mathbb{Z} = \lbrace 1n \wedge 1(-n) :n \in \mathbb{N} \rbrace= \langle 1 \rangle,$$ es un grupo cíclico infinito. O también el grupo visto al principio $$C_n = \langle \xi \rangle, \quad \xi = \cos\left(\dfrac{2\pi}{n}\right)+i\sin\left(\dfrac{2\pi}{n}\right),$$ es un grupo cíclico finito de orden $n$. Notar también que \textit{los grupos cíclicos son abelianos}, ya que dados dos elementos $y,z \in G$ cíclico entonces $yz = x^nx^m=x^{n+m}=x^{m+n} = x^mx^n=zy.$

\begin{proposition}\label{eq:subciclico} Dado un grupo $G$ cíclico y $H \leq G$. Entonces $H$ es cíclico.
\end{proposition}
\emph{Demostración: } Si $H = \lbrace 1 \rbrace$ no hay nada que probar. Sea $H \neq \lbrace 1 \rbrace$ y veamos que $H = \langle x^{k} \rangle$, con $k$ el menor entero positivo tal que $x^{k} \in H$.

Es claro, por ser el producto una operación interna en $H$, que $\langle x^{k} \rangle \in H$.

Ahora, dado $x ^{p} \in H$, comprobemos que $x^{p} \in \langle x^{k} \rangle$, es decir, que $p$ es múltiplo de $k$. Podemos suponer que $p \geq 0$ pues $p$ será múltiplo de $k$ si y sólo si lo es $-p$. Por el algoritmo de la división, al dividir $p$ entre $k$ existirán enteros no negativos $q,r$, $0 \leq r < k$, tales que $p = kq + r$. Entonces, 
\begin{center}
$x^{p} = x^{kq+r} = (x^{k})^{q}x^{r}$, por tanto $x^{r} = x^{p}(x^{k})^{-q} \in H$
\end{center}
pero por la elección de $k$ (el menor entero positivo tal que $x^{k} \in H$) necesariamente $r = 0$. Esto implica que $x^{p} = (x^{k})^{q} \in \langle x^{k} \rangle$.

$\hfill \square$

Por ejemplo, los subgrupos de $\mathbb{Z}$ son cíclicos y son de la forma $$m\mathbb{Z} = \lbrace mz : z \in \mathbb{Z} \rbrace = \langle m \rangle.$$

\begin{theorem}
Sea $G$ un grupo cíclico. Se verifica:
\begin{enumerate}
\item Si $G$ es infinito, entonces es isomorfo a $(\mathbb{Z},+)$.
\item Si $G$ es finito de orden $n$, entonces es isomorfo a $(\mathbb{Z}_{n},+)$.
\end{enumerate}
\end{theorem}
\emph{Demostración: }(Notar que hemos especificado que la operación en ambos grupos, $\mathbb{Z}$ y $\mathbb{Z}_{n}$, sea la adición, puesto que su elemento neutro será el $0$ y no el $1$)
Sea $G = \langle x \rangle$ y consideremos el homomorfismo $$\begin{array}{rccl}
f\colon &\mathbb{Z}& \longrightarrow &G\\
&k& \longmapsto &x^{k},
\end{array}
$$ que es claramente sobreyectivo ($Im f = G$). Veamos los dos casos: 

\begin{enumerate}
\item Basta comprobar que $f$ es inyectiva. Para ello supongamos por reducción al absurdo que $Ker f \neq \lbrace 0\rbrace$. Entonces, por ser $Ker f$ un subgrupo de $\mathbb{Z}$ no trivial, será de la forma $n\mathbb{Z}$ para algún $n \in \mathbb{N}$ no nulo. Ahora, el \textit{Primer Teorema de Isomorfía} nos asegura que $\mathbb{Z}_{n} = \mathbb{Z}/n\mathbb{Z} \cong G$, así $G$ tendría $n$ elementos, lo cual contradice la hipótesis de que sea infinito.
\item Si $G$ es finito de orden $n$, no puede ser $Ker f = \lbrace 0 \rbrace$, puesto que en ese caso $f$ sería  inyectiva y entonces $G$ infinito. Así pues $Ker f = m\mathbb{Z}$ para algún $m \in \mathbb{N}$ no nulo, usando de nuevo el \textit{Primer Teorema de Isomorfía} $\mathbb{Z}_{m} = \mathbb{Z}/m\mathbb{Z} \cong G$. Como $\mathbb{Z}_{m}$ y $G$ han de tener el mismo orden, $m=n$.
\end{enumerate}

$\hfill \square$

\begin{definition}Sea $G$ un grupo y $x \in G$. Si no existe ningún entero positivo $n$ tal que $x^n=1$ decimos entonces que el \textbf{orden} de $x$ es \textbf{infinito}. En caso contrario, diremos que el \textbf{orden} de $x$ es \textbf{finito} y denominaremos \textbf{orden} de $x$ al menor entero positivo $n$ tal que $x^n =1$. Lo escribiremos como $o(x) = n$ ó también $|x| = n$.
\end{definition}

Estudiemos ahora los subgrupos de un grupo cíclico finito $\langle x \rangle$ de orden $n$.

\begin{theorem}\label{eq:prelgrupcic}
Sea $G$ un grupo y $x \in G$ de orden $n$. Entonces:
\begin{enumerate}
\item Si $m$ es un entero, $x^m =1$ si y sólo si $n$ divide a $m$.
\item $\langle x \rangle = \lbrace 1, x, x^2, \ldots, x^{n-1} \rbrace$ y $|\langle x \rangle | = n$. En particular, el orden de $x$ coincide con el del subgrupo que genera.
\item Si $0\neq m$ es un entero, entonces $$o(x^m)= \dfrac{n}{mcd(n,m)}.$$ En particular, $x^m$ genera $\langle x \rangle$ si y sólo si $n$ y $m$ son coprimos.
\item Para cada divisor $d$ de $n$, $\langle x \rangle$ tiene un único subgrupo de orden $d$. Este es $\langle x^{n/d} \rangle$.
\end{enumerate}
\end{theorem}
\emph{Demostración: }Veamos:
\begin{enumerate}
\item Si $m = np$ es múltiplo de $n$, $x^{m} = x^{np} = (x^{n})^{p} = 1.$ Recíprocamente, si $m$ no es múltiplo de $n$, $m = np + r, \hspace{0.1cm} 1\leq r\leq n-1$ por el algoritmo de la división, luego $x^{m} = x^{np + r} = (x^{n})^{p}x^{r} = 1^{p}x^{r} = x^{r} \neq 1$.
\item Sea $n$ el menor natural que cumple $x^{n} = 1$. Si probamos que $$\langle x \rangle = \lbrace 1, x,x^2, \ldots, x^{n-1} \rbrace$$ y que todos los miembros de la derecha son distintos, entonces tendremos que $| \langle x\rangle | = n$.
Evidentemente el elemento de la izquierda de la igualdad contiene al de la derecha. Recíprocamente, si $y = x^{k}$, $k \in \mathbb{Z}$, dividimos por $n$ y por el algoritmo de la división sabemos que: $$k = qn + r, \hspace{0.1cm} 0\leq r \leq n-1,$$ luego $y = x^{qn+r}= (x^{n})^{q}x^{r} = 1^{q}x^{r} = x^{r}, \hspace{0.1cm}  0\leq r \leq n-1.$ Por último, si existieran $0\leq r < s \leq n-1$ tales que $x^{r} = x^{s},$ sería $x^{s-r} = x^{s}x^{-r} = x^{r}x^{-r} = x^{0} = 1, \hspace{0.1cm} s-r \leq n-1 < n,$ pero esto es absurdo porque $n$ es el menor entero positivo tal que $x^{n} = 1$.
\item Llamaremos $d = mcd(n,m)$ y veamos que $n/d$ es el menor entero positivo tal que $(x^{m})^{n/d} = 1$.

Para comenzar, $$(x^{m})^{n/d} = (x^{n})^{m/d} = 1^{m/d} = 1$$ ya que $d$ divide a $m$ por ser $d = mcd(n,m)$ y que el orden de $x$ es $n$.

Por otra parte, si $t$ es un entero positivo tal que $(x^{m})^{t} = 1$, entonces $mt$ es múltiplo de $n$, es decir que existe un $t'$ entero positivo tal que $mt = nt'$. De aquí, puesto que $d$ divide a $m$  y a $n$, $$\left( \dfrac{m}{d}\right)t =\left( \dfrac{n}{d}\right) t',$$ luego $\left( \dfrac{n}{d}\right) $ divide a $\left( \dfrac{m}{d}\right) t$. Pero como $n/d$ y $m/d$ son primos entre sí, necesariamente $(n/d)$ divide a $t$, como queríamos demostrar. ($n/d$ es el menor entero positivo tal que $(x^{m})^{n/d} = 1$).
\item Si $d$ divide a $n$, tenemos que $\langle x^{n/d} \rangle$ es un subgrupo de orden $d$ por los apartados anteriores. Supongamos ahora que $H \leq \langle x \rangle $ tiene orden $d$. Entonces $H$ es cíclico por~\ref{eq:subciclico} y deducimos que existe un entero $s$ tal que $H = \langle x^s \rangle$. Ahora, por el apartado $2.$ tenemos que $$1 = (x^s)^{o(x^s)} = (x^s)^{|H|} = (x^s)^d = x^{sd},$$ y por tanto $n$ divide a $sd$ por el apartado $1.$ Se sigue que $n/d$ divide a $s$. Por tanto, $x^s \in \langle x^{n/d} \rangle$ y así, $H = \langle x^s \rangle \subseteq \langle x^{n/d} \rangle$. Como ambos conjuntos tienen el mismo número de elementos, deben coincidir.
\end{enumerate}

$\hfill \square$

\begin{corolario}\label{eq:abSimple} Sea $G \neq \lbrace 1 \rbrace$ un grupo finito. Entonces $G$ no tiene subgrupos propios si y sólo si $|G|$ es primo. Por lo tanto, un grupo simple abeliano finito es de orden primo.
\end{corolario}
\emph{Demostración: }Si $|G|$ es primo, entonces $G$ no tiene subgrupos propios por el \textit{Teorema de Lagrange}. Supongamos ahora que $G$ no tiene subgrupos propios. Sea $1 \neq x \in G$, entonces $\langle x \rangle = G$. Si $p$ es un número primo que divide a $|G|$ entonces $G$ tiene un subgrupo $H$ de orden $p$ por~\ref{eq:prelgrupcic}. Luego $G = H$ tiene orden $p$. Por último, como en un grupo abeliano todos sus subgrupos son normales ya está.

$\hfill \square$

Ya hemos analizado $\mathbb{Z}$ pero no sus cocientes. Si $n$ es un entero, el grupo cociente $\mathbb{Z}/n\mathbb{Z}$ es un objeto matemático de interés. Ya sabemos que si $x,y \in \mathbb{Z}$ entonces $x+n\mathbb{Z} = y + n\mathbb{Z}$ si y sólo si $x-y \in n\mathbb{Z}$ si y sólo si $n$ divide a $x-y$. Esto lo escribiremos como $x \equiv y$ mod $n$.

\begin{proposition}Si $n \geq 1$, entonces $$\mathbb{Z}/n\mathbb{Z} = \lbrace n\mathbb{Z}, 1+n\mathbb{Z}, \ldots, (n-1)+n\mathbb{Z} \rbrace$$ es un grupo cíclico de orden $n$.
\end{proposition}
\emph{Demostración: }Como $\mathbb{Z}$ es abeliano, $n\mathbb{Z} \unlhd \mathbb{Z}$ y el grupo cociente $\mathbb{Z}/n\mathbb{Z}$ está bien definido. Si $x,y \in \mathbb{Z}$, entonces $x +n\mathbb{Z} = y + n\mathbb{Z}$ si y sólo si $n$ divide a $x-y$. Así, tenemos que las clases $n\mathbb{Z}, 1+n\mathbb{Z}, \ldots, (n-1) +n\mathbb{Z}$ son necesariamente distintas. Como $k(1+n\mathbb{Z}) = k + n\mathbb{Z}$, con $k \in \mathbb{Z}$ deducimos que $o(1+n\mathbb{Z})=n$. Por lo que $|\mathbb{Z}/n\mathbb{Z}| = n$.

$\hfill \square$

\begin{definition}Si $n$ es un entero positivo, llamamos \textbf{función de Euler}, y la denotamos por $\varphi$, a $$\varphi(n)=| \lbrace m \in \mathbb{Z}:1\leq m \leq n, \hspace{0.1cm} mcd(n,m)=1 \rbrace|.$$
\end{definition}

Notar que por~\ref{eq:prelgrupcic}, $\varphi(n)$ es el número de generadores en un grupo cíclico de orden $n$.

Finalmente, calculemos el grupo de automorfismos de un grupo cíclico. Será muy útil saber más adelante que este grupo es abeliano, veámoslo: si $G = \langle x \rangle $ y $\alpha, \beta \in Aut(G)$, entonces $\alpha (x) = x^d$ y $\beta(x) = x^e$ para algunos enteros $d,e$. Ahora, $\alpha\beta(x)=x^{de} = x^{ed}=\beta \alpha (x)$ y así $\alpha \beta = \because \alpha$ (esto es así porque todos los elementos de $G$ son potencias de $x$). Ahora examinaremos exactamente cómo es este grupo de automorfismos: 

Si $n \in \mathbb{Z}$, consideramos el grupo abeliano $\mathbb{Z}/n\mathbb{Z}$. En $\mathbb{Z}/n\mathbb{Z}$ también se pueden multiplicar elementos: si $x+n\mathbb{Z}=x'+n\mathbb{Z}$, $y +n\mathbb{Z}=y'+n\mathbb{Z}$ tenemos que $$xy-x'y' = xy-xy'+xy'-x'y'= x(y-y')+y'(x-x') \in n\mathbb{Z},$$ luego es divisible por $n$. Luego $xy + n\mathbb{Z} = x'y' +n\mathbb{Z}$ y la multiplicación $$(x+n\mathbb{Z})(y+n\mathbb{Z})=xy+n\mathbb{Z},$$ está bien definida. Esta multiplicación es asociativa, por serlo la de $\mathbb{Z}$, y tiene elemento neutro $1 + n\mathbb{Z}$. Llamaremos \textbf{$\mathcal{U}_n$} al conjunto de los elementos de $\mathbb{Z}/n\mathbb{Z}$ para los que existe un inverso respecto a la multiplicación.

\begin{proposition}Sea $n \geq 1$ y sea $0 \neq u \in \mathbb{Z}$, entonces $u + n\mathbb{Z}$ es invertible en $\mathbb{Z}/n\mathbb{Z}$ para la multiplicación si y sólo si $mcd(u,n)=1.$ En particular $|\mathcal{U}_n| = \varphi(n)$.
\end{proposition}
\emph{Demostración: }Se tiene que $u + n\mathbb{Z}$ es invertible en $\mathbb{Z}/n\mathbb{Z}$ si y sólo si existe $v \in \mathbb{Z}$ tal que $(u +n\mathbb{Z})(v+n\mathbb{Z})=1+n\mathbb{Z}$. Por lo que $u +n\mathbb{Z}$ si y sólo si existe $v \in \mathbb{Z}$ tal que $uv-1$ es divisible por $n$. Si esto ocurre, entonces $uv-1 = kn$ para cierto $k$. Ahora, si $d$ divide a $u$ y a $n$, entonces $d$ divide a $uv-kn = 1$, por lo que $mcd(u,n)=1$. Recíprocamente, supongamos que $mcd(u,n)=1$. Por la identidad de Bézout sabemos que existen $a,b \in \mathbb{Z}$ tales que $au+bn = 1$. Luego, $au-1$ es divisible por $n$ y así $u+n\mathbb{Z}$ tiene inverso.

$\hfill \square$

Así, es claro que $$\mathcal{U}_n = \lbrace u \in \mathbb{Z}/n\mathbb{Z}:mcd(u,n)=1 \rbrace.$$

\begin{proposition}Si $C_n$ es un grupo cíclico de orden $n$, entonces $Aut(C_n) \cong \mathcal{U}_n$. En particular, $Aut(C_n)$ es abeliano.
\end{proposition}
\emph{Demostración: }Sea $C_n = \langle x \rangle$, con $o(x)=n$. Si $n = 1$ el resultado está claro. Sea $n \geq 2$. Sea $d$ un entero cualquiera y definimos $$\begin{array}{rccl}
f_d \colon &C_n&\longrightarrow &C_n \\
&x^s& \longmapsto &x^{ds}
\end{array}
$$
con $s \in \mathbb{Z}$. Esta aplicación está bien definida, ya que si $x^s = x^t$, entonces $x^{ds}= (x^s)^d=(x^t)^d= x^{dt}$. Observamos que $$f_d(x^sx^r)=f_d(x^{s+r})=x^{d(s+r)} = x^{ds}x^{dr} = f_d(x^s)f_d(x^r),$$ con lo que $f_d$ es homomomorfismo de grupos. Recíprocamente, si $f \colon C_n \longrightarrow C_n$ es un homomorfismo y escribimos $f(x)=x^d$, entonces para cada entero $s$ tenemos que $f(x^s) = x^{ds}$ por~\ref{eq:propHoms} y deducimos que $f=f_d$.

Notamos también que $f_d \circ f_e = f_{ed} = f_e \circ f_d$ y que $f_e = f_d$ si y sólo si $x^d = x^e$ si y sólo si $x^{d-e}=1$ si y sólo si $n$ divide a $d-e$ si y sólo si $e+n\mathbb{Z} = d+n\mathbb{Z}.$

Ahora, $f_d( \langle x \rangle ) = \langle x^d \rangle$ por~\ref{eq:propHoms}. Si $d = 0$, entonces la aplicación $f_d$ no es biyectiva (pues $n\geq 2$). Si $d \neq 0$, tenemos que $f_d$ es biyectiva si y sólo si $f_d$ es suprayectiva si y sólo si $\langle x^d \rangle = \langle x \rangle$ si y sólo si $mcd(d,n)=1$, por~\ref{eq:prelgrupcic}.

Queda probado así que la aplicación $\mathcal{U}_n \longrightarrow Aut(C_n)$ dada por $d+n\mathbb{Z} \longmapsto f_d$ está bien definida y es un isomorfismo de grupos.

$\hfill \square$

Gracias a estos dos últimos resultados concluimos que $|Aut(C_p)| = p-1$. De hecho, este grupo es cíclico.

Finalmente, veamos el producto directo y semidirecto:

\begin{proposition}Sean $G_{1}$ y $G_{2}$ grupos. Dado el producto cartesiano $G_{1} \times G_{2}$, entonces podemos convertirlo en un grupo con la siguiente operación: $$\cdot \colon (g_{1},g_{2})(g'_{1},g'_{2})=(g_{1}g'_{1},g_{2},g'_{2}).$$
Además, dado un grupo $G$ y $N_{1},N_{2} \unlhd G$ subgrupos normales tales que $G=N_{1}N_{2}$ y $N_{1}\cap N_{2}=\lbrace 1_{G} \rbrace$. Entonces $$N_{1} \times N_{2} \cong G.$$
\end{proposition}
\emph{Demostración: }Para ver que es grupo con $\cdot$ basta con una simple comprobación. Para la segunda parte definimos la siguiente aplicación: 
$$\begin{array}{rccl}
f\colon &N_{1}\times N_{2} & \longrightarrow & G\\
&(n_{1},n_{2})& \longmapsto &n_{1}n_{2}
\end{array}
$$ 

Para ver que $f$ es homomorfismo: $$f((n_{1},n_{2})(n'_{1},n'_{2}))=f((n_{1}n'_{1},n_{2}n'_{2}))=n_{1}n'_{1}n_{2}n'_{2}.$$
$$f((n_{1},n_{2}))f((n'_{1},n'_{2}))=n_{1}n_{2}n'_{1}n'_{2}.$$
Para comprobar que son iguales bastará probar que $xy=yx$ para todo $x\in N_{1}$, $y\in N_{2}$. Sea $x^{-1}y^{-1}xy=x^{-1}(y^{-1}xy)\in N_{1}$, como también $x^{-1}y^{-1}xy=(x^{-1}y^{-1}x)y \in N_{2}$ y por hipótesis tenemos que $N_{1}\cap N_{2} = \lbrace 1_{G}\rbrace$, entonces será que $x^{-1}y^{-1}xy=1$, luego $xy=yx$. 

Ahora, como $G=N_{1}N_{2}$, $f$ es suprayectiva. $Ker f = \lbrace (n_{1},n_{2}) \in N_{1}\times N_{2}:n_{1}n_{2}=1 \rbrace$. Si $n_{1}n_{2}=1$, entonces $n_{2}=n_{1}^{-1}\in N_{1}\cap N_{2}=\lbrace 1_{G}\rbrace$. Así, $n_{1}=n_{2}=1_{G}$ y $Ker f=\lbrace 1_{G} \rbrace$ y $f$ es inyectiva. El resultado se sigue del \textit{Primer Teorema de Isomorfía}.

$\hfill \square$

\begin{definition}El producto cartesiano en el que hemos descompuesto $G$ antes, $N_{1}\times N_{2}$ con $N_{1}, N_{2}\unlhd G$ tales que con $G=N_{1}N_{2}$ y $N_{1}\cap N_{2}= \lbrace 1_{G} \rbrace$, es un \textbf{producto directo}. 
\end{definition}

\begin{proposition}Sean $N$ y $H$ grupos. Sea $\varphi \colon H \longrightarrow Aut(N)$ un homomorfismo entre $H$ y el grupo de los automorfismos de $N$. En el producto cartesiano $N \times H$ podemos definir una estructura de grupo, conocida como \textbf{producto semidirecto de $H$ por $N$ vía $\varphi$} y denotada por $N\times_{\varphi} H$, de la siguiente manera:$$(n_{1},h_{1})(n_{2},h_{2}) = (n_{1}\varphi(h_{1})(n_{2}),h_{1}h_{2}),$$ donde $\varphi(h_{1})(n_{2}) = n_{2}^{h_{1}}$ normalmente, es decir, que el automorfismo en cuestión será la conjugación por un elemento de $H$.

Ahora, sea $G$ un grupo, $N \unlhd G$ y $H \leq G$. Supongamos que $G = NH$ y $N \cap H = \lbrace 1_{G}\rbrace$. Dado un $$\begin{array}{rccl}
\varphi\colon &H & \longrightarrow & Aut(N)\\
&h& \longmapsto &n \longmapsto n^{h} = hnh^{-1}.
\end{array}
$$  Entonces $$N \times_{\varphi} H \cong G.$$
\end{proposition}
\emph{Demostración: }Lo primero de todo, veamos que $\varphi$ está bien definida: como $N \unlhd G$, si $n \in N$ y $h \in H$, $hnh^{-1} \in N$. Ya sabemos que la conjugación es un automorfismo. Además $\varphi$ es homorfismo: $$\varphi(h_{1}h_{2})(n)=h_{1}h_{2}nh_{2}^{-1}h_{1}^{-1}=(\varphi(h_{1}) \circ \varphi(h_{2}))(n).$$

Ahora veamos que es grupo. Cumple con la propiedad asociativa: \begin{center}$(n_{1},h_{1})((n_{2},h_{2})(n_{3},h_{3}))=(n_{1},h_{1})(n_{2}\varphi(h_{2})(n_{3}),h_{2}h_{3})=(n_{1}\varphi(h_{1})(n_{2}\varphi(h_{2})(n_{3})),h_{1}h_{2}h_{3})=(n_{1}\varphi(h_{1})(n_{2})\varphi(h_{1}h_{2})(n_{3}),h_{1}h_{2}h_{3}).$

$((n_{1},h_{1})(n_{2},h_{2}))(n_{3},h_{3})=(n_{1}\varphi(h_{1})(n_{2}),h_{1}h_{2})(n_{3},h_{3})=(n_{1}\varphi(h_{1})(n_{2})\varphi(h_{1}h_{2})(n_{3}),h_{1}h_{2}h_{3}).$
\end{center}
Tiene elemento neutro: 
$$(n,h)(1,1)=(n\varphi(h)(1),h)=(n,h) = (1\varphi(1)(n),h)=(1,1)(n,h).$$

Cada elemento $(n,h)$ tiene un inverso $(n,h)^{-1}=(\varphi(h^{-1})(n^{-1}),h^{-1})$.

\begin{center}$(n,h)(\varphi(h^{-1})(n^{-1}),h^{-1})=(n\varphi(h)(\varphi(h^{-1})(n^{-1})),1)=(n\varphi(hh^{-1})(n^{-1}),1)=(nn^{-1},1)=(1,1).$

$(\varphi(h^{-1})(n^{-1}),h^{-1})(n,h)=(\varphi(h^{-1})(n^{-1})\varphi(h^{-1})(n),1)=(h^{-1}n^{-1}hh^{-1}nh,1)=(h^{-1}h,1)=(1,1).$\end{center}

Ahora, veamos la segunda parte. Sea $G=NH$, con $N \unlhd G$, $H\leq G$ y $N \cap H = \lbrace 1_{G} \rbrace$, y sea 
$$\begin{array}{rccl}
\varphi\colon &H & \longrightarrow & Aut(N)\\
&h& \longmapsto &n \longmapsto n^{h} = hnh^{-1}.
\end{array}
$$

Ya sabemos que $\varphi$ está bien definida y que es un homomorfismo.

Definimos ahora $$\begin{array}{rccl}
f\colon &N \times _{\varphi} H & \longrightarrow & G\\
&(n,h)& \longmapsto &nh.
\end{array}
$$
y veamos que $f$ es homomorfismo: \begin{center}$f((n_{1},h_{1})(n_{2},h_{2}))=f((n_{1}\varphi(h_{1})(n_{2}),h_{1}h_{2})=n_{1}\varphi(h_{1})(n_{2})h_{1}h_{2}=n_{1}(h_{1}n_2h_{1}^{-1})h_{1}h_{2}=n_{1}h_{1}n_{2}h_{2}=f((n_{1},h_{1}))f((n_{2},h_{2})).$\end{center}

Como $G=NH$ entonces $f$ es claramente suprayectiva. Ahora, $Ker f= \lbrace (n,h) \in N\times_{\varphi} H :nh=1 \rbrace$. Y si $nh=1$ entonces $n=h^{-1}\in N \cap H$, pero como $N \cap H = \lbrace 1_{G} \rbrace$ tenemos que $n=h=1_{G}$ y así $f$ es inyectiva y por tanto isomorfismo.

$\hfill \square$

\begin{proposition}Sea $N = C_n$ un grupo cíclico de orden $n$ y sea $H = \langle x \rangle = C_2$. Entonces definimos $$\begin{array}{rccl}
\varphi\colon &H & \longrightarrow & Aut(N)\\
&x& \longmapsto &(n \longmapsto n^{-1}),
\end{array}
$$ con $\varphi(1) = id$.
Entonces $N\times_{\varphi} H$ es un grupo de $2n$ elementos denominado \textbf{grupo diédrico} de $2n$ elementos, y lo escribiremos como $D_{2n}$.
\end{proposition}
\begin{proof}
La aplicación $n \longrightarrow n^{-1}$ es un automorfismo de $N$ de orden $2$. Entonces $\varphi(x) \circ \varphi(x) = id$, y $\varphi(x^2) = \varphi(1) = id$. Así, $\varphi$ es homomorfismo.

\end{proof}

\subsection{Acciones de grupos. Teoremas de Sylow. Resolubilidad}

Los grupos se manifiestan a través de sus acciones sobre espacios vectoriales, sobre otros grupos o, en general, sobre conjuntos. En esta sección veremos las acciones sobre conjuntos, o equivalentemente, los homomorfismos de $G$ sobre grupos simétricos.

\begin{definition}Sea $\Omega$ un conjunto no vacío y sea $G$ un grupo. Diremos que $G$ \textbf{actúa} sobre $\Omega$ si para todo $\alpha \in \Omega$ y $g \in G$ tenemos definido un único elemento $g \cdot \alpha$ de tal forma que:
\begin{enumerate}
\item $h \cdot (g \cdot \alpha)=(hg) \cdot \alpha$ $\forall \alpha \in \Omega$, $g,h \in G$.
\item $1 \cdot \alpha =\alpha$ $\forall \alpha \in \Omega$.
\end{enumerate}

En este caso, diremos que $\cdot$ define una \textbf{acción} de $G$ sobre $\Omega$.
\end{definition}

\begin{example}\label{eq:ejcorazon}Los siguientes ejemplos son acciones de grupos sobre conjuntos:
\begin{enumerate}
\item Sea $G$ un grupo y $H \leq G$. Sea $\Omega = \lbrace xH : x \in G \rbrace$. Si $g \in G$ y $\alpha \in \Omega$, definimos $g \cdot \alpha = g\alpha$, es decir: $$g \cdot(xH) = gxH, \quad \forall x,g \in G.$$ Esta es la acción de $G$ sobre el conjunto de las coclases a izquierda de $H$ en $G$.
\item Sea $G$ un grupo y $\Omega = G$. Dado un $\alpha \in \Omega, g \in G$ definimos $$g \cdot \alpha= \alpha^g=g\alpha g^{-1}.$$ Esta es la \textbf{acción de $G$ sobre $G$ por conjugación} y ya la conocemos de haberla estudiado en los capítulos anteriores.
\item Sea $\Omega = \lbrace H : H \leq G \rbrace$ el conjunto de los subgrupos de $G$. Si $H \in \Omega$, $g \in G$ definimos $$ g \cdot H = H ^g.$$ Esta es la acción de $G$ sobre los subgrupos de $G$ por conjugación.
\item Sea $\Omega$ un conjunto no vacío y sea $G \leq S_{\Omega}$. Si $g \in G$, $\alpha \in \Omega$ definimos $$g \cdot \alpha = g(\alpha).$$ Esta es la \textbf{acción natural de $G$ sobre $\Omega$}. La llamamos así porque, como veremos más adelante, siempre va a existir una para cada grupo $G$ sobre un conjunto cualquiera $\Omega$ al ser todo grupo finito $G$ isomorfo a un subgrupo del grupo de permutaciones.
\end{enumerate}
\end{example}
$\hfill \blacksquare$

Como se verá ahora, una acción de un grupo $G$ sobre un conjunto $\Omega$ no es más que un homomorfismo de grupos $G \longrightarrow S_{\Omega}$.

\begin{theorem} \label{eq:princAcci}
Sea $G$ un grupo y $\Omega$ un conjunto no vacío. Entonces: 
\begin{enumerate}
\item Supongamos que $G$ actúa sobre $\Omega$. Para cada $g \in G$ consideremos la aplicación $$\begin{array}{rccl}
\rho_g \colon &\Omega&\longrightarrow &\Omega \\
&\alpha& \longmapsto &g \cdot \alpha
\end{array}
$$
Tenemos que $\rho_g$ es biyectiva y además la aplicación 
$$\begin{array}{rccl}
\rho \colon &G&\longrightarrow &S_{\Omega} \\
&g& \longmapsto &\rho_g
\end{array}
$$ es un homomorfismo de grupos.
\item Sea $\rho \colon G \longrightarrow S_{\Omega}$ homomorfismo de grupos. Para cada $g \in G$ y $\alpha \in \Omega$ definimos $g \cdot \alpha = \rho(g)(\alpha)$. Entonces $\cdot$ define una acción de $G$ sobre $\Omega$.
\end{enumerate}
\end{theorem}
\emph{Demostración: }Veamos primero $1.$, sea $g \in G$, veamos que $\rho_g$ es inyectiva. Si $\rho_g(\alpha)=\rho_g(\beta)$, con $\alpha, \beta \in \Omega$ entonces $g \cdot \alpha = g \cdot \beta$, por lo que $g^{-1} \cdot (g\cdot \alpha) = g^{-1}  \cdot (g \cdot \beta$) y aplicando las condiciones de las acciones tenemos que $ (g^{-1}g) \cdot \alpha = (g^{-1}g) \cdot \beta \Rightarrow 1 \cdot \alpha = 1 \cdot \beta \Rightarrow \alpha = \beta$. Para la sobreyectividad consideremos $\beta \in \Omega$, entonces $ g^{-1} \cdot \beta \in \Omega$ y $\rho_g(g^{-1}\cdot \beta)= g \cdot (g^{-1} \cdot \beta )= \beta.$. Luego $\rho_g$ es biyectiva.

Veamos ahora $2.$, como $\rho (1)$ es la identidad tenemos que $1 \cdot \alpha = \alpha$, $\forall \alpha \in \Omega$. Ahora, si $g,h \in G$ y $\alpha \in \Omega$ tenemos que $$(\rho(g)\rho(h))(\alpha) = \rho(g)(\rho(h)(\alpha)) = g \cdot(h \cdot \alpha ) = (gh) \cdot \alpha = \rho_{gh}(\alpha) = \rho(gh)(\alpha).$$

$\hfill \square$

Así que, podemos definir el concepto de acción de un grupo finito $G$ sobre un conjunto también finito $\Omega$ como un homomorfismo $\rho \colon G \longrightarrow S_\Omega$ que cumple que $\rho(gh)(\alpha) = \rho(g)(\rho(h)(\alpha))$ y $\rho(1)(\alpha) = \alpha$. O dicho de otra forma, que $(gh)\cdot \alpha = g \cdot (h\cdot \alpha)$ y que $1 \cdot \alpha = \alpha$.

\begin{definition}Si un grupo $G$ actúa sobre un conjunto $\Omega$, entonces podemos definir el siguiente conjunto. $$K = \lbrace g \in G : g\cdot \alpha = \alpha \hspace{0.1cm} \forall \alpha \in \Omega \rbrace,$$ como el \textbf{núcleo} de la acción. Notar que $K = Ker(\rho) \unlhd G$. Diremos que la acción de $G$ sobre $\Omega$ es \textbf{fiel} si $K = \lbrace 1 \rbrace.$
\end{definition}

De hecho, el núcleo de la acción de $G$ sobre $G$ por conjugación es $$K = \lbrace g \in G : x^g =x \hspace{0.1cm} \forall x \in G \rbrace = \lbrace g \in G:gx=xg \hspace{0.1cm} \forall x \in G \rbrace = Z(G).$$

Veamos ahora cuál es el núcleo de la acción del primer ejemplo:

\begin{proposition}Sea $H \leq G$ y sea $K = \cap_{x \in G} H^x$. Entonces $K$ es el núcleo de la acción de $G$ sobre $\Omega = \lbrace xH :x \in G \rbrace$ por multiplicación a izquierda.
\end{proposition}
\emph{Demostración: }Sea $g \in G$, entonces $g \in Ker (\rho)$ si y sólo si $gxH = xH$ $\forall x \in G$ si y sólo si $x^{-1}gx H = H$  $\forall x \in G$ si y sólo si $x^{-1}gx \in H$ $\forall x \in G$ si y sólo si $g \in H^x$ $\forall x \in G$ si y sólo si $g \in K$.

$\hfill \square$

Todo grupo finito es subgrupo de un grupo simétrico.

\begin{theorem}[\textbf{\textit{Teorema de Cayley}}]
Sea $H \leq G$, con $[G:H] = n$. Entonces, existe $K \unlhd G$ contenido en $H$ tal que $G/K$ es isomorfo a un subgrupo de $S_n$. En particular, si $G$ tiene orden $n$, entonces $G$ es isomorfo a un subgrupo de $S_n$.
\end{theorem}
\emph{Demostración: }Sea $\Omega$ el conjunto de las clases a izquierda de $H$ en $G$. Luego, $|\Omega | = n$. Sea $K \unlhd G$ el núcleo de la acción de $G$ sobre $\Omega$ Por el resultado anterior tenemos que $K \subseteq H$. Por la primera parte de~\ref{eq:princAcci} existe un homomorfismo de grupos $G \longrightarrow S_{\Omega}$ de núcleo $K$. Por el \textit{Primer Teorema de Isomorfía}, tenemos que $G/K$ es isomorfo a un subgrupo de $S_{\Omega} = S_n$. Para lo segundo tomar simplemente $H = \lbrace 1 \rbrace$.

$\hfill \square$

Ahora veremos que una acción de $G$ puede definir una relación de equivalencia en $\Omega$. En efecto, si $\alpha, \beta \in \Omega$ escribiremos $\alpha \sim \beta $ si existe $g \in G$ tal que $g \cdot \alpha = \beta$. Es decir, $\alpha$ y $\beta$ van a estar relacionados si existe un elemento de $G$ que actuando sobre $\alpha$ dé como resultado $\beta$. Esta relación va a dar mucho de que hablar, veamos que es de equivalencia:

$$g^{-1} \cdot \beta = g^{-1} \cdot (g \cdot \alpha ) = (g^{-1}g) \cdot \alpha = \alpha, $$ luego si $\alpha \sim \beta$ entonces $\beta \sim \alpha$ y tenemos que esta relación es simétrica. Además es claro que $1 \cdot \alpha = \alpha$, luego $\alpha \sim \alpha$ y esta relación es reflexiva. Finalmente, si $g \cdot \alpha = \beta$ ($\alpha \sim \beta$) y $h \cdot \beta = \gamma$ ($\beta \sim \gamma$), con $g, h \in G$, entonces $$\gamma = h \cdot (g \cdot \alpha) = (hg) \cdot \alpha,$$ y como $hg \in G$ por ser $G$ grupo entonces $\alpha \sim \gamma$ y esta relación es transitiva.

\begin{definition}Dado un grupo $G$ actuando sobre un conjunto $\Omega$, $\alpha \in \Omega$ y considerando la relación de equivalencia $\sim$ que acabamos de ver, entonces la clase de equivalencia de $\alpha$ es $$O_{\alpha} = \lbrace g\cdot \alpha : g \in G \rbrace.$$ A este conjunto lo llamamos \textbf{órbita} de $\alpha$ por $G$ ó \textbf{$G$-órbita} de $\alpha$. Notar que su \textbf{longitud} es $|O_{\alpha}|$.
\end{definition}

Notar que al tratarse las órbitas de clases de equivalencia para la relación de equivalencia $\sim$ entre elementos de $\Omega$ antes vista, entonces van a formar una partición de $\Omega.$ Es decir, que su unión disjunta forman la totalidad de $\Omega$. Así, si $R$ es un conjunto de representantes de estas clases de equivalencia (órbitas de la acción), tenemos que $$\Omega = \bigsqcup_{x\in R} O_x.$$ Como la unión es disjunta y $\Omega$ finito tenemos que $$|\Omega | = \sum_{x\in R} |O_x|.$$ A estas dos fórmulas equivalentes se las conoce como \textbf{\textit{fórmula de las órbitas}}. (Se ha empleado $|\cdot|$ para hablar de cardinal de un conjunto, lo cuál podría considerarse abuso de notación).

\begin{definition}Dado un grupo $G$ actuando sobre un conjunto $\Omega$, si $\alpha \in \Omega$ entonces definimos el \textbf{estabilizador} de $\alpha$ en $G$ como $$G_\alpha = \lbrace g \in G : g\cdot \alpha = \alpha \rbrace.$$
\end{definition}

Qué es el \textit{estabilizador} con respecto a $G$ y una propiedad fundamental del mismo nos lo dice el siguiente resultado:

\begin{proposition}\label{eq:coest}
Sea $G \longrightarrow S_\Omega$ una acción de un grupo $G$ sobre un conjunto $\Omega$, y $\alpha \in \Omega$. Entonces:

\begin{enumerate}
\item $G_{\alpha}$ es un subgrupo de $G$.
\item Si $g \in G$, entonces $(G_{\alpha})^{g} = gG_{\alpha}g^{-1} = G_{g \cdot \alpha}$. Es decir, \textbf{el conjugado de un estabilizador es un estabilizador}.
\end{enumerate}
\end{proposition}
\emph{Demostración: }Veamos:
\begin{enumerate}
\item Primero de todo, $1_{G} \in G_{\alpha}$ por la segunda condición a cumplir de las acciones de grupos, así que $G_{\alpha}$ es no vacío. Ahora, sean $g,h \in G_{\alpha}$. Está claro que $g \cdot \alpha = h \cdot \alpha = \alpha$, además $$h^{-1} \cdot \alpha = h^{-1}\cdot(h \cdot \alpha) = (h^{-1}h)\cdot \alpha = 1_{G} \alpha = \alpha.$$ Por lo que $(gh^{-1})\cdot \alpha= g\cdot(h^{-1}\cdot \alpha) = g\cdot \alpha= \alpha,$ luego $gh^{-1} \in G_{\alpha}.$
\item Sea $h \in G_{\alpha}$. Como  $$(ghg^{-1})\cdot(g\cdot \alpha) = g\cdot(h1_{G}\cdot \alpha)= g\cdot(h\cdot \alpha) = g\cdot \alpha,$$ tenemos que $ghg^{-1} \in G_{g\cdot \alpha}$, así que $(G_{\alpha})^{g} \subseteq G_{g\cdot \alpha}$.

Recíprocamente, si $h \in G_{g \cdot \alpha}$, entonces $h\cdot(g \cdot \alpha) = g \cdot \alpha$, y así $(g^{-1}hg)\cdot \alpha = \alpha$, y $(g^{-1}hg) \in G_{\alpha}$, luego $h \in (G_{\alpha})^{g}.$
\end{enumerate}

$\hfill \square$

De aquí es importante quedarse con que \textbf{\textit{si dos elementos de un conjunto cuaquiera $\Omega$ están en la misma órbita entonces sus estabilizadores son conjugados.}}

\begin{theorem}[\textbf{\textit{Teorema de la órbita-estabilizadora}}] \label{eq:torest}
Sea $G$ un grupo que actúa sobre un conjunto $\Omega$ y sea $\alpha \in \Omega$. Entonces $G_\alpha \leq G$ y $$|O_\alpha| = [G:G_\alpha].$$
\end{theorem}
\emph{Demostración: }Lo primero ya lo sabemos del resultado anterior.

Para lo segundo, busquemos una aplicación biyectiva $f \colon \lbrace gG_\alpha : g \in G \rbrace \longrightarrow O_\alpha$. Definimos $f(gG_\alpha) = g\cdot \alpha$. Ahora, $gG_\alpha = h G_\alpha$ si y sólo si $g^{-1}h \in G_\alpha$ si y sólo si $(g^{-1}h) \cdot \alpha = \alpha$ si y sólo si $g \cdot ((g^{-1}h) \cdot \alpha) = g \cdot \alpha$ si y sólo si $h \cdot \alpha = g \cdot \alpha$, luego $f$ está bien definida y si lo leemos al revés podremos comprobar que también es inyectiva. Al ser $f$ claramente suprayectiva, ya está.

$\hfill \square$

Cuando un grupo $G$ actúa sobre un conjunto $\Omega$, de entre todos los elementos de $\Omega$ destacamos aquellos que son fijados por todos los elementos de $G$:

\begin{definition}Dado un grupo $G$ actuando sobre un conjunto $\Omega$, y dado un $\alpha \in \Omega$ decimos que $\alpha$ es un \textbf{punto fijo} de $\Omega$ si $g \cdot \alpha = \alpha$ $\forall g \in G$, es decir aquellos $\alpha \in \Omega$ tales que $O_\alpha = \lbrace \alpha \rbrace$. Igualmente escribimos $$\Omega_0 = \lbrace \alpha \in \Omega : |O_\alpha | = 1. \rbrace$$ para referirnos al conjunto de los puntos fijos de $\Omega$.
\end{definition}

\begin{proposition}Sea un grupo $G$ actuando sobre un conjunto $\Omega$. Si $g \in G$, definimos $Fi(g) = \lbrace i \in \Omega: g \cdot i = i \rbrace$. Entonces, el número de órbitas de $\Omega$ bajo la acción de $G$ es $$\dfrac{1}{|G|} \sum_{g \in G} |Fi(g)|.$$
\end{proposition}
\emph{Demostración: }Hallaremos $|\lbrace (g,i) \in G \times \Omega : g \cdot i = i\rbrace |$. Contamos sus elementos de dos formas y tenemos que $$\sum_{g\in G} |Fi(g)| = \sum_{i\in \Omega}|G_i|.$$ Además, por~\ref{eq:coest} si dos elementos de $\Omega$ pertenecen a la misma órbita entonces sus estabilizadores son conjugados, luego tienen el mismo orden. Sean $O_{i_1}, \ldots, O_{i_r}$ las $r$ órbitas, entonces, teniendo en cuenta el \textit{Teorema de la órbita estabilizadora}, $$\sum_{i\in \Omega} |G_i| = \sum_{k=1}^r[G:G_{i_k}]|G_{i_k}| = \sum_{k=1}^r|G| = r|G|\Rightarrow r|G| = \sum_{g\in G} |Fi(g)|,$$ donde $[G:G_{i_k}]$ es el número de elementos de la órbita de $i_k$ y $|G_{i_k}|$ es el número de elementos $g\in G$ tales que $g\cdot i_k = i_k$ (además está claro que el cardinal del conjunto que hemos escrito al principio es la suma de los $[G:G_{i_k}]|G_{i_k}|$ para cada $k=1,\ldots, r$, aquí cada $i_k$ es un elemento de $\Omega$). Y de aquí, $$r = \dfrac{1}{|G|}\sum_{g\in G} |Fi(g)|.$$

$\hfill \square$

\begin{definition}Sea $p$ un número primo. Un grupo $G$ es un \textbf{$p$-grupo finito} si $G$ es finito y $|G|$ es una potencia de $p$.
\end{definition}

\begin{theorem}\label{eq:ecClasesp}
Sea $G$ un grupo actuando sobre un conjunto finito $\Omega$. Escogemos $\alpha_1, \ldots, \alpha_s$ representantes de las órbitas de longitud mayor que 1. Entonces $$|\Omega| = |\Omega_0| + \sum_{j=1}^s |O_{\alpha_j}|.$$ En particular, si $G$ es un $p$-grupo finito, entonces $$|\Omega| \equiv |\Omega_0|\hspace{0.1cm} \text{mod}\hspace{0.1cm} p.$$
\end{theorem}
\emph{Demostración: }La primera parte se deduce de la fórmula de las órbitas y del teorema de la órbita estabilizadora. Sea ahora $G$ un grupo tal que $|G| = p^n$. Por~\ref{eq:torest}, tendremos que $|O_{\alpha_j}| = [G:G_{\alpha_j}] > 1$, con $j = 1, \ldots , s$. Como cada $[G:G_{\alpha_j}]$ divide a $|G| = p^n$, ya está.

$\hfill \square$

La descomposición del conjunto $\Omega$ en unión de las diferentes órbitas tiene especial interés cuando la acción es la conjugación de un grupo $G$ sobre sí mismo. En este caso consideraremos: 

\begin{definition}\label{eq:accConj} Consideremos la acción de un grupo $G$ sobre sí mismo, $\Omega = G$, $$\begin{array}{rccl}
\rho\colon &G& \longrightarrow &S_G\\
&g& \longmapsto &\alpha_{g}
\end{array}
$$
donde ya sabemos que $\alpha_{g}(x) = x^{g}=gxg^{-1}$ con $x \in G$. Notar que en este caso el conjunto sobre el que consideramos la acción es $G$, y que también la hemos presentado antes, al comienzo del capítulo concretamente, como la \textbf{acción conjugación}.

Como $\alpha_{g} \in Aut(G)$ tenemos que en particular es biyectiva. Además es claro que $\alpha_{gh}=\alpha_{g}\alpha_{h}$, luego $\rho$ es homomorfismo.

El núcleo de $\rho$ es $Ker \hspace{0.1cm} \rho = \lbrace g \in G: \alpha_{g} = id \rbrace = \lbrace g \in G: gxg^{-1} = x \hspace{0.15cm} \forall x \in G \rbrace =  \lbrace g \in G: gx = xg \hspace{0.1cm} \forall x \in G \rbrace$ y es el \textbf{centro de $G$}, que se escribe \textbf{$Z(G)$}.

El estabilizador de un $x \in G$, $G_{x}= \lbrace g \in G: gxg^{-1} = x \rbrace = \lbrace g \in G: gx=xg \rbrace$ también se presentó en el primer capítulo y lo denominamos \textbf{centralizador de $x$ en $G$} y se escribe como \textbf{$C_{G}(x)$}. Además, como $G_{x} \leq G$ entonces también $C_{G}(x) \leq G$.

Por último, si $x \in G$, su órbita $O_{x}$ será $O_{x} = \lbrace gxg^{-1}:g \in G \rbrace$. La denominaremos \textbf{clase de conjugación de $x$ en $G$}. Y, siguiendo el teorema de la órbita estabilizadora vemos que tiene $$[G:C_{G}(x)] = \dfrac{|G|}{|C_{G}(x)|}$$ elementos. La denotaremos por $Cl_{G}(x)$, es decir, tendremos: $$Cl_{G}(x) = \lbrace gxg^{-1} : g \in G \rbrace$$ $$|Cl_{G}(x)| = [G :C_G(x)] = \dfrac{|G|}{|C_G(x)|}.$$
\end{definition}

Notar que $|Cl_G(x) | = 1$ si y sólo si $gx = xg$ $\forall g \in G$, es decir, si y sólo si $x \in Z(G)$. Luego, en este caso $\Omega_0 = Z(G).$

\begin{theorem}[\textit{\textbf{Ecuación de las clases de conjugación de un grupo}}] \label{eq:ecClases}
Sea $G$ un grupo finito. Sean $K_{1}, \ldots, K_{s}$ las clases de conjugación de $G$ de longitud mayor que $1$. Entonces $$|G| = |Z(G)| + \sum_{j=1}^{s} |K_{j}|.$$ Esta fórmula recibe el nombre de \textbf{ecuación de clases de conjugación de un grupo finito}.
\end{theorem} 
\emph{Demostración: } Se sigue inmediatamente a partir de lo discutido anteriormente (en este caso $\Omega_0 = Z(G)$) y del teorema~\ref{eq:ecClasesp}. Notar que, por el teorema de la órbita estabilizadora, $|K_{j}| = |O_{\alpha_{j}}| = [G:G_{\alpha_{j}}] = [G:C_{G}(\alpha_{j})]$ para $j=1, \ldots, s$, con los $\alpha_{j}$ representantes de las clases de conjugación (órbitas) de longitud mayor que $1$.   ($G = C_{G}(x) \Longleftrightarrow x \in Z(G)$, entonces $\left[ G:C_{G}(x) \right] > 1$ si y sólo si $x \notin Z(G)$.)

$\hfill \square$

\begin{corolario}Sea $G$ un $p$-grupo finito simple. Entonces $|G| = p$.
\end{corolario}
\emph{Demostración: }Si $G$ es simple entonces $Z(G) = G$, ya que sabemos por el resultado anterior que $Z(G) \neq \lbrace 1 \rbrace$, y como el centro es un subgrupo normal y $G$ es simple entonces necesariamente $Z(G) = G$. Luego $G$ es abeliano y el resultado se sigue de~\ref{eq:abSimple}.

$\hfill \square$

Notar que $N_G(H)$ es el estabilizador de $H$ en la acción de $G$ sobre sus subgrupos por conjugación. Es claro que $H \unlhd N_G(H)$ y que $H \unlhd G$ si y sólo si $N_G(H) =G$. Por el \textit{Teorema de la órbita estabilizadora} tenemos que el número de subgrupos distintos de la forma $H^g$, con $g \in G$, es $[G:N_G(H)]$.

\begin{proposition}Sea $G$ un grupo finito y $H \leq G$ con $|H| = p^a$ para cierto primo $p$. Entonces $$[G:H] \equiv [N_G(H):H] \hspace{0.1cm}\text{mod} \hspace{0.1cm} p.$$
\end{proposition}
\emph{Demostración: }Consideremos el conjunto $\Omega = \lbrace xH : x \in G \rbrace$. Tenemos que $H$ actúa sobre $\Omega$ por multiplicación a izquierda. Calculamos el número de puntos fijos, es decir $\Omega_0$. Se tiene que $hxH = xH$ $\forall h \in H$ si y sólo si $x^{-1}hx \in H$ $\forall h \in H$ si y sólo si $H^{x^{-1}} \subseteq H$ si y sólo si $H \subseteq H ^x$ si y sólo si $H = H^x$ (ya que $|H| = |H^x|$) si y sólo si $x\in N_G(H)$. El resultado se sigue de la segunda parte de~\ref{eq:ecClasesp}.

$\hfill \square$

\begin{corolario}\label{eq:cor411} Sea $G$ un $p$-grupo finito. Si $H \leq G$ entonces $H \leq N_G(H)$.
\end{corolario}
\emph{Demostración: }Como $p^a \not\equiv 1 \hspace{0.1cm}\text{mod} \hspace{0.1cm} p$ si $a \geq 1$, aplicando el resultado anterior ya está.

$\hfill \square$

Es decir, en los $p$-grupos los normalizadores crecen.

\begin{corolario}\label{eq:cor412} Sea $G$ un $p$-grupo finito. Si $p^a$ divide a $|G|$, entonces $G$ tiene un subgrupo de orden $p^a$.
\end{corolario}
\emph{Demostración: }Lo haremos por inducción sobre el orden de $G$. Podemos suponer que $G \neq \lbrace 1 \rbrace$ y que $p^a < |G|$. Entre los subgrupos propios de $G$ elegimos el de mayor orden posible, $H$. Por el corolario anterior sabemos que $H \unlhd G$. Por el \textit{Teorema de correspondencia} tenemos que $G/H$ no tiene subgrupos propios. Por~\ref{eq:abSimple}, se tiene que $[G:H] = p$. Ahora, $p^a$ divide a $|H|$ y el resultado se sigue por inducción.

$\hfill \square$

Finalmente, hablaremos de las acciones transitivas.

\begin{definition}Diremos que una acción de un grupo $G$ sobre un conjunto $\Omega$ es \textbf{transitiva} si sólo hay una órbita, es decir, si $\Omega$ es una $G$-órbita. Dicho de otra manera: la acción de $G$ sobre $\Omega$ es transitiva si dados $\alpha, \beta \in \Omega$ existe un $g \in G$ tal que $g \cdot \alpha = \beta$.
\end{definition}

Empezaremos con un resultado que es consecuencia de lo visto ahora y que básicamente nos dice que si tenemos un grupo de orden primo o múltiplo entonces contendrá un elemento de orden ese primo. Es el conocido como \textit{Teorema de Cauchy}, que lo probaremos primero para grupos abelianos y más tarde generalizaremos a todos.

\begin{theorem}[\textit{\textbf{Teorema de Cauchy para grupos abelianos.}}]
Sea $G$ un grupo abeliano finito, y $p$ un número primo que divide al orden de $G$. Entonces existirá un $x \in G$ tal que $o(x) = p$.
\end{theorem}
\emph{Demostración: } Lo haremos por inducción sobre $|G|$. Sea $H$ un subgrupo propio de $G$ de orden lo mayor posible. Si $p \mid |H|$, por hipótesis de inducción existirá un $x \in H \subset G$ tal que $o(x) = p$. Por lo tanto podemos suponer que $ p \nmid |H|$. Como $p \mid |G| = |G/H| |H|$ por el \textit{Teorema de Lagrange} (además podemos hacer el cociente porque al ser $G$ abeliano todo subgrupo es normal), y esto quiere decir que $p \mid |G/H|$. Además, como $H$ es de orden lo mayor posible entre los subgrupos de $G$, por el \textit{Teorema de la correspondencia} $G/H$ no tiene subgrupos propios no triviales y por tanto es simple.

Así, ahora partimos de que $G/H$ es simple y abeliano y que  $p \mid |G/H|$. Como los grupos simples abelianos son cíclicos de orden primo tenemos que $$G/H \cong C_{p}.$$ Sea $H \neq xH \in G/H$. Entonces es claro que $o(xH) = p$. Tenemos un elemento de orden $p$ dentro del cociente y queremos encontrar un elemento de orden $p$ dentro del grupo. Para ello construiremos el homomorfismo sobreyectivo que ya conocemos $$\begin{array}{rccl}
\pi \colon &G & \longrightarrow & G/H\\
&x & \longmapsto &xH
\end{array}
$$ y de las propiedades de los homomorfismos sabemos que $p = o(xH) = o(\pi(x)) \mid o(x)$. Esto quiere decir que $p \mid o(x)$ y así $x^{o(x)/p} \in G$ de orden $p$, ese es el elemento que buscábamos.

$\hfill \square$

Ahora, el resultado general:

\begin{theorem}[\textbf{\textit{Teorema de Cauchy.}}]
Sea $G$ un grupo finito y $p$ un número primo que divide al orden de $G$. Entonces existirá un $x \in G$ tal que $o(x) = p$.
\end{theorem}
\emph{Demostración: } Lo haremos nuevamente por inducción sobre $|G|$. Si existe un subgrupo propio $H$ de $G$ tal que $p \mid |H|$ ya hemos terminado, puesto que existirá un $x \in H \subset G$ tal que $o(x) = p$. Así, podemos suponer que $p \nmid |H|$ para todo $H$ subgrupo propio de $G$. Ahora, de la ecuación de clases: $$|G| = |Z(G)| + \sum_{i = 1}^{t}  \left[ G:C_{G}(x_{i}) \right]$$ sabemos que como $\left[ G:C_{G}(x_{i}) \right]>1$ entonces $p \nmid |C_{G}(x_{i})|$ $\forall i$, pero a la vez también $p \mid |G|$, esto quiere decir que $p \mid  \left[ G:C_{G}(x_{i}) \right]$ $\forall i$.

Como $p \mid |G|$ y $p \mid  \left[ G:C_{G}(x_{i}) \right]$ entonces necesariamente $p \mid |Z(G)|$, pero como $p$ no divide al cardinal de ningún subgrupo propio tenemos que $Z(G) = G$ y así $G$ es abeliano. Por el resultado para grupos abelianos tenemos éste.

$\hfill \square$

De aquí podemos sacar la siguiente conclusión interesante: \textbf{\textit{dado un grupo finito $G$ y $p$ un número primo, si $p$ no divide al orden de ningún subgrupo propio de $G$ entonces éste será abeliano.}}

Pasemos ya con las definiciones que emplearemos y con las que trabajaremos a partir de ahora:

\begin{definition} Sea $G$ un grupo finito, y $p$ un número primo que divide al orden de $G$. Por tanto $|G| = p^{n}m$, con $m$ y $n$ enteros positivos tales que $p$ no divide a $m$, es decir, $mcd(p,m)=1$. Notar que $n\neq0$. Sea $H$ subgrupo de $G$. Entonces:
\begin{enumerate}
\item Diremos que $H$ es un \textbf{$p$-subgrupo} de $G$ si el orden de $H$ es potencia de $p$, es decir, $|H| = p^{r}$ con $r \geq 0.$
\item Diremos que $H$ es un \textbf{$p$-subgrupo de Sylow} de $G$ si $H$ es un $p$-subgrupo de $G$ y $\left[ G:H \right]$ no es múltiplo de $p$, es decir, $|H| = p^{n}$ (la máxima potencia de $p$ que divide al orden de $G$). Al conjunto de todos los $p$-subgrupos de Sylow de $G$ los denotaremos por $$Syl_{p}(G) = \lbrace H \leq G : |H| = p^{n} \rbrace.$$
\end{enumerate}
\end{definition}

El objetivo fundamental de esta sección es demostrar que los subgrupos de Sylow siempre existen ($Syl_{p}(G) \neq \lbrace \emptyset \rbrace$, $\forall p$) y que son conjugados entre sí. 

\begin{theorem}[\textit{\textbf{Primer Teorema de Sylow}}]
Sea $G$ un grupo finito y $p$ un número primo, entonces $G$ tiene un $p$-subgrupo de Sylow.
\end{theorem}
\emph{Demostración: }Lo haremos por inducción sobre el orden de $G$. Si $|G| = 1$, entonces es evidente. Supongamos ahora que todos los grupos de orden menor que $|G|$ tienen $p$-subgrupos de Sylow y veamos que $G$ también los tiene.
Si $p \nmid |G|$ entonces el subgrupo trivial es un $p$-subgrupo de Sylow de $G$. Por lo que supongamos que $p \mid |G|$, así $|G| = p^{n}m$ con $p$ no dividiendo a $m$ ($mcd(p,m)=1$). Entonces, podemos distinguir dos casos: 

Primero, que exista un subgrupo $H \leq G$ tal que $p \nmid [G:H]$. Entonces es claro que $p^{n} \mid |H|$ y por hipótesis de inducción se tiene que $H$ tiene un $p$-subgrupo de Sylow de orden $p^{n}$, que llamaremos $P$ y que también será $p$-subgrupo de Sylow de $G$ .

Segundo, que para todo subgrupo $H$ de $G$, $p \mid [G:H]$. Entonces, por la ecuación de clases~\ref{eq:ecClases} tenemos que $p \mid |Z(G)|$, y como éste es un grupo abeliano entonces tiene un elemento de orden $p$, ó equivalentemente tiene un subgrupo $H \leq Z(G)$ de orden $p$. Como todos los elementos de $H$ conmutan con todos los elementos de $G$ entonces es claro que $H^{g} = H$ para todo $g \in G$, es decir, $H \unlhd G$. Se cumple que $[G:H] = p^{n-1}m$ y tiene un subgrupo de Sylow $P/H$ que cumplirá $[P:H] = p^{n-1}$, por lo que $|P| = p^{n}$ y así $P$ es un $p$-subgrupo de Sylow de $G$.

$\hfill \square$

\begin{theorem}[\textbf{\textit{Segundo Teorema de Sylow}}]Si $G$ es un grupo finito, entonces todo $p$-subgrupo de $G$ está contenido en un $p$-subgrupo de Sylow y dos $p$-subgrupos de Sylow cualesquiera son conjugados.

\end{theorem}
\emph{Demostración: }Sea $P$ un $p$-subgrupo de Sylow de $G$ y sea $H$ un $p$-subgrupo arbitrario. Entonces $H$ actúa sobre $\Omega= G/\sim_{P}$ por multiplicación a izquierda como vimos en el primer ejemplo de~\ref{eq:ejcorazon}. Por el teorema de la órbita estabilizadora tenemos que las órbitas de $\Omega$ tienen cardinal potencia de $p$ (incluyendo $p^{0}=1$). De hecho, alguna órbita ha de tener cardinal $1$, pues de lo contrario el cardinal de $\Omega$, que es $[G:P]$, sería suma de potencias (no triviales) de $p$, así sería múltiplo de $p$.

Por lo tanto, existirá un $g \in G$ tal que la clase de conjugación $x = gP$ formará una órbita trivial, con $x$ como único elemento. Concretamente $hgP = gP$ para todo $h \in H$. En particular $hg \in gP$ y así $h \in P^{g}$ para todo $h \in H$. De aquí $H \leq P^{g}$ y así $P^{g}$ es también $p$-subgrupo de Sylow.

En caso de que $H$ sea un $p$-subgrupo de Sylow de $G$, entonces ha de darse la igualdad $H = P^{g}$, puesto que tenemos una inclusión y ambos tienen el mismo orden.

$\hfill \square$

Por lo tanto, queda claro que los $p$-subgrupos de Sylow forman una órbita en la acción de $G$ sobre el conjunto de todos sus subgrupos por conjugación. Luego, \textbf{\textit{si $P$ es un $p$-subgrupo de Sylow entonces el número total de $p$-subgrupos de Sylow es $[G: N_{G}(P)]$. Éste número es un divisor del orden de $G$ y también de $[G:P]$.}}

\begin{corolario}Sean $p$ un número primo y $G$ un grupo finito cuyo orden es $|G| = p^{n}m$, donde $m$ y $n$ son enteros positivos y $p$ no divide a $m$. Sea $H$ un $p$-subgrupo de Sylow de $G$. Entonces $H$ es subgrupo normal si y sólo si es el único $p$-subgrupo de Sylow de $G$.
\end{corolario}
\emph{Demostración: }Los $p$-subgrupos de Sylow de $G$ son, por el \textit{Segundo Teorema de Sylow}, los subgrupos de $G$ conjugados de $H$, y coinciden todos con $H$ si y sólo si éste es normal. Es, por tanto, consecuencia inmediata de la definición de subgrupo normal y del \textit{Segundo Teorema de Sylow}.

$\hfill \square$

\begin{definition}Los grupos finitos con un único $p$-Sylow para cada divisor primo $p$ de $|G|$ se llaman \textbf{grupos nilpotentes finitos}.
\end{definition}

Finalmente veremos el último de los teoremas de Sylow:

\begin{theorem}[\textit{\textbf{Tercer Teorema de Sylow}}]
El número $v_{p}$ de $p$-subgrupos de Sylow de un grupo finito cumple que $v_{p} \equiv 1$ mod $p$.
\end{theorem}
\emph{Demostración: }Sea $G$ un grupo finito y $\Omega$ el conjunto de sus $p$-subgrupos de Sylow. Sea un $P \in \Omega$ y consideremos la acción de $P$ sobre $\Omega$ por conjugación. Ya sabemos que $v_p = [G:N_G(P)]$. Es claro que $P^{g}=P$ para todo $g \in P$, luego la órbita de $P$ es trivial. Veamos que es la única. Si $Q \in \Omega$ cumple que $Q^{g} = Q$ para todo $g \in P$, entonces $P \leq N_{G}(Q)$ y así $P$ y $Q$ son $p$-subgrupos de Sylow de $N_{G}(Q)$, luego son conjugados en $N_{G}(Q)$. Así, existe un $g \in N_{G}(Q)$ tal que $P = Q^{g}= Q$.

Las órbitas que la acción de $P$ forma en $\Omega$ tienen cardinal potencia de $p$, y se ha visto que la única que tiene cardinal $1$ es la de $P$, luego $v_{p}=|\Omega| \equiv 1$ mod $p$.

$\hfill \square$

La última de las consecuencias es equivalente a decir que $\left[ G:N_{G}(P) \right] \equiv 1$ $mod$ $p$, con $P$ un $p$-subgrupo de Sylow de $G$.

Finalmente, pasaremos con la resolubilidad de grupos.

\begin{definition}Un grupo $G$ se dice \textbf{resoluble} si existen subgrupos $$1 = G_0 \unlhd G_1 \unlhd \ldots \unlhd G_{k-1} \unlhd G_{k} = G$$ tales que $G_{i+1}/G_i$ es abeliano para todo $i= 0, \ldots, k-1$. Como $G_{i+1}/G_i$ es abeliano si y sólo si $$xG_iyG_i = yG_ixG_i$$ para todo $x,y \in G_{i+1}$, concluimos que $G_{i+1}/G_i$ es abeliano si y sólo $xyx^{-1}y^{-1} \in G_i$ para todo $x,y \in G_{i+1}$.
\end{definition}

La importancia de este concepto es fundamental en álgebra abstracta, ya que a cada \textit{ecuación polinómica} de la forma $$a_{n}x^{n} + \ldots + a_{1}x + a_{0} = 0, \hspace{0.2cm} a_{0}, \ldots , a_{n} \in \mathbb{Q}$$ se le puede asociar un grupo, y que dicho grupo sea resoluble es condición necesaria y suficiente para que las soluciones de la ecuación polinómica anterior se puedan expresar mediante sumas, restas, multiplicaciones, divisiones y extracción de raíces de números racionales. A esto se le conoce como \textit{ser resoluble por radicales}, y es ésta la razón de llamar así a estos grupos, porque podríamos resumirlo en: \textit{ecuación resoluble por radicales} $\Longleftrightarrow$ \textit{grupo asociado resoluble}. Esto es lo que se desarolla y estudia en el seno de la \textit{Teoría de Galois}. Podríamos considerar los grupos y su teoría como un ¿ingrediente? más, bastante potente y uno de los pilares, pero no el único. Como acabamos de ver los polinomios también juegan un papel central, y para poder relacionarlo con todo lo visto necesitaremos entender qué son y sobre qué estructuras se definen, pero eso lo veremos en la sección de anillos.

\begin{proposition} \label{eq:reso1} Sea $G$ un grupo.
\begin{enumerate}
\item Si $H \leq G$ y $G$ es resoluble, entonces $H$ es resoluble.
\item Supongamos que $N \unlhd G$. Entonces $G$ es resoluble si y sólo si $N$ y $G/N$ son resolubles.
\end{enumerate}
\end{proposition}
\emph{Demostración: }Supongamos que $$1 = G_0 \unlhd G_1 \unlhd \ldots \unlhd G_{k-1} \unlhd G_k = G$$ son tales que $G_{i+1}/G_i$ es abeliano para todo $i = 0, \ldots, k-1$. Por tanto, $xyx^{-1}y^{-1} \in G_i$ para todos $x,y \in G_{i+1}$ y para todo $i = 0, \ldots, k -1$.

Supongamos ahora que $H \leq G$. Sea $H_i = H \cap G_i$ para $i = 0, \ldots, k$. Tenemos que $H \cap G_{i+1} \leq G_{i+1}$ y $G_i \unlhd G_{i+1}$. Por el \textit{Segundo Teorema de Isomorfía}, tenemos que $H_i = H \cap G_i \unlhd H \cap G_{i+1} = H_{i+1}$ y $$H_{i+1}G_i/G_i \cong H_{i+1}/H_{i}.$$

Este grupo es abeliano ya que es isomorfo a un subgrupo de $G_{i+1}/G_i$. Tenemos que la serie $1 = H_0 \unlhd H_1 \unlhd \ldots \unlhd H_{k-1} \unlhd H_k = H,$ es tal que $H_{i+1}/H_{i}$ es abeliano. 

Supongamos ahora que $N \unlhd G$. Como $G_i \unlhd G_{i+1}$, se tiene que $NG_i \unlhd NG_{i+1}$ por~\ref{eq:ej218}. Por tanto, $NG_i/N \unlhd NG_{i+1}/N$ por~\ref{eq:ej32}. Así, tenemos una serie $$N = NG_0/N \unlhd NG_1/N \unlhd \ldots \unlhd NG_{k-1}/N \unlhd NG_k/N = G/N.$$ Notar que $NG_{i+1}/N = \lbrace Nx : x \in G_{i+1} \rbrace$. Ahora, $$(Nx)(Ny)(Nx)^{-1}(Ny)^{-1} = Nxyx^{-1}y^{-1} \in NG_i/N, \quad \forall x,y \in G_{i+1}.$$ Esto prueba que $G/N$ es resoluble. 

Supongamos finalmente que $N$ y $G/N$ son resolubles. Entonces existen series $$1 = N_0 \unlhd N_1 \unlhd \ldots \unlhd N_k = N$$ $$N = G_0 \unlhd G_1/N \unlhd \ldots \unlhd G_n/N = G/N$$ tales que $N_{i+1}/N_i$ y $(G_{j+1}/N)/(G_j/N)$ son abelianos para $i = 0, \ldots, k-1$ y $j = 0, \ldots, n-1$. Como $G_{j+1}/G_j \cong (G_{j+1}/N)/(G_j/N)$ por el \textit{Tercer Teorema de Isomorfía} la serie $$1 = N_0 \unlhd \ldots \unlhd N_k = N = G_0 \unlhd G_1 \unlhd \ldots \unlhd G_n = G$$ prueba que $G$ es resoluble.

$\hfill \square$

Ahora podemos redefinir la caracterización de los grupos resolubles: 

\begin{theorem}
Un grupo finito $G$ es resoluble si y sólo si $G$ tiene una serie $$1 = G_0 \unlhd G_1 \unlhd \ldots \unlhd G_k =G,$$ donde $G_{i+1}/G_i$ es cíclico de orden primo, con $i= 0, \ldots, k-1$.
\end{theorem}
\emph{Demostración: }Si $G$ tiene tal serie está claro que es resoluble. Para ver el recíproco, lo probaremos por inducción sobre $|G|$. Por ser $G$ resoluble, existe $N \unlhd G$ de orden más pequeño que el orden de $G$ tal que $G/N$ es abeliano. Sea $M/N$ un subgrupo propio de $G/N$ de orden el más mayor posible. Por el \textit{Teorema de la correspondencia} y de~\ref{eq:abSimple} tenemos que $G/M$ es cíclico de orden primo. Ahora, por la primera parte de~\ref{eq:reso1}, $M$ es resoluble y aplicamos la hipótesis de inducción.

$\hfill \square$

\begin{proposition}Si $n\geq 5$, entonces $S_n$ no es resoluble.
\end{proposition}
\emph{Demostración: }Si $S_n$ es resoluble, entonces $A_n$ es resoluble aplicando la primera parte de~\ref{eq:reso1}. Por tanto, existe $N \unlhd A_n$, tal que $A_n/N$ es abeliano. Como $A_n$ es simple, tenemos que $N = 1$. Pero $A_n$ no es abeliano, contradicción

$\hfill \square$

\begin{definition}Dados dos elementos $g$ y $h$ de un grupo $G$ se llama \textbf{conmutador} de $g$ y $h$ (importante que se diga en ese orden) al elemento $$[g,h] = ghg^{-1}h^{-1} \in G.$$ Además, si $H$ y $K$ son dos subgrupos de $G$, el subgrupo generado por $$\lbrace[h,k] : h \in H, k \in K \rbrace$$ se llama \textbf{subgrupo conmutador} de $H$ y $K$ y lo notaremos por $[H,K]$. Es decir, que $$[H,K] =\lbrace hkh^{-1}k^{-1}: h\in H, k \in K \rbrace.$$

Se llama \textbf{derivado} del grupo $G$ a $G^{'} = [G,G] = \lbrace ghg^{-1}h^{-1}: g,h \in G \rbrace$ e inductivamente definiremos $G^{i+1} = (G^i)^{'}$, con $i = 1,2, \ldots, etc.$
\end{definition}

\begin{definition}Dado un $H \leq G$, diremos que $H$ es \textbf{característico} si $\alpha (H) = H$ $\forall$ $\alpha \in Aut(G)$.
\end{definition}

\begin{observation} Sea $H \leq G$. Observar que $H$ es característico en $G$ si y sólo si $\alpha (H) \subseteq H$ $\forall$ $\alpha \in Aut(G)$. Esto es así ya que si $\alpha 	\in Aut(G)$ entonces $\alpha^{-1}(H) \subseteq H$, luego $H \subseteq \alpha(H)$ y así $\alpha (H) = H$.
\end{observation}

\begin{proposition}Sea $H \leq N \leq G$. Si $H$ es característico en $N$ y $N \unlhd G$, entonces $H \unlhd G$.
\end{proposition}
\begin{proof}
Sea $g \in G$. La aplicación $$\begin{array}{rccl}
\alpha_g \colon &G& \longrightarrow &G\\
&h& \longmapsto &ghg^{-1}
\end{array}
$$ 
es un automorfismo de $G$. Como $N \unlhd G$, $$\begin{array}{rccl}
\left.\alpha_g \right|_N \colon &N& \longrightarrow &N\\
&n& \longmapsto &gng^{-1}
\end{array}
$$ es un automorfismo de $N$. Como $H$ es característico en $N$, $(\left.\alpha_g \right|_N) (H) = H$. Así, $gHg^{-1} = H$ y  $H \unlhd G$.
\end{proof}

\begin{observation}\label{eq:conmutador} Veamos algunas observaciones:
\begin{enumerate}
\item $[a,b]^{-1} = [b,a]$ ya que $[a,b]^{-1} = (a^{-1}b^{-1}ab)^{-1} = b^{-1}a^{-1}ba = [b,a]$.
\item $[a,b] = 1$ si y sólo si $ab = ba$ ya que $[a,b] = 1$ equivale a decir que $a^{-1}b^{-1}ab = 1$ y esto equivale a que $(ba)^{-1}ab = 1$, o lo que es lo mismo, que $ab = ba.$
\item Si  $f \colon G_{1} \longrightarrow G_{2}$ es un homomorfismo sobreyectivo, se cumple $$(\ast)\hspace{0.2cm} f(G_{1}^{n}) = G_{2}^{n} \hspace{0.2cm} \forall n \geq 1.$$
\emph{Demostración: } Si llamamos $G_{1}^{0} = G_{1}$ y $G_{2}^{0} = G_{2}$, se tiene $$G_{1}^{n} = [G_{1}^{n-1},G_{1}^{n-1}], \hspace{0.1cm} G_{2}^{n}= [G_{2}^{n-1},G_{2}^{n-1}] \hspace{0.2cm} \forall n \geq 1.$$
Demostraremos $(\ast)$ por inducción sobre n.

Si $n = 1$, $$f(G_{1}^{'}) = f([G_{1}, G_{1}]) = [f(G_{1}), f(G_{1})] = [G_{2}, G_{2}]= G_{2}^{'}.$$ Si $n>1$, $$f(G_{1}^{n}) = f([G_{1}^{n-1}, G_{1}^{n-1}]) = [f(G_{1}^{n-1}), f(G_{1}^{n-1})] = [G_{2}^{n-1}, G_{2}^{n-1}]= G_{2}^{n},$$ la penúltima igualdad por la hipótesis de inducción.

$\hfill \square$
\end{enumerate}
\end{observation}

\begin{proposition} \label{eq:derivad} Sea $G$ un grupo. Se comprueba que:
\begin{enumerate}
\item $G^{n}$ es subgrupo característico de $G$ para cada $n \geq 1 $.
\item $G/G^{'}$ es un grupo abeliano.
\item Sea $N$ subgrupo normal de $G$. Entonces $G/N$ es abeliano si y sólo si $G^{'} \subseteq N$.
\item Todo subgrupo de $G$ que contiene a $G^{'}$ es subgrupo normal de $G$.
\end{enumerate}
\end{proposition}
\emph{Demostración: } 

$1.$ Sea $f \colon G \longrightarrow G$ un automorfismo. Del último ejemplo de la observación anterior deducimos que $$f(G^{n}) = G^{n},$$ luego $G^{n}$ es subgrupo característico de $G$.

$2.$ De $1.$ se deduce en particular que $G^{'}$ es subgrupo característico (luego normal) de $G$. Así $G/G^{'}$ es un grupo. Además, dados $x = aG^{'}$, $y = bG^{'}$, como $[a,b] \in G^{'}$ se sigue que $G^{'} = [a,b]G^{'}$ y por ello $$xy = abG^{'} = ab[a,b]G^{'} = ab[b,a]^{-1}G^{'} = [b,a]^{-1}abG^{'}= baG^{'} = yx$$ luego $G/G^{'}$ es abeliano.

$3.$ Basta ver que para cada $g,h \in G$, $[g,h] \in N$. Como $G/N$ es abeliano, resulta que $$ghN = (gN)(hN) = (hN)(gN) = hgN \Rightarrow (gh)(hg)^{-1} \in N,$$ es decir que $[g,h] = ghg^{-1}h^{-1} \in N.$

Recíprocamente, sean $g,h \in G$. Entonces $ghg^{-1}h^{-1} \in G'\subseteq N$. Así, $(gN)(hN) = (hN)(gN)$ y $G/N$ es abeliano.

$4.$ Sea $H$ subgrupo de $G$ tal que $G^{'} \subseteq H$. Entonces $H/G^{'}$ es subgrupo del grupo abeliano $G/G^{'}$. Así, sabemos que $H$ es subgrupo normal de $G$.

$\hfill \square$

\begin{proposition}$G$ es resoluble si y sólo si $G^n = 1$ para algún $n$.
\end{proposition}
\begin{proof}
Sea $1 = G_0 \unlhd G_1 \unlhd \ldots \unlhd G_1 \unlhd \ldots G_k=G$, con $G_{i+1}/G_i$ abeliano, $i = 0, \ldots, k-1$. Entonces $G/G_{k-1}= G_k/G_{k-1}$ es abeliano. Por $3.$ de~\ref{eq:derivad}, $G' \leq G_{k-1}$. Ahora, $G'' \leq G'_{k-1}\leq G_{k-2}$. Reiterando, $G^k \leq G_0 = 1$.

Recíprocamente, sea $1 = G^n \unlhd G^{n-1} \unlhd \ldots G' \unlhd G$. Cada $G^i/G^{i+1}$ es $G^i/G^{i^{'}}$ y es abeliano por $3.$ de~\ref{eq:derivad}, con $i = 0, \ldots, n-1$.

\end{proof}

\subsection{Grupos de permutaciones}

Partimos de un conjunto finito $\Omega$. Una \textbf{\textit{permutación}} de $\Omega$ es una aplicación biyectiva $f \colon \Omega \longrightarrow \Omega$. A lo largo de esta sección estudiaremos el grupo $S_\Omega$ de permutaciones de $\Omega$ con la operación composición (producto) $g \circ f = gf$, con $g,f \in S_\Omega$. Recordemos que $$|S_\Omega| = |\Omega|!.$$

\begin{definition}Dados $\alpha_1, \ldots, \alpha_n$ $n$ elementos distintos de $\Omega$, entonces designaremos por $(\alpha_1, \ldots, \alpha_n)$ a la única permutación $\sigma \in S_\Omega$ tal que $\sigma (\alpha) = \alpha$ si $\alpha \in \Omega \setminus \lbrace \alpha_1, \ldots, \alpha_n \rbrace$, $\sigma (\alpha_1)=\alpha_2$, $\sigma (\alpha_2) = \alpha_3$, $\ldots$, $\sigma(\alpha_{n-1}) = \alpha_n$ y $\sigma(\alpha_n) = \alpha_1$. A la permutación $\sigma = (\alpha_1, \ldots, \alpha_n ) \in S_\Omega$ la denominamos \textbf{$n$-ciclo} o \textbf{ciclo de longitud $n$}.

Notar que los $1$-ciclos son la aplicación identidad. A los $2$-ciclos, dada la importancia especial que tienen y que iremos viendo, los llamaremos \textbf{trasposiciones}. Notar que si $t$ es una transposición entonces $o(t)=2$ y $t=t^{-1}$.
\end{definition}

\begin{definition}Dada una permutación $\sigma \in S_n$, diremos que $\sigma$ \textbf{mueve} un $\alpha_i \in \Omega$ si $\sigma( \alpha_i) = \alpha_j$, con $i\neq j$. Por el contrario, diremos que $\sigma$ \textbf{fija} un $\alpha_i \in \Omega$ si $\sigma (\alpha_i ) = \alpha_i$.
\end{definition}

\begin{observation}\label{eq:obsabel}
Dados enteros $2 \leq n \leq m$, podemos ver a $S_{n}$ como subgrupo de $S_{m}$. En efecto, para todo $\sigma \in S_{n}$ denotamos por $\sigma' \in S_{m}$ a la biyección de $\lbrace 1, \ldots, m \rbrace$ en sí mismo que actúa como $\sigma$ sobre los primeros $n$ enteros positivos y fija los comprendidos entre $n+1$ y $m$. Es decir, la aplicación $$\begin{array}{rccl}
&S_{n}& \longrightarrow &S_{m}\\
&\sigma& \longmapsto &\sigma'
\end{array}
$$ es un homomorfismo inyectivo de grupos y, por el \textit{Primer Teorema de Isomorfía}, $S_{n}$ es isomorfo a su imagen, que es un subgrupo de $S_{m}$.

De aquí se desprende que, dado $H = \lbrace \sigma \in S_{n} : \sigma(n) = n \rbrace \leq S_{n}$ el estabilizador de $n$ en $S_{n}$ en su acción sobre $\Omega$, si $\sigma \in H$ y definimos un $\bar{\sigma} \in S_{n-1}$ como $\bar{\sigma}(i) = \sigma(i)$ para $i=1, \ldots, n-1$, entonces la aplicación $$\begin{array}{rccl}
&H& \longrightarrow &S_{n-1}\\
&\sigma& \longmapsto &\bar{\sigma}
\end{array}
$$ 
es un isomorfismo de grupos.
\end{observation}

Del conjunto $\Omega$ realmente lo que nos interesa desde el punto de vista de las permutaciones no es la naturaleza propia del conjunto o los elementos que la forman, sino que contiene un número $n$ de elementos cualesquiera, por lo que podríamos simplemente escribir $S_n$ para referirnos al grupo de permutaciones de un conjunto finito cualquiera $\Omega$ de $n$ elementos en lugar de $S_\Omega$.

Cada elemento de $S_n$ lo escribiremos en ocasiones de una forma un tanto especial, como sigue: 
$$\sigma = \left(
\begin{matrix}
1 & 2 & \ldots & n \\
\sigma(1) & \sigma(2) & \ldots & \sigma(n)
\end{matrix}
\right).
$$

Observar también que $$(\alpha_1, \ldots, \alpha_n) = (\alpha_n, \alpha_1, \ldots, \alpha_{n-1}) = \ldots = (\alpha_2, \alpha_3, \ldots, \alpha_n, \alpha_1),$$ luego cada $n$-ciclo se puede escribir de $n$ maneras distintas.

\begin{definition}Decimos que dos ciclos $(\alpha_1, \ldots, \alpha_m)$, $(\beta_1, \ldots, \beta_n)$ son \textbf{disjuntos} si los conjuntos $\lbrace \alpha_1, \ldots, \alpha_m \rbrace$ y $\lbrace \beta_1, \ldots, \beta_n \rbrace$ son disjuntos.
\end{definition}

\begin{proposition}\label{eq:permCo} Dado $\Omega$ un conjunto. Entonces:
\begin{enumerate}
\item Sea $\sigma = (\alpha_1, \ldots, \alpha_m) \in S_\Omega$. Entonces $\sigma^i(\alpha_1) = \alpha_{i+1}$, con $1 \leq i \leq m-1$ y $\sigma^m(\alpha_1)=\alpha_1$. En particular, $o(\sigma) = m$.
\item Si $\gamma = (\beta_1, \ldots, \beta_n) \in S_\Omega$ es disjunto con $\sigma = (\alpha_1, \ldots, \alpha_m) \in S_\Omega$, entonces $\gamma \sigma = \sigma \gamma$.
\item Sea un producto de ciclos disjuntos dos a dos $$\sigma= (a_{1}, \ldots, a_{m}) \cdots (b_{1}, \ldots, b_{n}),$$ y sea $G =\langle \sigma \rangle \leq S_{n}$. Entonces $\sigma^{i}(a_{1}) = a_{i+1}$ para $1 \leq i \leq m-1$, $\sigma^{m}(a_{1})=a_{1}, \ldots, \sigma^{j}(b_{1})=b_{j+1}$ para $1 \leq j \leq n-1$ y $\sigma^{n}(b_{1})=b_{1}$. Como consecuencia, los conjuntos $\lbrace a_{1}, \ldots, a_{m} \rbrace, \ldots, \lbrace b_{1}, \ldots, b_{n}\rbrace$ son órbitas de la acción de $G$ sobre $\Omega$ y las demás órbitas tienen longitud uno.
\end{enumerate}
\end{proposition}
\emph{Demostración: }
\begin{enumerate}
\item Es inmediato a partir de la definición de ciclo. 
\item Comprobemos que $(\gamma \sigma) \cdot w = (\sigma \gamma) \cdot w$, $\forall w \in \Omega$. Si $w \neq \alpha_i$ y $w \neq \beta_j$, entonces es claro que $(\gamma \sigma) \cdot w = (\sigma \gamma) \cdot w$. Ahora, si $w \in \lbrace \alpha_1, \ldots, \alpha_m \rbrace$ entonces $\sigma \cdot w \in \lbrace \alpha_1, \ldots, \alpha_m \rbrace$, luego $\gamma \cdot w = w$, y también $\gamma \cdot (\sigma \cdot w) = \sigma \cdot w$, y así $$(\gamma \sigma) \cdot w = \gamma \cdot (\sigma \cdot w) = \sigma \cdot w = \sigma \cdot (\gamma \cdot w) = (\sigma \gamma) \cdot w.$$

Y se razonaría de forma análoga si $w \in \lbrace \beta_1, \ldots, \beta_n \rbrace$.
\item La primera parte es consecuencia directa de lo visto en los apartados anteriores. Así, $\lbrace a_{1}, \ldots, a_{m} \rbrace = \lbrace \sigma^{r}(a_{1}) : r \geq 0 \rbrace, \ldots, \lbrace b_{1}, \ldots, b_{n} \rbrace = \lbrace \sigma^{r}(b_{1}) : r \geq 0 \rbrace.$
\end{enumerate}

$\hfill \square$

\begin{proposition}\label{eq:ciclosdis} Sea $n$ un entero positivo. Entonces cada elemento de $S_{n}$ se puede escribir como composición de ciclos disjuntos dos a dos. Dicha descomposición es además única salvo en el orden de los factores. En particular, los ciclos de $S_{n}$ constituyen un sistema generador de $S_{n}$.
\end{proposition}
\emph{Demostración: } 
Sea $\sigma \in S_{n}$ y $G= \langle \sigma \rangle$. Supongamos $O$ una $G$-órbita. Si $|O| = m$ y $a \in O$ vamos a probar que $O = \lbrace a, \sigma(a), \ldots, \sigma^{m-1}(a) \rbrace$. Por el \textit{Teorema de la órbita estabilizadora} tenemos que $[G:G_{a}] = m$. Así, $G/G_{a}$ es un grupo cíclico de orden $m$ generado por $\sigma G_{a}$. Luego, para cualquier entero $n$ tenemos que $\sigma^{n}(a) = a$ si y sólo si $\sigma^{n}\in G_{a}$ si y sólo si $(\sigma G_{a})^{n} = G_{a}$ si y sólo si $m \mid n$. Esto quiere decir que los elementos $a, \sigma(a), \ldots, \sigma^{m-1}(a)$ de la $G$-órbita de $a$ son distintos y que no puede haber más.

Supongamos ahora que $\lbrace a, \sigma(a), \ldots, \sigma^{m-1}(a) \rbrace, \ldots, \lbrace b, \sigma(b), \ldots, \sigma^{n-1}(b) \rbrace$ son todas las distintas $G$-órbitas. Entonces tenemos que $$\sigma = (a, \sigma(a), \ldots, \sigma^{m-1}(a))\cdots (b, \sigma(b), \ldots, \sigma^{n-1}(b)),$$ puesto que la aplicación de la derecha actúa sobre cada elemento de $\Omega$ de la misma forma que $\sigma$.

Por último, si $\sigma = (a_{1}, \ldots, a_{m}) \cdots(b_{1}, \ldots, b_{n})$ se escribe como producto de ciclos disjuntos, entonces por el resultado inmediatamente anterior tenemos que $\sigma$ determina unívocamente los ciclos $(a_{1}, \ldots, a_{m}), \ldots, (b_{1}, \ldots, b_{n})$, quedando así probada la unicidad.

$\hfill \square$

\begin{corolario} Todo $k$-ciclo es producto de $k-1$ transposiciones. Luego, toda permutación $g\in S_{n}$ es producto de transposiciones (aunque no de forma única).
\end{corolario}
\emph{Demostración: }
Hacemos $g = (a_{1}, \ldots, a_{m})=(a_{1},a_{2}) (a_{2},a_{3}) \cdots (a_{k-1},a_{k}).$

$\hfill \square$

\begin{corolario} 
Sean $\sigma \in S_{n}$ y $\tau_{1}, \ldots, \tau_{k} \in S_{n}$ ciclos disjuntos tales que $\sigma = \tau_{1} \circ \ldots \circ \tau_{k}$. Entonces el orden de $\sigma$ como elemento de $S_{n}$ es el mínimo común múltiplo de las longitudes de los ciclos $\tau_{1}, \ldots, \tau_{k}$.
\end{corolario} 
\emph{Demostración: }Sea $h$ el mínimo común múltiplo de los números $o(\tau_i)$ para $1 \leq i \leq m$. Es decir, tenemos que $o(\tau_i)$ divide a $h$ $\forall i$ y que si $o(\tau_i)$ divide a un entero $m$ $\forall i$, entonces $h$ divide a $m$.

Como $\tau_i\tau_j = \tau_j \tau_i$ $\forall i,j$ por el punto $2$ de~\ref{eq:permCo} tenemos que $(\tau_1 \ldots \tau_k)^n= (\tau_1)^n \ldots (\tau_k)^n$ para todo entero $n$. Así, observamos que $\sigma^h = 1$ y se deduce que $o(\sigma)$ divide a $h$.

Si $o(\sigma) = r$, entonces $(\tau_1)^r\ldots (\tau_k)^r = 1$. Probaremos que $(\tau_i)^r=1$ para todo $1 \leq i \leq k$. Para ello, basta probar que $(\tau_i)^r$ fija todos los elementos de $\Omega$. Dado un $\alpha \in \Omega$, si $\alpha$ es fijado por $\tau_i$, entonces $\alpha$ es fijado por $(\tau_i)^r$. Si $\tau_i$ mueve $\alpha$, entonces $\alpha$ es fijado por $\tau_j$ para todo $j \neq i$, en particular por $(\tau_j)^r$. Por tanto $\alpha = (\tau_k)^r \ldots (\tau_1)^r \cdot \alpha = (\tau_i)^r \cdot \alpha$ y deducimos que $(\tau_i)^r$ fija $\alpha$. Concluimos que $(\tau_i)^r = 1$. Por lo tanto, $o(\tau_i)$ divide a $r$ para todo $i$ y tenemos que $h$ divide a $r = o(\sigma).$ Luego $o(\sigma) = h$.


$\hfill \square$

\begin{proposition}Sea $\sigma = (\alpha_1, \ldots, \alpha_k)$ un $k$-ciclo de $S_n$ y sea $\gamma \in S_n$. Entonces $\sigma^\gamma = (\gamma(\alpha_1), \ldots, \gamma(\alpha_k))$.
\end{proposition}
\emph{Demostración: }Sabemos que $\sigma(\alpha_i) = \alpha_{i+1}$, con $i=1, \ldots, k-1$ y $\sigma(\alpha_k)= \alpha_1$ (recordemos que la acción es $\sigma \cdot \alpha = \sigma(\alpha)$). Así, $(\gamma \sigma \gamma^{-1}) (\gamma(\alpha_i)) = \gamma(\alpha_{i+1})$, con $i=1, \ldots, k-1$ y $(\gamma \sigma \gamma^{-1}) (\gamma(\alpha_k)) = \gamma(\alpha_{1})$. Finalmente, si $\beta \in \Omega \setminus \lbrace \sigma(\alpha_1), \ldots, \sigma(\alpha_k) \rbrace$ entonces $\gamma^{-1}(\beta) \in \Omega \setminus \lbrace \alpha_1, \ldots, \alpha_k \rbrace$. Por lo que $\sigma \cdot (\gamma^{-1} (\beta)) = \gamma^{-1}(\beta)$ y así $\sigma^\gamma$ fija $\beta$. Luego $\sigma^\gamma$ y $(\gamma(\alpha_1), \ldots, \gamma(\alpha_k))$ actúan igual sobre cada elemento de $\Omega$ y así son iguales.

$\hfill \square$

\begin{definition}Si $\alpha \in \S_n$ es una permutación, su \textbf{tipo} es la sucesión en orden descendente de las longitudes de los ciclos disjuntos en los que se descompone.
\end{definition}

\begin{proposition}Dos permutaciones $\gamma, \tau \in S_{n}$ son conjugadas en $S_{n}$ si y sólo si tienen el mismo tipo.
\end{proposition}
\emph{Demostración: }
Si $\tau =(a_{1}, \ldots, a_{m})\cdots(b_{1}, \ldots, b_{n})$ es una descomposición de $\tau$ en ciclos disjuntos y $\gamma \in S_{n}$ es tal que $\sigma = \tau^\gamma$, entonces por el resultado anterior tenemos que $$\sigma = \tau^{\gamma}=(\gamma(a_{1}), \ldots, \gamma(a_{m})) \cdots (\gamma(b_{1}), \ldots, \gamma(b_{n}))$$ es una descomposición en ciclos disjuntos de $\sigma (=\tau^{\gamma})$. Por lo que dos permutaciones conjugadas tienen el mismo tipo.

Recíprocamente, supongamos que $\tau =(a_{1}, \ldots, a_{m}) \cdots(b_{1}, \ldots, b_{n})$ y también $\gamma = (a'_{1}, \ldots, a'_{m})\cdots(b'_{1}, \ldots, b'_{n})$ tienen el mismo tipo, veamos que son conjugadas (en estas expresiones se han incluido los $1$-ciclos también). Tenemos que $$\Omega = \lbrace a_{1}, \ldots, a_{m} \rbrace \cup \cdots \cup \lbrace b_{1}, \ldots, b_{n} \rbrace = \lbrace a'_{1}, \ldots, a'_{m} \rbrace \cup \cdots \cup \lbrace b'_{1}, \ldots, b'_{n} \rbrace$$
son dos particiones de $\Omega$. Por lo que existe una única $\sigma \in S_{n}$ tal que $\sigma(a_{i})=a'_{i}, \ldots, \sigma(b_{j})=b'_{j}$ para $1\leq i \leq m, \ldots, 1 \leq j \leq n$. Luego, por el resultado anterior tenemos que $\tau^{\sigma} = \gamma.$

$\hfill \square$

De este resultado tenemos una importante consecuencia, y es que dado un $\sigma \in S_{n}$, entonces \textbf{\textit{la clase de conjugación de $\sigma$}} (ver~\ref{eq:accConj}) \textbf{\textit{está formada por todas las permutaciones del mismo tipo que $\sigma$}}.

\begin{observation} Sea $k>1$, entonces el número de $k$-ciclos que mueven $k$ elementos distintos $a_{1}, \ldots, a_{k} \in \Omega$ es $(k-1)!$. Si $|\Omega| = n$, el número de $k$-ciclos de $S_{n}$ es ${n \choose k} (k-1)!$.

Esto se puede generalizar a permutaciones de determinados tipos: es decir, si queremos saber el número de permutaciones de $S_{n}$ con $b_{j}$ ciclos de longitud $j$ tendremos $$ \dfrac{n!}{1^{b_{1}}2^{b_{2}} \cdots n^{b_{n}}b_{1}!b_{2}!\cdots b_{n}!}.$$(odio la combinatoria)
\end{observation}

\begin{example}\label{eq:excentra} Sea $G = S_{5}$.
\begin{enumerate}
\item Sea $\tau = (1,2,3)$. Sabemos que $|Cl_{G}(\tau)| = 20$. Entonces $C_{G}(\tau) = \langle \tau \rangle \langle (4,5) \rangle$.

Por un lado, como $|Cl_{G}(\tau)| = 20$, entonces $|C_{G}(\tau)| = \dfrac{|G|}{20} = \dfrac{120}{20} = 6$. Por otro lado, $\langle (1,2,3) \rangle = \lbrace id, (1,2,3), (1,3,2) \rbrace,$ y $\langle (4,5)\rangle = \lbrace id, (4,5) \rbrace $ (simple comprobación). 

$\langle (1,2,3) \rangle \cap \langle (4,5) \rangle = id$ y así $|\langle (1,2,3) \rangle \langle (4,5) \rangle| = \dfrac{|\langle (1,2,3) \rangle||\langle (4,5) \rangle|}{1} = 3 \cdot 2 = 6.$ Como $(4,5)$ es disjunta con $(1,2,3)$, entonces conmutan y así $\langle (4,5) \rangle \leq C_{G}(\tau)$, y también $\langle (1,2,3) \rangle \langle (4,5) \rangle \leq C_{G}(\tau)$ y como tienen el mismo orden se da la igualdad.
\item Sea $\gamma$ un $5$-ciclo de $G$. Entonces $C_{G}(\gamma) = \langle \gamma \rangle$. 

Como $\langle \gamma \rangle$ es un grupo cíclico, luego abeliano, entonces todos sus elementos formarán parte de $C_{G}(\gamma)$, luego $\langle \gamma \rangle \leq C_{G}(\gamma)$. Y, como $|Cl_{G}(\gamma)| = 24$, entonces $|C_{G}(\gamma)| = \dfrac{|G|}{|Cl_{G}(\gamma)|} = \dfrac{120}{24} = 5 = |\langle \gamma \rangle |$, luego se tiene la igualdad. 
\item Sea $\sigma = (1,2)(3,4)$. Entonces $C_{G}(\sigma) = \langle (1,3,2,4),(1,3)(2,4)\rangle$. Además, este grupo es isomorfo a $\mathcal{D}_{8}$. 

Por un lado, sabemos que hay $15$ ciclos de tipo $[2,2]$, luego $|Cl_{G}(\sigma)|=15 = \dfrac{|G|}{|C_{G}(\sigma)|} = \dfrac{120}{|C_{G}(\sigma)|}$, por lo que $|C_{G}(\sigma)| = \dfrac{120}{15}=8.$

Por otro lado, llamemos $a = (1,3,2,4)$ y $b = (1,3)(2,4)$. Es claro que $o(a) = 4$ y $o(b)=2$ (simple comprobación). Entonces $$\langle a \rangle = \lbrace id, (1,3,2,4), (1,2)(3,4), (1,4,2,3) \rbrace,$$ y $$\langle b \rangle = \lbrace id, (1,3)(2,4) \rbrace.$$

Luego $\langle a \rangle \cap \langle b \rangle = id$, y así $|\langle a \rangle \langle b \rangle | = |\langle a \rangle| |\langle b \rangle| = 4\cdot 2 = 8$. Sólo quedaría ver que $\langle (1,3,2,4),(1,3)(2,4)\rangle \leq C_{G}(\sigma)$, pero esto se desprende del hecho de que $\sigma \in \langle a \rangle$ (que es un grupo cíclico, luego abeliano) y de que $\sigma \cdot b = b \cdot \sigma = (1,4)(2,3)$ (simple comprobación). Así, tenemos un subgrupo del mismo orden que el centralizador, luego son lo mismo.
\end{enumerate}
\end{example}

$\hfill \blacksquare$

\begin{proposition} Sea $n \geq 3$. Entonces $Z(S_{n}) =1$.
\end{proposition}
\emph{Demostración: }
Sea $1 \neq \sigma \in Z(S_{n})$. Entonces va a existir un $a \in \Omega$ tal que $\sigma (a)= b \neq a$, con $b \in \Omega$. Sea ahora $c \in \Omega \setminus \lbrace a,b \rbrace$ y sea $\tau =(b,c)$. Entonces $\tau\sigma \tau^{-1} (a)= \tau \sigma (a) =\tau (b) = c \neq b$ $(=\sigma(a))$. Luego, $\sigma^{\tau} \neq \sigma$, lo cual es absurdo puesto que $\sigma \in Z(S_{n})$.

$\hfill \square$

Ahora, estudiaremos el conocido como \textit{grupo alternado}.

\begin{definition}Una permutación se dice \textbf{par}, o de signatura $1$, si se puede escribir como producto de un número par de transposiciones. En caso contrario diremos que es \textbf{impar}, o de signatura $-1$.
\end{definition}

\begin{definition}[\textbf{\textit{El grupo alternado}}] La aplicación signatura $$\begin{array}{rccl}
sig \colon &S_{n}& \longrightarrow &\lbrace -1, 1\rbrace\\
&\sigma& \longmapsto &sig(\sigma)
\end{array}
$$
es un homomorfismo de grupos. Su núcleo, que está formado por las permutaciones pares, es un subgrupo de índice $2$, el \textbf{grupo alternado $\mathcal{A}_{n}$}. Además, $$S_{n}/\mathcal{A}_{n} \cong C_{2}.$$
\end{definition} 
\begin{proof}
Veamos que la signatura de $\alpha \beta$ es el producto de la de $\alpha$ por la de $\beta$. Para ello, descompongamos $\alpha$ y $\beta$ en producto de transposiciones: $$\alpha = \tau_1 \ldots \tau_r$$ $$\beta = \gamma_1 \ldots \gamma_s,$$ luego $\alpha \beta = \tau_1 \ldots \tau_r \gamma_1 \ldots \gamma_s$. La signatura de $\alpha$ es $(-1)^r$ y la de $\beta$ es $(-1)^s$, luego $sig(\alpha \beta)$ es $(-1)^{r+s} = (-1)^r (-1)^s = sig(\alpha)sig(\beta).$

\end{proof}

Además, es claro que $|\mathcal{A}_n| = n!/2$.

\begin{proposition}\label{eq:cicimpar} Sea $\sigma = (a_{1}, \ldots, a_{k}) \in S_{n}$. Las transposiciones $\tau_{j} = (a_{j-1}, a_{j})$, con $2\leq j \leq k$, cumplen $\sigma = \tau_{k} \cdot \tau_{k-1} \ldots \tau_{2}.$ En particular $\sigma \in \mathcal{A}_{n}$ si y sólo si $k$ es impar.
\end{proposition}
\emph{Demostración: }La igualdad $\sigma = \tau_{k} \cdot \tau_{k-1} \ldots \tau_{2}$ se comprueba directamente. Además, como cada $\varepsilon(\tau_{i}) = -1$ resulta que $$\varepsilon(\sigma) = \prod_{i=2}^{k}\varepsilon(\tau_{i}) = (-1)^{k-1},$$ luego $\sigma \in \mathcal{A}_{n}$ si y sólo si $1 = (-1)^{k-1}$, esto es, si $k$ es impar.

$\hfill \square$

Del resultado que acabamos de ver se tiene que, dado un $k$-ciclo $(a_{1}, \ldots, a_{k}) \in S_{n}$, entonces su signatura es $(-1)^{k-1}$. 

\begin{observation} Para $n \geq 4$ el grupo alternado $\mathcal{A}_{n}$ no es abeliano puesto que las permutaciones $\sigma = (1,2,3) \in \mathcal{A}_{n}$ y $\tau = (1,2)(3,4) \in \mathcal{A}_{n}$, por la proposición anterior y que $\sigma\tau(1) = 1$ y $\tau\sigma(1)=3$, cumplen $\sigma\tau \neq \tau\sigma$.

Además, a partir de la proposición anterior y de~\ref{eq:ciclosdis}, podemos afirmar que las transposiciones generan el grupo $S_{n}$, o sea que cada permutación es producto de transposiciones.
\end{observation}

Una vez visto las primeras definiciones y propiedades de los grupos de permutaciones demostraremos uno de los resultados más importantes en \textit{Teoría de Grupos}: que $\mathcal{A}_{n}$ es simple si $n \geq 5$, también conocido como el \textit{Teorema de Abel}, en honor de Niels Henrik Abel.

\begin{proposition}\label{eq:preabel} Si $n \geq 3$, entonces $\mathcal{A}_{n}$ es transitivo sobre $\Omega =\lbrace 1, \ldots, n \rbrace$
\end{proposition}
\emph{Demostración: } Si $1 \leq i <j \leq n$, elegimos un $k \neq i,j$ y tenemos que $(i,j,k)(i) = j$ (la permutación $(i,j,k)$ sobre $i$). Claramente $(i,j,k) \in \mathcal{A}_{n}$.

$\hfill \square$

\begin{theorem}[\textbf{\textit{Teorema de Abel}}] Si $n \geq 5$, entonces $\mathcal{A}_{n}$ es simple.
\end{theorem}
\emph{Demostración: }\textbf{\textit{Primero demostraremos que $\mathcal{A}_{5}$ es simple}}. En $\mathcal{A}_{5}$ tenemos $20$ $3$-ciclos, $24$ $5$-ciclos y $15$ elementos del tipo $(a,b)(c,d)$. Veamos que los $3$-ciclos son conjugados en $\mathcal{A}_{5}$. Sea $g = (1,2,3)$. Sabemos de~\ref{eq:excentra} que $C_{S_{5}}(g)= \langle g\rangle \langle(4,5) \rangle$. Ahora, $$\langle g \rangle \subseteq C_{\mathcal{A}_{5}}(g) \leq C_{S_{5}}(g)$$ puesto que $(4,5) \in C_{S_{5}}(g) \setminus \mathcal{A}_{5}$. Como $|C_{S_{5}}(g)| = 6$, concluimos que $C_{\mathcal{A}_{5}}(g) = \langle g \rangle$. Por lo tanto, $|Cl_{\mathcal{A}_{5}}(g)| = 60/3 = 20.$ 

Veamos ahora que los $15$ elementos del tipo $(a,b)(c,d)$ son conjugados en $\mathcal{A}_{5}$. Nuevamente por~\ref{eq:excentra} tenemos que $$\langle (1,2)(3,4),(1,3)(2,4) \rangle \subseteq C_{\mathcal{A}_{5}}((1,2)(3,4)) \leq C_{S_{5}}((1,2)(3,4))$$ puesto que $(1,3,2,4) \in C_{S_{5}}((1,2)(3,4)) \setminus \mathcal{A}_{5}$. Como $|C_{S_{5}}((1,2)(3,4))| = 8$, concluimos que $|C_{\mathcal{A}_{5}}((1,2)(3,4))| = 4$ y así la clase de conjugación de $(1,2)(3,4)$ en $\mathcal{A}_{5}$ tiene $15$ elementos. (Esto también se puede ver teniendo en cuenta que todas las permutaciones de tipo $[2,2]$ son pares, es decir, que todas forman parte del grupo alternado).

Finalmente, notamos que hay dos clases de conjugación en $\mathcal{A}_{5}$ de $5$-ciclos. En efecto, sabemos que si $g$ es un $5$-ciclo, entonces $C_{S_{5}}(g) = \langle g \rangle = C_{\mathcal{A}_{5}}(g)$. Así, $|Cl_{\mathcal{A}_{5}}(g)| = 12$. Por tanto, las longitudes de las clases de conjugación de $\mathcal{A}_{5}$ son $1,12,12,15$ y $20$.

Sea ahora $N$ un subgrupo normal propio de $\mathcal{A}_{5}$. Tenemos que $N$ es una unión disjunta de clases de conjugación de $\mathcal{A}_{5}$ (siendo una de ellas el $1$) y que $1 < |N| < 60$ es un divisor de $60$. Por lo tanto, $$|N| = 1 + 12a + 12b + 15c + 20d,$$ con $a,b,c,d \in \lbrace 0, 1 \rbrace$. Pero no hay ningún divisor de $60$ de esta forma quitando el $1$ y el propio $60$. Luego no existe $N$ subgrupo normal propio y así $\mathcal{A}_{5}$ es simple.

\textbf{\textit{Probaremos ahora que $\mathcal{A}_{n}$ es simple}} para $n \geq 6$ por inducción sobre $n$. Supongamos que $n \geq 6$ y que $\mathcal{A}_{n-1}$ es simple. Sabemos que $\mathcal{A}_{n}$ actúa sobre $\lbrace 1,2, \ldots, n \rbrace$. Sea $K$ el estabilizador de $n$ en $\mathcal{A}_{n}$. Sea $K$ el estabilizador de $n$ en $\mathcal{A}_{n}$. Como hicimos en~\ref{eq:obsabel} para cada $\sigma \in K$, tenemos definido un $\bar{\sigma} \in S_{n-1}$. Como la descomposición de $\sigma$ y $\bar{\sigma}$ como producto de ciclos disjuntos es la misma entonces $\sigma$ es par si y sólo si $\bar{\sigma}$ lo es. Por lo tanto $K \cong \mathcal{A}_{n-1}$ es simple.

Por el resultado anterior $\mathcal{A}_{n}$ actúa transitivamente sobre $\lbrace 1, 2, \ldots, n \rbrace$ y por~~sabemos que todos los estabilizadores son conjugados en $\mathcal{A}_{n}$. Por lo tanto, si $\sigma \in \mathcal{A}_{n}$ fija algún elemento, entonces $\sigma \in K^{\tau}$ para cierto $\tau \in \mathcal{A}_{n}$.

Sea ahora $N\unlhd \mathcal{A}_{n}$. Entonces $K \cap N \unlhd K$ y por la simplicidad de $K$ concluimos que $K \subseteq N$ ó $K \cap N = 1$. En el primer caso tenemos que $K^{\tau} \subseteq N$ para todo $\tau \in \mathcal{A}_{n}$. Por lo tanto, si una permutación $\sigma \in \mathcal{A}_{n}$ fija un elemento, entonces $\sigma \in N$. En particular, $N$ contiene todos los productos $(a,b)(c,d)$. Como toda permutación par es producto de un número par de transposiciones tenemos entonces que $N = \mathcal{A}_{n}$ en este caso.

En el segundo caso, $K \cap N = 1$. Por lo tanto, $K^{\tau} \cap N = (K \cap N)^{\tau} = 1$ para todo $\tau \in \mathcal{A}_{n}$. Es decir, si $1 \neq \sigma \in \mathcal{A}_{n}$ fija algún elemento, entonces $\sigma$ no está en $N$. 

Supongamos que $N > 1$ y sea $1 \neq \sigma \in N$. Supongamos primero que en la descomposición de $\sigma$ como producto de ciclos disjuntos solo aparecen transposiciones. Tenemos que $\sigma = (a,b)(c,d) \cdots$. Sea $e$ una cifra distinta de $a,b,c,d$. Entonces $$\gamma = \sigma^{(a,b)(d,e)}=(b,a)(c,e) \cdots \in N.$$
Ahora $\sigma \gamma \in N$, $\sigma \gamma$ fija $a$ y $1 \neq \sigma \gamma$ (ya que manda $d$ a $e$). Esto es una contradicción. Finalmente, supongamos que en la descomposición de $\sigma$ como producto de ciclos disjuntos tenemos un $m$-ciclo con $m \geq 3$. Podemos escribir $\sigma (a,b,c, \ldots) \cdots$. Elegimos ahora dos cifras $d,e$ distintas de $a,b,c$ y escribimos $$\gamma = \sigma^{(c,d,e)} = (a,b,d, \ldots) \cdots \in N.$$ Tenemos que $\gamma \neq \sigma$ y $1 \neq \sigma \gamma^{-1} \in N$ fija $a$. Esta contradicción final prueba el teorema.

$\hfill \square$
\section{Anillos y cuerpos}
\subsection{Generalidades de anillos}

\begin{definition} Decimos que un \textbf{conjunto $A$} dotado de dos operaciones, que usualmente denominaremos suma y producto, $$\begin{array}{rccl}
+ \colon &A \times A & \longrightarrow & A\\
&(a,b) & \longmapsto &a+b
\end{array}
$$
$$\begin{array}{rccl}
\cdot \colon &A \times A & \longrightarrow & A\\
&(a,b) & \longmapsto &ab
\end{array}
$$
es un \textbf{anillo} si cumple que \begin{enumerate}
\renewcommand{\theenumi}{\roman{enumi}}
\item $A$ dotado de la suma es un \textbf{grupo conmutativo}, es decir, \begin{itemize}
\item La suma cumple las propiedades asociativa y conmutativa.
\item Existe un único elemento $0 \in A$ tal que $a + 0 = 0 + a = a\hspace{0.2cm} \forall a \in A$, que denominaremos \textbf{elemento neutro ó cero}.
\item Para todo $a \in A$ existe un único elemento $b$ tal que $a + b = b +a = 0$, que denominaremos \textbf{elemento opuesto} y denotaremos por $-a$.
\end{itemize}
\item $A$ dotado del producto es un \textbf{semigrupo}, es decir, que el producto cumple la propiedad \textbf{asociativa}. Dados $a, b, c \in A$, entonces se tiene que $$a(bc)= (ab)c.$$
\item La propiedad \textbf{distributiva} del producto con respecto a la suma, es decir que dados $a,b,c \in A$, tenemos que $$(a+b)c = ac+bc, \hspace{0.3cm} a(b+c) = ab+ac.$$
\end{enumerate}
Además es importante matizar que el elemento neutro para la suma, el cero, podrá escribirse como $0_{A}$ o simplemente $0$. Denotaremos por $A^{\ast} = A\setminus \lbrace 0 \rbrace.$ Y, como en grupos, la operación conocida como producto podrá denotarse con un $\cdot$ en ocasiones o con simple yuxtaposición.

Finalmente, una notación usual para los anillos será ($A$, $+$, $\cdot$), que incluye el conjunto y las dos operaciones dotadas.
\end{definition}

\begin{definition} Llamaremos \textbf{anillo unitario} a un anillo $A$ que posea \textbf{elemento unidad}, es decir,si existe $1_{A} = 1 \in A$ tal que $1 \cdot a = a \cdot 1 = a$ \hspace{0.1cm} $\forall a \in A$. También se puede denominar uno.
\end{definition}

\begin{definition}Sea $A$ un anillo unitario. Una \textbf{unidad} de $A$ es un elemento $a \in A$ para el que existe un $b \in A$ tal que $$ab = ba = 1.$$ Es decir, $b$ será el \textbf{inverso} de $a$ con respecto al producto. Lo denotaremos por $a^{-1}$, y observar que si ciertos $a, b, c \in A$ verifican $ab = ca = 1$, entonces $$c = c(ab) = (ca)b = b.$$ Por lo que, de existir el inverso, será único. El conjunto de todas las unidades de $A$ lo denotaremos por $\mathcal{U}(A)$, que es un grupo con la operación producto. En efecto, dados $a,b \in \mathcal{U}(A)$, entonces $$(ab)(b^{-1}a^{-1}) = a(bb^{-1})a^{-1} = aa^{-1} = 1 = b^{-1}b = b^{-1}(a^{-1}a)b = (b^{-1}a^{-1})(ab).$$ De aquí deducimos que $(ab)^{-1} = b^{-1}a^{-1}.$ Finalmente, diremos que un anillo es \textbf{conmutativo} si se cumple, para cualesquiera $a,b \in A$ que $$ab = ba.$$
\end{definition}

\begin{definition} Llamaremos \textbf{cuerpo} a un anillo $K$ tal que $K^{\ast} = K \setminus \lbrace 0 \rbrace$ forma un grupo con la multiplicación. Dicho de otra forma, en todo anillo unitario vamos a tener que $\mathcal{U}(A) \subseteq A^{\ast}$, y los cuerpos son aquellos anillos unitarios $K$ tales que $\mathcal{U}(A) = K^{\ast}$. De igual manera que para anillos, también podremos definir los \textbf{cuerpos conmutativos} como aquellos que, para cualesquiera $a,b \in K$ se tiene que $$ab = ba.$$
Además, un elemento $a \in A$ diremos que es \textbf{idempotente} si $a^{2} = a$. Y diremos que es \textbf{nilpotente} si existe un entero positivo $n$ tal que $a^{n} = 0$. Un anillo cuyo único elemento nilpotente sea el $0$ se dirá \textbf{reducido}.
\end{definition}

\begin{definition}Si $A$ es un anillo, podemos construir el \textbf{anillo de polinomios} $A[x]$ sobre $A$. 

Un polinomio $p \in A[x]$ es una suma de la forma $$p = \sum_n a_nx^n,$$ con $a_n \in A$ para todo $n$ y donde existe un $m$ tal que $a_n=0$ si $n>m$. En ocasiones también podremos escribir estos elementos como $p(x)$. Si tenemos que $p=a_mx^m+\ldots+a_1x+a_0,$ y $a_m\neq 0$ entonces podremos decir que el \textbf{grado} de $p$, $\delta(p)$, es $m$. También diremos que los términos $a_m,\ldots, a_1, a_0$ son los \textbf{coeficientes} de $p$ y concretamente que $a_m$ es el \textbf{coeficiente director} de $p$. Si este coeficiente director $a_m =1$ diremos que $p$ es mónico. El polinomio $0$ se suele convenir que tiene grado $-\infty$.

Diremos que dos polinomios $p = \sum_n a_nx^n$, $q = \sum	_n b_nx^n$ son iguales si y sólo si $a_n = b_n$ para todo $n$. También los podremos sumar y multiplicar: $$p+q= \sum_n(a_n+b_n)x^n,$$ $$pq = \sum_n\left(\sum_{i+j=n \atop i,j\geq 0} a_ib_j \right) x^n.$$
\end{definition}

\begin{definition}Sea $A$ un anillo. Llamaremos \textbf{divisor de cero} a un elemento $a \in A$ no nulo tal que $ab = 0$ para algún $b \in A$ no nulo.
\end{definition}

\begin{definition} Llamaremos \textbf{dominio de integridad}, ó D.I, a un anillo unitario y conmutativo sin divisores de cero.

Importante remarcar una propiedad fundamental de los dominios de integridad, y también de los cuerpos: se pueden simplificar factores comunes en las igualdades ya que si tenemos $ab = ac$, con $a \neq 0$, entonces $a(b-c) = 0$, y al no ser $a$ un divisor de cero, tenemos que $b-c = 0$ y de aquí $b = c$. Esto se conoce como \textbf{ley cancelativa} y también puede darse en estructuras de anillos, siempre y cuando los elementos implicados no sean divisores de cero. 
\end{definition}

\begin{definition}[\textbf{\textit{Característica de un anillo}}]
Llamaremos \textbf{característica} de un anillo $A$ al menor natural no nulo $n$ tal que $n\cdot 1=n1 = 0$. En caso de que no exista diremos que $A$ tiene característica $0$.
\end{definition}

Es decir, la característica de un anillo es el mínimo número de veces que hay que sumar $1$ consigo mismo para obtener $0$, y si no existe dicho número entonces diremos que será $0$.

\begin{proposition}La característica de un dominio de integridad $A$ es $0$ o $p$, con $p$ primo.
\end{proposition}
\emph{Demostración: }Supongamos que $A$ es un dominio de integridad cuya característica no es $0$. Sea $p$ la característica de $A$ y supongamos que no es primo, luego $p = nm$, con $n,m>1$ enteros, y $m 1 \neq 0 \neq n  1$ pero $(m 1)(n 1 ) = (n m)1 = 0$, contradiciendo que $A$ sea dominio de integridad.

$\hfill \square$

\begin{definition} Sea $B$ un anillo conmutativo y unitario, $A \subseteq B$ un subconjunto que, con las operaciones inducidas por $B$, es a su vez un anillo unitario tal que $1_{B} =1_{A}.$ Diremos que $A$ es un \textbf{subanillo} de $B$, y ya sabemos que la aplicación
$$\begin{array}{rccl}
&A&\longrightarrow &B \\
&x& \longmapsto &x
\end{array}
$$  es un monomorfismo, la inclusión canónica. Si $A$ y $B$ son cuerpos diremos que $A$ es un \textbf{subcuerpo} de $B$. Además, todo dominio de integridad es subanillo de su cuerpo de fracciones, vía el monomorfismo $x \longrightarrow x/1$.
\end{definition}

\begin{definition}Sea $A$ un anillo conmutativo y unitario. Llamaremos \textbf{ideal} a un subconjunto $I \subseteq A$ que cumplirá las siguientes condiciones: \renewcommand{\labelenumi}{\arabic{enumi}.}
\begin{enumerate}
\item $I$ es un subgrupo de $A$ para la suma, así habrá de incluir el elemento neutro, es decir, $0 \in I$.
\item $\forall x \in I, a \in A$ tenemos que $ax \in I$.
\end{enumerate}
Aunque la primera condición es también equivalente a: \begin{enumerate}
\item $\forall x,y \in I$, se tiene que $x+y \in I$. 
\end{enumerate}
Y esto es así ya que, al cumplirse $2.$ y esta nueva condición, tendremos que dados $x,y \in I$ $$x-y = x +(-1)y \in I$$ (ya que $(-1)y \in I$ por $2.$). Así, $I$ será subgrupo para la suma. Estas dos últimas condiciones son las que dió en su momento el matemático Richard Dedekind cuando definió el concepto de ideal (la primera es de Kummer).
\end{definition}

\begin{definition} Algunas definiciones de especial interés: \renewcommand{\labelenumi}{\arabic{enumi}.} \begin{enumerate}
\item El conjunto $\lbrace 0 \rbrace$ es un ideal de $A$, denominado \textbf{ideal nulo}. También $A$ cumple con las condiciones, así que también es ideal de $A$, y tanto este como el ideal nulo son los llamados \textbf{ideales impropios} de $A$. Esto sirve para distinguirlos de aquellos ideales $\lbrace 0 \rbrace \neq I \neq A$, a los que llamaremos \textbf{ideales propios} de $A$. Notar que si $1 \in I$, entonces por la segunda condición tenemos que $x = x \cdot 1 \in I$ para cualquier $x \in A$ y así $I = A$. Por lo tanto será importante tener en cuenta que \textbf{$I$ es propio si y sólo si $1 \notin I$.}
\item Si $x \in A$, entonces el conjunto $$xA = \lbrace xa : \hspace{0.1cm} a \in A \rbrace$$ es un ideal de $A$, denominado \textbf{ideal principal generado por $x$} y lo denotaremos por $(x)$. Un ejemplo de esto podrían ser los ideales de $\mathbb{Z}$ mencionados anteriormente, los conjuntos $n\mathbb{Z}$. Más adelante veremos esta expresión generalizada para hablar de ideales generados por conjuntos.
\end{enumerate}
\end{definition}

\begin{definition}\label{eq:ancoci} \textbf{\textit{Anillos cociente.}} Sea $A$ un anillo conmutativo y unitario e $I \subset A$ un ideal propio. Definiremos la siguiente relación de equivalencia: \begin{center}
$x \sim y$ si $x-y \in I$, con $x,y \in A$.
\end{center}
Es evidente que es una relación de equivalencia (cumple las propiedades reflexiva, simétrica y transitiva) ya que $I$ tiene estructura de subgrupo.

El conjunto cociente de $A$ para esta relación la denotaremos $A/I$ y la clase de equivalencia de un elemento $x \in A$ será: $$x + I = \lbrace x + a  : \hspace{0.1cm} a \in I \rbrace.$$
Que un elemento $y$ esté en la clase de equivalencia de $x$ significa que existirá un elemento $a \in I$ de la forma $a = y-x$. Además,\begin{center}
$x + I = y + I  \Leftrightarrow x \equiv y$ $mod$ $I$, es decir, que tanto $x-y \in I$ como $y-x \in I$.
\end{center} 
Ahora, dotaremos a $A/I$ de dos operaciones que lo convertirán en un anillo, dados $x,y \in A$: 
$$\begin{array}{rccl}
+ \colon &A/I \times A/I&\longrightarrow & A/I\\
&((x + I),(y + I)) & \longmapsto &(x + I) + (y + I) = (x + y) + I,
\end{array}
$$ que le confiere a $A/I$ estructura de grupo abeliano (conmutativo), y
$$\begin{array}{rccl}
\cdot \colon &A/I \times A/I&\longrightarrow & A/I\\
&((x + I),(y + I)) & \longmapsto &(x + I)\cdot(y + I) = xy + I.
\end{array}
$$ 
Las propiedades  asociativa y conmutativa del producto, así como la distributiva, son inmediatas. El \textbf{elemento neutro} de $A/I$ será $1 + I$. Así, $A/I$ dotado con las dos operaciones, suma y producto,  tiene estructura de anillo conmutativo unitario, que denominaremos \textbf{anillo cociente ó anillo de clases de restos módulo $I$}.

Además, notar que los ideales del cociente $A/I$ serán aquellos ideales de $A$ que contengan a $I$.
\end{definition}

\begin{definition} Sea $A$ un anillo conmutativo y unitario. Un ideal $I \subseteq A$ se llama \textbf{finitamente generado} si es un ideal generado por un subconjunto finito $L = \lbrace x_{1}, \ldots, x_{r}\rbrace \subseteq A.$ En dicho caso, $$I = Ax_{1} + \ldots + Ax_{r} = \left\lbrace \sum_{k=1}^{r}a_{k}x_{k} : \hspace{0.1cm} a_{1}, \ldots, a_{r} \in A \right\rbrace.$$ Lo denotaremos $I = (x_{1}, \ldots, x_{r}).$ Y recordar que si $r=1$, es decir, si el ideal está generado por un solo elemento, entonces $I$ se llama \textbf{ideal principal}.
\end{definition}

\begin{definition}Sea $A$ un anillo no necesariamente conmutativo ni unitario e $I$ un ideal de $A$. Diremos que $I$ es \textbf{maximal} si lo es, respecto de la inclusión, en la familia de todos los ideales propios de $A$, es decir, si no existe ningún ideal propio  $J$ de $A$ que lo contenga estrictamente ($I \subsetneq J$).
\end{definition}

A continuación daremos una caracterización de estos ideales:

\begin{proposition} Sea $A$ un anillo conmutativo y unitario e $I$ un ideal de $A$. Entonces $I$ será \textbf{maximal} si se cumple algunas  de las siguientes condiciones equivalentes: \begin{enumerate}
\item El anillo cociente $A/I$ es un cuerpo.
\item $I$ es un ideal propio y ningún otro ideal propio lo contiene estrictamente.
\end{enumerate}
\end{proposition}
\emph{Demostración: } Sea $A/I$ un cuerpo y supongamos que $I$ no es maximal. Entonces existirá un ideal $J$ de $A$ tal que $I \subsetneq J \subsetneq A$. Sea $x \in J \setminus I$ un elemento de $J$ que no pertenece a $I$. Entonces $x + I$ es un elemento no nulo del cuerpo $A/I$ ya que $x \notin I$, por lo que tendrá inverso, es decir, existirá $y \in A$ tal que $$1 + I = (x + I)(y + I)= xy + I,$$ y en consecuencia $1 -xy \in I \subseteq J$. Ahora como $xy \in J$, por ser $J$ un ideal, tendremos que $1 = (1- xy) + xy \in J$ y así $J = A$, lo cual es absurdo.

Recíprocamente, sea $x + I$ un elemento no nulo de $A/I$. Entonces $x \in A \setminus I$, es decir, será un elemento de $A$ que no estará en $I$, por lo que el ideal $I + (x)$ contiene estrictamente a $I$. Como este último es maximal tendremos que $I + (x) = A$, es decir que existirá $b \in I$ e $y \in A$ tal que $b + xy = 1$. Así que $1 - xy \in I$, es decir, $$xy + I = (x + I)(y + I ) = 1 + I,$$ por lo que $A/I$ es un cuerpo.

$\hfill \square$

\begin{proposition} Sea $A$ un anillo conmutativo y unitario e $I$ un ideal de $A$. Diremos que $I$ es \textbf{primo} si se verifica alguna de las siguientes condiciones: \begin{enumerate}
\item El anillo cociente $A/I$ es un dominio de integridad.
\item $I$ es un ideal propio y para cualesquiera $x, y \in A$, si $xy \in I$, entonces $x \in I$ ó $y \in I.$
\end{enumerate}
\end{proposition}
\emph{Demostración: } Si $xy \in I$, entonces $0 + I = xy + I = (x + I)(y + I),$ y como $A/I$ es dominio de integridad ó $x + I = 0 + I$ y $x \in I$ ó $y + I = 0 + I$ y así $y \in I$.

Recíprocamente, $0 + I = xy + I = (x+ I)( y + I)$ ya que $xy \in I$, y como ó $x \in I$ ó $y \in I$, entonces ó $(x + I)=  0 + I$ ó $(y + I) = 0 + I$ respectivamente. Así $A/I$ es dominio de integridad.

$\hfill \square$

\begin{definition} Sean $A$ y $B$ dos anillos conmutativos y unitarios. Definiremos un \textbf{homomorfismo de anillos} de $A$ en $B$ como una aplicación $$f \colon A \longrightarrow B$$ tal que: \begin{enumerate}
\item $f(x + y) = f(x) + f(y)$, $\forall x,y \in A$.
\item $f(xy) = f(x)f(y)$, $\forall x,y \in A.$
\item $f(1_{A}) = 1_{B}.$
\end{enumerate}
\end{definition}

Un homomorfismo muy importante es el conocido como \textit{homomorfismo evaluación}, que involucra anillos de polinomios. Si $p(x) = a_kx^k + \ldots + a_1x+a_0 \in A[x]$ y $a \in A$, con $A$ un anillo conmutativo y unitario, entonces definimos $p(b)=a_kb^k + \ldots + a_1b +a_0$. 

\begin{proposition}[\textbf{\textit{Homomorfismo evaluación}}]
Sea $A$ un anillo conmutativo y unitario, y supongamos que $a \in A$. Entonces, la aplicación $$\begin{array}{rccl}
e_a \colon &A[x]&\longrightarrow &A \\
&p& \longmapsto &p(a)
\end{array}
$$ es un homomorfismo de anillos.
\end{proposition}
\emph{Demostración: }Observar que $e_a(1) = 1$. Si $p(x) = \sum_n a_nx^n$ y $q(x) = \sum_n b_nx^n$ hay que comprobar que $(p+q)(a)=p(a)+q(a)$ y que $pq(a) = p(a)q(a)$. Es un simple ejercicio.

$\hfill \square$

\begin{definition} Sea $f \colon A \longrightarrow B$ un homomorfismo de anillos conmutativos y unitarios. Entonces: \begin{enumerate}
\item Llamaremos \textbf{núcleo} de $f$ y lo denotaremos \textbf{$ker f$} al ideal $$ker f = \lbrace x \in A:  f(x) = 0 \rbrace.$$ Es un ideal ya que, si $x,y \in ker f$, $a \in A$, tenemos que $$f(x+y) = f(x) + f(y) = 0 +0 = 0,$$ $$f(ax)=f(a) f(x) = f(a) \cdot 0 = 0.$$
\item Llamaremos \textbf{imagen} de $f$ y la denotaremos \textbf{$Im f$} al anillo $$Im f = \lbrace y \in B: \hspace{0.1cm} \exists x \in A, \hspace{0.1cm} y = f(x) \rbrace.$$
Es un anillo conmutativo y unitario con las operaciones heredadas de $B$, ya que si $y = f(x)$, $v = f(u)$, $x, u \in A$, tenemos que $$y-v = f(x) - f(u) = f(x-u) \in im f,$$ $$y \cdot v = f(x)f(u) = f(x u) \in im f,$$ $$1_{B} = f(1_{A}) \in imf.$$
\end{enumerate}
\end{definition}

\begin{proposition} Sea $f \colon A \longrightarrow B$ un homomorfismo de anillos conmutativos y unitarios. Como $f(1_{A}) = 1_{B} \neq 0$, $ker f$ es un ideal propio de $A$. Además, $f$ es inyectiva si y sólo si $ker f = \lbrace 0 \rbrace.$
\end{proposition}
\emph{Demostración: } Sea $f$ inyectiva, como $f(0) = 0$, entonces el núcleo ha de reducirse al elemento neutro $0$. Recíprocamente, supongamos que $ker f = \lbrace 0 \rbrace$. Si $x,y \in A$ y tenemos que $f(x) = f(y)$, entonces $f(x-y)= 0$. Esto quiere decir que $x-y \in ker f$, pero $ker f = \lbrace 0 \rbrace$ luego $x-y = 0$ y finalmente $x = y$. Y así, $f$ es inyectiva.

$\hfill \square$

\begin{definition} Sea $f \colon A \longrightarrow B$ un homomorfismo de anillos conmutativos y unitarios. Entonces diremos que: \begin{enumerate}
\item $f$ es un \textbf{epimorfismo}, si es una aplicación suprayectiva.
\item $f$ es un \textbf{monomorfismo}, si es una aplicación inyectiva.
\item $f$ es un \textbf{isomorfismo}, si es una aplicación biyectiva.
\end{enumerate}
\end{definition}

\begin{theorem}[\textbf{\textit{Primer Teorema de Isomorfía}}]\label{eq:1ti} Sea $f \colon A \longrightarrow B$ un homomorfismo de anillos conmutativos y unitarios. Consideremos el diagrama siguiente:
$$\xymatrix @=2cm {A\ar[r]^{f} \ar[d]_\pi & B  \\ A/Ker f \ar[r]^{\bar{f}} & Im f \ar[u]_{i}  }$$

con $A/Ker f$ el anillo de clases módulo $Ker f$ y $$\begin{array}{rccl}
\pi \colon &A&\longrightarrow &A/Ker f \\
&x& \longmapsto &x + Ker f,
\end{array}
$$ 
la proyección canónica, que es suprayectiva.
$$\begin{array}{rccl}
\bar{f} \colon &A/Ker f&\longrightarrow &Im f \\
&x + Ker f& \longmapsto &f(x),
\end{array}
$$ 
la aplicación que nos induce, que será biyectiva, es decir, un isomorfismo: 

$$A/Ker f \cong Imf.$$

y
$$\begin{array}{rccl}
i \colon &Im f&\longrightarrow &B \\
&f(x)& \longmapsto &f(x) =y,
\end{array}
$$ 
la inclusión canónica, que será inyectiva. 

Así, en estas condiciones, todas las aplicaciones son homomorfismos y el diagrama es conmutativo, es decir, $$f = i \circ \bar{f} \circ \pi.$$
\end{theorem}
\emph{Demostración: }Veamos que $\bar{f}$ \begin{enumerate}
\item está bien definida, y es que si $x + Ker f = y + Ker f$ entonces tenemos que $x-y \in Ker f$ y así $f(x-y) = 0$, pero $f(x-y)= f(x) -f(y)$ y de aquí deducimos que $$f(x) = f(y),$$ y así $\bar{f}(x + Kerf) = \bar{f}(y+ Kerf)$, es decir, $\bar{f}$ no depende del representante que escojamos de la clase.
\item es inyectiva. Sean $x,y \in A$ tales que $\bar{f}(x + Kerf) = \bar{f}(y + Kerf)$. Esto quiere decir que $f(x) = f(y)$, y así $f(x) - f(y) = f(x-y) = 0$, luego $x-y \in Kerf$. Así, $x + Kerf = y + Kerf$ y $\bar{f}$ es inyectiva.
\item es suprayectiva. Sea $y \in Imf$, entonces $y = f(x)$ para algún $x \in A$ y así, $$y = \bar{f}(x + Kerf),$$ y $\bar{f}$ es suprayectiva, es decir, $\forall y \in Imf$ existe un $x + Kef \in A/Kerf$ tal que $\bar{f}(x + Kerf) = y$.
\end{enumerate}
Lo último es claro ya que, dado un $x \in A$, tenemos que $$f(x) = (i \circ \bar{f} \circ \pi) (x) = i(\bar{f}(\pi(x))) = i(\bar{f}(x + Kerf)) = i(f(x)) = f(x).$$
$\hfill \square$

\begin{definition} Sean $x, y$ elementos de $A$ tales que $x \neq 0$. Se dice que \textbf{$x$ divide a $y$, que $x$ es un divisor de $y$, que $y$ es divisible por $x$ ó que $y$ es un múltiplo de $x$} si existe $a \in A$ tal que $y = ax$. Se escribe $x \mid y$. Si $x$ no divide a $y$ se escribe $x \nmid y$.

En otras palabras, $x \mid y \Leftrightarrow y \in (x)$, ó equivalentemente $(y) \subseteq (x)$.
\end{definition}

Esto nos presenta la divisibilidad como una relación de orden parcial que será inmediata para ideales pero que para entenderla entre elementos habrá que describir la relación de igualdad asociada: 

\begin{center}
$x$ está relacionado con $y$ si $x \mid y$ e $y \mid x$, o sea si $(x) = (y).$
\end{center} 
Estas condiciones son equivalentes a: \begin{enumerate}
\item Existe una unidad $a \in \mathcal{U}(A)$ tal que $y = ax$. Esto es así ya que si $(y) = (x)$ tendremos que $y \in (x), x \in (y)$, luego $y = ax$ y $x = by$. Luego $y = aby$ y como $A$ es un dominio de integridad podremos simplificar y obtener $1 = ab$, y así $a$ es unidad.
\item Si $y \in A^{\ast}$ no es unidad, denotaremos $div(y)$ el conjunto de todos los divisores de $y$. Es claro que los conjuntos $y \cdot \mathcal{U}(A)$ y $\mathcal{U}(A)$ están contenidos en $div(y)$. Así, si $y$ no tiene más divisores que las unidades y los productos del propio $y$ por unidades (después veremos que estos elementos se denominan asociados) diremos que $y$ es \textbf{\textit{irreducible}}.
\item Si $y \in A^{\ast}$ genera un ideal primo diremos que $y$ es primo. \textbf{\textit{Todo elemento primo es irreducible}}. Veámoslo. 

\emph{Demostración: } Sea $y = ax$. Si $y$ es primo entonces $(y)$ es primo y se tendrá que $a \in (y)$ ó $x \in (y)$. Si $a \in (y)$ tendremos que $a = zy$, luego $y = zyx$ y $1 = zx$. Así, $x \in \mathcal{U}(A)$ y $a = yx^{-1} \in y \cdot \mathcal{U}(A)$. Análogo si $x \in (y)$.

$\hfill \square$

El recíproco en general no se cumple, aunque esto lo desarrollaremos más adelante.
\end{enumerate}

\begin{definition}Dos elemento $x,y \in A$ se dirán \textbf{asociados} en $A$ si $x \mid y$ e $y \mid x$. Por ejemplo, en $\mathbb{Z}$ $n$ y $-n$ lo son. Ser asociados es una relación de equivalencia en $A$, en la que la clase de un $x$ cualquiera (sus asociados) estará formada por elementos de la forma $ux$, con $u \in \mathcal{U}(A)$. 
\end{definition}

\subsection{Algunas estructuras algebraicas}

\begin{definition} \label{eq:de} Diremos que $A$ es un \textbf{dominio euclídeo}, escrito $DE$, si existe una aplicación $$\begin{array}{rccl}
\norm{\cdot}\colon A\longrightarrow \mathbb{N}
\end{array}
$$
que cumpla: \begin{enumerate}
\item $\norm{x} = 0$ si y sólo si $x = 0$.
\item $\norm{xy} = \norm{x} \cdot \norm{y}.$
\item Si $x, y \in A^{\ast}$, existe $r \in A$ tal que $y \mid (x-r)$ y $\norm{r} < \norm{y}$. Esto no viene a ser más que la división de los enteros, donde $r$ es el resto y el elemento $q \in A$ tal que $x-r = qy$ el cociente. 
\end{enumerate}
A esta aplicación la denominaremos \textbf{norma euclídea}.
\end{definition}

La última condición puede ser reformulada tal que así: dados $x,y \in A$ no nulos (en realidad bastaría con que sólo lo fuera $y$) existen $r$ y $q$ tales que $x=qy+r$, con $r=0$ ó bien $\norm{r} < \norm{y}$.

Notar que el anillo de los enteros $\mathbb{Z}$ es un dominio eculídeo tomando como aplicación el módulo $|\cdot |$.

En un dominio euclídeo se cumple la siguiente propiedad, que ya vimos por encima cuando hablamos de los anillos $\mathbb{Z}[\sqrt{n}]$ en~\ref{def:ard}.

\begin{proposition} Sea $A$ un dominio euclídeo. Entonces: $$\mathcal{U}(A) = \lbrace x \in A : \norm{x} = 1 \rbrace.$$
\end{proposition}
\emph{Demostración: } Lo primero notar que $\norm{1_{A}} = 1$, puesto que $\norm{1_{A}} = \norm{1_{A}\cdot 1_{A}} = \norm{1_{A}}^{2}$ y como $\norm{1_{A}} \neq 0$, tenemos que $\norm{1_{A}} = 1$.

Veamos que $\mathcal{U}(A) \subseteq \lbrace x \in A : \norm{x} = 1 \rbrace$. Si $x \in A$ tiene inverso $x^{-1}$, resulta que $\norm{x} \cdot \norm{x^{-1}} = \norm{x\cdot x^{-1}} = \norm{1_{A}} = 1.$ Luego necesariamente $\norm{x} = 1$ (recordar que son naturales).

Recíprocamente, sea $x \in A$ con $\norm{x} = 1$. Entonces $x \neq 0$ y por definición se tiene que $x \mid (1_{A}-r)$ para un cierto $r \in A$, con $\norm{r} < \norm{x}.$ Como $\norm{x} = 1$, sólo puede ser $\norm{r} = 0$, luego $r = 0$. Así $x \mid 1_{A}$ y por tanto se trata de una unidad. 
 
$\hfill \square$

\begin{proposition}\label{eq:dedip} En un dominio euclídeo todos los ideales son principales.
\end{proposition}
\emph{Demostración: } Sea $I$ un ideal no nulo de un dominio euclídeo $A$. Elijamos un $x \in I$ tal que $$\norm{x} = \min \lbrace \norm{y} :0 \neq y \in I \rbrace.$$ Este mínimo existe y es $>0$, puesto que es el mínimo de un conjunto no vacío de números naturales positivos. Afirmamos que $I$ está generado por $x$.\vspace{0.2cm}\\
En efecto, sea $y \in I$, $y \neq 0$. Entonces como $x \in A^{\ast}$, existirá $r \in A$ tal que $x \mid (y-r)$ y con $\norm{r} < \norm{x}$. De esto deducimos que $y-r \in (x) \subseteq I$, y como $y \in I$ e $I$ es ideal, $r \in I$. Pero la minimalidad de $\norm{x}$ y la condición de que $\norm{r} < \norm{x}$ implican que $r = 0$. Así, $y = y-r$ está en $(x)$, y por lo tanto $I = (x)$.

$\hfill \square$

Esto quiere decir que todos los ideales de un DE son generados por un sólo elemento. Si definimos a éstos como una nueva clase de dominios habremos encontrado otra estructura que nos facilitará mucho el trabajo con ideales.

\begin{definition} Llamaremos \textbf{dominio de ideales principales}, escrito como $DIP$, a un dominio de integridad en el que todos sus ideales son principales. Todo $DE$ es un $DIP$.
\end{definition} 

\begin{proposition} Sea $A$ un $DIP$. Entonces todo elemento irreducible $a \in A^{\ast}$ genera un ideal maximal.
\end{proposition}
\emph{Demostración: } Sea $I \subseteq A$ un ideal que contiene al ideal principal $(a)$, generado por el elemento irreducible $a$. Veamos que ó bien $I = (a)$ ó $I = A$. Pero por ser $A$ un $DIP$, existirá un $b \in A$ tal que $I = (b)$. En consecuencia, $(a) \subseteq I = (b)$ y $b \mid a$. Como $a$ es irreducible, tendremos dos opciones: \begin{enumerate}
\item O bien $b = u \cdot a$, con $u \in \mathcal{U}(A)$, y entonces $(a) = (b) = I$.
\item O bien $b \in \mathcal{U}(A)$, y entonces $A = (b) = I$.
\end{enumerate}

$\hfill \square$

\begin{definition} Sean $x,y \in A\setminus \lbrace 0 \rbrace$. Diremos que $z \in A$ es: \begin{enumerate}
\item Un \textbf{máximo común divisor} (mcd) de $x,y$ si $z$ divide tanto a $x$ como a $y$, y es múltiplo de cualquier otro divisor de ambos.
\item Un \textbf{mínimo común múltiplo} (mcm) de$x,y$ si $z$ es múltiplo de $x$ y de $y$, y además divide a cualquier otro múltiplo de ambos.
\end{enumerate}
\end{definition}

\begin{proposition} \label{eq:lemdiv} Sean $x, y \in A\setminus \lbrace 0 \rbrace$, y supongamos que tienen un $mcm$ $z$. Entonces $t = xy/z \in A$ y $t$ es un $mcd$ de $x,y$.
\end{proposition}
\emph{Demostración: } Por definición de $mcm$, $z$ divide a $xy$, luego $t$ es un elemento de $A$ bien definido. Por otra parte, $x \mid z$ e $y\mid z$, luego $z = ax$, $z =by,$ con $a,b \in A.$ \vspace{0.2cm}\\
Se tiene $zx =byx = btz$, y como $A$ es dominio $x = bt$ y $t \mid x$. Análogamente, $t \mid y$. Por otra parte, si $u$ es un divisor común de $x$ e $y$, entonces $x = cu, y = du$, con $c,d \in A$. Observamos que  $$xy/u = (x/u)y = cy, \hspace{0.2cm} xy/u = (y/u)x = dx,$$ luego $xy/u$ es múltiplo común de $x$ e $y$, con lo que $z$ divide a $xy/u$, y en consecuencia, $u$ divide a $xy/z = t$. Esto prueba que $t$ es múltiplo de cualquier divisor común $u$ de $x$ e $y$.

$\hfill \square$

\begin{proposition} \label{eq:mcmd} Sea $A$ un dominio de integridad, entonces son equivalentes:
\begin{enumerate}
\item Todo par de elementos no nulos tienen $mcm$.
\item Todo par de elementos no nulos tienen $mcd$.
\end{enumerate}
Y se cumple que, si $x,y \in A^{\ast}$, entonces $$mcm(x,y) \cdot mcd(x,y) = xy.$$
\end{proposition}
\emph{Demostración: } Que el primero implica el segundo es claro por el resultado anterior. Veamos el recíproco. Sean $x,y \in A$, $t = mcd(x,y)$. Entonces $$z = xy/t = (x/t)y = x(y/t)$$ es múltiplo de $x$ y de $y$. Consideremos otro múltiplo común $u$. Entonces $$tu = mcd(xu,yu) \hspace{0.2cm} (\ast).$$ En efecto, sea $d = mcd(xu,yu)$. Evidentemente $tu \mid d$ y así $d = tuv$. Entonces $tuv$ divide a $xu$ y a $yu$, de donde $tv$ divide a $x$ e $y$, luego $tv$ divide a $t$ y $v$ es unidad. Así, tenemos $(\ast)$.\vspace{0.2cm}\\
Claramente $xy \mid xu$ y $xy \mid tu$, esto es, $xy / t$ divide a $u$. Así $z = xy/t = mcm(x,y)$, y multiplicando esta igualdad por $t$ queda $zt = xy$.

$\hfill \square$

Anteriormente vimos que todo elemento primo es irreducible, ahora veremos que dadas unas condiciones también se cumple el recíproco.

\begin{proposition}\label{pregauss0} Supongamos que en un dominio de integridad $A$ se cumple cualquiera de las condiciones de~\ref{eq:mcmd}. Entonces todo elemento irreducible de $A$ es primo.
\end{proposition}
\emph{Demostración: } Sean $a \in A$ irreducible e $I = (a)$. Para comprobar que $I$ es primo consideremos $x,y \in A$ con $xy \in I$. Entonces $xy = ab$ con $b \in A$. Por la hipótesis existen $$\alpha = mcm (y,b)$$ $$\beta = mcd(y,b)$$ y se verifica $\alpha \beta = yb.$ Observemos ahora que $xy$ es múltiplo de $b$ y de $y$, luego $\alpha \mid xy$. En consecuencia, podemos escribir $$a = \frac{xy}{\alpha} \cdot \frac{\alpha}{b}; \hspace{0.2cm} \frac{xy}{\alpha}, \frac{\alpha}{b} \in A.$$ Por ser $a$ irreducible existe una unidad $u \in A$ tal que se verifica una de las dos condiciones siguientes: \begin{enumerate}
\item $xy/\alpha = ua$. Entonces $x = u(\alpha/y)a$, con lo que $x \in (a) = I$. (Notar que $y \mid \alpha$, luego $\alpha /y \in A$.)
\item $\alpha/b = ua$. Entonces $y = \alpha \beta /b = u \beta a$ y así $y \in (a) = I$.
\end{enumerate}

$\hfill \square$

\begin{proposition}[\textbf{\textit{Identidad de Bézout}}] Sean $x, y \in A^{\ast}$, y supongamos que generan un ideal principal. Entonces existe $z = mcd(x,y)$ y $$z = ax + by$$ con $a,b \in A$.
\end{proposition}
\emph{Demostración: }Sea $z \in A$ un generador de $(x) + (y)$. Entonces: \begin{enumerate}
\item $x,y \in (z)$, luego $z$ es un divisor común de $x$ e $y$.
\item $z = ax + by$ para ciertos $a,b \in A$.
\end{enumerate}
Por último, además, si $t \mid x$ y $t \mid y$, es claro que $t \mid z$. Por lo que tendremos que $z = mcd(x,y).$

$\hfill \square$

\begin{definition} Dos elementos $x,y \in A^{\ast}$ se denominan \textbf{primos entre sí} cuando no comparten más divisores comunes que las unidades, es decir, cuando $mcd(x,y) = 1$.
\end{definition}

\begin{definition}\label{eq:defdfu} Un \textbf{dominio de factorización única}, escrito $DFU$ es un dominio de integridad en el que se cumple: \begin{enumerate}
\item Todo elemento irreducible es primo.
\item Todo elemento no nulo que no sea unidad es producto de elementos irreducibles.
\end{enumerate}
\end{definition}

Los $DFU$ satisfacen la condición de cadena ascendente para ideales principales.

\begin{observation} Algunas observaciones:\begin{enumerate}
\item Que todo elemento no nulo que no sea unidad sea producto de elementos irreducibles no garantiza la unicidad de dicha factorización. Es necesaria también la primera condición, ya que la unicidad se desprende de que ésta se cumple sobre un dominio de ideales principales.
\item En un DFU siempre existen mcd y mcm. Efectivamente, puesto que el mcd es el producto de los factores irreducibles comunes elevados al menor exponente y el mcm es el producto de todos los factores irreducibles (comunes y no comunes) elevados al mayor exponente.
\item Las relaciones entre las distintas estructuras algebraicas estudiadas se puede resumir en: $$Cuerpos \subseteq DE \subseteq DIP \subseteq DFU 	\subseteq DI \subseteq Anillo.$$
Por ejemplo, las matrices constituyen un anillo pero no un DI, $\mathbb{Z}[\sqrt{-3}]$ es un DI que no es DFU (puesto que $(1+\sqrt{-3})(1-\sqrt{-3}) = 4 = 2 \cdot 2$), el anillo de los polinomios con coeficientes enteros $\mathbb{Z}[X]$ es un DFU que no es DIP o $\mathbb{Z}$ es un DE que no es un cuerpo. 

Los anillos $\mathbb{Z}$ y $\mathbb{Z}[i]$ son DE y por tanto DFU. Es precisamente en $\mathbb{Z}$ donde éste resultado se manifiesta como el \textbf{\textit{teorema fundamental de la Aritmética}}: \textit{todo número entero positivo $n$ se escribe de modo único como producto de números primos positivos $p_{1}, \ldots, p_{r}$ de la forma $n = p_{1}^{\alpha_{1}} \ldots p_{r}^{\alpha_{r}}.$}
\end{enumerate}
\end{observation}

\subsection{Anillos de restos}

Primero, el resultado central de la sección, y a partir del cual desarrollaremos el resto.

\begin{proposition}Sea $n$ un entero positivo. El anillo $\mathbb{Z}/n\mathbb{Z}$ es un cuerpo si y sólo si $n$ es primo.
\end{proposition}
\emph{Demostración: }Está claro que podemos suponer que $n \geq 2$. Supongamos que $n=ab$, con $1 <a,b<n$ y que $\mathbb{Z}/n\mathbb{Z}$ es cuerpo. Entonces $(a+n\mathbb{Z})(b+n\mathbb{Z}) = 0$ pero esto sería absurdo si $a+n\mathbb{Z},b+n\mathbb{Z}\neq 0$ puesto que un $\mathbb{Z}/n\mathbb{Z}$ es cuerpo y no tiene divisores de cero, así que necesariamente $n$ es primo.

Recíprocamente, supongamos que $n$ es primo, y sea $1 \leq m < n$, entonces se tiene que $mcd(n,m)=1$.  En este caso, sabemos que van a existir $a,b \in \mathbb{Z}$ tales que $an+bm = 1$ por la identidad de Bézout. Por lo tanto, $$(m+n\mathbb{Z})(b+n\mathbb{Z}) = 1+n\mathbb{Z},$$ y tenemos que $m+n\mathbb{Z}$ es invertible.

$\hfill \square$

A este anillo lo podremos denotar indistintamente tanto $\mathbb{Z}/n\mathbb{Z}$ como $\mathbb{Z}/(n)$ tal y como iremos viendo.

\begin{enumerate}
\item Un número entero $p$ es \textit{irreducible} si y solo si es primo, si y sólo si genera un ideal maximal y si y sólo si $\mathbb{Z}/(p)$ es un cuerpo.
\item El anillo $\mathbb{Z}$ es un \textit{dominio de factorización única} (en particular es un $DE$). Todo entero $n >1$ se escribe de manera única como sigue: $$n = p_{1}^{\alpha_{1}} \ldots p_{s}^{\alpha_{s}},$$ con $p_{i}$ números primos conocidos como factores primos de $n$.
\end{enumerate}

Con esto ya podemos pasar a describir los cocientes de $\mathbb{Z}$:

\begin{definition} Sea $n$ un número entero. Llamaremos \textbf{anillo de restos módulo n} al cociente $\mathbb{Z}/(n)$. Como $(n) = (-n)$ al ser $-1$ unidad, podremos suponer que $n \geq 0$. Si $n = 0$ el cociente es el propio $\mathbb{Z}$ y si $n=1$ entonces $(n) = \mathbb{Z}$  y no tendría sentido considerar el cociente. Luego $n >1$.

Sea $k \in \mathbb{Z}$. Denotaremos $[k]_{n}$, ó simplemente $[k]$ si no es necesario especificar, la clase de $k$ $$k + (n) = \lbrace k + qn: q \in \mathbb{Z}\rbrace.$$ 
Para obtener otro representante de la clase de $k$, $[k]$, dividiremos por $n$ y tendremos $k = qn + r$. El resto ha de ser positivo o nulo y esto plantea un problema si $k <0$ (porque recordemos que $k$ es un entero), bastará dividir por exceso en vez de por defecto y ya está. Con esto $k -r = qn \in (n)$, por lo tanto $[k] = [r]$. 

Por ejemplo, en $\mathbb{Z}/(3)$ si $k = -8$ tenemos que $-8 = -3 \cdot 3 + 1$, luego $-8$ pertenece a la clase de $[1]$ y así la clase de $[-8] = [1] = \lbrace \ldots, -11, -8, -5, -2, 1, 4, 7, 10, \ldots \rbrace$ (notar que en $\mathbb{Z}/(3)$ la clase de $8$ no es la de $-8$). 

Consideremos ahora dos restos $0 \leq r < s < n$. Si $[r] = [s]$, entonces $s-r \in (n)$, y así $n \mid (s-r)$, y en particular $n  \leq s-r$. Esto es absurdo porque $s-r \leq s < n$. Por lo tanto, en $\mathbb{Z}/(n)$ cada clase de equivalencia está determinada por un \textbf{único} representante $r$ tal que $0 \leq r <n$, es decir, $$\mathbb{Z}/(n) = \lbrace [0], [1], \ldots, [n-1] \rbrace.$$
En particular, $\mathbb{Z}/(n)$ tiene $n$ elementos. $[0]$ y $[1]$ son el cero y el uno de $\mathbb{Z}/(n)$. Es evidente que si sumamos $n$ veces la clase del uno tenemos: $[1] + \ldots +[1] = [n] = [0]$, y que $-[1] = [-1] = [n-1]$. Con esto recordemos que las igualdades entre clases las podemos escribir como $$k \equiv l \hspace{0.1cm}\text{mod}\hspace{0.1cm} n$$ y viene a decir que $[k] = [l]$, es decir, que $k-l = qn$ con un $q \in \mathbb{Z}$. 

Si nos situamos, por ejemplo, en $\mathbb{Z}/(5)$, tenemos que $[3] + [1] = [4]$, que $[2] + [0] = [2]$ y que $[4]+ [3] = [2]$, además $[2] \cdot [2] = [4]$, $[4] \cdot [1] = [4]$ y $[2] \cdot [4] = [3]$; esto por poner sólo unos ejemplos. En $\mathbb{Z}/(6)$, sin embargo, $[2] \cdot [4] = [2]$ y $[4] + [3] = [1]$.
\end{definition}

Pasemos a ver ahora cómo son los ideales de un anillo de restos:

\begin{definition} Sea $n > 1$. Ya vimos en~\ref{eq:ancoci} que los ideales de $\mathbb{Z}/(n)$ están en biyección con los ideales $I \subseteq \mathbb{Z}$ que contienen $(n)$. Sea entonces un ideal $I = (m) \subseteq \mathbb{Z}$ tal que $(m) \supseteq (n)$. Entonces $m \mid n$, y así los ideales de $\mathbb{Z}/(n)$ están en biyección con aquellos ideales generados por los divisores positivos de $n$ (positivos porque $I = (-m) = (m)$).
\end{definition}

Podemos dar una versión alternativa del teorema chino de los restos:

\begin{theorem}
Si $a,b$ son enteros primos entre sí, entonces se tendrá un isomorfismo de anillos unitarios $$\mathbb{Z}(ab) \cong \mathbb{Z}/(a) \times \mathbb{Z}/(b).$$
\end{theorem}
\emph{Demostración: } Definimos $$\begin{array}{rccl}
f \colon &\mathbb{Z}/(ab)&\longrightarrow &\mathbb{Z}/(a) \times \mathbb{Z}/(b)\\
&[k]_{ab}& \longmapsto &([k]_{a}, [k]_{b}).
\end{array}
$$ Está bien definido, pues si $k \equiv l \hspace{0.1cm} \text{mod} \hspace{0.1cm} ab$ entonces $ab \mid (k-l)$ y así tanto $a$ como $b$ dividen a $k-l$ y tenemos que $k \equiv l \hspace{0.1cm} \text{mod} \hspace{0.1cm} a$ y $k \equiv l \hspace{0.1cm} \text{mod} \hspace{0.1cm} b$. 

Que es homomorfismo es evidente. Es inyectiva, sea $k$ un entero tal que $f([k]_{ab}) = 0$, entonces $([k]_{a}, [k]_{b}) = (0,0)$ y así $$k \equiv 0 \hspace{0.1cm} \text{mod} \hspace{0.1cm} a$$ $$k \equiv 0 \hspace{0.1cm} \text{mod} \hspace{0.1cm} b.$$ Esto quiere decir que $a \mid k$ y $b \mid k$, luego $mcm(a,b) \mid k$, pero como $a$ y $b$ son primos entre sí tenemos que $mcm(a,b) = ab$. Por lo tanto, $ab \mid k$, es decir, $$k \equiv 0 \hspace{0.1cm} \text{mod} \hspace{0.1cm} ab.$$ Luego $ker f = \lbrace 0 \rbrace$ y $f$ es  inyectiva.

Como es una aplicación inyectiva entre dos conjuntos finitos de igual cardinal $ab$ entonces también será biyectiva, y así isomorfismo.

$\hfill \square$

Veamos las unidades de los anillos de restos:

\begin{proposition} Sean $n >1$ y $k \in \mathbb{Z}$. Entonces son equivalentes: \begin{enumerate}
\item $[k] \in \mathcal{U}(\mathbb{Z}/(n)).$
\item $mcd (k,n) = 1.$
\item $[k] \neq 0$ y no es divisor de cero en $\mathbb{Z}/(n)$.
\end{enumerate}
\end{proposition}
\emph{Demostración: } Si $[k]$ es unidad, existirá un $l \in \mathbb{Z}$ tal que $$[1] = [l] \cdot [k] = [lk],$$ y así $1-lk \in (n)$, es decir, $1-lk = mn$ para algún $m \in \mathbb{Z}$. Con esto, $$1 = lk  + mn,$$ y por tanto, $mcd(k,n) = 1$. Tenemos así la primera implicación. Haciendo lo mismo al revés tenemos la implicación inversa y en cualquier anillo $1.\Rightarrow 3.$

Veamos ahora que $3. \Rightarrow 2.$, es decir, dado $mcd(k,n) = d>1$ entonces o bien $[k] = [0]$ o bien es un divisor de cero. Como $$n \mid \left( \dfrac{k}{d}\right) n = k\left( \dfrac{n}{d}\right),$$ o bien $[k] = [0]$, ó $[k]$ es divisor de cero, ó $\left[\dfrac{n}{d} \right] = [0]$, pero en este último caso se tendría que $n \mid \dfrac{n}{d}$ luego $d = 1$, lo cuál contradice la hipótesis.

$\hfill \square$

Con este último resultado del capítulo llegamos a un concepto que ya vimos antes:
 
\begin{definition} Dado un $m$ entero positivo. Denotaremos por $\phi (m)$ el número de enteros $k$ que cumplen: \begin{enumerate}
\item $0 < k \leq m$.
\item $mcd(k,m) = 1$.
\end{enumerate}
Esta aplicación $\phi$ ya la conocemos, es la llamada \textbf{función de Euler}.
\end{definition}

Sobre los anillos la \textit{función de Euler} puede tomar una interpretación diferente: si $n>1$, entonces $\phi(n)$ es el número de unidades de $\mathbb{Z}/(n)$. En efecto, por la proposición anterior $$\mathcal{U}(\mathbb{Z}/(n)) = \lbrace [k]: 0 < k < n, \hspace{0.1cm} mcd(k,n) = 1 \rbrace.$$

Ya sabemos que, dado un primo $p>1$, $\phi(p) = p-1$. Esto está relacionado con el hecho de que si $p$ es primo entonces el cociente $\mathbb{Z}/(p)$ es un cuerpo. Entonces: $$\mathcal{U}(\mathbb{Z}/(p)) = \lbrace [1], \ldots, [p-1] \rbrace.$$

\subsection{Polinomios}

\begin{definition}Sea $A$ un anillo conmutativo y unitario. Diremos que $X$ es una \textbf{indeterminada} ó \textbf{variable} si sus potencias son algebraicamente independientes, es decir, $$\sum_{i=0}^{n} a_{i}X^{i}=0, \hspace{0.2cm} a_{i}\in A \Longleftrightarrow a_0 = \ldots = a_n = 0  \quad\forall n.$$

Un \textbf{polinomio en $X$} con coeficientes en $A$ es una suma finita $$f(X) = a_0+a_1X+\ldots + a_nXn, \hspace{0.1cm} a_0, a_1, \ldots, a_n \in A$$ a la que se puede agregar un número finito y arbitrario de ceros.  
\end{definition}

\begin{definition}Dados polinomios $f(X) = \sum_{i=0}^n a_iX^i$ y $g(X) = \sum_{j=0}^m b_jX^j$ y $s = max\lbrace n,m \rbrace$ definimos su \textbf{suma} por $$f(X) +g(X) = \sum_{k\geq 0}^s(a_k+b_k)X^k = (a_0+b_0)+\ldots + (a_k+b_k)X^k + \ldots + (a_s+b_s)X^s,$$
y su \textbf{producto} como $$f(X)\cdot g(X) = \sum_{k=1}^{n+m}c_k X^k, \hspace{0.2cm} c_k = \sum_{i+j=k}a_ib_j,$$ teniendo en cuenta que si algún coeficiente $a_i$ ó $b_j$ no aparece es $0$.

Así, construimos un nuevo anillo $A[X]$ cuyo \textbf{cero} es $0 = 0X + \ldots + 0X^n$, y cuyo \textbf{uno} es $1 = 1+ 0X + \ldots + 0X^n$. Diremos que $A[X]$ es el \textbf{anillo de polinomios en la variable $X$ con coeficientes en $A$}.
\end{definition}

\begin{observation}Este nuevo anillo, $A[X]$, contiene a $A$ ya que los elementos de $A$ son polinomios de la forma $a = a+0X+\ldots + 0X^n$.
\end{observation}

A partir de ahora supondremos que $A$ es un dominio de integridad.

\begin{definition}Si $0 \neq f(X) = \sum_{i=0}^n a_nX^n \in A[X]$, el \textbf{grado} de $f(X)$ es el mayor entero $n \geq 0$ tal que $a_n \neq 0$ y se denota $\delta (f)$. Los polinomios de grados $0,1,2,3,4$ los llamaremos constantes, lineales, cuadráticos, cúbicos y cuárticos respectivamente.

Diremos que un $a_iX^i$ es el término de grado $i$. El de grado $0$ se denomina \textbf{término independiente}. El coeficiente del término de mayor grado lo llamaremos \textbf{coeficiente director de $f(X)$}. Diremos que un $f(X)$ es mónico si su coeficiente director es una unidad del anillo.
\end{definition}

Ahora, dado $0 \neq f(X_1, \ldots, X_n) \in A[X_1,\ldots, X_n]$ el $grado_{X_i}(f)$ ó $\delta_{X_i}(f)$ es el grado de $f$ como polinomio en $X_i$. El \textbf{\textit{grado total}} de $f = \sum a_{i_1\ldots i_n}X^{i_1}_1\cdots X^{i_n}_n$ es el máximo $\lbrace i_1+\ldots+i_n : a_{i_1 \ldots i_n} \neq 0 \rbrace$.

Por convenio asumiremos que el polinomio cero no tiene grado o que tiene grado $- \infty$.

\begin{proposition} Un anillo de polinomios $A[X]$ es dominio de integridad ($DI$) si y sólo si lo es $A$.
\end{proposition}
\emph{Demostración: }  Como $A$ es subanillo de $A[X]$, el sólo si es claro. Supongamos ahora que $A$ es $DI$. Consideremos la indeterminada $X$ y dos polinomios de $A[X]$: $$f = a_{0} + a_{1}X + \ldots + a_{p}X^{p}, \hspace{0.2cm} g = b_{0} + b_{1}X + \ldots + b_{q}X^{q},$$ vemos que $\delta (f) = p$ y que $\delta (g) = q$, lo que significa que $a_{p} \neq 0$, $b_{q} \neq 0$. Hagamos su producto: $$fg = \sum_{r}^{p+q}c_{r}X^{r} = a_{0}b_{0} + \ldots + (a_{p-1}b_{q} + a_{p}b_{q-1})X^{p+q-1} + a_{p}b_{q}X^{p+q}.$$ Por tanto, $c_{p+q} = a_{p}b_{q} \neq 0$ ya que $A$ es $DI$. Pero esto quiere decir que $fg \neq 0$ pues al menos el coeficiente $c_{p+q}$ es no nulo. Quedaría así probado que $A[X]$ es $DI$.

$\hfill \square$

De esto se deduce que, como hemos considerado que de ahora en adelante $A$ será un dominio de integridad, $A[X]$ va a ser un dominio de integridad.

De hecho, en general general vamos a tener que $\delta(f \cdot g ) \leq \delta(f)+\delta(g)$, pero como $A[X]$ es dominio de integridad entonces: $$\delta(f\cdot g) =  \delta(f)+\delta(g).$$ Además,

\begin{corolario} Si $A$ es un dominio de integridad, entonces $$\mathcal{U}(A) = \mathcal{U}(A[X]).$$
\end{corolario}
\emph{Demostración: } Si $a \in \mathcal{U}(A)$ existirá $a^{-1} \in A$ y $a^{-1}$ será también el inverso de $a$ en $A[X]$, luego $a \in \mathcal{U}(A[X])$. Recíprocamente, sea $f \in \mathcal{U}(A[X])$. Entonces existe $g \in A[X]$ con $1 = fg$ $(\ast)$. Como $A$ es dominio de integridad, tenemos que $$0 = \delta (1) = \delta (fg) = \delta (f) + \delta (g).$$ Esto sólo puede significar que $\delta (f) = \delta (g) = 0$, es decir, $f \in A$ y $g \in A$. Así, por $(\ast)$ $f$ es unidad en $A$.

$\hfill \square$

La división en $A[X]$ está regulada por la conocida como \textbf{\textit{pseudodivisión}}.

\begin{proposition}\label{eq:divPol} Dados $0 \neq f(x), g(x) \in A[x]$, si $a$ es el coeficiente director de $f(x)$, existen un entero $t \geq 0 $ y polinomios $q(x), r(x) \in A[x]$ tales que $a^tg(x) = f(x)q(x)+r(x)$ y ó $r(X) = 0$ ó $\delta (r) < \delta (f)$.
\end{proposition}
\emph{Demostración: }Si $\delta (g) < \delta (f)$,  basta tomar $t = 0$, $q(x) = 0$ y $r(x) = g(x)$. Supongamos $m = \delta(g) \geq \delta(f) = n$ y procedamos por inducción sobre $m$. Sea $b$ el coeficiente director de $g(x)$. Si $m = 0$, se tiene que $g(x) = b$ y $n = 0$. Como $ag(x)=f(x)b$, basta tomar $t=1$, $q(x)=b$ y $r(x)=0$. Si $m >0$, sea $h(x)=ag(x)-bf(x)x^{m-n}$. Como $\delta(h) < \delta(g)=m$, por inducción existen $t'\geq 0$ y $q'(x), r'(x) \in A[x]$ verificando $a^{t'}h(x) = q'(x)f(x) + r'(x)$, donde ó $r'(x) = 0$ ó $\delta(r') < \delta(f)$. Así $a^{t'+1}g(x) = (q'(x)+a^{t'}bx^{m-n})f(x)+r'(x)$ y basta tomar $t = t'+1$, $q(x) = q'(x) + a^{t'}bX^{m-n}$ y $r(x) = r'(x)$.

$\hfill \square$

\begin{corolario}SI $K$ es un cuerpo, $K[x]$ es un dominio euclídeo.
\end{corolario}
\emph{Demostración: }En este caso, el grado es una función euclídea.

$\hfill \square$

\begin{corolario}[\textbf{\textit{Teorema del resto}}] Si $a \in A$ y $f(x) \in A[x]$, el resto de dividir $f(x)$ por $(x-a)$ es $f(a)$. En particular, $f(a) = 0$ si y sólo si $x-a \mid f(x)$.
\end{corolario}
\emph{Demostración: }Aplicamos~\ref{eq:divPol} con $f(x)$ como dividendo y $x-a$ como divisor y después sustituir $x = a$.

$\hfill \square$

La aplicación reiterada del \textit{Teorema del resto} permite deducir una cierta factorización de un polinomio quitándole sus raíces en $A$. Es decir, si $f(x) \in A[x]$ y $a_1, a_2, \ldots, a_r \in A$ son sus raíces en $A$, cada una de ellas apareciendo $m_1, \ldots, m_r$ veces respectivamente, entonces existe $g(x) \in A[x]$ tal que $$f(x) = (x-a_1)^{m_1}\ldots (x-a_r)^{m_r}g(x),$$ donde $g(a) \neq 0$, para todo $a \in A$. Cada factor $x-a_i$ es irreducible, puesto que es mónico de grado $1$, aunque $g(x)$ no tiene por qué serlo. Se tiene que $\delta(f) = m_1+m_2 + \ldots + m_r+\delta(g)$, luego $\sum_i^r m_i \leq \delta(f)$. 
\begin{itemize}
\item \textit{Raíces} en $A$: la condición necesaria para su existencia es la \textit{regla de Ruffini}: $f(x) = a_nx^n+\ldots+ a_1x+a_0 \in A[x]$, $a \in A$ y $f(a)=0 \Rightarrow a \mid a_0$.
\item \textit{Multiplicidades de raíces}: que se caracterizará usando el criterio de la derivada, para ello recordamos que la derivación de polinomios es una aplicación lineal $$\begin{array}{rccl}
&A[x]&\longrightarrow &A[x] \\
&f(x)=\sum_{i=0}^na_iX^i& \longmapsto &f'(x) = \sum_{i=1}^{n-1} ia_ix
\end{array}
$$
Notar que es una aplicación que se puede aplicar tantas veces como queramos, obteniendo las derivadas sucesivas del polinomio: $f''(x), \ldots, f^{(n}(x), \ldots$, esto lo hacemos de forma inductiva: $f^{(0}(x)=f(x)$ y $f^{(n}(x) = (f^{(n-1}(x))'$, con $n >0$. 

Recordamos también las siguientes propiedades de la derivación de polinomios: 
\renewcommand{\theenumi}{\arabic{enumi}}
\begin{enumerate}
\item Si $a\in A$, $a' = 0$.
\item Si $n\geq 1$, $(x^n)' = nx^{n-1}.$
\item $(f(x) + g(x))' = f'+g'$.
\item $(f(x)g(x))' = f'(x)g(x) +f(x)g'(x)$. (\textit{Regla de Leibniz})
\end{enumerate}
Notar que podría ser $f(x)$ no constante y $f'(x)$ nulo. Esto pasaría si $f(x) \in A[x^n]$, con $n$ la característica de $A$. 
\end{itemize}

\begin{proposition}Si la característica de $A$ no divide al grado de $f(x) \in A[x]$, entonces $a \in A$ es una raíz múltiple de $f(x)$ si y sólo si $f(a) =f'(a)=0$.
\end{proposition}
\emph{Demostración: }En general, tenemos que $f(x) = (x-a)^ng(x)$ con $n \geq 0$ y $g(a)\neq 0$. Así, se tiene que $f'(x) = n(x-a)^{n-1}g(X)+(x-a)^ng'(x)$. El resultado se obtiene aplicando el \textit{Teorema del resto}, teniendo en cuenta que $a$ se repite si y sólo si $n >1$.

$\hfill \square$

\begin{definition}Una raíz $a \in A$ de un polinomio $f(X) \in A[x]$ se dice que es \textbf{simple} si $f'(a) \neq 0$ y \textbf{múltiple} en caso contrario. El menor $n \geq 1$ tal que $f^n(a) \neq 0$ se llama \textbf{multiplicidad de $a$} como raíz de $f(X)$. Así, $a$ será simple si y sólo si $n=1$ y múltiple si y sólo si $n > 1$.
\end{definition}

\subsection{Cuerpos y polinomios}

En esta sección presentaremos las bases para luego desarrollar lo que serán las conocidas \textit{extensiones de cuerpos}. Para ello, en lugar de sobre un anillo $A$, en esta sección estudiaremos polinomios sobre un cuerpo $K$.

\begin{proposition} Dado un cuerpo $K$ y $p \in K[x]$. Entonces $p$ es irreducible si y sólo si $K[x]/(p)$ es un cuerpo.
\end{proposition}
\emph{Demostración: }Veamos la primera implicación. Sea $f + (p) \neq (p)$. Veamos que $f + (p)$ tiene inverso. Como $p$ es irreducible, el máximo común divisor de $f$ y $p$ es $1$. Por Bézout, existen $a,b \in K[x]$ tales que $1 = af + bp$. Tendríamos así que $$1 + (p) = (a+ (p))(f+(p)) + (b+(p))(p+(p)) = (a+ (p))(f+(p))$$ ya que $p+(p)=0$. Así, $a+(p)$ es el inverso de $f+(p)$. Luego, $K[x]/(p)$ es un cuerpo.

Recíprocamente, supongamos que $p$ no es irreducible y sea $p = fg$, con $\delta(f) < \delta (p)$ y $\delta(g) < \delta (p)$. $0 =p +(p) = (f+(p))(g+(p))$. Entonces $f + (p)$ y $g +(p)$ serían divisores de cero en $K[x]/(p)$, lo que es imposible porque se trata de un cuerpo. Así, $p$ es irreducible.

$\hfill \square$

\begin{proposition}\label{eq:ac1} Sea $p \in K[x]$ irreducible. Entonces $K$ está contenido en un cuerpo en el que $p$ tiene alguna raíz.
\end{proposition}
\emph{Demostración: } Sea $E = K[x]/(p)$. Entonces sabemos que $E$ es un cuerpo por el resultado anterior. Consideramos la aplicación $$\begin{array}{rccl}
&K[x]&\longrightarrow &K[x]/(p) \\
&f& \longmapsto &f+(p)
\end{array}
$$
Si $0 \neq a \in K$ y $\bar{a}$ es su imagen en $K[x]/(p)$ por la aplicación anterior, $\bar{a} \neq 0$. Así, $K$ es isomorfo a $\bar{K} = \lbrace \bar{a}: a \in K \rbrace$ y podemos identificar $K$ con $\bar{K}$. Si $p = x^{n} + a_{n-1}x^{n-1} + \ldots + a_{1}x + a_{0}$, $p$ considerado como polinomio en $\bar{K}[x]$ es $\bar{p} = x^{n}+ \bar{a}_{n-1}x^{n-1}+ \ldots + \bar{a}_{1}x + \bar{a}_{0}$.

Ahora, $\bar{x} = x +(p)$ es raíz del polinomio $\bar{p}$ en $E= K[x]/(p)$, es decir, $\bar{p}(\bar{x}) = p+(p) = (p) = 0 +(p)$, el cero de $K[x]/(p)$. ($(x^{n}+ \bar{a}_{n-1}x^{n-1}+ \ldots + \bar{a}_{1}x + \bar{a}_{0}) + (p) = (p)$).

$\hfill \square$

\begin{example} Un ejemplo claro y sencillo de lo que nos dice la proposición anterior es el caso de $p(x) = x^{2}+1$. Está claro que $p(x) \in \mathbb{Q}[x]$ y que es irreducible. Entonces, de acuerdo al resultado que acabamos de ver, este cuerpo $\mathbb{Q}$ va a estar contenido en otro en el que $p(x)$ sí tenga alguna raíz. En efecto, en este caso dicho cuerpo va a ser $$\mathbb{Q}(i) = \lbrace a + bi :a,b \in \mathbb{Q} \rbrace.$$ Además, $$\mathbb{Q}[x]/(x^{2}+1) \cong \mathbb{Q}(i).$$
\end{example}

$\hfill \blacksquare$

\begin{proposition}\label{eq:ac2} Sea $p \in K[x]$ y $a \in K$. Entonces $p(a) = 0$ si, y sólo si $x-a \mid p$.
\end{proposition}
\emph{Demostración: } Aplicamos el algoritmo de la división a $p$ y $x-a$: $p=(x-a)q + r$, donde $r = 0$ ó $\delta(r) < \delta(x-a)$. Si $r= 0$ ya está, si no entonces es una constante y como $p(a) = 0 \Leftrightarrow r(a)= 0$ entonces $r = 0$ y así $x-a \mid p$.

$\hfill \square$

\begin{proposition} \label{eq:raimu}
Sea $K$ un cuerpo y $E$ un cuerpo que contenga a $K$. Sea $f \in K[x]$ y $f'$ la derivada de $f$. Supongamos que $f'\neq 0$. Entonces:
\begin{enumerate}
\item Sea $a \in E$ raíz de $f$. Entonces $a$ es raíz múltiple de $f$ si y sólo si $f'(a)=0$.
\item Si $f$ y $f'$ son primos entre sí, $f$ no tiene raíces múltiples en $E$.
\item Si $f \in K[x]$ es irreducible, $f$ no tiene raíces múltiples en $E$.
\item Si $char K = 0$, los polinomios  irreducibles de $K[x]$ no tienen raíces múltiples en $E$.
\item Si $char K = p$, los polinomios irreducibles de $K[x]$ cuyo grado no es múltiplo de $p$ no tienen raíces múltiples en $E$.
\end{enumerate}
\end{proposition}
\emph{Demostración: }
\begin{enumerate}
\item Sea $a$ raíz múltiple de $f$, entonces $f=(x-a)^ng$, con $n >1$ y un $g \in K[x]$. Entonces $f' = n(x-a)^{n-1}g+(x-a)^ng'$ y así $f'(a)=0$. Recíprocamente, si $a$ no fuera raíz múltiple entonces $f=(x-a)g$, con $g(a) \neq 0$ y $f'=g+(x-a)g'$ y $f'(a)=g(a) \neq 0$, absurdo.
\item Por Bézout, existen $g,h \in K[x]$ tales que $1=fg+f'h$. Si fuera $f(a)=f'(a) = 0$ entonces $1(a) = 0$, absurdo. Por el punto $1.$ $f$ no tiene raíces múltiples.
\item Como $f$ es irreducible y $f'\neq 0$, entonces $f$ y $f'$ son primos entre sí y aplicamos el punto anterior.
\item Si $char K = 0$ y $g$ es un polinomio irreducible en $K[x]$, $g$ es no constante y $g'\neq 0$. Aplicamos el punto anterior.
\item Si $char K = p$ y $g$ es un polinomio irreducible en $K[x]$ tal que $p$ no divide a $\delta (g)$, $g'\neq 0$ y aplicamos el punto $3$.
\end{enumerate}
$\hfill \square$

\begin{proposition}[\textbf{\textit{Criterio de Eisenstein}}] Sea $f= a_{0} + a_{1}x + \ldots + a_{n}x^{n} \in \mathbb{Z}[x]$. Supongamos que existe $p$ primo tal que $p \mid a_{i}$, con $0 \leq i \leq n-1$, $p \nmid a_{n}$ y $p^2 \nmid a_{0}$. Entonces $f$ es irreducible en $\mathbb{Q}[x]$.
\end{proposition} 


\subsection{Raíces de la unidad} \label{eq:raicesUnidad}

A las raíces del polinomio $f(x) = x^{n}-z \in \mathbb{C}[x]$, con $z \in \mathbb{C}$ y $n \geq 1$ las denominamos \textbf{\textit{raíces complejas de la unidad}}. Como, para $n \geq 2$, el polinomio derivado $f'(x) = nx^{n-1}$ tiene como única raíz el cero y los polinomios $f(x)$ y $f'(x)$ no tienen raíces en común, entonces todas las raíces $n$-ésimas de $z$ son todas distintas. Para determinarlas, usaremos la conocida como \textbf{\textit{fórmula de De Moivre}} para la multiplicación de números complejos en forma trigonométrica: $$(\cos(x) + i\sin(x))^{n} = \cos(nx) + i\sin(nx).$$ Si $$z_{1} = \rho_{1}(\cos (\theta_{1}) +i\sin (\theta_{1})) \hspace{0.2cm}z_{2} = \rho_{2}(\cos (\theta_{2}) +i\sin (\theta_{2})),$$ con $\rho_{1}, \rho_{2}$ reales positivos, ahora usando propiedades de las funciones trigonométricas tenemos que:
$$z_{1}z_{2} = \rho_{1}\rho_{2}(\cos(\theta_{1} + \theta_{2}) + i \sin(\theta_{1} + \theta_{2})).$$ Ahora podemos simplificar y hacer que $z = \rho (\cos(\theta) + i\sin(\theta))$, con $\rho > 0$. Si $\zeta = \sigma (\cos(\varphi) + i\sin(\varphi)) $ es una raíz $n$-ésima de $z$, entonces tiene que ser que $$\sigma^{n}(\cos(n\varphi) + i\sin(n\varphi)) = \rho (\cos(\theta)+ i\sin(\theta)),$$ de lo que deducimos que $\sigma^{n} = \rho$ y $n\varphi = \theta +2k\pi$, con $k \in \mathbb{Z}$, es decir, $$\sigma = \sqrt[n]{\rho}, \hspace{0.2cm} \varphi = \dfrac{\theta+2k\pi}{n}.$$
De todo esto concluimos que las raíces complejas $n$-ésimas de $z = \rho(\cos(\theta) + i\sin(\theta))$ se obtienen para $k = 0, 1, \ldots, n-1$ y son precisamente los números complejos $$ (\ast) \hspace{0.3cm}\zeta_{k} = \sqrt[n]{\rho} \hspace{0.1cm}\left(\cos\left(\dfrac{\theta+2k\pi}{n}\right) + i\sin\left(\dfrac{\theta+2k\pi}{n}\right)\right).$$

Por ejemplo, si tenemos $z = 3i= 3\left(\cos \left( \dfrac{\pi}{2})\right) + i\sin \left( \dfrac{\pi}{2} \right)\right)$ y queremos calcular sus raíces cuadradas, entonces \begin{center}$\zeta_{0} = \sqrt{3} \left( \cos \left( \dfrac{\pi}{4}\right) + i \sin \left( \dfrac{\pi}{4}\right)\right) = \dfrac{\sqrt{6}}{2} + \dfrac{\sqrt{6}}{2}i, \hspace{0.2cm} \zeta_{1} = \sqrt{3}\left( \cos \left( \dfrac{5 \pi}{4}\right) + i \sin \left( \dfrac{5 \pi}{4}\right)\right) =- \dfrac{\sqrt{6}}{2} - \dfrac{\sqrt{6}}{2}i.$\end{center}

Otro ejemplo, las raíces terceras de $1 + i = \sqrt{2}\left(\cos \left( \dfrac{\pi}{4})\right) + i\sin \left( \dfrac{\pi}{4} \right)\right)$ entonces se tiene que $$ \zeta_{0} = \sqrt[6]{2}\left(\cos \left( \dfrac{\pi}{12})\right) + i\sin \left( \dfrac{\pi}{12} \right)\right),$$ $$\zeta_{1} = \sqrt[6]{2}\left(\cos \left( \dfrac{3 \pi}{4})\right) + i\sin \left( \dfrac{3 \pi}{4} \right)\right),$$ $$\zeta_{2} = \sqrt[6]{2}\left(\cos \left( \dfrac{17 \pi}{12})\right) + i\sin \left( \dfrac{17 \pi}{12} \right)\right).$$

Ahora, hemos visto (o más bien recordado brevemente) cómo se calculan las raíces en general de cualquier número complejo. Pero las que nos van a interesar a lo largo del texto van a ser las raíces de $z = 1$, es decir, las \textbf{\textit{raíces complejas $n$-ésimas de la unidad}}. Vamos, por tanto, a tener el número complejo $z = 1 = \cos(2\pi) + i \sin (2\pi)$. Utilizando ahora $(\ast)$ llegamos a la fórmula para calcular las raíces de la unidad: $$\zeta_{k} = \cos \left( \dfrac{2k\pi}{n} \right) + i\sin \left( \dfrac{2k\pi}{n} \right), \hspace{0.2cm} k = 1, \ldots n.$$
Notar que $k$ va de $1$ hasta $n$ y que sería equivalente a que fuera desde $0$ hasta $n-1$. Notar también que la fórmula de los $\zeta_{k}$ la podemos reescribir como $e^{2\pi k i/n}$.

De esto, lo primero que observamos es que empleando nuevamente la fórmula de De Moivre, resulta que $\zeta_{1}^{k} = \zeta_{k}$, donde $$\zeta_{1} =  \cos \left( \dfrac{2\pi}{n} \right) + i\sin \left( \dfrac{2\pi}{n} \right) = \xi,$$ y así podemos llegar a escribir todas las $n$-ésimas raíces de la unidad como $$\zeta_{1} = \xi, \hspace{0.1cm} \zeta_{2} = \xi^{2}, \ldots, \hspace{0.1cm} \zeta_{n-1} = \xi^{n-1}, \hspace{0.1cm}\zeta_{n} = \xi^{n} = 1.$$

Así, es claro cómo las raíces forman un grupo cíclico de orden $n$.

\section{Extensiones de Cuerpos}

Nos encuadramos en una área de las matemáticas donde las estructuras algebraicas son fundamentales de conocer, en este caso, y durante todo el texto, conocer los grupos y anillos es imprescindible. Y como ya sabemos, un tipo concreto de anillo son los cuerpos, en los que se cumple que todo elemento no nulo es una unidad, o dicho de otra manera, el grupo de las unidades es el propio anillo a excepción del cero. 

Nosotros nos vamos a parar a estudiar estas estructuras, cómo se relacionan entre ellas (veremos similitudes con grupos en algunos casos) y cómo se relacionan con la \textit{Teoría de Galois}. Sin más comencemos:

\subsection{Generalidades}
\begin{definition} Dados dos cuerpos $E,K$, diremos que $E$ es una extensión de un cuerpo $K$ si existe un monomorfismo de cuerpos $\varphi \colon K \longrightarrow E$. Dicho de otra forma, si $K$ es un subcuerpo de $E$. A las extensiones las denotaremos por $E/K$.
Además, se cumplirá que $E$ es un $K-$espacio vectorial. A la dimensión de este $K-$espacio vectorial la denotaremos por $dim_{K}E$. Si $dim_{K}E$ es finita, se dice que la extensión $E/K$ es \textbf{finita} y $dim_{K}E$ se escribirá como $| E : K|$ y se denominará \textbf{grado} de la extensión.
\end{definition}

Dada una extension $E/K$, $E$ tendrá una estructura de espacio vectorial sobre $K$. Para ver esto simplemente hay que considerar las operaciones $+$, $\cdot$ y partir de un grupo abeliano $(E, +)$. Al ser $K$ un subcuerpo de $E$ las operaciones anteriores inducen las de $K$. En este grupo definimos la siguiente operación: $$(\lambda, a) \longmapsto \lambda a = \lambda \cdot a, \hspace{0.2cm} \lambda \in K, a \in E,$$ con $\lambda \cdot a$ el producto de elementos habitual en $E$. Como además, $1_{K} = 1_{E}$ por ser $K$ subcuerpo, entonces se va a tener que $1_{K} \cdot x = x$ $\forall x$. Así es fácil ver que, con lo anterior, tenemos una estructura de espacio vectorial.

\begin{example} Veamos algunos ejemplos de extensiones conocidas: \begin{enumerate}
\item $|\mathbb{R} : \mathbb{Q}| = \infty$, pues en caso de que fuese un natural $n$ cualquiera entonces $\mathbb{R} \simeq \mathbb{Q}^{n}$ y $\mathbb{R}$ sería numerable.
\item $|\mathbb{C} : \mathbb{R} | = 2$, puesto que $\lbrace 1, i \rbrace$ es una base de $\mathbb{C}$ como $\mathbb{R}$-espacio vectorial.
\item Si $E$ es una extensión de $K$, entonces $|E : K | = 1$ si y sólo si $E = K$.
\end{enumerate}
\end{example}

$\hfill \blacksquare$

Veamos que ocurre si intentamos encadenar extensiones:

\begin{proposition} \label{eq:trgr} Sea $E$ una extensión de $L$, y a su vez $L$ una extensión de $K$. Diremos entonces que $L$ es un cuerpo intermedio, ya que se tiene que $K \subseteq L \subseteq E$. Entonces $E/K$ es finita si y sólo si $E/L$ y $L/K$ lo son. En este caso, se tiene $$|E: K| = |E:L| |L:K|.$$
\end{proposition}
\emph{Demostración: } Partimos primero de que $E/K$ es finita, entonces $|E:K|$ es finita y que $L$ como $K$-espacio vectorial esté contenido en $E$ $K$-espacio vectorial implica que $dim_{K} L \leq dim_{K} E < \infty$, es decir, $|L:K|$ es finito. Por otro lado, si $B = \lbrace u_{1}, \ldots, u_{n}\rbrace$ es una base de $E$ como $K$-espacio vectorial y $v \in E$, entonces $v = \sum_{i} k_{i}u_{i}$, con los $k_{i} \in K \subseteq L$. Así, $B$ genera $E$ como $L$-espacio vectorial, es decir, $dim_{L}E$ es finita y así $|E:L|$ también.

Recíprocamente, si $|L:K| = s$ y $|E:L| = r$, sean $\lbrace l_{1}, \ldots, l_{s} \rbrace$ y $\lbrace e_{1}, \ldots, e_{r} \rbrace$ bases de $L$ como $K$-espacio vectorial y $E$ como $L$-espacio vectorial respectivamente. Veamos ahora que $U= \lbrace v_{ij} : v_{ij} = l_{i}e_{j}, \hspace{0.1cm} \forall i,j \rbrace$ es una base de $E$ como $K$-espacio vectorial. En efecto, si $m \in E$, $m = \sum_{j}^{r}d_{j}e_{j}$, con $d_{j} \in L$, y a su vez $d_{j} = \sum_{i}^{s}c_{ji}l_{i}$, con los $c_{ji} \in K$. Por lo tanto, $$m = \sum_{j=1}^{r} \left(\sum_{i=1}^{s} c_{ji}l_{i}\right) e_{j} = \sum_{j=1}^{r} \sum_{i=1}^{s}c_{ji}v_{ij}, \hspace{0.2cm} c_{ji} \in K.$$ Con esto, $U$ genera el $E$ $K$-espacio vectorial. Ahora veamos que $U$ es también linealmente independiente, para ello supongamos que $$0 = \sum_{j=1}^{r} \sum_{i=1}^{s} c_{ji}v_{ji} = \sum_{j=1}^{r}\left(\sum_{i=1}^{s} c_{ji}l_{i}\right) e_{j}, \hspace{0.2cm} c_{ji} \in K.$$ Como $\lbrace e_{1}, \ldots, e_{r} \rbrace$ es una base de $E$ como $L$-espacio vectorial tenemos que $\sum_{i}^{s} c_{ji}l_{i} = 0$ para todo $j=1, \ldots, r$. Y como $\lbrace l_{1}, \ldots, l_{s} \rbrace$ es una base de $L$ como $K$-espacio vectorial entonces $c_{ji} = 0$ también para todo $i = 1, \ldots, s$. Así, es linealmente independiente, y además $$|E:K| = rs = |E:L| |L:K|.$$

$\hfill \square$

\begin{proposition}\label{eq:propprinp} Sean $E_{1}/K_{1}$, $E_{2}/K_{2}$ extensiones, y $\sigma \colon E_{1} \longrightarrow E_{2}$ un isomorfismo de cuerpos. Si $K_{2} = \sigma (K_{1})$, entonces $$|E_{1}:K_{1}| = |E_{2}:K_{2}|.$$
\end{proposition}

Veamos ahora alguna definiciones:
\begin{definition}\label{defac} Sea $E$ una extensión de $K$, y sean $f(x) = \sum_{i} k_{i}x^{i} \in K[x]$ y $a \in E$. Diremos que $a$ es una \textbf{raíz} de $f$ si $f(a) = \sum_{i} k_{i}a^{i} = 0$.
\end{definition}

Llegados  a este punto hay que aclarar que, como una extensión la hemos definido al fin y al cabo como un monomorfismo (una inyección) de un cuerpo en otro, estamos cometiendo un abuso de notación al identificar los $k_{i}$ anteriores con los $\varphi (k_{i})$. En realidad deberíamos poner $f(a)$ como $f^{\varphi} (a) = \sum_{i} \varphi(k_{i}) a^{i}$.

Ahora, una observación que ya conocemos del capítulo anterior:
\begin{observation} Sea $E/K$ una extensión, y $a \in E$ una raíz de un polinomio $f$ de $K[x]$. Entonces $f(x) = (x-a)g(x)$, con $g \in E[x]$.
\end{observation} 

\begin{definition} Sea $E/K$ una extensión y $X \subseteq E$. Entonces $K(X)$ es la intersección de los subcuerpos de $E$ que contienen a $K$ y a $X$, es decir, el menor subcuerpo de $E$ que contiene a $K$ y a $X$.
\end{definition}

\begin{proposition} \label{eq:kalfa} Sea $E/K$ una extensión y $\alpha \in E$. Entonces $$K (\alpha) = \left\lbrace \dfrac{f(\alpha)}{g(\alpha)} : f,g \in K[x], g(\alpha) \neq 0 \right\rbrace.$$
\end{proposition}

Además, por inducción podemos definir $K(\alpha_{1}, \ldots, \alpha_{n} ) = K(\alpha_{1}, \ldots, \alpha_{n-1})(\alpha_{n}).$

Un resultado que se desprenden de forma inmediata de la transitividad del grado de las extensiones y de la noción que acabamos de ver es el siguiente:

\begin{proposition} Sea $E/K$ una extensión de cuerpos, finita, y $|E:K|$ un número primo. Entonces cada elemento $\alpha \in E \setminus K$ cumple que $E = K(\alpha)$.
\end{proposition}
\emph{Demostración: } Aplicando~\ref{eq:trgr} a los cuerpos $K \subseteq K(\alpha) \subset E$ tenemos que $$|E:K| = |E: K(\alpha)| |K(\alpha) : K|$$ y como $|E:K|$ es un número primo y $|K(\alpha) :K| \neq 1$ ya que $\alpha \notin K$, entonces se tiene que $|E:K(\alpha)| = 1$, es decir, que $E = K(\alpha)$ $\forall \alpha \in E \setminus K$.

$\hfill \square$

\begin{definition} Sea  $E/K$ una extensión y $\alpha \in E$. Diremos que $\alpha$ es \textbf{algebraico} sobre $K$ si existe un $p \in K[x]$ no nulo tal que $p(\alpha) = 0$, es decir, que $\alpha$ sea una raíz de $p$. Si $\alpha$ no es algebraico sobre $K$ se dice entonces que es \textbf{trascendente}. La extensión $E/K$ se dirá \textbf{algebraica} si todo elemento de $E$ es algebraico sobre $K$.
\end{definition}
\begin{example} Algunos ejemplos: \begin{enumerate}
\item Si $\alpha \in K$, entonces $\alpha$ es algebraico sobre $K$. En particular, será raíz de $f(x) = x-\alpha$.
\item $\sqrt{2}$ es algebraico sobre $\mathbb{Q}$, ya que es raíz de $x^{2}-2$.
\item Los números $e$ y $\pi$ son trascendentes  sobre $\mathbb{Q}$.
\item El número $\alpha = \sqrt{2 + \sqrt{5}}$ es algebraico sobre $Q$, pues $\alpha^{2} = 2 + \sqrt{5}$, es decir, $\alpha^{2}-2 = \sqrt{5}$, y entonces $\alpha^{4}-4\alpha^{2}-1 = 0$. Por tanto, $\alpha$ es raíz del polinomio $p(x) = x^{4}-4x^{2}-1 \in \mathbb{Q}[x]$.
\end{enumerate}
\end{example}

$\hfill \blacksquare$

\begin{proposition} Toda extensión finita es algebraica.
\end{proposition}
\emph{Demostración: } Sea $E/K$ finita y $n = |E:K|$. Si $\alpha \in E$, la familia $\lbrace 1, \alpha, \ldots, \alpha^{n} \rbrace$ tiene $n+1$ elementos (iguales o repetidos). Como $dim_{K} E = n$, dicha familia tiene que ser linealmente dependiente. Así, existen $t_{0}, t_{1}, \ldots, t_{n} \in K$ no todos nulos tales que $t_{0}1 + t_{1}\alpha + \ldots + t_{n}\alpha^{n} = 0$. Sea $p(x) = t_{0} + t_{1}x + \ldots + t_{n}x^{n}$. Entonces $p(x) \in K[x]$, $p(x) \neq 0$ y $p(\alpha) = 0.$

$\hfill \square$

Es interesante ver que, como hemos dicho, dada una extensión $E/K$ de grado $n$ y un $\alpha \in E$, entonces la familia $\lbrace 1, \alpha, \ldots, \alpha^{n} \rbrace$ va a ser linealmente dependiente. Más adelante veremos qué significa esta familia, qué hay que hacer para convertirla en linealmente independiente y si será base de algo, ya que al fin y al cabo estamos hablando de espacios vectoriales.

Ahora, estudiaremos un resultado que nos dice que a cada cuerpo le podemos asignar una extensión que contendrá una raíz de un polinomio de su anillo de polinomios.

\begin{proposition} Sea $K$ un cuerpo y sea $f \in K[x]$, con $\delta(f) > 0$. Entonces existen una extensión $E$ de $K$ y $\alpha \in E$ tal que $\alpha$ es raíz de $f$.
\end{proposition}
\emph{Demostración: } Como $K[x]$ es un dominio de factorización única, factorizamos $f$ como producto de polinomios irreducibles en $K[x]$. Sea $p(x) = \sum_{i}^{n}a_{i}x^{i}$ uno de los factores irreducibles de $f$ y consideremos el ideal $I$ generado por $p$ en $K[x]$. Entonces $E = K[x]/I$ es un cuerpo y podemos ver que el homomorfismo $$\begin{array}{rccl}
\varphi \colon &K&\longrightarrow &E \\
&a& \longmapsto &a + I,
\end{array}
$$ es un monomorfismo de cuerpos. En efecto, $\varphi (a) = 0$ quiere decir que $a \in I$, es decir, que $p(x)$ divide a $a$. Como $\delta (p) \geq 1$ y $a \in K$, tenemos que $a = 0$.

Ahora, veamos que existe $\alpha \in E$ tal que $p(\alpha) = 0$ (o dicho de otra forma, que $p^{\varphi} (\alpha) = I$). En efecto, sea $\alpha = x + I \in E$. Entonces $p^{\varphi} (\alpha) = \sum_{i}^{n}\varphi(a_{i})\alpha^{i} = \sum_{i}^{n}(a_{i} + I) (x + I)^{i} = \sum_{i}^{n}(a_{i} + I) (x^{i} + I) = \sum_{i}^{n}a_{i}x^{i} + I = p(x) + I = I,$ es decir, $p(\alpha) = 0$. Como $p$ divide a $f$, $f(\alpha) = 0$.

$\hfill \square$

\begin{corolario}Sea $K$ un cuerpo y sea $f \in K[x]$, con $\delta(f) > 0$. Entonces existe una extensión $E$ de $K$ tal que $f$ tiene todas sus raíces en $E$.
\end{corolario}
\emph{Demostración: } Por el resultado anterior existen una extensión $K_{1}$ de $K$ y $\alpha_{1} \in K_{1}$ tal que $f(\alpha_{1}) = 0$. Luego $f(x) = (x-\alpha_{1})f_{1}(x)$ en $K_{1}[x]$. Si aplicamos nuevamente el resultado anterior a $f_{1}(x)$ obtendremos una extensión $K_{2}$ de $K_{1}$ y $\alpha_{2} \in K_{2}$ tal que $f_{1}(\alpha_{2}) = 0$ (es decir, $f(\alpha_{2}) = 0$). Si continuamos haciendo esto obtendremos $$f(x) = e(x-\alpha_{1})(x-\alpha_{2}) \ldots (x-\alpha_{n}).$$ Donde $\alpha_{i} \in K_{i}$, $e \in K$, con los $K_{i}$ las sucesivas extensiones, que cumplen: $$K \subseteq K_{1} \subseteq \ldots \subseteq K_{n-1} \subseteq K_{n}.$$

$\hfill \square$

Veremos más adelante que este tipo de descomposiciones serán de gran importancia, y cuando ocurra diremos que $E$ es un \textit{cuerpo de escisión de $f$ sobre $K$}.

\begin{corolario} \label{eq:preclau} Si $K$ es un cuerpo, y $\lbrace f_{1}, f_{2}, \ldots, f_{m} \rbrace \subseteq K[x]$, con $\delta (f_{i}) \geq 1$ $\forall$ $i$, entonces existirá una extensión $E$ de $K$ que contiene a todas las raíces de $f_{i}$ $\forall$ $i$.
\end{corolario}

Ahora, dada una extensión $E/K$ y un  elemento $\alpha \in E$, una forma alternativa a~\ref{eq:kalfa} de ver $K(\alpha)$ es como la intersección de todos los cuerpos intermedios que contengan a ese elemento, es decir $$K(\alpha) = \bigcap \lbrace L: L \hspace{0.2cm} \text{cuerpo}: K \subseteq L \subseteq E,\hspace{0.1cm} \alpha \in L\rbrace.$$

Ahora para ver qué pasa si $|K(\alpha) : K| = \infty$ recordemos que, dado un cuerpo cualquiera $K$, su cuerpo de fracciones $K(x)$ es de la forma: $$K(x) = \left\lbrace \dfrac{f}{g} : f,g \in K[x], g\neq 0 \right\rbrace.$$

\begin{proposition} Sea $E/K$ una extensión, $\alpha \in E$ trascendente, entonces $|K(\alpha): K| = \infty$ y $K(\alpha) \cong K(x)$.
\end{proposition}
\emph{Demostración: } Consecuencia de que, en este caso al ser $\alpha$ trascendente, la aplicación $$\begin{array}{rccl}
\theta \colon &K(x)&\longrightarrow &K(\alpha) \\
&\dfrac{p(x)}{q(x)}& \longmapsto &\dfrac{p(\alpha)}{q(\alpha)}
\end{array}
$$ es un isomorfismo de cuerpos y de espacios vectoriales sobre $K$.

$\hfill \square$

Sabemos que si $K$ es un cuerpo, entonces también será un dominio de ideales principales ($DIP$), es decir, que cualquier ideal de $K$ estará generado por un sólo elemento, que será mónico.

\begin{definition} Sea $E/K$ y $\alpha \in K$ algebraico sobre $K$, llamaremos \textbf{polinomio irreducible de $\alpha$ sobre $K$} al único generador mónico del ideal $I = \lbrace f \in K[x]: f(\alpha) = 0 \rbrace$. Este polinomio se denotará por $Irr(\alpha, K)$ y su grado se denomina \textbf{grado de $\alpha$ sobre $K$}.
\end{definition}

Es importante observar que $Irr(\alpha, K)$ siempre existe, ya que $K[x]$ es $DIP$. Además, su grado es el menor posible entre los polinomios no nulos de $K[x]$ de los cuales $\alpha$ es raíz. Es decir, $Irr(\alpha, K)$ \textbf{\textit{es el polinomio mónico irreducible de menor grado posible de $K[x]$ que tiene a $\alpha$ por raíz.}}

Recordemos antes de ver el siguiente resultado que, dado un anillo conmutativo y unitario $A$, un elemento cualquiera $f$ de $A[x]$ es irreducible en $A[x]$ si: \begin{enumerate}
\item $f$ no es invertible en $A[x]$.
\item Si $f = qp$, con $q,p \in A[x]$, entonces $q$ es invertible o $p$ lo es.
\end{enumerate}

\begin{proposition} Sea $E/K$ una extensión, $\alpha \in K$ algebraico sobre $K$ y $Irr(\alpha, K)$. Entonces: \begin{enumerate}
\item $Irr(\alpha, K)$ es irreducible sobre $K$.
\item Si $\delta(Irr(\alpha, K)) = n$, entonces $\lbrace 1, \alpha, \alpha^{2}, \ldots, \alpha^{n-1} \rbrace$ es base de $K(\alpha)$ sobre $K$. Así, $K(\alpha) = K + \alpha K + \ldots + \alpha^{n-1} K.$
\item $|K(\alpha) : K| = n = \delta (Irr(\alpha, K)).$
\item Si $q$ es un polinomio mónico irreducible en $K[x]$ y $\alpha$ es raíz de $q$, entonces $q = Irr(\alpha, K)$.
\end{enumerate}
\end{proposition}
\emph{Demostración: }Vamos a llamar a  $Irr(\alpha, K) = p(x)$ y a definir que  $I = \lbrace f \in K[x] : f(\alpha) = 0\rbrace = (p).$ \begin{enumerate}
\item $p(x)\notin K$ pues es no nulo. Además, si $p(x) = h(x) g(x)$ en $K[x]$, se tendría que $0 = p(\alpha) = h(\alpha) g(\alpha)$ y por ejemplo  tomemos $h(\alpha) = 0$. Entonces $h \in I$, es decir, que existiría $f \in K[x]$ tal que $pf = h$, por lo que $p = pfg$ en $K[x]$. De esto se deduce que $1 = fg$ y así $g$ es invertible, por tanto $p$ irreducible. Análogo si $g(\alpha)=0$.
\item  Si $\sum_{i= 0}^{n-1}c_{i}\alpha^{i} = 0$, con $c_{i} \in K$ y algún $c_{i}$ es no nulo, entonces $\alpha$ sería raíz de $k(x) = \sum_{i = 0}^{n-1}c_{i}x^{i}$, es decir, $k \in I$ , lo cual es absurdo, ya que $\delta (k) \leq n-1.$ Por lo tanto, $c_{i} = 0$ $\forall i$ y así la familia $\lbrace 1, \alpha, \ldots, \alpha^{n-1} \rbrace$ es linealmente independiente (esto tiene sentido con lo que vimos al demostrar que toda extensión finita es algebraica). Veamos ahora que genera $K(\alpha)$. Como $$K \subseteq T = K + \alpha K + \ldots + \alpha^{n-1} K \subseteq K(\alpha),$$ para ver que $K(\alpha) \subseteq K + \alpha K + \ldots + \alpha^{n-1} K$ bastará con ver que esto último, $T$, es un cuerpo. Lo veremos en dos partes: 

Primero, $p(\alpha) = 0$ y si $p(x) = x^{n} + k_{n-1}x^{n-1} + \ldots + k_{0}$, entonces $\alpha^{n} = -k_{0} - k_{1}\alpha - \ldots - k_{n-1}\alpha^{n-1} \in T$. Luego $\alpha^{n+1} \in \alpha T \subseteq  \alpha K + \ldots + \alpha^{n-1} K + \alpha^{n} K \subseteq T + \alpha^{n} K \subseteq T + T E \subseteq T + T \subseteq T.$ En general se tiene así que los $\alpha^{i} \in T$ $\forall i \geq n$, y como $1, \alpha, \ldots, \alpha^{n-1} \in T$ entonces $\alpha^{i} \in T$ $\forall i \geq 0$.

Segundo, de lo que acabamos de ver se deduce que $T$ es cerrado para la suma y el producto, y es fácil ver que es anillo unitario. Ahora, si $0 \neq t \in T$, $t = \lambda_{0} + \lambda_{1} \alpha + \ldots + \lambda_{n-1} \alpha^{n-1}$, con $\lambda_{i} \in K$, veamos que $t$ es invertible en $T$. Si $v(x) = \lambda_{0} + \lambda_{1} x + \ldots + \lambda_{n-1} x^{n-1}$, entonces $v(\alpha) = t \neq 0$ y $v(x) \notin I$, es decir, $p$ no divide a $v(x)$. Como $p$ es irreducible, resulta que $p$ y $v(x)$ son coprimos, y por Bézout existirán $q,r \in K[x]$ tales que $1 = rv + qp$. Ahora, $1 = r(\alpha)v(\alpha) + q(\alpha) p(\alpha) = r(\alpha) t$, con $r(\alpha) \in T$, y así $t$ es invertible en $T$.
\item De la segunda parte del apartado anterior se tiene que $\lbrace 1, \alpha, \alpha^{2}, \ldots, \alpha^{n-1} \rbrace$ es base de $K(\alpha)$ sobre $K$, con $n = \delta (Irr(\alpha K))$, por lo que $|K(\alpha) : K| = n = \delta (Irr(\alpha, K))$. 
\item Como $q \in I$, $q = rp$ con $r \in K[x]$. Al ser $q$ irreducible en $K[x]$ se tiene que cumplir que $\delta (q) = \delta (p)$ ó bien $\delta (q) = \delta (r)$. En el primer caso, $r$ es constante y como $q$ y $p$ son ambos mónicos entonces son iguales. En el segundo caso, $p$ sería constante y así reducible, lo cual es absurdo.
\end{enumerate}

$\hfill \square$

De lo último además se puede deducir que, dado un $q \in K[x]$ cualquiera, $q(\alpha) = 0$ si y sólo si $Irr(\alpha, K) \mid q.$


Ahora, bajo las mismas condiciones que en el anterior resultado, se va a tener que $K(\alpha) = \lbrace f(\alpha) : f \in K[x] \rbrace$. En efecto, si consideramos una aplicación $$\begin{array}{rccl}
\varphi \colon &K[x]&\longrightarrow &E \\
&f& \longmapsto &f(\alpha).
\end{array}
$$ Como $Ker \hspace{0.1cm} \varphi = (p)$ (el pol. irreducible) y $p$ es irreducible, $K[x]/Ker \hspace{0.1cm} (\varphi)$ es un cuerpo. Por el \textit{Primer Teorema de Isomorfía de anillos}, $\varphi (K[x])$ también será un cuerpo, y $\varphi(K[x]) = \lbrace f(\alpha) :f \in K[x] \rbrace.$ Como $\lbrace f(\alpha) : f \in K[x] \rbrace \subseteq K(\alpha)$, entonces $K(\alpha) = \lbrace f(\alpha) : f \in K[x] \rbrace$.
\begin{corolario}\label{eq:cor1} Sea $E/K$ una extensión y $\alpha \in E$, entonces $\alpha$ es algebraico sobre $K$ si y sólo si $|K(\alpha) : K|$ es finito.
\end{corolario}

\begin{corolario} Sea $E/K$ una extensión, $\alpha \in E$ y $|E:K| = m$, entonces el grado de $\alpha$ sobre $K$ divide a $m$.
\end{corolario}
Visto ya cómo conseguir una base de una extensión, y que para ello necesitaremos encontrar un polinomio irreducible sobre un cuerpo, importante remarcar el hecho de que sea irreducible, para comprobarlo disponemos de algunos criterios como el visto anteriormente, el criterio de Eisenstein. Ahora unos ejemplos: 

\begin{example} Veamos algunos casos de polinomios irreducibles: \begin{enumerate}
\item Si consideramos la extensión $\mathbb{Q}(i)/\mathbb{Q}$, entonces $x^{2}+1 \in \mathbb{Q}[x]$ es irreducible, mónico y tiene a $i$ por raíz, luego es el polinomio irreducible de $i$ sobre $\mathbb{Q}$. Por la proposición anterior $\lbrace 1, i \rbrace$ es una base de $\mathbb{Q}(i)$ sobre $\mathbb{Q}$, así $$\mathbb{Q}(i) = \lbrace a+bi : a,b \in \mathbb{Q} \rbrace.$$

\item $x^{2}-2 = Irr(\sqrt{2}, \mathbb{Q})$, $|\mathbb{Q}(\sqrt{2}) : \mathbb{Q} | = 2$ y $\mathbb{Q}(\sqrt{2}) = \lbrace a+b\sqrt{2}: a,b \in \mathbb{Q} \rbrace$.
\item $x^{2}-3 = Irr(\sqrt{3}, \mathbb{Q})$, $|\mathbb{Q}(\sqrt{3}) : \mathbb{Q}| = 2$ y $\mathbb{Q}(\sqrt{3}) = \lbrace a+b \sqrt{3}: a,b \in \mathbb{Q} \rbrace$.
\item El polinomio irreducible de $\sqrt{3}$ sobre $\mathbb{Q}(\sqrt{2})$ tiene que tener a $\sqrt{3}$ por raíz, sabemos que $x^{2}-3$ lo tiene y podemos intentar ver si es irreducible sobre $\mathbb{Q}(\sqrt{2})[x]$ (lo es en $\mathbb{Q}[x]$ pero eso no nos asegura nada). 

Si fuera reducible tendría que tener alguna raíz en $\mathbb{Q}(\sqrt{2})$, luego $\pm \sqrt{3} \in \mathbb{Q}(\sqrt{2})$ y así $\sqrt{3} = a+b\sqrt{2}$, con $a,b \in \mathbb{Q}$, es decir, que $\sqrt{3} -b \sqrt{2} = a \in \mathbb{Q}$. Si elevamos al cuadrado: $$3+2b^{2}-2b\sqrt{6} = a^{2} \in \mathbb{Q},$$ de lo que deducimos que $b\sqrt{6} \in \mathbb{Q}$, ya que $\mathbb{Q}$ es un cuerpo. Pero como $\sqrt{6} \notin \mathbb{Q}$ sólo puede ser $b = 0$, y así $\sqrt{3} = a \in \mathbb{Q}$, lo cual es absurdo. Por lo tanto, $x^{2}-3$ es irreducible en $\mathbb{Q}(\sqrt{2})[x]$, y así $Irr(\sqrt{3}, \mathbb{Q}(\sqrt{2}))=x^{2}-3$, luego $|\mathbb{Q}(\sqrt{2}, \sqrt{3}) : \mathbb{Q}(\sqrt{2})| = 2$. Notar que así: $$|\mathbb{Q}(\sqrt{2},\sqrt{3}):\mathbb{Q}| = |\mathbb{Q}(\sqrt{2},\sqrt{3}):\mathbb{Q}(\sqrt{2})||\mathbb{Q}(\sqrt{2}):\mathbb{Q}| = 2 \cdot 2 = 4.$$
\end{enumerate}
\end{example}

$\hfill \blacksquare$

\begin{example} Analizaremos ahora otra extensión que veremos que guarda relación con el ejemplo anterior, la extensión $\mathbb{Q}(\sqrt{2}+\sqrt{3})/\mathbb{Q}$. Y es que se tiene que $\mathbb{Q}(\sqrt{2}, \sqrt{3}) = \mathbb{Q}(\sqrt{2}+\sqrt{3})$, esto es así ya que $\mathbb{Q}(\sqrt{2}+\sqrt{3}) \subseteq \mathbb{Q}(\sqrt{2}, \sqrt{3})$ es evidente y para ver el otro contenido simplemente basta comprobar que $\sqrt{2}, \sqrt{3} \in \mathbb{Q}(\sqrt{2}+\sqrt{3})$. Para ver esto último tengamos en cuenta que $$11\sqrt{2} + 9\sqrt{3} = (\sqrt{2}+ \sqrt{3})^{3} \in \mathbb{Q}(\sqrt{2}+\sqrt{3}),$$ de lo que deducimos que $$\sqrt{2} = \dfrac{(11\sqrt{2} + 9\sqrt{3}-9(\sqrt{2}+\sqrt{3}))}{2} \in \mathbb{Q}(\sqrt{2}+\sqrt{3}) $$ $$\sqrt{3} = \dfrac{-(11\sqrt{2} + 9\sqrt{3})+11(\sqrt{2} + \sqrt{3})}{2} \in \mathbb{Q}(\sqrt{2}+\sqrt{3}).$$

Así, $\mathbb{Q}(\sqrt{2}, \sqrt{3}) \subseteq \mathbb{Q}(\sqrt{2}+\sqrt{3})$ y por tanto tenemos la igualdad: $\mathbb{Q}(\sqrt{2}, \sqrt{3}) = \mathbb{Q}(\sqrt{2}+\sqrt{3})$.

Una consecuencia de esto es que: $$|\mathbb{Q}(\sqrt{2} + \sqrt{3}) : \mathbb{Q}| = |\mathbb{Q}(\sqrt{2}, \sqrt{3}) : \mathbb{Q}| = |\mathbb{Q}(\sqrt{2}, \sqrt{3}) : \mathbb{Q}(\sqrt{2})| |\mathbb{Q}(\sqrt{2}): \mathbb{Q}| = 2 \cdot 2 = 4.$$
\end{example}

$\hfill \blacksquare$

\begin{example}Sea $\alpha = \sqrt{5} + \sqrt{-5}$ y $\beta = \sqrt[4]{5}$. Vamos a calcular el grado de la extensión $\mathbb{Q}(\alpha, \beta) /\mathbb{Q}$.

Notar primero que $\beta^{2} = \sqrt{5}$ y que $\alpha = \sqrt{5} + \sqrt{5}i$, es decir, $\alpha = \beta^{2} + \beta^{2}i$. Así, $\mathbb{Q}(\alpha, \beta) = \mathbb{Q}(\beta^{2} + \beta^{2}i, \beta) = \mathbb{Q}(\beta^{2}i, \beta) = \mathbb{Q}(i, \beta) = \mathbb{Q}(\beta) (i)$. 

Ahora, al estar claramente $\mathbb{Q}(\beta) \subseteq \mathbb{R}$ pero $i \notin \mathbb{R}$, el polinomio irreducible de $i$ sobre $\mathbb{Q}(\beta)$ va a ser el mismo que sobre $\mathbb{Q}$, es decir, $x^{2}+1$. Así, va a ser $|\mathbb{Q}(i,\beta) : \mathbb{Q}(\beta)| = 2$.

Por otro lado, es claro que $|\mathbb{Q}(\beta) : \mathbb{Q}| = 4$ ya que el polinomio irreducible de $\beta = \sqrt[4]{5}$ sobre $\mathbb{Q}$ es $x^{4}-5$. (por el criterio de Eisenstein). Así, $$|\mathbb{Q}(\alpha, \beta) : \mathbb{Q}| = |\mathbb{Q}(i, \beta) : \mathbb{Q}| = |\mathbb{Q}(i, \beta) : \mathbb{Q}(\beta)| |\mathbb{Q}(\beta) : \mathbb{Q}| = 2 \cdot 4 = 8.$$
\end{example}

$\hfill \blacksquare$

\begin{proposition}\label{eq:pirrdiv} Dada $E/K$ una extensión, y $L$ un cuerpo intermedio. Sea $a \in E$ algebraico sobre $K$. Entonces $a$ también será algebraico sobre $L$ y $$Irr(a, L) \mid Irr (a, K).$$
\end{proposition}
\emph{Demostración: }Si $a \in E$ es algebraico sobre $K$ entonces existe un $f \in K[x]$ tal que $f(a) = 0$. Como $f$ también pertenecerá a $L[x]$, $a$ también será algebraico sobre $L$. Recordemos que el polinomio irreducible de un elemento es el de menor grado (mónico) que lo anula y cualquier otro que lo anule es múltiplo suyo. Como $Irr(a,K) \in L[x]$ y anula a $a$ entonces $Irr(a, L) \mid Irr(a,K)$.

$\hfill \square$

\begin{proposition} Dada una extensión $E/K$ de cuerpos, y $u,v \in E$ elementos algebraicos sobre $K$. Sea $m = \delta(Irr(u, K))$ y $n = \delta(Irr(v,K))$, entonces son equivalentes: \begin{enumerate}
\item $|K(u,v) :K(v) | = m$.
\item $|K(u,v) : K(u) | = n$.
\end{enumerate}
Además, ambas se cumplen si $mcd(m,n) = 1$.
\end{proposition}
\emph{Demostración: }
Está claro que $|K(u) : K| = m$ y que $|K(v) : K| = n$, luego $$\dfrac{|K(u,v):K(u)|}{|K(u,v):K(v)|} = \dfrac{|K(u,v):K|/|K(u):K)|}{|K(u,v):K|/|K(v):K|} = \dfrac{|K(v):K|}{|K(u):K|} = \dfrac{n}{m}.$$
De lo que se desprende la equivalencia entre $1.$ y $2.$ Ahora, si $mcd(m,n) = 1$, la fracción $\dfrac{n}{m}$ no se puede simplificar, luego existirá un entero positivo $a$ tal que $$|K(u,v):K(u)| = an, \hspace{0.2cm} |K(u,v):K(v)| = am.$$ Ahora, $$n \leq an = |K(u,v):K(u)| = \delta(Irr(v, K(u))) \leq \delta (Irr(v,K)) = n,$$ donde la última desigualdad se desprende de lo visto en el anterior resultado, como $K \subseteq K(u)$ el polinomio $Irr(v,K)$ es múltiplo de $Irr(v,K(u))$. Así, $an = n$ y $a = 1$. Luego: $$|K(u,v):K(u)| = n, \hspace{0.2cm} |K(u,v):K(v)| = m.$$

$\hfill \square$

Hay que tener en cuenta que el resultado dice que si se cumple una se cumple la otra, pero en general no tiene por qué ocurrir ninguna. Ocurrirá cuando $m,n$ sean coprimos. 

Vamos a ver un caso donde podamos aplicar esto que acabamos de ver:

\begin{example} Sea $E = \mathbb{Q}(\sqrt{2}, \sqrt{3})$ y $\alpha = \sqrt[5]{2}$. Vamos a calcular $Irr(\alpha, E)$.

Para empezar, si tomamos $x^{5}-2$, por el criterio de Eisenstein, es irreducible en $\mathbb{Q}[x]$. Así, $|\mathbb{Q}(\alpha) : \mathbb{Q}| = 5$. Ahora, ya hemos visto en ejemplos anteriores que si $v = \sqrt{2}+ \sqrt{3}$ entonces $E = \mathbb{Q}(v)$, y que $|\mathbb{Q}(v) : \mathbb{Q}| = 4$. Como $mcd(4,5) = 1$ entonces podemos aplicar el resultado que acabamos de ver: $$|E(\alpha) : E| = |\mathbb{Q}(\alpha,v) : \mathbb{Q}(v) | = \delta (Irr(\alpha, \mathbb{Q})) = 5.$$ Así, al ser $x^{5}-2$ un polinomio de grado $5$ en $E[x]$ que tiene por raíz a $\alpha$, entonces $$Irr(\alpha, E) = x^{5}-2.$$
\end{example}

$\hfill \blacksquare$

\begin{definition} Sea una extensión $E/K$, llamaremos \textbf{clausura algebraica} de $K$ en $E$ al conjunto de los elementos algebraicos de una extensión, y la denotaremos por $Cl_{K}^{E} = \lbrace \alpha \in E: \alpha \hspace{0.2cm} \text{es} \hspace{0.1cm} \text{algebraico} \hspace{0.1cm} \text{sobre} \hspace{0.1cm} K \rbrace$.
\end{definition} 

\begin{proposition} Sea $E/K$ una extensión, entonces la clausura algebraica de $K$ en $E$ es un subcuerpo de $E$.
\end{proposition}
\emph{Demostración: } Si $\alpha, \beta \in Cl_{K}^{E}$, entonces $|K(\alpha, \beta) : K(\beta) |$ es finito pues $\alpha$ es algebraico sobre $K$ y por lo tanto sobre $K(\beta)$. Además, como $\beta$ es algebraico sobre $K$, $|K(\beta) : K|$ es finito. Así, $|K(\alpha, \beta) : K|$ es finito y por~\ref{eq:cor1} $\alpha + \beta$, $\alpha - \beta$, $\alpha \beta \in Cl_{K}^{E}$, también $1/\alpha \in Cl_{K}^{E}$ si $\alpha \neq 0$.

$\hfill \square$

\begin{proposition}Sea $E/K$ una extensión, y $K$ numerable, entonces $Cl_{K}^{E}$ es numerable.
\end{proposition}
\emph{Demostración: } Como $K[x]$ es numerable, contiene numerables polinomios y cada uno de ellos tiene un número finito de raíces en cualquier extensión de $K$, y por lo tanto en $E$. Así, $Cl_{K}^{E}$ es numerable.

$\hfill \square$

\begin{corolario} $\mathbb{R}$ contiene más elementos trascendentes que algebraicos sobre $\mathbb{Q}$.
\end{corolario}
\emph{Demostración: }$Cl_{\mathbb{Q}}^{\mathbb{R}}$ (todos los $\alpha \in \mathbb{R}$ algebraicos sobre $\mathbb{Q}$) es numerable, pero $\mathbb{R}$ es no numerable. Si el conjunto $T$ de los $\beta	 \in \mathbb{R}$ trascendentes sobre $\mathbb{Q}$ fuese también numerable, entonces $\mathbb{R} = Cl_{\mathbb{Q}}^{\mathbb{R}} \cup T$ sería numerable.

$\hfill \square$

\begin{proposition}\label{eq:finalg} Sea $E/K$ una extensión. Si $\alpha_{1}, \ldots, \alpha_{n} \in E$ son algebraicos sobre $K$, $K(\alpha_{1}, \ldots, \alpha_{n})/K$ es finita, luego algebraica.
\end{proposition}
\emph{Demostración: } La haremos por inducción sobre $n$. Si $n = 1$, ya sabemos que $|K(\alpha_{1}):K|$ es finito. Supongamos el resultado cierto para $n-1$ y probémoslo para $n$. Como $\alpha_{n}$ es algebraico sobre $K$, también es algebraico sobre $K(\alpha_{1}, \ldots, \alpha_{n-1})$. Así, $|K(\alpha_{1}, \ldots, \alpha_{n-1}) (\alpha_{n}) : K(\alpha_{1}, \ldots, \alpha_{n-1})|$ es finito. Por inducción, $|K(\alpha_{1}, \ldots, \alpha_{n-1}) : K|$ es finito. Pero $K(\alpha_{1}, \ldots, \alpha_{n-1}) (\alpha_{n}) = K(\alpha_{1}, \ldots, \alpha_{n})$. Por~\ref{eq:trgr} $$|K(\alpha_{1}, \ldots, \alpha_{n}) : K| = |K(\alpha_{1}, \ldots, \alpha_{n}) : K(\alpha_{1}, \ldots, \alpha_{n-1})| |K(\alpha_{1}, \ldots, \alpha_{n-1}) : K|$$ es finito.

$\hfill \square$

Un resultado que puede parecer obvio pero que es interesante es la “transitividad” de las extensiones algebraicas, es decir, 

\begin{proposition}Si $E$ es una extensión algebraica de $K$ y $F$ es una extensión algebraica de $E$, entonces $F$ es una extensión algebraica de $K$.
\end{proposition}
\emph{Demostración: } Si $\alpha \in F$ existirá en $E[x]$ un elemento no nulo $f = \sum _{i=0}^{n} a_{i}x^{i}$ tal que $f(\alpha)= 0$. Por hipótesis $a_{i}$ es algebraico sobre $K$, $\forall$ $i$. Si $L = K(a_{0}, a_{1}, \ldots, a_{n})$ se tiene \begin{center}$|L : K| = |L:K(a_{0}, a_{1}, \ldots, a_{n-1})| |K(a_{0}, a_{1}, \ldots, a_{n-1}):K(a_{0}, a_{1}, \ldots, a_{n-2})| \ldots |K(a_{0}:K|.$\end{center} Como $a_{i}$ es algebraico sobre $K(a_{0}, a_{1}, \ldots, a_{i-1})$ $\forall i$, cada factor es finito y por lo tanto $|L:K|$ es finito. Además, $\alpha$ es algebraico sobre $L$, pues $f \in L[x]$ y $f(\alpha) = 0$, por lo que $|L(\alpha):L|$ es finito y así $|L(\alpha) : K|$ es finito. Luego, $L(\alpha)$ es una extensión algebraica de $K$ y $\alpha$ es algebraico sobre $K$.

$\hfill \square$


\begin{lemma}Sea $\sigma \colon K_{1} \longrightarrow K_{2}$ un isomorfismo de cuerpos. Entonces $\sigma$ se extiende a un isomorfismo de $K_{1}[x]$ en $K_{2}[x]$ haciendo que, si $f \in K_{1}[x]$ con $f = a_{0} + a_{1}x + \ldots + a_{k}x^{k}$, entonces  $\sigma (f) =  \sigma(a_{0}) + \sigma( a_{1})x + \ldots + \sigma(a_{k})x^{k}$. En particular, $$f \hspace{0.1cm} \text{es} \hspace{0.1cm} \text{irreducible} \Longleftrightarrow \sigma (f) \hspace{0.1cm} \text{es} \hspace{0.1cm} \text{irreducible}.$$
\end{lemma}

Esta extensión se produce de manera natural siempre, por lo que muchas veces se obviará. Además hay que puntualizar una cuestión de notación, tal y como comentamos al principio (tras~\ref{defac}) en este caso a $\sigma(f)$ se le denotará en ocasiones $f^{\sigma}$, ya que estrictamente hablando $\sigma$ es un isomorfismo de cuerpos y $f \in K_{1}[x]$.

\begin{proposition} \label{eq:extc} Sean $E_{1}/K_{1}$ y $E_{2}/K_{2}$ dos extensiones. Sean $\sigma \colon K_{1} \longrightarrow K_{2}$ un isomorfismo. Sea $p_{1} \in K_{1}[x]$ irreducible. Sea $p_{2} = \sigma (p_{1})$. Sea $\alpha_{i}$ raíz de $p_{i}$, $i = 1,2$. Entonces $\sigma$ se extiende a un isomorfismo de cuerpos $\theta \colon K_{1}(\alpha_{1})\longrightarrow K_{2}(\alpha_{2})$ tal que $\theta(\alpha_{1}) = \alpha_{2}$.

$$\xymatrix @=2cm {K_{1}(\alpha_{1})\ar[r]^{\theta} & K_{2}(\alpha_{2})  \\ K_{1} \ar[r]^{\sigma} \ar[u] & K_{2} \ar[u]  }$$
\end{proposition}
\emph{Demostración: } Supongamos que $p_{1}$ es mónico, con lo que $p_{2}$ también lo es. Entonces, como $p_{1}$ y $p_{2}$ son irreducibles, $$p_{1} = Irr(\alpha_{1}, K_{1}),$$ $$p_{2} = Irr (\alpha_{2}, K_{2}).$$ Ahora, $K_{1}(\alpha_{1}) = \lbrace f(\alpha_{1}): f \in K_{1}[x]\rbrace$, $K_{2}(\alpha_{2}) = \lbrace f(\alpha_{2}) : f \in K_{2}[x]\rbrace$. Definimos $$\begin{array}{rccl}
\theta \colon &K_{1}(\alpha_{1})&\longrightarrow &K_{2}(\alpha_{2}) \\
&f(\alpha_{1})& \longmapsto &\sigma(f)(\alpha_{2}).
\end{array}
$$ 

Y ahora veamos que está bien definida: si $f,g \in K_{1}[x]$, $f(\alpha_{1}) = g(\alpha_{1}) \Leftrightarrow (f-g)(\alpha_{1}) = 0 \Leftrightarrow p_{1} \mid f-g \Leftrightarrow \sigma (p_{1}) \mid \sigma(f-g) \Leftrightarrow p_{2} \mid \sigma (f) - \sigma (g) \Leftrightarrow (\sigma(f) -  \sigma (g)) (\alpha_{2}) = 0 \Leftrightarrow \sigma (f)(\alpha_{2}) = \sigma (g) (\alpha_{2})$.

Es inyectiva: $\theta (f(\alpha_{1})) =  \sigma (f) (\alpha_{2}) = 0 \Rightarrow f(\alpha_{1}) = 0.$  Es fácil ver que también es suprayectiva.

Y es claro que $\theta$ es homomorfismo de cuerpos: \begin{center}$\theta (f(\alpha_{1}) + g(\alpha_{1})) = \theta ((f+g) (\alpha_{1})) = \sigma (f+g) (\alpha_{2}) = (\sigma (f) + \sigma (g))(\alpha_{2}) = \sigma (f) (\alpha_{2}) + \sigma (g) (\alpha_{2}) = \theta (f(\alpha_{1})) + \theta(g(\alpha_{1})).$\end{center}
Igual con el producto.

$\hfill \square$

\begin{corolario}\label{eq:irrcor} Sea $p \in K[x]$ irreducible, $\alpha$ y $\beta$ raíces de $p$ en una extensión $E$ de $K$. Existe un isomorfismo $\theta \colon K(\alpha) \longrightarrow K(\beta)$ tal que $\left. \theta \right|_K = id, \theta(\alpha) = \beta$. Recíprocamente, si $\alpha, \beta \in E$, siendo $E/K$ una extensión, y existe un isomorfismo $\theta \colon K(\alpha) \longrightarrow K(\beta)$ tal que $\left. \theta \right|_K = id, \theta(\alpha) = \beta$, entonces $Irr(\alpha, K) = Irr(\beta, K).$
\end{corolario}
\emph{Demostración: } La primera parte se deduce del anterior resultado, tomando $K_{1} = K_{2}$ y $\sigma = id$. Sea ahora $Irr(\alpha, K) = x^{k} + a_{k-1}x^{k-1} + \ldots + a_{1}x + a_{0}.$ Entonces, $$\alpha^{k} + a_{k-1}\alpha^{k-1} + \ldots + a_{1}\alpha + a_{0} =0.$$ Aplicando $\theta$ tenemos: $\theta( \alpha)^{k} + a_{k-1}\theta( \alpha)^{k-1} + \ldots + a_{1}\theta( \alpha) + a_{0} = \beta^{k} + a_{k-1}\beta^{k-1} + \ldots + a_{1}\beta + a_{0} = 0$ (ya que $\left. \theta \right|_K = id$). Luego, $Irr(\alpha, K) = Irr(\beta, K)$.

$\hfill \square$

Recordemos la necesidad de que $p \in K[x]$ sea irreducible. Entonces, dadas $\alpha$ y $\beta$ raíces en una extensión $E$ de $K$, $$\begin{array}{rccl}
\theta \colon &K(\alpha)&\longrightarrow &K(\beta) \\
&\alpha& \longmapsto &\beta \\
&k& \longmapsto &k
\end{array}
$$ 

Respecto al resultado anterior tenemos la siguiente definición:

\begin{definition} Si $E$ es una extensión algebraica de $K$, $\alpha, \beta \in E$, diremos que $\alpha$ y $\beta$ son \textbf{conjugados sobre $K$} si $Irr(\alpha, K) = Irr(\beta, K)$, o equivalentemente si $\alpha$ es raíz de $Irr(\beta, K)$. Lo denotaremos por $\alpha$ $conj_{K}$ $\beta$.
\end{definition}

Así, el anterior corolario nos viene a decir que todo eso ocurre si y sólo si $\alpha$ y $\beta$ son conjugados.

\begin{definition} Sea $E/K$ una extensión. Diremos que $\varphi \colon E \longrightarrow E$ es un \textbf{$K$-homomorfismo de cuerpos} si \begin{enumerate}
\item $\varphi$ es un homomorfismo de cuerpos.
\item $ \left.\varphi \right|_K  = id_{K}$, es decir, $\varphi (k) = k$ $\forall k \in K$. 
\end{enumerate}
\end{definition}

Un simple ejemplo de esto podría ser, dada la extensión $\mathbb{Q}(\sqrt{5})/\mathbb{Q}$ $$\begin{array}{rccl}
\varphi \colon &\mathbb{Q}(\sqrt{5})&\longrightarrow &\mathbb{Q}(\sqrt{5}) \\
&a+b\sqrt{5}& \longmapsto &a-b\sqrt{5}\\
\end{array}
$$ es un $\mathbb{Q}$-homomorfismo de cuerpos.

\begin{example} Vamos a describir ahora el subcuerpo $\mathbb{Q}(\sqrt{5}, \sqrt{7})$ de $\mathbb{C}$.

Lo primero, notar que $\mathbb{Q}(\sqrt{5}, \sqrt{7}) = \mathbb{Q}(\sqrt{5})(\sqrt{7})$, luego $\mathbb{Q} \subseteq \mathbb{Q}(\sqrt{5}) \subseteq \mathbb{Q}(\sqrt{5})(\sqrt{7}) \subseteq \mathbb{C}$. 

Calculemos primero $|\mathbb{Q}(\sqrt{5}) : \mathbb{Q}|$. $\sqrt{5}$ es algebraico sobre $\mathbb{Q}$ porque es raíz de $x^{2}-5$, $x^{2}-5$ es irreducible en $\mathbb{Q}[x]$ y es mónico, luego $Irr(\sqrt{5}, \mathbb{Q}) = x^{2}-5$ y así $|\mathbb{Q}(\sqrt{5}):\mathbb{Q}| = 2$ y $\lbrace 1, \sqrt{5} \rbrace$ es una base de $\mathbb{Q}(\sqrt{5})$.

Calculemos ahora $|\mathbb{Q}(\sqrt{5})(\sqrt{7}):\mathbb{Q}(\sqrt{5})|$, para lo cual necesitaremos $Irr(\sqrt{7}, \mathbb{Q}(\sqrt{5}))$. Sabemos que $x^{2}-7 = Irr(\sqrt{7}, \mathbb{Q})$ y que $x^{2}-7 \in \mathbb{Q}[x] \subseteq \mathbb{Q}(\sqrt{5})[x]$. Las únicas raíces del polinomio son $\sqrt{7}$ y $- \sqrt{7}$. Si dichas raíces no pertenecen  a $\mathbb{Q}(\sqrt{5})$ entonces $x^{2}-7$ será también irreducible sobre $\mathbb{Q}(\sqrt{5})[x]$.

Ahora, recordemos que $\mathbb{Q}(\sqrt{5}) = \lbrace a +b \sqrt{5} : a,b \in \mathbb{Q}\rbrace$. Si $\sqrt{7} \in \mathbb{Q}(\sqrt{5})$ entonces existen $a,b \in \mathbb{Q}$ tales que $\sqrt{7} = a+b\sqrt{5}$, es decir, $7 = a^{2}+2ab\sqrt{5}+5b^{2}$. Con esto tenemos que: \begin{enumerate}
\item Si $a = 0$, entonces $7 = 5b^{2}$ y de aquí $b = \pm  \dfrac{\sqrt{7}}{5} \notin \mathbb{Q}.$ Absurdo
\item Si $b = 0$, entonces $7 = a^{2}$ y de aquí $a = \pm \sqrt{7} \notin \mathbb{Q}$. Absurdo.
\item Si $a,b \neq 0$, entonces $\sqrt{5} = \dfrac{7-a^{2}-5b^{2}}{2ab}$, pero esto último es racional, luego absurdo también.
\end{enumerate}
Luego, como las raíces no pertenecen a $\mathbb{Q}(\sqrt{5})$, tenemos que $Irr(\sqrt{7}, \mathbb{Q}(\sqrt{5})) = x^{2}-7$, por lo que $|\mathbb{Q}(\sqrt{5})(\sqrt{7}):\mathbb{Q}(\sqrt{5})| = 2$. Así $|\mathbb{Q}(\sqrt{5})(\sqrt{7}):\mathbb{Q}| = |\mathbb{Q}(\sqrt{5})(\sqrt{7}):\mathbb{Q}(\sqrt{5})| |\mathbb{Q}(\sqrt{5}):\mathbb{Q}| = 2 \cdot 2 = 4.$
Por tanto, podemos ver a $\mathbb{Q}(\sqrt{5}, \sqrt{7})$ como un $\mathbb{Q}$-e.v de dimensión $4$. Calcularemos ahora una base: \begin{center} $\mathbb{Q}(\sqrt{5}, \sqrt{7}) = \lbrace c +d\sqrt{7} : c,d \in \mathbb{Q}(\sqrt{5}) \rbrace = \lbrace (a_{0}+b_{0}\sqrt{5}) + (a_{1}+b_{1}\sqrt{5})\sqrt{7}: a_{0},b_{0},a_{1},b_{1} \in \mathbb{Q} \rbrace = \lbrace a_{0}+a_{1}\sqrt{7} + b_{0}\sqrt{5} + b_{1} \sqrt{5} \sqrt{7} :a_{0},b_{0},a_{1},b_{1} \in \mathbb{Q} \rbrace.$ \end{center}
De lo que deducimos que, por ejemplo, $\lbrace 1, \sqrt{5}, \sqrt{7}, \sqrt{5}\sqrt{7} \rbrace$ es una base de $\mathbb{Q}(\sqrt{5}, \sqrt{7})$.
\end{example}

$\hfill \blacksquare$

\begin{example} Sea $a\in \mathbb{C}$ raíz de $x^{3}+x+1$. Veamos que $\mathbb{Q}(a\sqrt{2}) = \mathbb{Q}(a,\sqrt{2})$. Lo veremos por doble inclusión:

Primero veamos que $\mathbb{Q}(a\sqrt{2}) \subseteq \mathbb{Q}(a,\sqrt{2})$. Como $a$ y $\sqrt{2} \in \mathbb{Q}(a,\sqrt{2})$ y $\mathbb{Q}(a,\sqrt{2})$ es un cuerpo entonces $a \sqrt{2} \in \mathbb{Q}(a,\sqrt{2})$ y como $\mathbb{Q}(a\sqrt{2})$ es el menor subcuerpo de $\mathbb{Q}$ conteniendo al mismo $\mathbb{Q}$ y a $a\sqrt{2}$, concluimos que $$\mathbb{Q}(a\sqrt{2}) \subseteq \mathbb{Q}(a,\sqrt{2}).$$

Ahora veamos que $\mathbb{Q}(a, \sqrt{2}) \subseteq \mathbb{Q}(a\sqrt{2})$. Para esto basta ver que $a \in \mathbb{Q}(a\sqrt{2})$ (y así $\sqrt{2}$ ya que $\sqrt{2} = a^{-1}(a\sqrt{2})$) ya que como $\mathbb{Q}(a, \sqrt{2})$ es el menor cuerpo conteniendo a ambos elementos se tendrá que $$\mathbb{Q}(a,\sqrt{2}) \subseteq \mathbb{Q}(a\sqrt{2}).$$

Como $x^{3}+x+1$ es irreducible en $\mathbb{Q}[x]$ entonces se tiene que $Irr(a, \mathbb{Q}) = x^{3}+x+1$ y $|\mathbb{Q}(a) : \mathbb{Q}| = 3$. Así, $\mathbb{Q}(a) = \lbrace d+ba + ca^{2}: b,c,d \in \mathbb{Q} \rbrace.$ Luego ó $\mathbb{Q}(a^{2}) = \mathbb{Q}(a)$ ó $\mathbb{Q}(a^{2}) = \mathbb{Q}$. Pero esto último no puede ser ya que si $\mathbb{Q}(a^{2}) = \mathbb{Q}$ entonces $a^{2} \in \mathbb{Q}$ y así $a^{2} = t \in \mathbb{Q}$ y $x^{2}-t$ tiene como raíz $a$. Absurdo porque $x^{3}+x+1$ es su polinomio irreducible. Con esto, tenemos que $a^{2}= \dfrac{(a\sqrt{2})^{2}}{2} \in \mathbb{Q}(a\sqrt{2})$ y así $\mathbb{Q}(a) = \mathbb{Q}(a^{2}) \subseteq \mathbb{Q}(a\sqrt{2})$.

$$\mathbb{Q}(a,\sqrt{2}) \subseteq \mathbb{Q}(a\sqrt{2}) \subseteq \mathbb{Q}(a,\sqrt{2})\Rightarrow \mathbb{Q}(a\sqrt{2}) = \mathbb{Q}(a, \sqrt{2}).$$
\end{example}

$\hfill \blacksquare$

\subsection{Clausura Algebraica}
Como ya vimos en~\ref{eq:preclau}, dado un cuerpo $K$ y un subconjunto $M$ finito de polinomios no constantes de $K[x]$, entonces existe una extensión $E$ de $K$ que contienen a todas las raíces de todos los elementos de $M$. Ahora veremos que esto es cierto aunque $M$ no sea finito.

\begin{definition} Diremos que un cuerpo $K$ es \textbf{algebraicamente cerrado} si contiene a todas las raíces de los polinomios no constantes de $K[x]$.
\end{definition}

\begin{proposition}Si $K$ es un cuerpo algebraicamente cerrado y $E$ es un extensión algebraica de $K$, entonces $E = K$.
\end{proposition}
\emph{Demostración: } Si $\alpha \in E$, $f(x) = Irr(\alpha, K)$ es un polinomio no constante de $K[x]$. En consecuencia $\alpha$ es raíz de $f$, con $f \in K[X]$. Como $K$ es algebraicamente cerrado, $\alpha \in K$.

$\hfill \square$

Anteriormente ya definimos lo que era la clausura algebraica a partir de los elementos algebraicos de una extensión, pero ahora adaptaremos el concepto usando los cuerpos algebraicamente cerrados.
\begin{definition} Sea $E/K$ una extensión de cuerpos, se dice que $E$ es una \textbf{clausura algebraica} de $K$ si \begin{enumerate}
\item $E$ es algebraico sobre $K$.
\item $E$ es algebraicamente cerrado.
\end{enumerate}
\end{definition}

Ahora, se presentará el resultado más importante de esta sección:
\begin{theorem}
Todo cuerpo admite una clausura algebraica.
\end{theorem}
\emph{Demostración: } La idea de la demostración va a consistir en que para cada $f \in K[x]$ con $\delta (f) \geq 1$, y $x_{f}$ una indeterminada formaremos un conjunto infinito $S = \lbrace x_{f} : f \in K[x], \hspace{0.1cm} \delta (f) \geq 1 \rbrace$. Entonces, sea $K[S]$ el anillo de polinomios en las indeterminadas $x_{f}$ de $S$, y sea $I$ el ideal de $K[S]$ generado por el conjunto $\lbrace f(x_{f}): f \in K[x]\rbrace$. Construiremos cuerpos $E_{i}$ con $K \subseteq E_{1} \subseteq E_{2} \subseteq \ldots$ tales que todo $g \in E_{i}[x]$ con $\delta (g) \geq 1$ tenga raíces en $E_{i+1}$, y luego formaremos $E = \cup_{i=1}^{\infty} E_{i}$ que resultará un cuerpo algebraicamente cerrado con $K \subseteq E$. Finalmente, si $L = Cl_{K}^{E}$ demostraremos que $L$ es una clausura algebraica de $K$ y se habrá probado el teorema.

Comenzaremos entonces construyendo los $E_{i}$. El ideal $I$ está propiamente contenido en $K[S]$, ya que si $I = K[S]$ se tiene $$ (\ast) \hspace{0.2cm} 1 = g_{1}f_{1}(x_{f_{1}})+ \ldots + g_{k}f_{k}(x_{f_{k}}), \hspace{0.2cm} g_{i} \in K[S].$$

Por~\ref{eq:preclau} existe una extensión $E$ de $K$ en la cual $f_{1}, \ldots, f_{k}$ tienen todas sus raíces. Sea $\alpha_{i} \in E$ una raíz de $f_{i}$, $i = 1, \ldots, k$. Haciendo en $(\ast)$ $x_{f_{i}} = \alpha_{i}$ para $1 \leq i \leq k$, y $x_{t} = 0$ $\forall t \neq f_{i}$, se obtiene $1 = 0$, que es una contradicción. Luego $I \subset K[S]$ y por lo tanto existe un ideal maximal $M$ de $K[S]$ tal que $I \subseteq M$. Sea $\varphi =  \left.\pi \right|_K$, siendo $\pi$ la proyección canónica de $K[S]$ en $K[S]/M$. Entonces, $\varphi \colon K \longrightarrow K[S]/M$ es un monomorfismo, pues si $k \in K$ y $\varphi (k) = M$, entonces $k \in M$ por lo que $k$ debe ser no invertible, es decir, $k = 0$. Veamos ahora que $\forall f \in K[x]$ con $\delta (f) \geq 1$, $f$ tiene raíces en $E_{1} = K[S]/M$. Efectivamente, si $a_{0}+ a_{1}x + \ldots + a_{n}x^{n} = f(x) \in K[x],$ entonces $f(x_{f}) =  a_{0}+ a_{1}x_{f} + \ldots + a_{n}x_{f}^{n} \in M$ y se tiene que \begin{center}$M = \pi(f(x_{f})) = f(x_{f}) + M = (a_{0}+ M) + (a_{1}x_{f}+ M)+ \ldots + (a_{n}x_{f}^{n}) + M) = \varphi(a_{0})(1 + M) + \varphi(a_{1})(x_{f} + M) + \ldots + \varphi(a_{n})(x_{f} + M)^{n}.$\end{center} 
Si ahora $\bar{1} = 1 + M$ y $\bar{x}_{f} = x_{f}+ M$, obtenemos que $\bar{x}_{f} \in E_{1}$ y es raíz del polinomio $h(x) = \sum_{i = 0}^{n} \varphi(a_{i})x^{i}$. Si repetimos el razonamiento anterior tomando $E_{1}$ en lugar de $K$, tendremos que $E_{2} \supseteq E_{1} \supseteq K$ tal que todo $g \in E_{1}[x]$ con $\delta (g) \geq 1$ tiene raíces en $E_{2}$. Continuando con este proceso se obtiene $K \subseteq E_{1} \subseteq E_{2} \subseteq E_{3} \ldots$, tales que todo $g \in E_{i}[x]$ con $\delta (g) \geq 1$ tiene raíces en $E_{i+1}$, Evidentemente, $E = \cup_{i}E_{i}$ es un cuerpo que contiene a $K$. Veamos que $E$ es algebraicamente cerrado: en efecto, si $p(t) = \sum_{i=0}^{n}e_{i}t^{i} \in E(t)$, entonces $p(t) \in E_{m}(t)$ para algún $m$ y por lo tanto tiene raíces en $E_{m+1}$. Por lo tanto, $p$ tiene una raíz $\alpha$ en $E$, y así $p(t) = (t-\alpha) h(t)$, con $h(t) \in E[t]$. Si aplicamos este razonamiento con $h(t)$ y los sucesivos polinomios que vayan saliendo obtendremos que $p(t)$ tiene todas sus raíces en $E$.

Probaremos ahora que $L = Cl_{K}^{E}$ es una clausura algebraica de $K$. Obviamente $L$ es algebraico sobre $K$. Para ver que es algebraicamente cerrado tomaremos $f \in L[x]$ con $\delta (f) \geq 1$. Entonces $f \in E[x]$, y como $E$ es algebraicamente cerrado existirá un $\alpha \in E$ con $f(\alpha)=0$. Entonces $L(\alpha)$ es una extensión finita de $L$, luego algebraica sobre $L$. Como además $L$ es algebraico sobre $K$, y así también extension algebraica, tenemos que también $L(\alpha)$ es una extensión algebraica de $K$, luego $\alpha$ es algebraico sobre $K$. Entonces $\alpha \in Cl_{K}^{E} = L$. Hemos probado así que todo polinomio no constante de $L[x]$ tiene alguna raíz en $L$, es decir, que $L$ es algebraicamente cerrado.

$\hfill \square$

\begin{proposition} Sea $C/K$ una extensión algebraica. Si $C$ es una clausura algebraica de $K$, entonces dada cualquier extensión algebraica $E$ de $K$, existirá un monomorfismo $\psi \colon E \longrightarrow C$ tal que $\psi \sigma = \varphi$, es decir, el siguiente diagrama es conmutativo 
$$\xymatrix @=2cm {K \ar[r]^{\sigma} \ar[d]_{\varphi} & E\ar[ld]^\psi  \\ C   }$$
\end{proposition}
\emph{Demostración: }
Sea $\sigma \colon K \longrightarrow E$ una extensión algebraica y consideremos el conjunto \begin{center}$S = \lbrace (F, F', \psi): \sigma (K) \subseteq F \subseteq E,\hspace{0.2cm} \varphi(K) \subseteq K' \subseteq C, \hspace{0.2cm} \psi \colon F \longrightarrow F' \hspace{0.1cm} \text{isomorfismo} \hspace{0.1cm}, \psi \sigma = \varphi \rbrace .$\end{center}
Notar que $S \neq \emptyset$, ya que $(\sigma(K), \varphi(K), \varphi \sigma^{-1}) \in S$. Definiremos en $S$ un orden parcial de la siguiente manera: $$(F, F', \psi) \leq (L,L', \phi) \Longleftrightarrow F \subseteq L, \left.\phi \right|_F = \psi.$$ 
Visto esto, es claro que se puede aplicar el lema de Zorn para obtener un elemento maximal de $S$, $(F_{0},F'_{0}, \psi_{0})$. Veamos que $F_{0} = E$. Es evidente que $F_{0} \subseteq E$, así que solo tendremos que ver el contenido contrario $E \subseteq F_{0}$. Supongamos que existe $\alpha \in E \setminus F_{0}$ y sean $f_{1} = Irr(\alpha, F_{0}) \in F_{0}[x]$ y $f_{2} = f_{1}^{\psi_{0}} \in F'_{0}[x] \subseteq C[x]$.

Como $C$ es algebraicamente cerrado, existirá un $\alpha' \in C$ tal que $f_{2}(\alpha') = 0$ y, por~\ref{eq:extc}, existirá un único isomorfismo de cuerpos $\psi_{1} \colon F_{0}(\alpha) \longrightarrow F'_{0}(\alpha')$ tal que $\psi_{1}(\alpha) = \alpha'$ y $\left.\psi_{1} \right|_{F_{0}} = \psi_{0}$, es decir, que extiende $\psi_{0}$. Además, $\psi_{0}\sigma = \varphi$ y $\sigma(K) \subseteq F_{0}$, por lo que $\forall u \in K$, $\sigma(u) \in F_{0}$ y $\psi_{1}\sigma(u) = \psi_{0}\sigma(u) = \varphi(u)$, es decir, $\psi_{1}\sigma = \varphi$. Entonces $(F_{0}(\alpha), F'_{0}(\alpha'), \psi_{1}) \in S$, lo cual contradice la maximalidad de $(F_{0}, F'_{0}, \psi_{0})$. Por lo tanto, $F_{0} = E$ y $(E, F'_{0}, \psi_{0}) \in S$, y como $\psi_{0} \colon E \longrightarrow F'_{0} \subseteq C$, se tiene que el siguiente diagrama es conmutativo:
$$\xymatrix @=2cm {K \ar[r]^{\sigma} \ar[d]_{\varphi} & E\ar[ld]^{\psi_{0}}  \\ C   }$$

$\hfill \square$

\subsection{Cuerpo de escisión de un polinomio}
De lo que se trata de ver en esta sección es la existencia y unicidad (salvo isomorfismo como siempre) de los cuerpos de escisión. Pero primero vamos a definir lo que son:

\begin{definition} Sea $f \in K[x]$ un polinomio y $E/K$ una extensión. Diremos que $f$ \textbf{se escinde} en $E$ si existen $a_{1}, \ldots, a_{n} \in E$ tales que $f = a(x-a_{1}) \ldots (x-a_{n})$, con $a \in K$. Si además $E = K(a_{1}, \ldots, a_{n})$ decimos que $E$ es un \textbf{cuerpo de escisión de $f$ sobre $K$}.
\end{definition}

Una definición más general (la anterior sólo sirve para casos finitos) sería: \textit{diremos que un cuerpo $E$ es un \textbf{cuerpo de escisión} de un $f$ sobre un cuerpo $K$ si $f$ se puede descomponer como producto factores lineales en $E$}.

\begin{observation} Algunas observaciones: 
\begin{enumerate}
\item Todo polinomio de grado $1$ de $K[x]$ se escinde en $K$.
\item $f \in K[x]$ se escinde en $K$ si, y sólo si todos los polinomios irreducibles que aparecen en su descomposición son de grado $1$.
\item Si $f \in K[x]$ se escinde en $K$ y $g \mid f$, entonces $g$ también se escinde en $K$.
\end{enumerate}
\end{observation}

Pasemos ahora a probar la existencia:
\begin{theorem}[\textbf{\textit{Existencia de cuerpos de escisión}}]Si $f \in K[x]$, existe un cuerpo de escisión de $f$ sobre $K$.
\end{theorem}
\emph{Demostración: }Lo haremos por inducción sobre el grado de $f$:
Si $f$ se escinde en $K$ (en particular, si $\delta(f) = 1$), entonces $K$ es un cuerpo de escisión de $f$ sobre $K$. Supongamos que no es así y sea $f_{1}$ un factor irreducible de $f$ de grado mayor que $1$. Por~\ref{eq:ac1}, existe una extensión $E$ de $K$ en la que $f_{1}$ tiene una raíz $a$. Entonces $f(a) = 0$ ya que $f_{1}(a) = 0$. Por~\ref{eq:ac2} $x-a \mid f$ y así $f = (x-a)g$, con $g \in K(a)[x]$. Como $\delta (g) < \delta(f)$, por la hipótesis de inducción tenemos que existe un cuerpo de escisión de $g$ sobre $K(a)$. Será $g = b(x-b_{1}) \ldots (x-b_{m})$ y el cuerpo de escisión de $g$ (sobe $K(a)$) será $K(a)(b_{1}, \ldots, b_{m}) = K(a,b_{1}, \ldots, b_{m})$. Ahora, $f = b(x-a)(x-b_{1}) \ldots (x-b_{m})$ y su cuerpo de escisión sobre $K$ es $K(a, b_{1}, \ldots, b_{m})$.

$\hfill \square$

\begin{example}Hallar un cuerpo de escisión de $f(x) = x^4-5x^2+5 \in \mathbb{Q}[x]$ sobre $\mathbb{Q}$.

Sabemos que $f(x)$ es irreducible por Eisenstein, sus raíces son: $$x = \pm \sqrt{\dfrac{5 \pm \sqrt{25-20}}{2}}, \quad \alpha = \sqrt{\dfrac{5 + \sqrt{5}}{2}}, \hspace{0.1cm}  \beta = \sqrt{\dfrac{5 - \sqrt{5}}{2}}, \hspace{0.1cm}, -\alpha, -\beta.$$

Es inmediato ver que $\alpha \beta = \sqrt{5}$. Notar que tanto $\alpha$ como $\beta$ son reales. El cuerpo de escisión será $\mathbb{Q}(\alpha, \beta, -\alpha, -\beta) = \mathbb{Q}(\alpha,\beta)$.

Ahora, $\alpha^2 = \dfrac{5+\sqrt{5}}{2}$, luego $\mathbb{Q}(\alpha^2) = \mathbb{Q}(\sqrt{5})$ ó $\sqrt{5} \in \mathbb{Q}(\alpha)$. Así, $\beta = \alpha /\sqrt{5} \in \mathbb{Q}(\alpha)$, luego $\mathbb{Q}(\alpha, \beta) = \mathbb{Q}(\alpha)$ y así el cuerpo de escisión es $\mathbb{Q}(\alpha)$. Y $|\mathbb{Q}(\alpha) : \mathbb{Q} | = \delta(f) = 4$, ya que $f=Irr(\alpha, \mathbb{Q})$.
\end{example}

$\hfill \blacksquare$

De este ejemplo podemos ver que en estos casos, en los polinomios bicuadrados de la forma $x^4+ax^2+b$, las raíces van a ser de la forma: $$\alpha = \sqrt{\dfrac{-a+\sqrt{a^2-4b}}{2}}, \hspace{0.1cm} \beta =\sqrt{\dfrac{-a-\sqrt{a^2-4b}}{2}}, \hspace{0.1cm} -\alpha, \hspace{0.1cm}, -\beta,$$ y van a cumplir que $\alpha\beta = \sqrt{b}$. Luego, el cuerpo de escisión de estos polinomios será de la forma $\mathbb{Q}(\alpha, \beta)$.

\begin{example}Hallar el cuerpo de escisión de $f(x)= x^4+3x^2-3 \in \mathbb{Q}[x]$ sobre $\mathbb{Q}$.
$$\alpha= \sqrt{\dfrac{-3+\sqrt{21}}{2}},\hspace{0.1cm} \beta = \sqrt{\dfrac{-3-\sqrt{21}}{2}}, \hspace{0.1cm} \alpha\beta = \sqrt{-3}, \hspace{0.1cm} \mathbb{Q}(\alpha^2) = \mathbb{Q}(21).$$ Notar que $\beta \notin \mathbb{Q}(\alpha)$ ya que $\beta \notin \mathbb{R}$ pero $\alpha \in \mathbb{R}$. Así, el cuerpo de escisión de $f(x)$ sobre $\mathbb{Q}$ es $\mathbb{Q}(\alpha, \beta)$. Se tiene que $\beta^2 \in \mathbb{Q}(\sqrt{21})=\mathbb{Q}(\alpha^2)$, luego $\beta^2 = t \in \mathbb{Q}(\alpha^2)\subseteq \mathbb{Q}(\alpha)$ y así $Irr(\beta, \mathbb{Q}(\alpha))=x^2-t$, luego $|\mathbb{Q}(\alpha)(\beta):\mathbb{Q}(\beta)| =2$, y  $$|\mathbb{Q}(\alpha,\beta):\mathbb{Q}| = |\mathbb{Q}(\alpha) (\beta):\mathbb{Q}(\alpha)||\mathbb{Q}(\alpha):\mathbb{Q}| = 8.$$

\end{example}

$\hfill \blacksquare$

\begin{proposition}\label{eq:cuesc} Sea $\sigma \colon K_{1} \longrightarrow K_{2}$ un isomorfismo, $f_{1} \in K_{1}[x]$ y $f_{2} = \sigma (f_{1}) \in K_{2}[x]$. Sean $E_{i}$, con $i = 1,2$ cuerpos de escisión de $f_{i}$ sobre $K_{i}$, $i = 1,2$. Entonces existe un isomorfismo $\tau \colon E_{1} \longrightarrow E_{2}$ que extiende $\sigma$, es decir, $ \left.\tau \right|_{K_{1}} = \sigma$.
\end{proposition}
\emph{Demostración: } Inducción sobre $|E_{1}: K_{1}|$ :

Si $|E_{1}:K_{1}| = 1$, entonces $E_{1} = K_{1}$ es cuerpo de escisión de $f_{1}$ sobre $K_{1}$. Como $\sigma \colon K_{1}[x] \longrightarrow K_{2}[x]$ es isomorfismo de anillos, también $\sigma (f_{1})$ ($=f_{2}$) se escindirá sobre $K_{2}$. Así $E_{2} = K_{2}$ y basta tomar $\tau = \sigma$.

Supongamos que $|E_{1}: K_{1}| > 1$ y que el resultado es cierto para extensiones de menor grado. Como $|E_{1}:K_{1}| > 1$, $f_{1}$ no se escinde en $K_{1}$ y existe un factor irreducible (importante esto!) $p$ de $f_{1}$ tal que $\delta (p) > 1$. Como $f_{1}$ se escinde en $E_{1}$, también $p$ se escinde en $E_{1}$ y $\sigma (p)$ se escinde en $E_{2}$. Sea $a \in E_{1}$, raíz de $p$ y sea $b \in E_{2}$ raíz de $\sigma (p)$. Por~~ existe un isomorfismo $\theta	 \colon K_{1}(a) \longrightarrow K_{2}(b)$ que extiende $\sigma$, es decir $\left.\theta \right|_{K_{1}} = \sigma$.

Ahora, $E_{1}$ es cuerpo de escisión de $f_{1}$ sobre $K_{1}(a)$. Y $E_{2}$ es cuerpo de escisión de $f_{2}$ ($= \sigma(f_{1})$) sobre $K_{2}(b)$. Además, \begin{center}$|E_{1} : K_{1}| = |E_{1} : K_{1}(a)| |K_{1}(a) : K_{1} | > |E_{1}:K_{1}(a)|,$ ya que $a \notin K_{1}$ .\end{center}

Por inducción, existe $\tau \colon E_{1} \longrightarrow E_{2}$ isomorfismo que extiende $\theta$, luego también extiende $\sigma$. 

$$\xymatrix @=2cm {E_{1}\ar[r]^{\tau} & E_{2} \\ K_{1}(\alpha)\ar[r]^{\theta} \ar@{_(->}[u] & K_{2}(b) \ar@{_(->}[u] \\ K_{1} \ar[r]^{\sigma} \ar@{_(->}[u] & K_{2} \ar@{_(->}[u]  }$$

$\hfill \square$

\begin{corolario}[\textbf{\textit{Unicidad de los cuerpos de escisión}}] \label{eq:unicuer} Si $E_{1}, E_{2}$ son cuerpos de escisión de un mismo polinomio $f$ de $K[x]$ sobre $K$, existe entonces $\tau \colon E_{1} \longrightarrow E_{2}$ isomorfismo tal que $\left.\tau \right|_{K} = id.$
\end{corolario}
\emph{Demostración: } Basta hacer $K_{1} = K_{2} = K$ y $\sigma = id$ en la proposición anterior.

$\hfill \square$

\subsection{Extensiones normales}

\begin{definition} Una extensión de cuerpos $E/K$ es una \textbf{extensión normal} si existe $f \in K[x]$ tal que $E$ sea cuerpo de escisión de $f$ sobre $K$.
\end{definition}

\begin{observation}Un par de observaciones: \begin{enumerate}
\item Si $E/K$ es normal, $E/K$ es finita. Esto es así ya que $E$ lo vamos a obtener adjuntando a $K$ un número finito de elementos algebraicos y aplicar~\ref{eq:finalg}.
\item Si $E/K$ es normal y $K \subseteq L \subseteq E$, $E/L$ también es normal. En este caso, ya que $E$ es cuerpo de escisión de un $f \in K[x]$ sobre $K$, también es cuerpo de escisión de $f \in L[x]$ sobre $L$.
\end{enumerate}
\end{observation}

\begin{proposition} Toda extensión de grado $2$ es normal.
\end{proposition}
\emph{Demostración: }$E/K$ es algebraica ya que es finita. Sea ahora $f \in K[x]$ irreducible con una raíz $\alpha$ en $E$. Veamos que $f$ se escinde en $E$. $\alpha$ es algebraico sobre $K$ y $|K(\alpha) :K| = \delta(Irr(\alpha, K)) = \delta(f)$. Como $K \subseteq K(\alpha) \subseteq E$, entonces $|K(\alpha):K| \leq |E:K| = 2$. Luego $\delta(f) = 1$ ó $2$.

Si $\delta(f) = 1$ entonces $f$ se escinde en $K$. Si $\delta(f) = 2$, como sabemos que $x -\alpha$ divide a $f$ en $E[x]$ existe un $g \in E[x]$ tal que $f=(x-\alpha)g$, y como $\delta(f) = 2$ entonces $\delta(g) = 1$ y $f$ se escinde en $E$.

$\hfill \square$


\begin{proposition} \label{eq:extcint} Sea $E/K$ una extensión normal y $K \subseteq M_{1}, M_{2} \subseteq E$ cuerpos intermedios. Sea $\sigma \colon M_{1} \longrightarrow M_{2}$ un isomorfismo tal que $\left.\sigma \right|_K  = id$. Entonce existe un isomorfismo $\tau \colon E \longrightarrow E$ que extiende $\sigma$.
\end{proposition}
\emph{Demostración: } Por definición de extensión normal, $E$ es cuerpo de escisión de un $f \in K[x]$ sobre $K$. Como hemos observado, $E$ también es cuerpo de escisión de $f$ sobre $M_{i}$, con $i = 1,2$. Además, $\sigma (f) = f$ ya que $\left.\sigma \right|_K  = id$. Aplicamos ahora~\ref{eq:cuesc} y tenemos $\tau \colon E \longrightarrow E$ tal que $\tau$ extiende $\sigma$.

$\hfill \square$

\begin{proposition}\label{eq:isoimp} Sea $E/K$ una extensión normal, $p \in K[x]$ irreducible, $a, b \in E$ raíces de $p$ en $E$. Entonces existe $\tau \colon E \longrightarrow E$ isomorfismo tal que $\tau (a) = b$ y $\left.\tau \right|_K  = id$.
\end{proposition}
\emph{Demostración: } Por~\ref{eq:irrcor}, existe $\theta \colon K(a) \longrightarrow K(b)$ isomorfismo tal que $\theta (a) = b$ y $\left.\theta \right|_K  = id$. Por la proposición anterior existe $\tau \colon E \longrightarrow E$ que extiende $\theta$. Entonces $\tau (a) = \theta(a) = b$ y $\left.\tau \right|_K  = id$.

$\hfill \square$

\begin{example}Veamos el cuerpo de escisión de $x^{3}-2 \in \mathbb{Q}[x]$ sobre $\mathbb{Q}$.
\end{example}

\begin{proposition}\label{eq:extnou} Sea $E/K$ una extensión finita. Entonces $E/K$ es normal si y sólo si todo polinomio irreducible de $K[x]$ que tenga una raíz en $E$ se escinde en $E$.
\end{proposition}
\emph{Demostración: } Como $E/K$ finita entonces $\lbrace a_{1}, \ldots, a_{n}$ es una base de $E$ como $K-e.v$. Entonces $E= K(a_{1}, \ldots, a_{n})$. Sea ahora $p_{i} = Irr(a_{i}, K)$, con $i = 1, \ldots, n$. Entonces, por hipótesis, $p_{i}$ se escinde en $E$, $i = 1, \ldots , n$. Sea $f = p_{1} \ldots p_{n}$. Claramente $E$ es un cuerpo de escisión de $f$ sobre $K$ ($E= K(a_{1}, \ldots, a_{n}) = K(Kerf)$, ya que los $a_{1}, \ldots, a_{n}$ anulan a $f$). Así que $E/K$ es normal.

Recíprocamente, como $E/K$ es normal, $E$ es cuerpo de escisión de un polinomio $f \in K[x]$ sobre $K$. Sea $p \in K[x]$ irreducible con una raíz $a$ en $E$. Sea $b$ otra raíz de $p$ en un cuerpo de escisión de $p$ ($p \in K[x]$ luego también está en $E[x]$) sobre $E$. Tenemos que ver que $b \in E$. Para ello, por~\ref{eq:irrcor} existe un isomorfismo $\theta \colon K(a) \longrightarrow K(b)$ tal que $\left.\theta \right|_K  = id$. Ahora, $E$ es un cuerpo de escisión de $f$ sobre $K(a)$ (lo era sobre $K$). También $E(b)$ es cuerpo de escisión de $f$ sobre $K(b)$. Además, como $f \in K[x]$ y $\theta$ fija $K$, tenemos que $\theta (f) = f$. Por~\ref{eq:cuesc}, existe un isomorfismo $\tau \colon E \longrightarrow E(b)$ que extiende $\theta$. Por~\ref{eq:propprinp}, se tiene que $$|E:K(a)| = |E(b) :K(b)|.$$ Como $a$ y $b$ son raíces de $p \in K[x]$ irreducible, $|K(a) :K| = |K(b) : K| = \delta (p)$. Así, \begin{center}$|E(b) : E| |E: K| = |E(b): K| = |E(b) :K(b)| |K(b):K| = |E:K(a)| |K(a) :K| = |E:K|,$\end{center} luego $|E(b) :E| = 1$, es decir, $b \in E$.

$$\xymatrix @=2cm {E\ar[r]^{\tau} & E_{b} \\ K(a)\ar[r]^{\theta} \ar@{_(->}[u] & K(b) \ar@{_(->}[u] \\ K \ar[r]^{id} \ar[u] & K \ar[u]  }$$

$\hfill \square$

\subsection{Extensiones separables}

\begin{definition}Una extensión $E/K$ se dice \textbf{separable} si todo $f \in K[x]$ irreducible que tenga una raíz en $E$ no tiene raíces múltiples en $E$. Es decir, todas sus raíces son distintas.
\end{definition}

De igual forma podremos definir: 

\begin{definition}Dado un cuerpo $K$, un polinomio $f \in K[x]$ diremos que es \textbf{separable} si el máximo común divisor de $f$ y su derivada $f'$ es $1$.
\end{definition}

\begin{definition}Sea $E/K$ una extensión. Un elemento algebraico $a \in E$ se dice que es \textbf{separable} si su polinomio irreducible lo es. Evidentemente si todo $a \in E$ es separable entonces la extensión será separable.
\end{definition}

Por ejemplo, el polinomio $x^2 -1 \in \mathbb{Q}[x]$ es separable, pero $(x-1)^2 \in \mathbb{Q}[x]$ no.

Toda extensión de cuerpos de característica $0$ es separable por~\ref{eq:raimu}. Recordemos que es así porque entonces $Irr(a,K)$ de un elemento $a \in E$ es irreducible y así el máximo común divisor con su derivada sólo puede ser $1$.

\begin{proposition}Sea $E/K$ una extensión algebraica y separable y $L$ un cuerpo intermedio de la extensión. Entonces $E/L$ y $L/K$ son separables.
\end{proposition}
\emph{Demostración: }La extensión $L/K$ es separable ya que $L \subseteq E$ y todo elemento de $E$ es separable sobre $K$.

Sea ahora $\alpha \in E$ y $f \in K[x]$ su polinomio irreducible. Entonces $q=Irr(\alpha, L) \mid f$. Si $q$ no fuera separable, cualquier factor común entre $q$ y su derivada sería también un factor común entre $f$ y su derivada, por lo que $f$ no sería separable.

$\hfill \square$

\begin{definition}Una extensión $E/K$ se dice \textbf{extensión de Galois} si es normal y separable.
\end{definition}

\section{La correspondencia de Galois}
\subsection{El grupo de Galois}

Lo que a continuación vamos a definir será el objeto de estudio del resto del texto, imprescindible para entender lo que venga en adelante y eje vertebrador de la \textit{Teoría de Galois}. Empezaremos definiendo el grupo de Galois.

Recordemos que, dado un cuerpo $E$, denotaremos por $Aut(E)$ al grupo de los automorfismos de $E$, es decir, al grupo de los isomorfismos $\sigma \colon E \longrightarrow E$ con la operación composición de aplicaciones.

\begin{definition} Sea $E/K$ una extensión de cuerpos. Llamaremos \textbf{grupo de Galois de $E/K$}, y lo denotaremos por $Gal(E/K)$, a $$Gal(E/K) = \lbrace \sigma \colon E \longrightarrow E:\hspace{0.1cm} \sigma\text{ es isomorfismo}, \left.\sigma \right|_K  = id_{K} \rbrace.$$

Es decir, que $\sigma \in Aut(E)$ y $\sigma(k) = k$, $\forall k \in K$. Además, va a ser un subgrupo de $Aut(E)$ con la composición de aplicaciones: $$(\sigma \circ \tau) (e) = \sigma (\tau (e)), \hspace{0.2cm} \forall e \in E.$$
\end{definition}

\begin{definition}Si $\sigma \in Aut(E)$, definimos el \textbf{cuerpo fijo de $\sigma$}, escrito $C_{E}(\sigma)$, como $$C_{E}(\sigma) = \lbrace a \in E: \sigma (a) = a \rbrace.$$
\end{definition}

\begin{observation}$C_{E}(\sigma)$ es un subcuerpo de $E$. Esto es así ya que, dados $a,b \in C_{E}(\sigma)$, se tiene que $\sigma(a-b) = \sigma(a) -\sigma(b) = a-b$. Luego $a-b \in C_{E}(\sigma)$. Y si $b\neq 0$ entonces $\sigma(ab^{-1}) = \sigma(a) \sigma(b)^{-1} = ab^{-1}$, y $ab^{-1} \in C_{E}(\sigma)$.
\end{observation}

\begin{example} El grupo de Galois de $\mathbb{Q}(\sqrt[3]{2}/\mathbb{Q})$, escrito $Gal(\mathbb{Q}(\sqrt[3]{2}/\mathbb{Q})$. Sabemos que $x^{3}-2 = Irr(\sqrt[3]{2}, \mathbb{Q})$, y que sus raíces son $\sqrt[3]{2},$  $\sqrt[3]{2}w,$  $\sqrt[3]{2}w^{2}$, con $$w = -\dfrac{1}{2} + \dfrac{\sqrt{3}}{2}i = \cos \left( \dfrac{2\pi}{3} \right) + i\sin \left( \dfrac{2\pi}{3} \right)$$ (recordar la fórmula de las raíces de la unidad).

Sea $\sigma \in Gal(\mathbb{Q}(\sqrt[3]{2}/\mathbb{Q})$, debe llevar $\sqrt[3]{2}$ a otra raíz de $Irr(\sqrt[3]{2}, \mathbb{Q})$. Sabemos también que $\mathbb{Q}(\sqrt[3]{2}) \subset \mathbb{R}$, sin embargo $\sqrt[3]{2}w,$  $\sqrt[3]{2}w^{2}$ no pertenecen a $\mathbb{R}$. Por lo tanto, $\sigma (\sqrt[3]{2}) = \sqrt[3]{2}$ y $\sigma (a + b\sqrt[3]{2} + c\sqrt[3]{2}^{2}) = a + b\sqrt[3]{2} + c\sqrt[3]{2}^{2}$, ya que ha de fijar $\mathbb{Q}$ (como el irreducible es de grado $3$ entonces una base de la extensión es esa). Así, $\sigma = id$ y $Gal(\mathbb{Q}(\sqrt[3]{2}/\mathbb{Q}) = 1$.
\end{example}

$\hfill \blacksquare$

\begin{proposition}\label{eq:ggal1} Sea $E_{1}/K_{1}$ una extensión de cuerpos y $\sigma \colon E_{1} \longrightarrow E_{2}$ isomorfismo. Si $K_{2} = \sigma (K_{1})$, se cumple que $Gal(E_{1}/K_{1})$ y $Gal(E_{2}/K_{2})$ son isomorfos.
\end{proposition}

\begin{definition} Dado un $f \in K[x]$ definimos el \textbf{grupo de Galois de $f$} como $Gal(E/K)$, siendo $E$ un cuerpo de escisión de $f$ sobre $K$.

Notar que si $E_{1}, E_{2}$ son cuerpos de escisión de $f$ sobre $K$, sabemos que por~\ref{eq:unicuer} existe $\tau \colon E_{1} \longrightarrow E_{2}$ isomorfismo tal que $\left.\tau \right|_K = id$. Por~\ref{eq:ggal1}, $Gal (E_{1}/K)$ es isomorfo a $Gal(E_{2}/K)$. Luego el concepto de grupo de Galois de $f$ está bien definido.
\end{definition}

\begin{proposition}\label{eq:gall} Sea $E = K(a_{1}, \ldots, a_{n})$. Sean $\sigma, \tau \in Gal(E/K)$ tal que $\sigma (a_{i}) = \tau (a_{i})$, $i = 1, \ldots, n$. Entonces $\sigma = \tau$.
\end{proposition}
\emph{Demostración: } 
Por hipótesis, $\sigma(a_{i}) = \tau (a_{i})$, con $i = 1, \ldots, n$. Es decir, que $(\sigma \circ \tau^{-1})(a_{i}) = a_{i}$, con $i = 1, \ldots, 0$. Entonces $a_{i}\in C_{E}(\sigma \tau^{-1})$. Además, $K$ es subcuerpo de $C_{E}(\sigma \tau^{-1})$. Como a su vez $C_{E}(\sigma \tau^{-1})$ es subcuerpo de $E$ y $K(a_{1}, \ldots, a_{n})$ es el menor subcuerpo de $E$ que contiene a $K$ y a $a_{1}, \ldots, a_{n}$ entonces $E = K(a_{1}, \ldots, a_{n}) \in C_{E}(\sigma \tau^{-1})$. Asi, $\sigma = \tau$.

$\hfill \square$

Básicamente esto quiere decir que un elemento de $Gal(E/K)$ queda unívocamente determinado por las imágenes de los $a_{i}$.

\begin{proposition}\label{eq:accgal} Sea $f \in K[x]$ y sea $a$ una raíz de $f$ en una extensión $E$ de $K$. Si $\sigma \in Gal(E/K)$, también $\sigma (a)$ es raíz de $f$. Sea $\Omega = \lbrace \text{raíces de} \hspace{0.1cm} f \text{en} \hspace{0.1cm} E \rbrace. $ La aplicación  $$\begin{array}{rccl}
\varphi \colon &Gal(E/K)&\longrightarrow &S_{\Omega} \\
&\sigma& \longmapsto &\left.\sigma \right|_\Omega \\
\end{array}
$$ es una acción de $Gal(E/K)$ sobre $\Omega$. Si $E$ es cuerpo de escisión de $f$ sobre $K$, dicha acción es fiel, es decir, cumple que $Ker \hspace{0.1cm} \varphi = 1$. Si además $f$ es irreducible, dicha acción es transitiva, es decir, tiene sólo una órbita.
\end{proposition}
\emph{Demostración: }
Veamos que $\sigma(a)$ es también una raíz de $f$. Sea $f = a_{0}+a_{1}x+ \ldots + a_{k}x^{k}$, entonces $a_{0}+a_{1}a+ \ldots + a_{k}a^{k} =0$, y de aquí $\sigma(a_{0}+a_{1}a+ \ldots + a_{k}a^{k}) =\sigma(0) = 0$. Pero  $\sigma(a_{0}+a_{1}a+ \ldots + a_{k}a^{k}) =  \sigma(a_{0})+\sigma(a_{1})\sigma(a)+ \ldots + \sigma(a_{k})\sigma(a)^{k} = 0$. Como $\left.\sigma \right|_K = id$ tenemos que $a_{0}+a_{1}\sigma(a)+ \ldots + a_{k}\sigma(a)^{k} = 0$, es decir, que $\sigma(a)$ es raíz de $f$.

Ahora, supongamos que $E$ es un cuerpo de escisión de $f$ sobre $K$. Luego $E = K(a_{1}, \ldots, a_{n})$ siendo $\Omega = \lbrace a_{1}, \ldots, a_{n} \rbrace$. Si $\sigma \in Ker \hspace{0.1cm} \varphi$, $\sigma$ fijará $a_{1}, \ldots, a_{n}$. Por el resultado anterior~\ref{eq:gall} $\sigma = id$. Supongamos que además $f$ es irreducible. Por~\ref{eq:isoimp}, dados $a,b \in \Omega$, existe $\sigma \colon E \longrightarrow E$ isomorfismo, $\left.\sigma \right|_K = id$ y $\sigma (a) = b$. Entonces $\sigma \in Gal(E/K)$ y $a,b$ están en la misma órbita, luego hay sólo $1$ órbita y la acción es transitiva.

$\hfill \square$

\begin{proposition}\label{eq:sigK} Sea $E/K$ una extensión, $a_{1}, \ldots, a_{n} \in E$. Sea $L$ un cuerpo cualquiera y $\sigma \colon E \longrightarrow L$ un isomorfismo. Entonces tenemos que $\sigma(K(a_{1}, \ldots, a_{n})) = \sigma(K)(\sigma(a_{1}), \ldots, \sigma(a_{n})).$
\end{proposition}
\emph{Demostración: }$\sigma(K(a_{1}, \ldots, a_{n}))$ es un cuerpo y contiene a $\sigma(K)$ y a $\sigma(a_{1}), \ldots, \sigma(a_{n})$. Como $\sigma(K)(\sigma(a_{1}), \ldots, \sigma(a_{n}))$ es el menor subcuerpo de $L$ que contiene a $\sigma(K)$ y a $\sigma(a_{1}), \ldots, \sigma(a_{n})$, será $$\sigma(K)(\sigma(a_{1}), \ldots, \sigma(a_{n})) \subseteq \sigma(K(a_{1}, \ldots, a_{n})).$$ $\sigma^{-1}(\sigma(K)(\sigma(a_{1}), \ldots, \sigma(a_{n})))$ es un cuerpo y contiene a $K, a_{1}, \ldots, a_{n}$. Por el mismo argumento tenemos que $$\sigma^{-1}(\sigma(K)(\sigma(a_{1}), \ldots, \sigma(a_{n})))\supseteq K(a_{1}, \ldots, a_{n}).$$ Aplicando $\sigma:$ $$\sigma(K)(\sigma(a_{1}), \ldots, \sigma(a_{n})) \supseteq \sigma(K(a_{1}, \ldots, a_{n})).$$

$\hfill \square$

\begin{proposition}\label{eq:preGal0} Sean $K \subseteq L \subseteq E$. \begin{enumerate}
\item $Gal(E/L) \leq Gal(E/K)$.
\item Si $L/K$ es normal, entonces $\sigma (L) = L$ $\forall \sigma \in Gal(E/K)$.
\item Supongamos que $E/K$ es normal. Entonces $L/K$ es normal si y sólo si $\sigma (L) = L$ $\forall \sigma \in Gal(E/K)$. Si $L/K$ es normal, $Gal(E/L) \unlhd Gal(E/K)$ y $$Gal(L/K) \cong \dfrac{Gal(E/K)}{Gal(E/L)}.$$
\end{enumerate}
\end{proposition}
\emph{Demostración: }\begin{enumerate}
\item Si $\sigma$ fija a $L$ también fija a $K$, ya que $K \subseteq L$.
\item Si $L/K$ es normal, $L = K(a_{1}, \ldots, a_{n})$, siendo $\Omega = \lbrace a_{1}, \ldots, a_{n} \rbrace $ el conjunto de raíces de un $f \in K[x]$. Vimos en~\ref{eq:accgal} que si $\sigma \in Gal(E/K)$, $\sigma$ permuta las raíces de $f$ y $\sigma(\Omega) = \Omega$. Por~\ref{eq:sigK} $$\sigma(K(a_{1}, \ldots, a_{n})) = \sigma(K)(\sigma(a_{1}), \ldots, \sigma(a_{n})).$$ Como $\lbrace \sigma(a_{1}), \ldots, \sigma(a_{n}) \rbrace = \lbrace a_{1}, \ldots, a_{n} \rbrace$ entonces $\sigma(L) = L$.
\item Veamos que si $\sigma(L) = L$ $\forall \sigma \in Gal(E/K)$ se tiene que $L/K$ es normal. Por~\ref{eq:extnou} bastará ver que si $p \in K[x]$ es irreducible y tiene una raíz $a \in L$, entonces $p$ se escinde en $L$. Como $E/K$ es normal, de nuevo por~\ref{eq:extnou}, todas las raíces de $p$ están en $E$. Sea $b \in E$ otra raíz de $p$. Por~\ref{eq:isoimp} existe $\sigma \in Gal(E/K)$ tal que $\sigma (a) = b$. Como, por hipótesis, $\sigma (L) = L$, tenemos que $b \in L$. Así, $L/K$ es normal.

Ahora, consideremos la aplicación (suponiendo que $L/K$ es normal) $$\begin{array}{rccl}
&Gal(E/K)&\longrightarrow &Gal(L/K) \\
&\sigma& \longmapsto &\left.\sigma \right|_L \\
\end{array}
$$
Por $2.$ $\sigma(L) = L$, luego $\left.\sigma \right|_L \colon L \longrightarrow L$ y la aplicación está bien definida. Es evidentemente homomorfismo. Si $\tau \colon L \longrightarrow L$ es un isomorfismo tal que $\left.\tau \right|_K=id$, por~\ref{eq:extcint} y por ser $E/K$ normal, existe $\sigma \colon E \longrightarrow E$ isomorfismo con $\left.\sigma \right|_K = id$. Así, $\sigma \in Gal (E/K)$ y $\left.\sigma \right|_L = \tau$. Así, la aplicación  es suprayectiva. Su núcleo es $Gal(E/L)$. Así $Gal(E/L) \unlhd Gal(E/K).$ Luego, por el \textit{Primer Teorema de Isomorfía} $$Gal(L/K) \cong \dfrac{Gal(E/K)}{Gal(E/L)}.$$
\end{enumerate}

$\hfill \square$

\begin{definition} Sea $E$ un cuerpo y $H \leq Aut(E)$. Definimos el cuerpo fijo de $H$ como $$C_{E}(H) = \bigcap_{\sigma \in H} C_{E}(\sigma).$$ Que es un subcuerpo de $E$, por serlo cada $C_{E}(\sigma)$ ($C_{E}(\sigma) = \lbrace a \in E :\sigma (a) = a \rbrace$).
\end{definition}
\begin{definition} Una extensión $E/K$ se dice \textbf{extensión de Galois} si es normal y separable.
\end{definition}

\begin{proposition}\label{eq:cuerpIntGal} Sea $K\subseteq L \subseteq E$. Si $E/K$ es de Galois, $E/L$ es de Galois.
\end{proposition}
\emph{Demostración: }Recordar que una extensión se dice de Galois si es normal y separable. Por lo tanto, partiremos de que $E/K$ es normal y separable. Veamos que $E/L$ también lo es.

Recordar también que una extensión $E/K$ es normal si existe un $f \in K[x]$ tal que $E$ es cuerpo de escisión de $f$ sobre $K$. Pero si $E/K$ es normal entonces $E$ es un cuerpo de escisión también de un $f \in L[x]$ sobre $L$ (si lo es de $f \in K[x]$, también $f$ estará en $L$).

Para ver que es separable (todo $f \in K[x]$ irreducible que tenga una raíz en $E$ no tiene raíces múltiples en $E$) sea $p \in L[x]$ irreducible con una raíz $a \in E$. Podemos suponer que $p$ es mónico y así $p = Irr(a,L)$. Entonces, por~\ref{eq:pirrdiv} $$Irr(a,L) \mid Irr(a,K).$$ Como $E/K$ es separable, $Irr(a,K)$ no tiene raíces múltiples en $E$, y así $Irr(a,L)$ tampoco. Luego $E/L$ es separable y de Galois.

$\hfill \square$

\begin{proposition}\label{eq:extGalois} Sea $E/K$ una extensión de Galois. Entonces $$|E:K| = |Gal(E/K)|.$$
\end{proposition}
\emph{Demostración: } Lo haremos por inducción sobre $|E:K|$. Si $|E:K| = 1$, $E=K$ y $Gal(E/K)= 1$ y ya está.

Supongamos que $|E:K|>1$. Sea $a \in E \setminus K$ y $p = Irr(a,K)$. Entonces $\delta(p)>1$. Como $E/K$ es normal, por~\ref{eq:extnou} tenemos que todas las raíces de $p$ están en $E$. Como $E/K$ es separable, todas las raíces son distintas entre sí.

Sea $\Omega = \lbrace \text{raíces de p en E} \rbrace$. Entonces $|\Omega | = \delta(p)$. Por~\ref{eq:accgal} $Gal(E/K)$ actúa sobre $\Omega$. Por~\ref{eq:isoimp}, dadas dos raíces de $p$ en $E$ existe $\sigma \in Gal(E/K)$ que lleva una a la otra. Esto significa que hay sólo una órbita en esta acción, es decir, que la acción es transitiva. El estabilizador de $a$ en esta acción 

$$\begin{array}{rccl}
&Gal(E/K)&\longrightarrow &S_{\Omega} \\
&\sigma& \longmapsto &\left.\sigma \right|_\Omega 
\end{array}
$$

es $Gal(E/K(a))$ puesto que $\sigma(a) = a$ si y sólo si $\sigma (x) = x$ \hspace{0.1cm} $\forall x \in K(a)$. Entonces $|\Omega| = |Gal(E/K)|/|Gal(E/K(a))|$. Pero $|\Omega| = \delta(p) = |K(a):K|$. $|Gal(E/K)| = |Gal(E/K(a))| |\Omega| = |Gal(E/K(a))||K(a):K|.$ Por~\ref{eq:cuerpIntGal}, $E/K(a)$ es de Galois. Por inducción, $|E:K(a)| = |Gal(E/K(a))|$. 

Sustituyendo: $$|Gal(E/K)| = |E:K(a)| |K(a):K| = |E:K|.$$ 


$\hfill \square$

\begin{example}Sea $E = \mathbb{Q}(\sqrt[4]{2}).$ Entonces $|E:\mathbb{Q}| = 4$, $|Gal(E/\mathbb{Q})| = 2$. Si $\sigma \in Gal(E/\mathbb{Q})$, $\sigma(\sqrt[4]{2})$ será raíz de $x^4-2$, $\sigma(\sqrt[4]{2}) = \sqrt[4]{2}$, $\sigma(\sqrt[4]{2}) = -\sqrt[4]{2}$, pero también están $\sqrt[4]{2}i \notin \mathbb{Q}(\sqrt[4]{2})$ y $-\sqrt[4]{2}i \notin \mathbb{Q}(\sqrt[4]{2})$.
\end{example}

$\hfill \blacksquare$

\subsection{El Teorema Fundamental de la Teoría de Galois}

Vamos a partir de una extensión $E/K$, con sus respectivos cuerpos intermedios $L$ tales que $K \subseteq L \subseteq E$, y su grupo de Galois $Gal(E(K)$, con sus respectivos subgrupos $H$. Entonces, si $E/k$ es de Galois vamos a poder establecer una biyección entre los subgrupos de $Gal(E/K)$ y los respectivos cuerpos intermedios de la extensión $E/K$. En esto consiste el teorema fundamental de la \textit{Teoría de Galois}.

$$\xymatrix @=2cm {E & Gal(E/K) \\ C_{E}(H)\ar@{-}[u] &H\ar@{-}[u] \ar@{~>}[l]_g\\ L\ar@{-}[u] \ar@{~>}[r]^f &Gal(E/L)\ar@{-}[u] \\ K \ar@{-}[u] & 1 \ar@{-}[u]  }$$

\begin{proposition}\label{eq:preGal1} Sea $E/K$ de Galois. Entonces $C_{E}(Gal(E/K)) = K$.
\end{proposition}
\emph{Demostración: }Podemos suponer que $E\neq K$. Sea $a \in E \setminus K$ y sea $p = Irr(a,K)$. Entonces $\delta(p) >1$. Como la extensión $E/K$ es normal, por~\ref{eq:extnou} $p$ se escinde en $K$. Como $E/K$ es separable, todas las raíces de $p$ son distintas. Sea $a \neq b$ una raíz de $p$. Ahora, por~\ref{eq:isoimp}, existe $\sigma \in Gal(E/K)$ tal que $\sigma(a)=b$. Así, $a \notin C_{E}(Gal(E/K))$ y $C_{E}(Gal(E/L))=K.$

$\hfill \square$

\begin{observation}Sea $K \subseteq L \subseteq E$ y $E/K$ de Galois. Entonces $C_{E}(Gal(E/L)) = L$. Recordemos que $E/L$ también es de Galois.
\end{observation}

\begin{proposition}\label{eq:preGal2} Sea $E/K$ extensión de Galois y $H \leq Gal(E/K)$. Entonces $Gal(E/C_{E}(H)) = H.$
\end{proposition}
\emph{Demostración: }Claramente $H \leq Gal(E/C_{E}(H))$. Por~\ref{eq:cuerpIntGal}, $E/C_{E}(H)$ es de Galois. Por~\ref{eq:extGalois}, $|Gal(E/C_{E}(H))| = |E:C_{E}(H)|$. Así, $|H| \leq |E:C_{E}(H)|$. Bastará ver que $|E:C_{E}(H)|\leq |H|$.

Sea $H= \lbrace id=\sigma_{1}, \sigma_{2},\ldots, \sigma_{n} \rbrace$. Así, $|H| = n$. Sea $F = C_{E}(H)$. Tenemos que probar que cualesquiera $n+1$ elementos de $E$ son $F$-linealmente dependientes. Sean $a_{1}, \ldots, a_{n+1} \in E$. Vamos a considerar el sistema de $n$ ecuaciones lineales con $n+1$ incógnitas $$\sigma_{1}(a_{1})x_{1}+\ldots + \sigma_{1}(a_{n+1})x_{n+1}=0$$ $$\ldots \ldots \ldots \ldots \ldots \ldots \ldots$$ $$\sigma_{n}(a_{1})x_{1}+\ldots + \sigma_{n}(a_{n+1})x_{n+1}=0$$

Como es un sistema homogéneo y hay más incógnitas que ecuaciones existe alguna solución no trivial, es decir, que no todo son $0$. Elegimos una solución no trivial $x_{i}=t_{i}$, con $i = 1, \ldots, n+1$ que tenga el menor número posible de $t_{i}$'s no nulos. Veamos que $t_{i} \in F$, con $i = 1, \ldots, n+1$. Ahora, como $\sigma_{1}=id$ la primera ecuación es $t_{1}a_{1}+\ldots+t_{n+1}a_{n+1}=0$ y $\lbrace a_{1}, \ldots, a_{n+1}\rbrace$ será linealmente dependiente, como queríamos. Reordenando los $a_{i}$'s podemos suponer que $t_{1} \neq 0$ y, dividiendo por él, que $t_{1}=1$. Por reducción al absurdo y reordenando de nuevo puedo suponer que $t_{2}\in E \setminus F$. Como $F= C_{E}(H)$, existe algún $\sigma_{i} \in H$ tal que $\sigma_{i}(t_{2}) \neq t_{2}.$ Como $H$ es un grupo, $\lbrace \sigma_{i}\sigma_{j} : 1 \leq j \leq n \rbrace = H$. El sistema de ecuaciones $$(\sigma_{i}\sigma_{1})(a_{1})x_{1}+\ldots + (\sigma_{i}\sigma_{1})(a_{n+1})x_{n+1}=0$$ $$\ldots \ldots \ldots \ldots \ldots \ldots \ldots$$ $$(\sigma_{i}\sigma_{n})(a_{1})x_{1}+\ldots + (\sigma_{i}\sigma_{n})(a_{n+1})x_{n+1}=0$$ es el mismo sistema de antes (sólo cambian el orden de las ecuaciones). Entonces $x_{j} = \sigma_{i}(t_{j})$, con $j = 1, \ldots, n+1$, es solución del sistema: $$\sigma_{1}(a_{1})t_{1}+\ldots + \sigma_{1}(a_{n+1})t_{n+1}=0$$ $$\ldots \ldots \ldots \ldots \ldots \ldots \ldots$$ $$\sigma_{n}(a_{1})t_{1}+\ldots + \sigma_{n}(a_{n+1})t_{n+1}=0$$ ya que si hacemos $$\sigma_{i}(\sigma_{1}(a_{1})t_{1}+\ldots + \sigma_{1}(a_{n+1})t_{n+1})=\sigma_{i}(0)=0$$ con todas las ecuaciones entonces: $$(\sigma_{i}\sigma_{1})(a_{1})\sigma_{i}(t_{1})+\ldots + (\sigma_{i}\sigma_{1})(a_{n+1})\sigma_{i}(t_{n+1})=0$$ $$\ldots \ldots \ldots \ldots \ldots \ldots \ldots$$ $$(\sigma_{i}\sigma_{n})(a_{1})\sigma_{i}(t_{1})+\ldots + (\sigma_{i}\sigma_{n})(a_{n+1})\sigma_{i}(t_{n+1})=0.$$

Y como toda combinación lineal de soluciones de un sistema homogéneo es también solución entonces una nueva solución será restarle a la primera la segunda: $$x_{1} = 1-\sigma_{i}(1) = 0$$ $$x_{2}=t_{2}-\sigma_{i}(t_{2}) \neq 0$$ $$ \ldots \ldots$$ $$x_{n+1} = t_{n+1} - \sigma_{i}(t_{n+1}).$$ Si un $t_j =0$ entonces $t_j - \sigma_i(t_j)=0$. Luego esta nueva solución (la obtenida de restar) tiene como mínimo un $0$ más que la original. Absurdo.

$\hfill \square$

\begin{proposition}\label{eq:preGal3}Sea $K \subseteq L \subseteq E$. Sea $H = Gal(E/L) \leq Gal(E/K)$. Dado un $\tau \in Gal(E/K)$ entonces $H^\tau = Gal(E/\tau(L))$.
\end{proposition}
\emph{Demostración: }Sea $\sigma \in Gal(E/K)$. $\sigma \in Gal(E/\tau(L))$ si y sólo si $\sigma (\tau (l)) = \tau (l)$ \hspace{0.1cm} $\forall l \in L$ si y sólo si $(\tau^{-1}\sigma \tau )(l) = l$ $\forall l \in L$ si y sólo si $\tau^{-1}\sigma \tau \in Gal(E/L) = H$ si y sólo si $\sigma \in \tau H \tau^{-1} = H^\tau.$

$\hfill \square$

\begin{theorem}[\textbf{\textit{Teorema fundamental de la teoría de Galois.}}]Sea $E/K$ extensión de Galois y $G = Gal(E/K)$. Consideremos los siguientes conjuntos $\mathcal{G} = \lbrace \text{subgrupo de G} \rbrace$ y $\mathcal{K} = \lbrace \text{cuerpos intermedios de E/K} \rbrace$. Entonces:
\begin{enumerate}
\item Las aplicaciones $$\begin{array}{rccl}
f \colon &\mathcal{G}&\longrightarrow &\mathcal{K} \\
&H& \longmapsto &C_{E}(H)
\end{array}
$$
 $$\begin{array}{rccl}
g \colon &\mathcal{K}&\longrightarrow &\mathcal{G} \\
&L& \longmapsto &Gal(E/L)
\end{array}
$$
son inversas una de la otra, por lo que ambas son biyectivas. Esto quiere decir que $Gal(E/C_{E}(H)) = H$, con $H \in \mathcal{G}$ y $L = C_{E}(Gal(E/L))$, con $L \in \mathcal{K}$.

\item Sea $L \in \mathcal{K}$. Entonces $L/K$ es normal si y sólo si $Gal(E/L) \unlhd Gal(E/K)$. En este caso $$Gal(L/K) \simeq \dfrac{Gal(E/K)}{Gal(E/L)}.$$
\end{enumerate}
\end{theorem}
\emph{Demostración: }
\begin{enumerate}
\item Sea $H \in \mathcal{G}$. Vimos en~\ref{eq:preGal2} que $Gal(E/C_{E}(H)) = H$ y así $(g \circ f)(H)=H$. Luego $g \circ f = id$. Sea ahora $L \in \mathcal{L}$. Como $E/K$ es de Galois, $E/L$ también lo será por~\ref{eq:cuerpIntGal}. Por~\ref{eq:preGal1}, $C_{E}(Gal(E/L)) = L$, luego $(f\circ g)(L) = L$ y $f\circ g = id$. Por lo que $f = g^{-1}$ y $g = f^{-1}$ y ambas son biyectivas.
\item Sea $H = Gal(E/L)$. Por~\ref{eq:preGal3}, si $\tau \in G$ tenemos que $H^{\tau}= Gal(E/\tau(L))$. Ahora $H \unlhd G$ si y sólo si $H^{\tau} = H$ $\forall \tau \in G$ si y sólo si $Gal(E/\tau (L)) = Gal(E/L)$ $\forall \tau \in G$ si y sólo si $g(\tau(L)) = g(L)$ $\forall \tau \in G$ ($g$ es inyectiva) si y sólo si $\tau (L) = L$ $\forall \tau \in G$ si y sólo si $L/K$ es normal.

Ahora, si suponemos que $L/K$ sea normal,~\ref{eq:preGal0} (c) nos dice que $$Gal(L/K) \simeq \dfrac{Gal(E/K)}{Gal(E/L)}.$$
\end{enumerate}

$\hfill \square$

Es decir, el conjunto de los subgrupos de un grupo de Galois y el de los cuerpos intermedios de la extensión de Galois de la parte son biyectivos.

\begin{corolario}Sea $E/K$ una extensión de Galois, $G = Gal(E/K)$ y $H \leq G$. Entonces $|E:C_{E}(H)| = |H|$. Además, como la aplicación $f$ de antes es suprayectiva, todo cuerpo intermedio de la extensión $E/K$ es de la forma $C_{E}(H)$ para un cierto $H \leq G$. Es decir, conociendo los subgrupos de $G$ y sus cuerpos fijos conozco todos los cuerpos intermedios de la extensión.
\end{corolario}
\emph{Demostración: }Por~\ref{eq:cuerpIntGal}, como $E/K$ es de Galois, $E/C_{E}(H)$ también es de Galois. Además $Gal(E/C_{E}(H))=H$ por el \textit{Teorema fundamental}. Ahora, por~\ref{eq:extGalois}, $|E/C_{E}(H)| = |Gal(E/C_{E}(H))| = |H|.$

Para la segunda parte, $$\begin{array}{rccl}
f \colon &\mathcal{G}&\longrightarrow &\mathcal{K} \\
&H& \longmapsto &C_{E}(H)
\end{array}
$$ y como $f$ es suprayectiva, si $L \in \mathcal{K}$, $L = f(H) = C_{E}(H)$ para algún $H \in \mathcal{G}$.

$\hfill \square$

Este resultado lo podemos esquematizar tal que así: 

\begin{center}
\begin{tikzpicture}
\draw (0,0) rectangle (7,7) node at(3.5,3.5){$\xymatrix @=2cm {E & Gal(E/K) \\ C_{E}(H)\ar@{-}[u]^m &H\ar@{-}[u] \\ K \ar@{-}[u] & 1 \ar@{-}[u]^m}$};
\end{tikzpicture}
\end{center}
donde $E/K$ es de Galois.
\section{Polinomios resolubles por radicales}

\subsection{Extensiones radicales}

\begin{definition}Una extensión $E/K$ se dice \textbf{radical} si existen subcuerpos $$K=K_{0} \subseteq K_{1} \subseteq \ldots \subseteq K_{n} = E$$ tales que $K_{i+1} = K_{i}(a_{i})$ y $a_{i}^{n_{i}} \in K_{i+1}$, para algún $a_{i}$ y $n_{i}$ con $i = 1, \ldots, n-1$. Dicho de otro modo, diremos que una extensión $E/K$ es \textbf{radical} si existen $a_{1}, \ldots, a_{r}$ y naturales $n_{1}, \ldots, n_{r}$ tales que $E=K(a_{1}, \ldots, a_{r})$, $a_{1}^{n_{1}} \in K$ y $a_{j}^{n_{j}} \in K(a_{1}, \ldots, a_{j-1})$ $\forall j \geq 2.$

Un polinomio $f \in K[x]$ se dice que es \textbf{resoluble por radicales} si existe una extensión radical $E/K$ que contenga un cuerpo de escisión de $f$ sobre $K$.
\end{definition}
Por ejemplo, la extensión $\mathbb{Q}(\sqrt{2}, \sqrt[3]{5+\sqrt{2}})/\mathbb{Q}$ es radical.

\begin{proposition}Toda extensión radical $E/K$ es finita.
\end{proposition}
\emph{Demostración: }Como $a_{1}^{n_{1}} = \alpha_{1} \in K$, $a_{1}$ es una raíz de $x^{n_{1}}-\alpha_{1} \in K[x]$ y por ello $K(a_{1})/K$ es una extensión de grado finito. En general, tendremos que $a_{j}$ es algebraico sobre $K(a_{1}, \ldots, a_{j-1})$, con $j=2, \ldots, r$, lo cual garantiza que $|K(a_{1}, \ldots,a_{r}) :K| = |E:K| < \infty.$

$\hfill \square$


De lo que se trata de ver es que, si tenemos un $f \in K[x]$ y $E$ un cuerpo de escisión de $f$ sobre $K$ entonces:

\begin{enumerate}
\item $f$ es resoluble por radicales $\Rightarrow$ $Gal(E/K)$, el grupo de Galois de $f$, es resoluble.
\item Si el grupo de Galois de $f$ es resoluble $\Rightarrow$ $f$ es resoluble por radicales.
\end{enumerate}

Y así poder establecer el si y sólo si.

Necesitaremos que $K$ contenga a las $n$ raíces de la unidad, para un cierto $n$. Tal y como se vió en~\ref{eq:raicesUnidad} las $n-$raíces de la unidad forman un grupo cíclico, por lo que podemos definir:

\begin{definition} Una \textbf{$n$-raíz primitiva de la unidad} es un generador del grupo multiplicativo generado por ellas: $$ \lbrace \text{raíces de $x^{n}$-1}\rbrace =\lbrace 1, \xi, \ldots, \xi^{n-1} \rbrace,$$ con $\xi$ una $n-$raíz primitiva.
\end{definition}

Es claro que si tenemos una $n-$ésima raíz primitiva de la unidad $\xi$ sobre un cuerpo $K$, entonces la extensión $K(\xi)/K$ también será una extensión radical.

\begin{proposition}Sea $E/K$ una extensión y supongamos que existe una raíz $n$-ésima primitiva de la unidad $\xi$ en $E$. Entonces $K(\xi)/K$ es de Galois y con grupo de Galois abeliano.
\end{proposition}
\begin{proof}
Las raíces de $x^n -1$ son $H = \lbrace 1, \xi, \ldots, \xi ^{n-1} \rbrace$. Entonces $K(\xi)$ es cuerpo de escisión de $x^n-1$ sobre $K$, luego $K(\xi)/K$ es normal, luego de Galois. Si $\sigma \in Gal(K(\xi)/K)$, entonces, por~\ref{eq:accgal}, $\sigma(H) \subseteq H$. Como $\sigma$ es biyectiva y $H$ es finito, tendremos $\sigma (H) = H$. Además, $\sigma$ es automorfismo de $H$ como grupo multiplicativo. Si $\left.\sigma \right|_H = id$, tendremos $\sigma (\xi)= \xi$ y por~\ref{eq:gall}, $\sigma = id$. Así, $Gal(K(\xi)/K)$ es un subgrupo del grupo de automorfismos de un grupo cíclico que ya sabemos que es abeliano.

\end{proof}

\begin{proposition}Sea $E/K$ una extensión. Supongamos que $E= K(a)$ y que existe un $n$ tal que $a^n \in K$ y que $K$ contiene una raíz $n$-ésima primitiva de la unidad. Entonces $E/K$ es de Galois con grupo de Galois cíclico de orden divisor de $n$.
\end{proposition}
\begin{proof}
Si $a = 0$, es evidente. Supongamos que $a \neq 0$ y consideremos el polinomio $x^n-a^n$. Sea $\xi \in K$ una raíz $n$-ésima primitiva de la unidad. Las raíces de $x^n-a^n$ son $\xi^ia$, con $i = 0, \ldots, n-1$. Ahora, $E = K(a)$ es cuerpo de escisión de $x^n-a^n$ sobre $K$, luego $E/K$ es normal, y así de Galois. Si $\sigma \in Gal(E/K)$, por~\ref{eq:accgal}, $\sigma (a) = \xi^ia$ para algún $i$. Definimos así una aplicación $$\begin{array}{rccl}
&Gal(E/K)&\longrightarrow &\langle \xi \rangle \\
&\sigma& \longmapsto &\xi^i
\end{array}
$$
con $\sigma(a) = \xi^ia$. Es homomorfismo de grupos: $\sigma_1(a)=\xi^ia$, $\sigma_2(a) = \xi^ja$. Así $$(\sigma_1\sigma_2)(a)= \sigma_1(\xi^ja) = \sigma_1(\xi^j)\sigma_1(a) = \xi^j\sigma_1(a) = \xi^{j+i}a,$$ teniendo en cuenta que $\xi^j \in K$. Ahora, si la imagen de $\sigma$ es $1$ entonces $\sigma(a) = a$ y así $\sigma = id$ por~\ref{eq:gall}, luego es inyectiva. Así, $Gal(E/K)$ es isomorfo a un subgrupo de un grupo cíclico de orden $n$, luego es cíclico de orden divisor de $n$.

\end{proof}

\end{document}



