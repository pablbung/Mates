\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{blindtext}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{cancel}
\usepackage[left=2cm,top=2cm,right=2cm,bottom=2cm]{geometry}
\usepackage[all]{xy}
\usepackage{cancel}
\usepackage{pictexwd}
\usepackage{parskip}
\usepackage{pgfplots}
\pgfplotsset{compat=1.15}
\usepackage{mathrsfs}
\usepackage{vmargin}
\usepackage{graphicx}
%activar hyperref para moverse rápidamente en el documento, desactivar para visualizar o imprimir
%\usepackage{hyperref} 

\DeclarePairedDelimiter\Floor\lfloor\rfloor
\DeclarePairedDelimiter\Ceil\lceil\rceil


\newtheorem{theorem}{Teorema}[section]
\newtheorem{definicion}[theorem]{Definición}
\newtheorem{proposition}[theorem]{Proposición}
\newtheorem{lemma}{Lema}[theorem]
\newtheorem{definition}[theorem]{Definición}
\newtheorem{example}{Ejemplo}[theorem]
\newtheorem{corolario}{Corolario}[theorem]
\newtheorem{observation}{Observación}[theorem]
\newtheorem{properties}{Propiedades}[theorem]
\newtheorem{exercise}{Ejercicio}
\providecommand{\abs}[1]{\lvert#1\rvert}
\providecommand{\norm}[1]{\lVert#1\rVert}
\graphicspath{{images/}}

\author{Pablo Pallàs}
\title{Estructuras Algebraicas}
\setlength{\parindent}{10pt}
\newpage
\begin{document}
\rmfamily
\maketitle
\vspace{2.5cm}
\tableofcontents
\parindent= 0cm
\newpage
\section{Introducción}

Imaginemos un conjunto cualquiera, con sus respectivos elementos y luego usemos una operación, normalmente suma o producto. Si juntamos estos dos objetos tan simples (un conjunto y una operación) habremos creado sin darnos cuenta algo que ya conocemos como \textit{estructura algebraica}. Esto que se acaba de explicar en unas pocas líneas llevó mucho más tiempo a los matemáticos del que pueda parecer, y cuando hablamos de mucho tiempo estamos hablando de siglos. Se sabe que incluso pueblos y civilizaciones anteriores a la griega ya conocían y hacían uso de las matemáticas, y la aparición y posterior definición y axiomatización de las estructuras algebraicas no tuvo lugar hasta el siglo XIX, así que estamos hablando de casi 5000 años.

Concretamente la primera piedra la pone un joven matemático noruego, hijo de un pastor luterano, llamado Niels Henrik Abel. Seguramente el nombre sea de sobra conocido por cualquier estudiante de matemáticas, y no es algo extraño teniendo en cuenta el enorme calibre de sus aportaciones. Como se ha dicho puso la primera piedra, con el permiso de Cauchy y Ruffini, para que puediera aparecer lo que hoy día se conoce como \textit{álgebra abstracta}, también conocida como \textit{álgebra moderna}. Como ya sabemos, cuando hablamos de \textit{álgebra} en líneas generales nos referimos al estudio de las ecuaciones y sus soluciones, pero ¿a qué nos referimos cuando hablamos de álgebra moderna?

Ya desde los tiempos de los griegos se conocían los principales métodos de sustitución y resolución de ecuaciones de primer grado, incluso sabían resolver lo que hoy conocemos como ecuaciones de segundo grado, aunque las expresiones 

$$ax^{2}+bx +c=0, \hspace{0.3cm} x=\dfrac{-b \pm \sqrt{b^{2}-4ac}}{2a}$$ 

son modernas. Para la formalización del estudio de las ecuaciones cuadráticas y la aparición de estas expresiones hubo que esperar unos cuantos siglos, hasta el siglo IX d.C. cuando el matemático persa Abu Abdallah Muḥammad Ibn Mūsā Al-Jwarizmī publica el primer tratado considerado genuinamente algrebaico, el \textit{Compendio de cálculo por reintegración y comparación}. De hecho el álgebra como la conocemos hoy no aparece hasta su llegada, para hacernos una idea de la importancia de la irrupción del gran matemático nacido en lo que hoy conocemos como Irán. De su nombre se deriva la palabra \textit{algoritmo}, y de hecho la palabra \textit{álgebra} proviene de \textit{al-ŷabr}, que aparece en el título original del tratado mencionado anteriormente. Para la aparición y formalización del estudio de las ecuaciones de tercer y cuarto grado con sus respectivas fórmulas (bastante más complejas que en el caso de las cuadráticas) tuvimos que esperar al Renacimiento italiano con los \textit{Niccolò Tartaglia, Gerolamo Cardano y Lodovico Ferrari} (una historia muy interesante de retos, traiciones y desprestigio entre ellos), aunque ya hicieron aportes y hay antecedentes de otros matemáticos que contribuyeron a su estudio anteriormente, como los italianos \textit{Scipione del Ferro ó Fibonacci}, el indio \textit{Bhaskara II} o el chino \textit{Liu Hui}, quién en el siglo III ya publicó un tratado que contenía el estudio de algunos métodos para resolver ecuaciones cúbicas. El problema llegó al intentar dar una fórmula para las ecuaciones de quinto grado. 

Durante muchos años se intentó llegar a una fórmula que diera las soluciones de una ecuación quíntica, sin éxito. Este arduo trabajo frustró a muchos matemáticos durante toda la época moderna y pre-decimonónica, entre ellos Lagrange. Éste empleó como herramienta las permutaciones de ráices de polinomios para intentar abordar el problema, lo cúal fue muy interesante y supuso el comienzo de la utilización directa del concepto de permutación, que veremos en las siguientes páginas lo importante que es y los avances que supuso en la formación del álgebra moderna. Álgebra que poco tardaría en aparecer, en estos momentos, ante la frustración de Lagrange y toda la comunidad matemática de la época llegaría un Paolo Ruffini que, en contra de lo que por entonces se intentaba demostrar, estaba convencido de la imposibilidad de llegar a una fórmula que diera las soluciones de la ecuación de quinto grado como sí se hizo con las de tercer y cuarto grado. Fue de hecho él quién acuñó el término \textit{permutazioni}, que hasta entonces simplemente se definían como ordenaciones, así como la forma en la que una permutación se transformaba en otra. Comenzó a partir de un conjunto de permutaciones, y estudió sus propiedades y cómo dos de éstas podían combinarse para dar una tercera. Observó algo intersante: que el orden en el que éstas se combinaban era importante, no producían la misma tercera permutación, es decir, si pensamos esa combinación de permutaciones como una operación entonces diríamos que esa operación no es conmutativa. Esto era bastante novedoso en ese momento, pues contrasta con lo que ocurre con las operaciones clásicas de la suma y la multiplicación ó producto. Ruffini utilizó estas \textit{estructuras} para demostrar que no existía ninguna fórmula para las ecuaciones quínticas, sin embargo no encontró respuesta ni visibilidad a sus estudios por parte de Lagrange ni tampoco parecía que nadie en esa época tuviese interés alguno en esa nueva álgebra de permutaciones que había construido Ruffini. Nadie hasta que apareció Cauchy. Fue él quien visibilizó, a su manera, el trabajo de Ruffini y estableció la notación moderna de ciclos, de producto de permutaciones y también enunció resultados acerca de la conjugación de las mismas, algo que también veremos en las siguientes páginas. ES aquí cuando retomamos lo primero que hemos dicho, puesto que el siguiente paso lo da Abel, el que puso la primera piedra como dijimos. Y el siguiente paso, aunque realmente fue el mismo, lo daría otro famoso matemático conocido por sus grandísimos aportes y su épica historia de romance, traición y muerte a una edad temprana, hablamos de \textit{Evariste Galois}. No se conocieron nunca, y sin embargo compartieron mucho más que descubrimientos, ambos mandaron sus aportes al también matemático y secretario por aquel entonces de la Academia de las Ciencias Joseph Fourier, y en ambos casos se reportaron dichos aportes a Cauchy, y también en ambos casos el resultado fue vano puesto que no les dió, al menos al principio, la importancia que merecían.

Pero, ¿qué fue lo que estos dos jóvenes matemáticos aportaron? ¿qué hicieron para que acabaran siendo reconocidos como fundadores del álgebra moderna?, de hecho ¿qué es el álgebra moderna?. Pues bien, lo que supuso realmente un salto cualitativo con respecto a todo lo que se hizo antes fue considerar estas \textit{estructuras} formadas por las permutaciones y sus combinaciones, y centrar la atención en el estudio de las propiedades de éstas estructuras. Lo que hicieron Galois y Abel fue introducir todo un vocabulario matemático entero completamente nuevo que podía describir bastante bien estas estructuras de permutaciones. Fue así como nació el concepto de \textit{grupo}, y fueron las permutaciones sobre las que primero se definió esta estructura, que ya acuñarle un apellido y hablar así de \textit{estructuras algebraicas}, conectando así con lo que se ha dicho al principio. Así, la diferencia fundamental entre el álgebra que nosotros conocemos del instituto, y que se desarrollo durante siglos, y el álgebra moderna es que en ésta última el objeto de estudio ya no son las ecuaciones (lineales, cuadráticas, etc.) sino estructuras algebraicas. La estructura de grupo fue la primera en aparecer, y supuso el que es con toda seguridad el avance más importante en la historia de las matemáticas.

Por lo tanto, el paso del álgebra convencional al álgebra absrtracta supuso pasar de estudiar ecuaciones a estudiar operaciones abstractas que definimos entre los elementos de un conjunto. Curiosamente la teoría de conjuntos no se formalizó hasta finales del s.XIX, casi cien años después. 

A parte del grupo, existen otras estructuras algebraicas como anillos, dominios de integridad, cuerpos, módulos, o los espacios vectoriales. Todas ellas combinan distintas operaciones que definimos sobre unos conjuntos específicos y que cumplen una serie de propiedades.
\newpage
\section{Grupos}
\subsection{Generalidades}

Supongamos que $G$ es un conjunto no vacío. Entonces definimos una \textbf{operación binaria} en $G$ como una aplicación $G \times G \longrightarrow G$. Usaremos esta operación:
 $$\begin{array}{rccl}
&G \times G&\longrightarrow &G \\
&(x,y)& \longmapsto &x\cdot y = xy
\end{array}
$$
y notar que no todas las operaciones binarias van a ser de interés para nuestros propósitos. Para que lo sean definiremos el concepto de \textbf{\textit{grupo}}.

\begin{definition}Diremos que $G$ es un \textbf{grupo} con una operación $\cdot$ y lo denotaremos $(G,\cdot)$ si se satisfacen las siguientes condiciones:
\begin{enumerate}
\renewcommand{\theenumi}{\roman{enumi}} %Números arábigos
\item $(x\cdot y)\cdot z = x\cdot(y\cdot z)$ $\forall x,y,z \in G$. 
\item Existe un elemento $1 \in G$, que denotaremos $e$, tal que $e\cdot x = x \cdot e = x$. Este elemento lo denominaremos \textbf{elemento neutro}.
\item $\forall x \in G$ existe $y \in G$ tal que $x\cdot y = y \cdot x = e$. A este elemento lo denominaremos \textbf{elemento inverso} de $x$.
\end{enumerate}

A esta operación se le suele llamar \textbf{producto}.

Si $G$ es un grupo, el elemento neutro es único, ya que si tenemos $e,e'\in G$ dos elementos neutros de $G$ entonces $$e=e\cdot e' = e'.$$
También el elemento inverso de un $x\in G$ cualquiera es único, ya que si $y,z \in G$ son inversos de $x$ entonces $$y = y \cdot e = y \cdot (x \cdot z) = (y \cdot x) \cdot z = e \cdot z = z.$$
Al inverso de un $x \in G$ lo denotaremos por $x^{-1}$ y al producto lo podremos denotar por $xy$ en vez de $x \cdot y$, con $x,y \in G$.
\end{definition}

\begin{definition}Diremos que un grupo $G$ es \textbf{finito} si $G$ es un conjunto finito. En ese caso, llamaremos \textbf{orden} de $G$ a su número de elementos, y lo denotaremos por $|G|$.
\end{definition}

\begin{example} Algunos ejemplos de grupos:
\begin{enumerate}
\item $\mathbb{Z}, \mathbb{Q}, \mathbb{R}, \mathbb{C}$ son grupos con la suma usual. También lo son $\mathbb{Q}^*, \mathbb{R}^*, \mathbb{C}^*$ con la multiplicación usual.
\item Dado un conjunto no vacío $\Omega$, consideramos $S_{\Omega}$ el conjunto de las aplicaciones biyectivas $\alpha \colon \Omega \longrightarrow \Omega$. Si $\alpha, \beta \in S_{\Omega}$ podemos componerlas y $\alpha \circ \beta \in S_{\Omega}$, así $S_{\Omega}$ es un grupo con la operación $$\alpha \beta = \alpha \circ \beta.$$ A este grupo lo denominaremos \textbf{grupo simétrico} sobre $\Omega$. Si $\Omega$ tiene $n$ elementos, entonces hay $n!$ aplicaciones biyectivas $\Omega \longrightarrow \Omega$, por lo que $|S_{\Omega}| = n!$. Cuando $\Omega = \lbrace 1, 2, \ldots, n \rbrace$ entonces escribiremos $S_{n}$.

Este tipo de grupos los estudiaremos en detalle más adelante. 

\item Dado $K = \mathbb{Q}, \mathbb{R}, \mathbb{C}$ o en general cualquier cuerpo, entonces el conjunto $GL_{n}(K)$ de matrices $n\times n$ con coeficientes en $K$ y cuyo determinante es no nulo es un grupo conocido como \textbf{grupo general lineal}.
\item Consideremos el siguiente subconjunto de los números complejos $$C = \lbrace a+bi \in \mathbb{C}: a^2+b^2 = 1 \rbrace,$$ formado por los elementos de la circunferencia de radio $1$. Entonces $C$ es un grupo con la multiplicación de números complejos. Es lo que conocemos como \textbf{grupo circular}. Si tenemos un $n$ entero positivo, el subconjunto de $C$ formado por las $n$ raíces $n-$ésimas de la unidad $$C_{n}= \lbrace \xi^k : k =0, \ldots, n-1 \rbrace,$$ con $\xi = \cos\left( \dfrac{2\pi}{n} \right) + i\sin\left(\dfrac{2\pi}{n}\right)$ es también un grupo con la misma multiplicación, de un tipo que veremos más tarde conocido como \textbf{grupo cíclico}.
\end{enumerate}
\end{example}
$\hfill \blacksquare$


En general, dado un grupo $G$, no será cierto que $xy = yx$ para cualesquiera $x,y \in G$. Por ejemplo, en $S_{3}$, si $\alpha, \beta \in S_{3}$ con $\alpha(1) = 2, \alpha (2)=3, \alpha (3) = 1$, $\beta (1)=2, \beta(2)=1, \beta (3) = 3$, entonces $\alpha \beta \neq \beta \alpha$. Aquellos grupos $G$ en los que sí se cumpla la igualdad, es decir $xy = yx$ $\forall x,y \in G$, los denominaremos \textbf{grupos abelianos}.

Cuando trabajemos con grupos abelianos será habitual emplear la notación aditiva y escribiremos $x+y$ en lugar de $xy$, $-x$ en lugar de $x^{-1}$ y el elemento neutro será $0$.

\begin{proposition}\label{eq:primGrup} Dado un grupo $G$ tenemos:
\begin{enumerate}
\item Dados $x,y \in G$, si $xy = e$ entonces $x = y^{-1}$, $y = x^{-1}$. En particular, $(xy)^{-1} = y^{-1}x^{-1}$.
\item La aplicación $$\begin{array}{rccl}
&G&\longrightarrow &G\\
&x& \longmapsto &x^{-1}
\end{array}
$$ es una biyección.
\item Dado un $g \in G$, las aplicaciones $$\begin{array}{rccl}
&G&\longrightarrow &G\\
&x& \longmapsto &xg
\end{array}
$$
$$\begin{array}{rccl}
&G&\longrightarrow &G\\
&x& \longmapsto &gx
\end{array}
$$ son biyectivas.
\end{enumerate}
\end{proposition}
\emph{Demostración: }Veamos: \begin{enumerate}
\item Si $xy = 1$ entonces $x^{-1} = x^{-1}e= x^{-1}(xy) = y$, y análogo con $y^{-1}$. Ahora, como $(xy) (y^{-1}x^{-1})=xex^{-1} = e$, de la primera parte ya se tiene.
\item Veamos que la aplicación es biyectiva. Si $x^{-1} = y^{-1}$, con $x,y \in G$, entonces $x = (x^{-1})^{-1} = (y^{-1})^{-1}=y$ y así es inyectiva. Ahora, dado un $z \in G$ tenemos que $z$ es el inverso de $z^{-1}$ y también es suprayectiva.
\item Veamos que la aplicación $$\begin{array}{rccl}
&G&\longrightarrow &G\\
&x& \longmapsto &xg
\end{array}
$$ es biyectiva. Si $xg = yg$, multiplicando por $g^{-1}$ a la derecha tenemos que $x = y$ y así es inyectiva. Si $z \in G$ entonces existirá un elemento $zg^{-1} \in G$ por ser $G$ grupo y la aplicación manda $zg^{-1}$ a $z$ y es suprayectiva también. Para ver la otra la demostración es completamente análoga.
\end{enumerate}

$\hfill \square$

Una vez definida una estructura algebtaica cualquiera siempre nos interesaremos por su subestructura. Esto es particularmente relevante en \textit{Teoría de grupos}.

\begin{definition}Un \textbf{subgrupo} $H$ de $G$, denotado $H \leq G$, es un subconjunto no vacío $H \subseteq G$ tal que $xy \in H$ para todos $x,y \in H$ y $x^{-1} \in H$ para todo $x \in H$. Es decir, que también es un grupo con la operación de $G$: la asociatividad se sigue de la de $G$, que $xy \in H$ para cualesquiera $x,y \in H$ quiere decir que la operación es binaria y como $x^{-1} \in H$ entonces $xx^{-1} = 1 \in H$.
\end{definition}

\begin{example}El subconjunto $SL_{n}(K)$ de matrices de determinante $1$ con coeficientes en $K$ es un subgrupo de $GL_n(K)$ conocido como \textbf{subgrupo especial lineal}.
\end{example}
$\hfill \blacksquare$

Observar que un grupo $G$ siempre tiene al menos los subgrupos, $\lbrace 1 \rbrace$ y el propio $G$. Son los conocidos como \textbf{subgrupos triviales}. Los subgrupos $H \leq G $ tales que $H \neq G$, son los llamados subgrupos \textbf{propios}.

Veamos ahora la caracterización de los subgrupos: 

\begin{proposition}Sea $G$ un grupo y sea $H$ un subconjunto no vacío de $G$. Entonces $H \leq G$ si y sólo si $xy^{-1} \in H$ para cualesquiera $x,y \in H$.
\end{proposition}
\emph{Demostración: }
Supongamos que $H \leq G$ y sean $x,y \in H$. Entonces $y^{-1} \in H$ y $xy^{-1} \in H$ por definición. Recíprocamente, supongamos que $xy^{-1} \in H$ $\forall x,y \in H$. Eligiendo cualquier $h \in H$ tenemos que $1 = h h^{-1} \in H$. Luego $y^{-1} = 1y^{-1} \in H$ $\forall y \in H$. Finalmente, si $x,y \in H$ entonces $xy = x(y^{-1})^{-1} \in H$. Así, $H$ es grupo.

$\hfill \square$

\begin{example}Otro ejemplo podría ser el caso de los números enteros $\mathbb{Z}$. Sabemos que $\mathbb{Z}$ es un grupo con la suma usual, nos preguntamos ahora cómo son sus subgrupos. Es fácil comprobar que, dado un $n\in \mathbb{Z}$ cualquiera, los subconjuntos de $\mathbb{Z}$ de la forma $$n\mathbb{Z} = \lbrace nx: x \in \mathbb{Z} \rbrace,$$ conforman todos los subgrupos posibles de $\mathbb{Z}$. Basta ver que si $a,b \in n\mathbb{Z}$ entonces $a-b \in n\mathbb{Z}$, ya que si $a,b\in n\mathbb{Z}$ entonces $a=nx $ y $b = nx'$, con $x,x' \in \mathbb{Z}$, y $a-b = nx -nx' = n(x-x') \in n\mathbb{Z}$.

Notar que si tenemos un $p \in n\mathbb{Z}$, éste será de la forma $p = nx$, para un $x \in \mathbb{Z}$ cualquiera, es decir, que $n$ dividirá a $p$ (en capítulos posteriores veremos con más detalle el concepto de divisibilidad).
\end{example}
$\hfill \blacksquare$

\begin{definition} Dados dos subgrupos $H$ y $K$ de un grupo $G$, se define $$HK = \lbrace hk : h \in H, k \in K \rbrace.$$ A este grupo lo llamaremos \textbf{grupo producto}. Igualmente también podremos definir su \textbf{intersección} como
$$H \cap K = \lbrace x: x\in H \wedge x \in K \rbrace.$$
\end{definition}

Si tenemos dos subgrupos cualesquiera $H$ y $K$ de $G$ está claro que $H \cap K$ es subgrupo también. Sin embargo, en general $HK$ no lo será. Para que lo sea ha de cumplirse la siguiente condición:

\begin{proposition}\label{eq:progruesgru} Sean $H,K \leq G$. Entonces $HK \leq G$ si y sólo si $HK = KH$.
\end{proposition}
\emph{Demostración: }Supongamos que $HK$ es subgrupo de $G$. Si $x = hk \in HK$ entonces $k^{-1}h^{-1} = x^{-1} \in HK$, luego $k^{-1}h^{-1} = uv$ con $u \in H$, $v \in K$ y así $x = hk = (k^{-1}h^{-1})^{-1} = (uv)^{-1} = v^{-1}u^{-1} \in KH$ y esto prueba $HK \subseteq KH$. Sea ahora $y = kh \in KH$. Entonces $z = h^{-1}k^{-1} \in HK$, y como $HK$ es subgrupo $y = kh = (h^{-1}k^{-1})^{-1} = z^{-1} \in HK$, y así $KH \subseteq HK$.
 
Recíprocamente, supongamos que $HK = KH$. Evidentemente $HK$ es no vacío, pues $1 = 1 \cdot 1 \in HK$. Además, dados $x = h_{1}k_{1}$, $y = h_{2}k_{2}$, con $x,y \in HK$, $xy^{-1} = h_{1}k_{1}k_{2}^{-1}h_{2}^{-1} = h_{1}k_{3}h_{2}^{-1}$, con $k_{3} = k_{1}k_{2}^{-1} \in K$. Como $k_{3}h_{2}^{-1} \in KH = HK$, $k_{3}h_{2}^{-1} = h_{3}k$, con $h_{3} \in H$, $k \in K$. Así, $xy^{-1} = h_{1}h_{3}k = hk \in HK$, con $h = h_{1}h_{3} \in H$.

$\hfill \square$

\begin{example}\label{eq:gib}Sean $m$ y $n$ enteros no negativos, $H = m\mathbb{Z}$, $K = n\mathbb{Z}$ dos subgrupos de $\mathbb{Z}$. Como $\mathbb{Z}$ es abeliano es obvio que $H+K = K+H$, luego por el resultado anterior $H+K$ es subgrupo de $\mathbb{Z}$ (notar que aquí la operación que utilizamos es la suma).


$H+K$ no es el subgrupo $\lbrace 0 \rbrace$ pues, $m = m + 0 \in H + K$. Y, como ya sabemos, existirá un $d \in \mathbb{Z}$ tal que $m\mathbb{Z}+n\mathbb{Z} = d\mathbb{Z}$, veamos que $d = mcd(m,n)$ (más adelante veremos que este resultado se conoce como la identidad de Bézout):

Como $m = m + 0 \in m\mathbb{Z}+n\mathbb{Z} = d\mathbb{Z}$, $d$ divide a $m$, y como $n = 0 + n \in m\mathbb{Z}+n\mathbb{Z} = d\mathbb{Z}$, $d$ divide a $n$. Además $d \in d\mathbb{Z} = m\mathbb{Z} + n\mathbb{Z}$ luego existen $a,b \in \mathbb{Z}$, tal que $d = ma + nb$. Entonces, dado un $c$ que divida a $m$ y $n$:
$$m = cu,\hspace{0.1cm} n = cv, u, v \in \mathbb{Z},$$ tendremos $d = (cu)a + (cv)b = c(ua + vb)$ y $c$ divide a $d$. Esto prueba que $d = mcd(m,n)$. 

En particular, dos números enteros $m,n$ son primos entre sí si y sólo si $$1 = am + bn \hspace{0.2cm} a,b \in \mathbb{Z}.$$ En efecto, si $mcd(m,n) = 1$, tenemos $m\mathbb{Z} + n\mathbb{Z} = 1\mathbb{Z}$ por lo visto ahora. Así, $1 \in m\mathbb{Z}+n\mathbb{Z}$. Recíprocamente, si $1 = am + bn$ y $d$ es un divisor de $m$ y $n$, tendremos $m = du$, $n = dv$, luego $1 = d(au + bv)$ y así $d = +1$ ó $-1$. Y como podemos asumir que $mcd(m,n)$ es positivo entonces $mcd(m,n) = 1$.
\end{example}

$\hfill \blacksquare$

Ya sabemos cómo son y cómo se caracterizan los subgrupos, ahora veremos cómo podemos obtenerlos a partir de ciertos conjuntos de elementos, que llamaremos generadores.

\begin{definition}Si $S$ es un subconjunto no vacío de un grupo $G$, el conjunto $$\langle S \rangle = \lbrace s_{1}^{h_{1}} \ldots s_{n}^{h_{n}} : n \in \mathbb{N},\hspace{0.1cm} s_{i} \in S,\hspace{0.1cm} h_{i} \in \mathbb{Z}, \hspace{0.2cm} 1 \leq i \leq n \rbrace$$ es un subgrupo de $G$ que contiene a $S$, llamado \textbf{subgrupo generado por $S$}.


Si $\mathcal{F}$ es la familia de todos los subgrupos de $G$ que contienen a $S$, $$ \langle S \rangle = \bigcap_{H \in \mathcal{F}} H$$ y, en particular, $\langle S\rangle \subseteq H$ para cada $H \in \mathcal{F}$.
\end{definition}

\begin{observation} Un caso particular pero muy importante es aquel en que $S = \lbrace a \rbrace$ con $a \in G$. En tal caso escribimos $\langle a \rangle$. Y tenemos que, $$\langle a \rangle = \lbrace a^{k} : k \in \mathbb{Z}\rbrace$$ y se le llama \textbf{subgrupo generado por a}.\end{observation}

De hecho, a partir de este caso surgirán una tipo de grupos muy importantes e interesante, los \textit{grupos cíclicos}, y que estudiaremos detalladamente más adelante.

Ya hemos definido lo que son los grupos abelianos, y hemos visto que ha de cumplirse la propiedad conmutativa. Esto en general no se tendrá en grupos no abelianos, pero sin embargo sí podremos encontrar subconjuntos de elementos que sí cumplan la propiedad conmutativa, es decir, que sus elementos conmutan. Además vamos a comprobar que a estos subconjuntos les vamos a poder dotar de estructura de grupo (en este caso subgrupo).

\begin{definition}\label{eq:centro} Dado $H$ un subgrupo de un grupo $G$, llamaremos \textbf{centralizador} de $H$ en $G$ a $$C_{G}(H) = \lbrace x \in G : xg = gx \hspace{0.15cm} \forall g \in H\rbrace.$$
Al caso particular de $H = G$, es decir, al centralizador de $G$ en $G$ lo denotaremos por $Z(G)$ y lo llamaremos \textbf{centro} de $G$. Así, $$Z(G) = \lbrace x \in G : xg = gx \hspace{0.15cm} \forall g \in G\rbrace.$$
Como consecuencia se tiene que $G$ es abeliano si y sólo si $G = Z(G)$. Además, el centro es un subgrupo de $G$. De hecho, más en general todavía: se tiene que $C_{G}(H)$ es un subgrupo de $G$
\end{definition}
\emph{Demostración: } Demostraremos esto último. Como $1_{G} \in C_{G}(H),$ éste es no vacío. Sean $x,y \in C_{G}(H),\hspace{0.1cm} g \in H$. Como $x\in C_{G}(H),\hspace{0.1cm} xg = gx$. Como $y \in C_{G}(H), \hspace{0.1cm} g^{-1} \in H,\hspace{0.1cm} yg^{-1} = g^{-1}y$. Por lo tanto, \begin{center}$(xy^{-1})g = x(y^{-1}g) = x(g^{-1}y)^{-1} = x(yg^{-1})^{-1} = x(gy^{-1}) = (xg)y^{-1} = (gx)y^{-1} = g(xy^{-1})$\end{center} luego $xy^{-1} \in C_{G}(H)$. Así, $C_{G}(H)$ es un subgrupo de $G$.

$\hfill \square$

Tanto el centralizador como el centro de un grupo necesitan de un subgrupo para poder definirse, y forman sendos subgrupos para un grupo $G$ cualquiera, sin embargo lo que vamos a ver a continuación no necesita definirse sobre un subgrupo, con un simple conjunto basta.

Antes de eso necesitaremos definir el concepto de \textit{conjugado}, que también se aplica sobre conjuntos en general:

\begin{definition} \label{eq:conjugado} Si $S$ es un subconjunto no vacío de un grupo $G$ y $g \in G$, se llama \textbf{conjugado de $S$ por $g$} al conjunto $$S^{g} = \lbrace gxg^{-1}: x \in S\rbrace$$ Diremos que $y \in S^{g} \Leftrightarrow g^{-1}yg \in S$. Ya que si $y \in S^{g} \Rightarrow y = gxg^{-1}\Rightarrow g^{-1}yg = x, \hspace{0.1cm} x \in S$.
\end{definition}

\begin{definition}\label{eq:normalizador} Dado $X$ un subconjunto no vacío de un grupo $G$, llamaremos \textbf{normalizador} de $X$ en $G$ a $$N_{G}(X) = \lbrace g \in G : X^{g} = X\rbrace,$$ que además es un subgrupo de $G$.
\end{definition}

\emph{Demostración: } Ya sabemos que $X^{1} = X$, por lo que $1 \in N_{G}(X)$ y así $N_{G}(X)$ es no vacío. Por otro lado, si $g,f \in N_{G}(X)$, $X^{gf^{-1}} = (X^{g})^{f^{-1}} = X^{f^{-1}}$ pues $g \in N_{G}(X)$. Además, $X = X^{1} = X^{ff^{-1}} = (X^{f})^{f^{-1}} = X^{f^{-1}}$, ya que $f \in N_{G}(X)$. Tenemos entonces que $X^{gf^{-1}} = X$, luego $gf^{-1} \in N_{G}(X)$.

$\hfill \square$

Más adelante daremos otras definiciones y llegaremos a estos subconjuntos y subgrupos de otra forma a través de unos conceptos que veremos en los siguientes capítulos.

Notar que en el caso particular de que $H = \langle g \rangle$, con $g \in G$, entonces $x \in C_{G}(H)\Leftrightarrow xg = gx$. De hecho, cuando hablemos del centralizador del subgrupo generado por $g$ en $G$ escribiremos $C_{G}(g)$ en vez de $C_{G}(\langle g \rangle)$ y $$C_{G}(g) = \lbrace x \in G : xg = gx \rbrace$$ y, es obvio que $$Z(G) = \bigcap_{g \in G} C_{G}(g).$$ Además, $g \in Z(G) \Leftrightarrow C_{G}(g) = G$, ya que si $g \in Z(G)$ cada $x \in G$ cumple $gx = xg$, luego $G \subseteq C_{G}(g) \subseteq G$. Recíprocamente, si $C_{G}(g) = G$, cada $x \in G$ pertenece a $C_{G}(g)$, luego $xg = gx$ para cada $x \in G$ y así $g \in Z(G)$.

\begin{definition}Si $H \leq G$ y $x \in G$, llamamos a $$Hx = \lbrace hx : h \in H \rbrace$$ \textbf{clase a derecha} (o \textbf{coclase a derecha}) de $x$ módulo $H$. Análogamente, a $$xH = \lbrace xh : h \in H \rbrace$$ lo llamamos \textbf{clase a izquierda} (o \textbf{coclase a izquierda}) de $x$ módulo $H$. 
\end{definition}

En general, aunque ambos conjuntos contienen al elemento $x$, se tiene que $xH \neq Hx$. Más adelante veremos qué ocurre cuando estos conjuntos coinciden.

\begin{proposition}\label{eq:partiGrupo} Sea $H \leq G$ y $x,y \in G$. Entonces: \begin{enumerate}
\item $xH = H$ si y sólo si $x \in H$.
\item $xH = yH$ si y sólo si $x^{-1}y \in H$.
\item $xH \cap yH \neq 0$ si y sólo si $xH = yH$.
\end{enumerate}
\end{proposition}
\emph{Demostración: }\begin{enumerate}
\item Si $x \in H$ ya sabemos por~\ref{eq:primGrup} que $xH = H$. Recíprocamente, si $xH = H$ entonces $x = x1 \in xH = H$.
\item Sea $xH = yH$, entonces $y \in yH = xH$ luego $y = xh$ para algún $h \in H$. De aquí tenemos que $x^{-1}y = h \in H$. Recíprocamente, sea $x^{-1}y \in H$, luego $x^{-1}y = h \in H$ y se tiene que $y = xh$ y $x = yh^{-1}$. Sea $a \in xH$, entonces $a = xh'$, $h' ,\in H$. Ahora $a = xh' = yh^{-1}h' = y(h^{-1}h') \in yH$ ya que $h^{-1}h' \in H$. Así, $xH \subseteq yH$. Al revés es análogo. Así, $xH = yH$.
\item Sea $z \in (xH \cap yH)$. Entonces $z = xh \in xH$ y también $z= yh' \in yH$, luego $x^{-1}z \in H$ e $y^{-1}z \in H$. Como $H$ es grupo, $(y^{-1}z)^{-1} = z^{-1}y \in H$ y $(x^{-1}z)(z^{-1}y) = x^{-1}y \in H$. Ahora, por el apartado anterior $xH = yH$. El recíproco es evidente.
\end{enumerate}

$\hfill \square$

El resultado anterior es completamente análogo para las clases a derecha.

Con esto, vamos a comprobar que la relación en $G$ definida por: dados $x,y \in G$, entonces $x\sim_{H} y \Longleftrightarrow xH = yH$ es una relación de equivalencia, de hecho la clase de equivalencia de $x \in G$ es $xH$, es decir, una clase (o coclase) a izquierda. Luego las coclases, tanto a izquierda como a derecha, forman una partición de $G$. Así, $G$ es unión disjunta de estas clases: $$G = \bigcup_{x \in R} xH,$$ con $R$ un conjunto de representantes de las clases de equivalencia.

Con esto, podemos definir las siguientes relaciones de equivalencia:

\begin{definition}Sea $G$ un grupo y $H$ un subgrupo de $G$. Llamaremos $\sim_{H}$ y $\sim^{H}$ a las siguientes \textit{relaciones} en $G$:
\begin{center}
$x\sim^{H}y$ si y sólo si $xy^{-1} \in H$\\
$x\sim_{H}y$ si y sólo si $x^{-1}y \in H$
\end{center}
\end{definition}

Tanto $\sim_{H}$ como  $\sim^{H}$ son relaciones de equivalencia.

\emph{Demostración: } Lo haremos para $\sim_{H}$ (para $\sim^{H}$ es análoga). Tenemos que ver que cumplen con las propiedades \textit{reflexiva} (1), \textit{simétrica} (2) y \textit{transitiva} (3)\begin{enumerate}
\item Si $x \in G$, $x^{-1}x = 1 \in H$ luego $x\sim_{H}x$.
\item Si $x\sim_{H}y$ entonces $x^{-1}y \in H$, luego $(x^{-1}y)^{-1} \in H,$ y esto es $y^{-1}x \in H$ así que $y\sim_{H}x$.
\item Si $x\sim_{H}y$, y $y\sim_{H}z$, entonces se tiene $x^{-1}y \in H, \hspace{0.2cm} y^{-1}z \in H$
y así $x^{-1}z = (x^{-1}y)(y^{-1}z) \in H$ por lo que $x\sim_{H}z$.
\end{enumerate}

$\hfill \square$

Sea ahora $\left[ x \right]_{\sim_{H}}$ la clase de equivalencia del elemento $x \in G$ definida por la relación $\sim_{H}$. Entonces \begin{center}$\left[ x \right]_{\sim_{H}} = \lbrace a \in G : x\sim_{H}a \rbrace = \lbrace a \in G : x^{-1}a = h \in H \rbrace = \lbrace a \in G: a = xh, \hspace{0.1cm} h \in H \rbrace = xH.$\end{center}

Análogo con $\sim^{H}$, \begin{center}$\left[ x \right]_{\sim^{H}} = \lbrace a \in G : x\sim^{H}a \rbrace = \lbrace a \in G: ax^{-1} = h \in H \rbrace = \lbrace a \in G : a = hx, \hspace{0.1cm} h \in H \rbrace = Hx.$\end{center} Notar que en este último caso tomamos los $h$ de la forma $ax^{-1}$ cuando la relación $\sim^{H}$ en realidad vendría a decir que $h$ sería de la forma $xa^{-1}$, simplemente tomamos el inverso (que también está en $H$) ya que la relación es de equivalencia e igual da hacer $x \sim^{H}a$ que $a\sim^{H}x$.

\begin{definition}A los conjuntos de estas clases los llamaremos \textbf{conjuntos cocientes} definidos por las respectivas relaciones de equivalencia (a izquierda o derecha). Los denotaremos: $$G/\sim_{H} = \lbrace xH : x \in G \rbrace,$$ $$G/\sim^{H} = \lbrace Hx : x \in G \rbrace.$$
\end{definition}

\begin{proposition}
Sea $H \leq G$. Entonces:
$$card(G/\sim_{H})= card(G/\sim^{H}).$$
\end{proposition}
\emph{Demostración: } Veamos que la aplicación
$$
\begin{array}{rccl}
\Psi \colon &G/\sim_{H} & \longrightarrow & G/\sim^{H}\\
&xH & \longmapsto &Hx^{-1}
\end{array}
$$
es biyectiva. \begin{enumerate} 
\item Veamos primero que $\Psi$ está \textit{bien definida}, es decir, si $xH = yH$ entonces $Hx^{-1} = Hy^{-1}$. En efecto, si $xH = yH$, entonces tenemos que $x\sim_{H} y$, es decir, $x^{-1}y \in H$. Como $H$ es subgrupo de $G$, $(x^{-1}y)^{-1} \in H$, y como $(x^{-1}y)^{-1} = y^{-1}(x^{-1})^{-1}$ se tiene que $y^{-1}\sim^{H} x^{-1}$ y por tanto $Hy^{-1} = Hx^{-1}$.
\item Veamos ahora que es \textit{inyectiva}. Sean $xH, \hspace{0.1cm} yH \in G/\sim_{H}$. Si $\Psi (xH) = \Psi (yH)$, entonces $Hx^{-1} = Hy^{-1}$, luego $y^{-1}\sim^{H} x^{-1}$ y así $y^{-1}(x^{-1})^{-1} = (x^{-1}y)^{-1} \in H$ por lo que también $x^{-1}y \in H$, pero esto quiere decir que $x \sim_{H}y$ o lo que es lo mismo: que $xH = yH$. Así $\Psi$ es inyectiva.
\item Veamos que es \textit{suprayectiva}. Si $Hx \in G/\sim^{H}$, como $x^{-1}H \in G/\sim_{H}$ y $\Psi (x^{-1}H) = H(x^{-1})^{-1} = Hx$ tenemos que $\Psi$ es suprayectiva.
\end{enumerate}
Por lo tanto, $\Psi$ es una aplicación biyectiva y así $$card(G/\sim_{H}) = card(G/\sim^{H}).$$
$\hfill \square$

Si tenemos que estos conjuntos de coclases son finitos (y por tanto de igual cardinal por el resultado que acabamos de ver) entonces:

\begin{definition}Dado $H \leq G$, llamamos \textbf{índice} de $H$ en $G$, y lo denotamos por $[G:H]$, al número de elementos de $G/\sim_{H}$ (el mismo que $G/\sim^{H}$). Es decir, el número de coclases a izquierda (ó a derecha).
\end{definition}

$$[G:H] = card(G/\sim_{H}) = card(G/\sim^{H}).$$

\begin{example} Veamos cómo se relacionan los subgrupos de $\mathbb{Z}$ con el mismo $\mathbb{Z}$ a través de sus respectivos índices:

Sea $G = \mathbb{Z}$ y $H \neq \lbrace 0 \rbrace$ un subgrupo de $\mathbb{Z}$. Ya sabemos que $H$ es de la forma $H = m\mathbb{Z}$, con $m$ un entero positivo cualquiera. Como la operación en $\mathbb{Z}$ es la \textit{suma}, las clases respecto de $\sim_{H}$, que son las mismas que respecto $\sim_{m\mathbb{Z}}$, serán de la forma $$x+ m\mathbb{Z}, \hspace{0.1cm} x \in \mathbb{Z}.$$ Veamos que $$\mathbb{Z}/m\mathbb{Z} = \lbrace 0+m\mathbb{Z},1+ m\mathbb{Z}, \ldots,(m-1)+ m\mathbb{Z}\rbrace.$$ Dado $x \in \mathbb{Z}$ obtenemos, por el algoritmo de la división, $$x = qm + r, \hspace{0.1cm} 0\leq r\leq m-1,$$y así $x-r = qm \in m\mathbb{Z}$, luego $x\sim_{m\mathbb{Z}}r$, es decir, $x+m\mathbb{Z}=r+ m\mathbb{Z}$, lo que prueba la igualdad. Además las clases son todas distintas, es decir, los elementos del segundo miembro son distintos, pues si $k+m\mathbb{Z} =l+ m\mathbb{Z}$, con $\hspace{0.1cm} 0\leq k,l \leq m-1$, entonces $l\sim_{m\mathbb{Z}}k$, y por tanto $l-k \in m\mathbb{Z}, \hspace{0.1cm} 1\leq l-k <m,$ y tenemos que $l-k = qm, \hspace{0.1cm} q \in \mathbb{Z}$ lo cual implicaría que $l = qm +k > m$ si $q>0$ ó $k = l - qm >m$ si $q < 0$ ( y así $-q >0$), lo cual es imposible.

Así, $\left[ \mathbb{Z}:m\mathbb{Z} \right] = m$. Notar que $\mathbb{Z}$ es un grupo infinito cuyos subgrupos no nulos tienen índice finito.
\end{example}
$\hfill \blacksquare$

\begin{theorem}[\textbf{\textit{Teorema de Lagrange}}]
Sea $H \leq G$. Si $G$ es finito, entonces $|H|$ divide a $|G|$ y $$|G| = |H|\cdot \left[ G:H \right].$$
\end{theorem}
\emph{Demostración: }Ya sabemos que $$G = \bigcup_{x\in G} xH,$$ y que $G$ es la unión disjunta de estas coclases a izquierda , cuyo número es $[G:H]$. Basta ver que todas estas clases a izquierda tienen cardinal $|H|$, pero esto ya lo vimos en~\ref{eq:primGrup} cuando vimos que la aplicación que manda $g \longmapsto xg$ es biyectiva.

$\hfill \square$

Notar que, al ser grupos finitos podemos poner la anterior expresión como $$[G:H] = \dfrac{|G|}{|H|}.$$
Notar también que, si tenemos $H \leq K \leq G$ entonces, aplicando dos veces el \textit{Teorema de Lagrange} tenemos $$[G:H]=[G:K][K:H],$$ es lo que se conoce como \textbf{\textit{transitividad del índice}}.

En diagramas como el siguiente se nos presenta información útil para representar una serie de relaciones en un grupo, esquemas así serán utilizados con frecuencia. En éste podemos apreciar una serie de nodos, que son grupos y subgrupos, en este caso $G$ y dos subgrupos suyos: $H$ y $K$ cualesquiera. Las líneas representan \textit{contenido}, el subgrupo de abajo está contenido en el de arriba. En este caso $G=HK$ y lo expresaremos como un diamante. 
$$\xymatrix @=2cm {&G \ar@{-}[ld]_n \ar@{-}[rd]^m  \\ H \ar@{-}[rd]_m & & K \ar@{-}[ld]^n \\ &H \cap K }$$

Además, si $G$ es un grupo finito, se tiene que $n= [G:H] = [K: K \cap H]$ y $m= [G:K] = [H : H \cap K]$. Este diagrama nos va a proporcionar información también sobre los órdenes de los subgrupos, después de ver el siguiente resultado será interesante volver a revisarlo.

\begin{proposition} Sea $G$ un grupo y $H$, $K$ subgrupos de $G$ de orden finito. Entonces, $$|HK| = \dfrac{|H||K|}{|H \cap K|}.$$
\end{proposition}
\emph{Demostración: } Sean $h_{1}(H \cap K), \cdots, h_{m}(H \cap K)$ representantes de las clases laterales a izquierda de $H\cap K$ en $H$. Veamos que los elementos de $HK$ son de la forma $h_{i}k$, con $1 \leq i \leq m$, $k \in K$ y que todos son diferentes.

Por un lado está claro que $m = [H : H \cap K ]$. Si $hk_1 \in HK$, tendremos que $h = h_{i}x$, con un $i$ cualquiera, y $x \in H \cap K$. Así, $hk = h_{i}xk_1 = h_{i}(xk_1)$, con $xk_1 \in K$, haremos $xk_1 = k$. Ahora, supongamos que $h_{i}k =h_{j}k'$, con $1 \leq i,j \leq m$, $k, k' \in K$. Entonces, $h_{j}^{-1}h_{i} = k'k^{-1} \in H \cap K$. Por~\ref{eq:partiGrupo} tenemos que $h_i(H \cap K) = h_j(H \cap K)$. Pero como $h_{i}(H \cap K) \neq h_{j}(H \cap K)$ si $i \neq j$, necesariamente $i =j$. Así, $h_{i}k =h_{i}k'$ y multiplicando a izquierda por $h_{i}^{-1}$ se tiene que $k = k'$. Por lo tanto, ha quedado claro que los elementos de $HK$ son de la forma $h_{i}k$ y que además son todos diferentes, luego $$|HK| = [H : H\cap K]|K| = \dfrac{|H||K|}{|H \cap K|}.$$

$\hfill \square$

De aquí se desprende que, evidentemente, si tenemos dos grupos disjuntos (es decir, que sólo comparten el elemento neutro) entonces $|HK| = |H||K|$. Esto es muy útil cuando son dos subgrupos de un grupo cualquiera $G$ tales que $G = HK$, es decir, cuando se da que el producto de dos subgrupos es un grupo.

Volvamos ahora al diagrama en diamante antes dibujado. Si lo observamos, teniendo en cuenta lo que acabamos de ver y que habíamos definido $G= HK$, entonces necesariamente $|G| =|HK| = \dfrac{|H| |K|}{|H \cap K |} = |H| [K : K \cap H]$ y de aquí $[G:H] = \dfrac{|G|}{|H|} = [K : K \cap H]$, tal y cómo habíamos visto. Análogamente con $[G:K]$.

\begin{example}[\textbf{\textit{El grupo cuaternión.}}]
Consideremos los ocho símbolos siguientes: $$ Q = \lbrace 1,-1, i, j, k, -i,-j,-k \rbrace$$ y una operación $Q \times Q \longrightarrow Q$ que tiene a $1$ por elemento neutro, cumple la propiedad asociativa, la regla de los signos que todos conocemos (por ejemplo $i(-k) = -(ik)$) y \begin{equation*}
\begin{aligned}
&ij = k, \hspace{0.2cm} ji = -k\\
&jk = i, \hspace{0.2cm} kj = -i\\
&ki = j, \hspace{0.2cm} ik = -j\\
&i^{2} = j^{2} = k^{2} = -1
\end{aligned}
\end{equation*}
Con esto, está claro que $Q$ es un grupo de orden $8$. Sólo queda demostrar que tiene elemento inverso. 


Como se cumple la regla de los signos tenemos que $(-1)^{2} = 1$, luego $o(-1) =2$ y $-1$ es su propio inverso. Como $i^{2} = -1$, resulta que $(-i)^{4} = (-1)^{4}i^{4} = i^{4} = (-1)^{2} = 1,$ luego el orden de $i$ $o(i) = o(-i) = 4$, y así $i^{-1} = i^{3}$ ya que $ii^{3} = i^{4} = 1$, además $(-i)^{-1} = -i^{3}$ ya que $-i(-i)^{3} = (-i)^{4} = 1$. \vspace{0.2cm}\\
Análogamente, $o(j) = o(-j) = 4$ y $o(k) = o(-k) = 4$ y $j^{-1} = j^{3}$, $k^{-1} = k^{3}$, $(-j)^{-1} = -j^{3}$, $(-k)^{-1} = -k^{3}$. Luego todos los elementos tienen inverso y así $Q$ es un grupo.


Veamos ahora cuáles son los subgrupos de $Q$. Evidentemente, $\lbrace 1 \rbrace$ y $Q$ lo son y por el \textit{Teorema de Lagrange} los demás han de tener orden $2$ ó $4$. Como $-1$ es el único elemento de orden $2$ de $Q$ $\lbrace 1, -1 \rbrace$ es el único subgrupo de orden $2$. Si $H$ es un subgrupo de orden $4$, deberá contener algún elemento $x$ que no sea el $1$ ó el $-1$. Entonces necesariamente $o(x) = 4$ y como $H$ es de orden $4$ tendremos que $H = \langle x \rangle$. Además, como $-x = (-1)x = x^{2}x = x^{3} \in \langle x \rangle$ y $x  = (-1)(-x) = (-x)^{2}(-x) = (-x)^{3} \in \langle -x \rangle$, los subgrupos de orden $4$ de $Q$ serán $\langle i \rangle$, $\langle j \rangle$ y, $\langle k \rangle$.


A este grupo $Q$ lo llamaremos \textbf{\textit{grupo cuaternión}}. Además estará generado por $i$ y $j$, es decir, $Q = \langle i,j \rangle$ ya que \begin{equation*}
\begin{aligned}
&i = i, \hspace{0.2cm} ij = k\\
&j = j, \hspace{0.2cm} i^{3}j = i^{2}ij =(-1)k = -k\\
&i^{0} = 1, \hspace{0.2cm} i^{3} = i^{2}i = (-1)i = -i\\
&i^{2} = -1, \hspace{0.2cm} i^{2}j = (-1)j = -j.
\end{aligned}
\end{equation*}
Y así, se tiene que $$Q = \lbrace 1, i, i^{2}, i^{3}, j, ij, i^{2}j, i^{3}j \rbrace.$$
Este grupo además se suele presentar como el generado por las siguientes matrices: $$a = \left(
\begin{matrix}
i & 0 \\
0 & -i
\end{matrix}
\right) \hspace{0.3cm} b = \left(
\begin{matrix}
0 & 1 \\
-1 & 0
\end{matrix}
\right)$$
\end{example}
$\hfill \blacksquare$

Dentro de la \textbf{\textit{Teoría de grupos}}, un concepto fundamental es el de subgrupo \textit{normal}. Antes habíamos mencionado que, dado un subgrupo $H$ de un grupo $G$ cualquiera y un elemento $x\in G$, en general no se cumplía $xH = Hx$. Veamos ahora qué ocurre en caso de que sí.

\begin{definition} Un subgrupo $N$ de $G$ se dice \textbf{normal} si $$xN = Nx,$$ para todo $x \in G$. En ese caso, escribiremos $N \unlhd G$. También denotaremos por $$G/N = \lbrace gN : g\in G\rbrace$$ al conjunto de las clases a izquierda de $G$ módulo $N$. Si el conjunto $G/N$ es finito, tenemos que $$|G/N| = [G:N].$$
\end{definition}

Notar que todo grupo posee al menos dos subgrupos normales, $1 \unlhd G$, $G \unlhd G$. NOtar también que el conjunto $G/N$ puede estar formado igualmente por las clases a derecha, $Ng$, al ser el subgrupo $N$ normal.

\begin{definition} Un grupo $G$ cuyos únicos subgrupos normales sean $\lbrace 1 \rbrace$ y él mismo se dice que es \textbf{simple}.
\end{definition}

\begin{theorem}[\textbf{\textit{Criterio de normalidad}}]
Sea $N$ un subgrupo de $G$. Entonces son equivalentes:
\begin{enumerate}
\item $N\unlhd G$.
\item $xN x^{-1} = N$ $\forall x \in G$.
\item $xNx^{-1} \subseteq N$ $\forall x \in G$.
\end{enumerate}
\end{theorem}
\emph{Demostración: }Veamos primero que $1.\Rightarrow 2.$, para ello notemos que si $y\in xNx^{-1}$ entonces $x^{-1}yx = n \in N$. Como $yx = xn \in xN = Nx$ existirá algún $n' \in N$ tal que $yx = n'x$, y simplificando tendremos que $y = n' \in N$, luego $xNx^{-1} \subseteq N$. Como esto es válido para todo $x \in G$, en particular si aplicamos este contenido para $x^{-1}$ tenemos que $x^{-1}N(x^{-1})^{-1}= x^{-1}Nx \subseteq N$. Así, $N = xx^{-1}Nxx^{-1} = x(x^{-1}Nx)x^{-1} \subseteq xNx^{-1}$ y tenemos la igualdad. 

Es evidente que $2.\Rightarrow 3.$, así que veamos que $3.\Rightarrow 1.$ Sabiendo que $xNx^{-1} \subseteq N$ $\forall x\in G$, lo aplicamos a $x^{-1}$ y tenemos nuevamente que $N \subseteq xNx^{-1}$ $\forall x \in G$, así, tenemos la igualdad ($2.$) y de aquí sacamos que $xN = Nx$ y $N$ es normal.

$\hfill \square$

\begin{example} Sea $n>0$ un entero y $O_{n}(\mathbb{R})$ un subgrupo de $GL_{n}(\mathbb{R})$ llamado subgrupo de las \textbf{matrices ortogonales} o simplemente \textbf{subgrupo ortogonal} de orden $n$ con coeficientes en $\mathbb{R}$. $$O_{n}(\mathbb{R}) = \lbrace A \in GL_{n}(\mathbb{R}):A^{t}A = I_{n}\rbrace$$ donde $A^{t}$ es la matriz traspuesta de $A$ y $I_{n}$ es la matriz identidad.

Veamos que $O_{2}(\mathbb{R})$, subgrupo formado por las matrices ortogonales de orden 2, no es subgrupo normal de $GL_{2}(\mathbb{R})$:
\begin{center}
Sea $P = \left(
\begin{matrix}
1 & 0 \\
1 & 1
\end{matrix}
\right) \in GL_{2}(\mathbb{R})$, \hspace{0.1cm} $A =\left(
\begin{matrix}
1 & 0 \\
0 & -1
\end{matrix}
\right) \in O_{2}(\mathbb{R})$ y \hspace{0.1cm }$P^{-1} = \left(
\begin{matrix}
1 & 0 \\
-1 & 1
\end{matrix}
\right)$.\\
\end{center}
Simplemente multiplicando se tiene que $$B = PAP^{-1} = \left(
\begin{matrix}
1 & 0 \\
1 & 1
\end{matrix}
\right) \left(
\begin{matrix}
1 & 0 \\
0 & -1
\end{matrix}
\right)\left(
\begin{matrix}
1 & 0 \\
-1 & 1
\end{matrix}
\right) = \left(
\begin{matrix}
1 & 0 \\
2 & -1
\end{matrix}
\right).$$
Y $B$ no es ortogonal, ya que $$B^{t}B = \left(
\begin{matrix}
1 & 2 \\
0 & -1
\end{matrix}
\right)\left(
\begin{matrix}
1 & 0 \\
2 & -1
\end{matrix}
\right)= \left(
\begin{matrix}
5 & -2 \\
-2 & -1
\end{matrix}
\right) \neq \left(
\begin{matrix}
1 & 0 \\
0 & 1
\end{matrix}
\right).$$
$\hfill \blacksquare$
\end{example}

\begin{proposition}Si $G$ es un grupo y $H$ un subgrupo de $G$ con $\left[ G:H \right] = 2$, entonces $H$ es subgrupo normal de $G$.
\end{proposition}
\emph{Demostración: }Como $\left[ G:H \right] = 2$, tanto $G/\sim_{H}$ como $G/\sim^{H}$ tienen 2 elementos. Entonces, dado un $g \in G$, puede ocurrir que:\begin{enumerate}
\item Si $g \in H$. En tal caso, $g^{-1}1 = g^{-1} \in H$ (por ser $H$ subgrupo) y así $g\sim_{H}1$, luego $gH = 1H = H.$ Y como $g1^{-1} = g \in H$, entonces $g\sim^{H}1$ y así, $Hg = H1 = H.$ Por lo tanto, $$gH = Hg.$$
\item Si $g \notin H$, $gH \neq H$. Como $G/\sim_{H}$ tiene dos elementos, tendremos que $G = H\sqcup gH$ (unión disjunta).
Pero si $g\notin H$, también se cumplirá $H \neq Hg$. Y como $G/\sim^{H}$ también tiene dos elementos, tenemos $ G = H \sqcup Hg$ (unión disjunta).

Por lo tanto, $gH = G\setminus H = Hg$, y $H$ es normal. Ésto se desprende de que $G$ es unión disjunta de clases y que sólo existen dos, la del neutro y la del elemento $g \notin H$.
\end{enumerate}
$\hfill \square$

\begin{proposition}Si $G$ es un grupo, todo subgrupo $H \subseteq Z(G)$ es un subgrupo normal de $G$.
\end{proposition}
\emph{Demostración: } Recordar que el centro de $G$ es $$Z(G) = \lbrace x \in G : xg = gx \hspace{0.2cm} \forall g \in G\rbrace$$ y es subgrupo de $G$ tal y como vimos en~\ref{eq:centro}.

Basta probar que $H^{g}\subseteq H$ para cada $g \in G$. Sea $x \in H^{g}$. Así $g^{-1}xg = h \in H$, luego $x = ghg^{-1}$. Como $h \in H \subseteq Z(G)$, $gh = hg$ y así $x = hgg^{-1} = h \in H.$

$\hfill \square$

\begin{definition}Si $H$ y $K$ son subgrupos de un grupo $G$ decimos que $K$ es un \textbf{subgrupo conjugado} de $H$ si existe $g \in G$ tal que $K =H^{g}$.
\end{definition}

El siguiente resultado vendrá bien tenerlo en cuenta cuando demos los \textit{Teoremas de Sylow} más adelante: 

\begin{proposition}~\label{eq:conjug}Sean $H$ y $K$ subgrupos de un grupo $G$:
\begin{enumerate}
\item Si $K$ es conjugado de $H$, entonces $H$ es conjugado de $K$, y diremos que $H$ y $K$ son \textit{conjugados}.
\item Si $\Sigma$ es la familia de subgrupos conjugados de $H$ (distintos) y $N = N_{G}(H)$ es el normalizador de $H$ en $G$, la aplicación $$
\begin{array}{rccl}
\varphi \colon &G/\sim_{N} & \longrightarrow & \Sigma\\
&gN & \longmapsto &H^{g}
\end{array}
$$ es biyectiva.
\item En particular, si $N_{G}(H)$ tiene índice finito en $G$, el número de conjugados de $H$ en $G$ es $\left[ G:N_{G}(H) \right]$.
\end{enumerate}
\end{proposition}
\emph{Demostración: }\begin{enumerate}
\item Es evidente, pues si $K = H^{g}$, $K^{g^{-1}} =(H^{g})^{g^{-1}} = H$.
\item Comencemos por demostrar que $\varphi$ está bien definida:

Si $gN = fN$, entonces $g^{-1}f \in N$, luego $H^{g^{-1}f} = H$ y así $H^{g} = (H^{g^{-1}f})^{g} = H^{f}$. Veamos ahora que es inyectiva: 

Si $H^{g} = H^{f}$ se tiene $H^{g^{-1}f} = (H^{f})^{g^{-1}} = (H^{g})^{g^{-1}} = H$, luego $g^{-1}f \in N$ y $gN = fN.$ Como la sobreyectividad es evidente, queda demostrado.
\item  Es claro ya que $$card\hspace{0.1cm} \Sigma = card(G/\sim_{N}) = \left[ G:N \right].$$
\end{enumerate}
$\hfill \square$

\begin{definition}Si $H$ es un subgrupo de un grupo $G$, se llama \textbf{corazón} de $H$ a $$K(H) = \bigcap_{g \in G} H^{g}. \label{eq:corazon}$$ Además, $K(H)$ es un subgrupo de $G$, en particular es un subgrupo normal de $G$.
\end{definition}
\emph{Demostración: }Basta probar que $K(H)^{f} \subseteq K(H)$ para cada $f \in G$:

Sea $x \in K(H)^{f}$, tenemos que ver que $x \in H^{g}$ para cada $g \in G$. Pero $
f^{-1}xf \in K(H) \subseteq H^{g^{-1}f}$ (ya que $g^{-1}f$ es un elemento de $G$), luego $g^{-1}f(f^{-1}xf)(g^{-1}f)^{-1} \in H,$ y por lo tanto $g^{-1}xg \in H$ y $x\in H^{g}$.

$\hfill \square$

Los subgrupos normales son importantes porque nos permiten construir un nuevo tipo de grupo.

\begin{proposition}\label{eq:cociente} Supongamos que $N \unlhd G$. El conjunto $G/N$ de las clases a izquierda módulo $N$ es un grupo con la operación de $G$ 
$$(xN)(yN)=xyN,$$ con $x,y \in G$. El elemento neutro del grupo $G/N$ es $N$ y $(xN)^{-1} = x^{-1}N$ para todo $x \in G$.
\end{proposition}
\emph{Demostración: }Tenemos que $$(xN)(yN)=x(Ny)N = x(yN)N = xyN.$$ Luego es una operación binaria. 

Veamos que la operación está bien definida: sean $xN = x'N$, $yN = y'N$, veamos que $xyN = x'y'N$. Por~\ref{eq:partiGrupo}, $x^{-1}x' \in N$, $y^{-1}y' \in N$. Ahora $(xy)^{-1}(x'y') = y^{-1}x^{-1}x'y' = y^{-1}x^{-1}x'yy^{-1}y'=y^{-1}(x^{-1}x')y(y^{-1}y') \in N$. Nuevamente por~\ref{eq:partiGrupo} se tiene.

Como $N = 1N$, por lo primero tenemos que $$(xN)N=xN = N(xN)$$ y así es el elemento neutro de $G/N$. También tenemos que $$(xN)(x^{-1}N) = N = (x^{-1}N)(xN),\quad \forall x\in G.$$

$\hfill \square$

\begin{definition}Dado $N \unlhd G$, llamaremos \textbf{grupo cociente} de $G$ por $N$ al grupo $G/N$.
\end{definition}

Notar que en un grupo abeliano $G$, todo subgrupo $H$ va a cumplir que $xH = Hx$, por lo que en un grupo abeliano todos sus subgrupos son normales.

\begin{proposition}Sea $N \unlhd G$ y $H \leq G$. Entonces $HN \leq G$.
\end{proposition}
\emph{Demostración: }Como $N$ es subgrupo normal: $$NH = \bigcup_{h\in H} hN = \bigcup_{h\in H} Nh = HN.$$ Aplicamos~\ref{eq:progruesgru} y ya está.

$\hfill \square$

\begin{proposition}\label{eq:ej218} Sea $N \unlhd G$, sean $H, K \leq G$ tales que $H \unlhd K$. Entonces $HN$ es subgrupo normal de $KN$.
\end{proposition}
\emph{Demostración: }Primeramente veamos que $NH=HN$ y así $NH$ es subgrupo de $G$:

En particular $NH$ es subgrupo de $NK$, pues $NH \subseteq NK$. Si $x \in NH$ escribiremos $x = nh, \hspace{0.1cm} n \in N, \hspace{0.1cm} h \in H$. Así $x \in Nh = hN \subseteq HN$, la igualdad $Nh = hN$ se tiene por ser $N$ subgrupo normal de $G$. Esto prueba el contenido $NH \subseteq HN$. El otro es análogo. De igual forma se prueba que $NK = KN$, luego $NK$ es subgrupo de $G$, y así es grupo. Ahora veamos la normalidad:

Veamos ahora que si $a \in NK$, entonces $a(NH) = (NH)a$. Como $a \in NK$ se escribirá $a = nk, \hspace{0.1cm} n \in N, \hspace{0.1cm} k \in K$. Si $x \in a(NH) = a(HN)$ se tendrá $x = ahn_{1}, \hspace{0.1cm} h \in H, \hspace{0.1cm} n_{1} \in N.$ Como $x \in (ah)N = N(ah)$ por ser $N$ subgrupo normal de $G$, tendremos entonces $x = n_{2}ah = n_{2}nkh, \hspace{0.1cm} n_{2} \in N.$ Como $kh \in kH = Hk$ por ser $H$ subgrupo normal de $K$, $x = n_{2}nh_{1}k, \hspace{0.1cm} h_{1} \in H,$ o también, $x = n_{2}nh_{1}n^{-1}nk = n_{2}nh_{1}n^{-1}a$. Ahora $h_{1}n^{-1} \in HN = NH$, con lo que se tiene $h_{1}n^{-1} = n_{3}h_{2}$, $n_{3} \in N$, $h_{2} \in H$. Finalmente, $x = n_{2}nn_{3}h_{2}a \in (NH)a$. Y así $a(NH) \subseteq (NH)a$. Para el otro contenido se procede de igual forma.

$\hfill \square$

\begin{example}
Dado un entero positivo $m$, el subgrupo $H = m\mathbb{Z}$ del grupo $\mathbb{Z}$ es desde luego normal, por ser $\mathbb{Z}$ abeliano. Como la notación es aditiva, la operación en el cociente vendrá dada por $$\begin{array}{rccl}
&\mathbb{Z}/m\mathbb{Z} \times \mathbb{Z}/m\mathbb{Z} & \longrightarrow & \mathbb{Z}/m\mathbb{Z}\\
&(a+m\mathbb{Z}, b+m\mathbb{Z}) & \longmapsto &a+b+m\mathbb{Z}.
\end{array}
$$
Además el grupo cociente $\mathbb{Z}/m\mathbb{Z}$ es de orden $m$ y sabemos que $$\mathbb{Z}/m\mathbb{Z} = \lbrace 0+m\mathbb{Z}, 1+m\mathbb{Z}, \ldots, (m-1)+m\mathbb{Z}\rbrace,$$ siendo todos sus elementos distintos. Finalmente es claro que $\mathbb{Z}/m\mathbb{Z} = \langle 1+m\mathbb{Z}\rangle.$ Además definiremos un grupo abeliano concreto que estudiaremos más adelante, y que veremos que es muy interesante:
$$\mathbb{Z}_{m}^{\ast} = \lbrace a+m\mathbb{Z} \in \mathbb{Z}/m\mathbb{Z} : mcd(a,m) = 1\rbrace,$$
con la operación 
$$\begin{array}{rccl}
&\mathbb{Z}_{m}^{\ast} \times \mathbb{Z}_{m}^{\ast} & \longrightarrow & \mathbb{Z}_{m}^{\ast}\\
&(a+m\mathbb{Z}, b+m\mathbb{Z}) & \longmapsto &ab+m\mathbb{Z}.
\end{array}
$$
\end{example}

$\hfill \blacksquare$

Veamos ahora una clase especial de grupos, los conocidos como \textit{grupos cíclicos}. Ya hemos hablado antes de los generadores de un grupo, bien pues los grupos cíclicos son aquellos que están generados por un sólo elemento, repasemos las potencias y el concepto de grupo generado por un elemento:

Dado un $n$ entero positivo y $x\in G$, tenemos que $$x^n = x\underbrace{\ldots}_{n} x, \quad x^{-n} = x^{-1} \underbrace{\ldots}_n x^{-1}.$$ También convenimos que $x^0 = 1$. Si $G$ es un grupo abeliano escribiremos $$nx = x\underbrace{+\ldots +}_n x, \quad (-n)x=(-x)\underbrace{+\ldots +}_n(-x), \quad 0x = 0.$$ También es claro que $$x^{n+m} = x^nx^m, \quad (x^n)^m=x^{nm}.$$

\begin{definition}Si consideramos un grupo $G$ y un $x\in G$, entonces $$\langle x \rangle = \lbrace x^k:k \in \mathbb{Z} \rbrace,$$ es un subgrupo de $G$ que lo denominaremos \textbf{subgrupo generado por $x$}. Es claro que si $H$ es un subgrupo de $G$ que contiene a $x$, entonces $\langle x \rangle \subseteq H$.
\end{definition}

Notar que, dado un grupo $G$ y un $x \in G$, si estamos utilizando la notación aditiva entonces: $$\langle x \rangle = \lbrace kx : k \in \mathbb{Z} \rbrace.$$

\begin{definition}Diremos que un grupo $G$ es \textbf{cíclico} si existe un $x \in G$ tal que $$\langle x \rangle = G.$$ A este elemento $x$ lo llamamos \textbf{generador} de $G$. En general, un grupo cíclico puede tener varios elementos generadores. Además, a un grupo cíclico de orden $n$ se le suele denotar $C_n$.
\end{definition}

Notar que, por ejemplo $$\mathbb{Z} = \lbrace 1n \wedge 1(-n) :n \in \mathbb{N} \rbrace= \langle 1 \rangle,$$ es un grupo cíclico infinito. O también el grupo visto al principio $$C_n = \langle \xi \rangle, \quad \xi = \cos\left(\dfrac{2\pi}{n}\right)+i\sin\left(\dfrac{2\pi}{n}\right),$$ es un grupo cíclico finito de orden $n$. Notar también que \textit{los grupos cíclicos son abelianos}, ya que dados dos elementos $y,z \in G$ cíclico entonces $yz = x^nx^m=x^{n+m}=x^{m+n} = x^mx^n=zy.$

Estudiemos ahora los subgrupos de un grupo cíclico finito $\langle x \rangle$ de orden $n$.

\begin{proposition}\label{eq:subciclico} Dado un grupo $G$ cíclico y $H \leq G$. Entonces $H$ es cíclico.
\end{proposition}
\emph{Demostración: } Si $H = \lbrace 1 \rbrace$ no hay nada que probar. Sea $H \neq \lbrace 1 \rbrace$ y veamos que $H = \langle x^{k} \rangle$, con $k$ el menor entero positivo tal que $x^{k} \in H$.

Es claro, por ser el producto una operación interna en $H$, que $\langle x^{k} \rangle \in H$.

Ahora, dado $x ^{p} \in H$, comprobemos que $x^{p} \in \langle x^{k} \rangle$, es decir, que $p$ es múltiplo de $k$. Podemos suponer que $p \geq 0$ pues $p$ será múltiplo de $k$ si y sólo si lo es $-p$. Por el algoritmo de la división, al dividir $p$ entre $k$ existirán enteros no negativos $q,r$, $0 \leq r < k$, tales que $p = kq + r$. Entonces, 
\begin{center}
$x^{p} = x^{kq+r} = (x^{k})^{q}x^{r}$, por tanto $x^{r} = x^{p}(x^{k})^{-q} \in H$
\end{center}
pero por la elección de $k$ (el menor entero positivo tal que $x^{k} \in H$) necesariamente $r = 0$. Esto implica que $x^{p} = (x^{k})^{q} \in \langle x^{k} \rangle$.

$\hfill \square$

Por ejemplo, los subgrupos de $\mathbb{Z}$ son cíclicos y son de la forma $$m\mathbb{Z} = \lbrace mz : z \in \mathbb{Z} \rbrace = \langle m \rangle.$$

El siguiente resultado ya lo habíamos tenido en cuenta cuando hablamos de los subgrupos, pero ahora lo formalizamos:

\begin{corolario}Sea $H$ un subconjunto no vacío de $\mathbb{Z}$. Entonces $H \leq \mathbb{Z}$ si y sólo si existe un único entero no negativo $d$ tal que $H = d\mathbb{Z}$. Además, si $e \in \mathbb{Z}$, entonces $d\mathbb{Z} \subseteq e\mathbb{Z}$ si y sólo si $e$ divide a $d$.
\end{corolario}
\emph{Demostración: }Si $H = d\mathbb{Z}$, ya sabemos que $H$ es subgrupo de $\mathbb{Z}$. Recíprocamente, si $H \leq \mathbb{Z}$, por el resultado anterior existirá un $d \in \mathbb{Z}$ tal que $H = d\mathbb{Z}$. Como $d\mathbb{Z} = (-d)\mathbb{Z}$ podemos elegir $d \geq 0$. Finalmente, $d\mathbb{Z} \subseteq e\mathbb{Z}$ si y sólo si $d \in e\mathbb{Z}$ si y sólo si $e$ divide a $d$.

$\hfill \square$

\begin{corolario}Sean $0\neq a,b \in \mathbb{Z}$. Entonces:
\begin{enumerate}
\item Existe un único entero positivo $d \in \mathbb{Z}$ tal que $$a\mathbb{Z}+b\mathbb{Z} = d\mathbb{Z}.$$ Además, $d = mcd(a,b)$.
\item Si $d = mcd(a,b)$, entonces $mcd \left(\dfrac{a}{d}, \dfrac{b}{d} \right) = 1.$
\end{enumerate}
\end{corolario}
\emph{Demostración: }Lo primero ya está probado en el ejemplo~\ref{eq:gib}.

Si un entero positivo $n$ divide a $a/d$ y a $b/d$, entonces $nd$ divide a $a$ y a $b$. Entonces es claro que $nd$ divide a $d$ (por ser éste el mcd) y de aquí $n=1$. Esto prueba $2.$

$\hfill \square$

Al principio definimos el orden de un grupo como el número de elementos que contiene, análogo al cardinal en los conjuntos. Ahora veremos que los elementos también tienen orden:

\begin{definition}Sea $G$ un grupo y $x \in G$. Si no existe ningún entero positivo $n$ tal que $x^n=1$ decimos entonces que el \textbf{orden} de $x$ es \textbf{infinito}. En caso contrario, diremos que el \textbf{orden} de $x$ es \textbf{finito} y denominaremos \textbf{orden} de $x$ al menor entero positivo $n$ tal que $x^n =1$. Lo escribiremos como $o(x) = n$ ó también $|x| = n$.
\end{definition}

\begin{theorem}\label{eq:prelgrupcic}
Sea $G$ un grupo y $x \in G$ de orden $n$. Entonces:
\begin{enumerate}
\item Si $m$ es un entero, $x^m =1$ si y sólo si $n$ divide a $m$.
\item $\langle x \rangle = \lbrace 1, x, x^2, \ldots, x^{n-1} \rbrace$ y $|\langle x \rangle | = n$. En particular, el orden de $x$ coincide con el del subgrupo que genera.
\item Si $0\neq m$ es un entero, entonces $$o(x^m)= \dfrac{n}{mcd(n,m)}.$$ En particular, $x^m$ genera $\langle x \rangle$ si y sólo si $n$ y $m$ son coprimos.
\item Para cada divisor $d$ de $n$, $\langle x \rangle$ tiene un único subgrupo de orden $d$. Este es $\langle x^{n/d} \rangle$.
\end{enumerate}
\end{theorem}
\emph{Demostración: }Veamos:
\begin{enumerate}
\item Si $m = np$ es múltiplo de $n$, $x^{m} = x^{np} = (x^{n})^{p} = 1.$ Recíprocamente, si $m$ no es múltiplo de $n$, $m = np + r, \hspace{0.1cm} 1\leq r\leq n-1$ por el algoritmo de la división, luego $x^{m} = x^{np + r} = (x^{n})^{p}x^{r} = 1^{p}x^{r} = x^{r} \neq 1$.
\item Sea $n$ el menor natural que cumple $x^{n} = 1$. Si probamos que $$\langle x \rangle = \lbrace 1, x,x^2, \ldots, x^{n-1} \rbrace$$ y que todos los miembros de la derecha son distintos, entonces tendremos que $| \langle x\rangle | = n$.
Evidentemente el elemento de la izquierda de la igualdad contiene al de la derecha. Recíprocamente, si $y = x^{k}$, $k \in \mathbb{Z}$, dividimos por $n$ y por el algoritmo de la división sabemos que: $$k = qn + r, \hspace{0.1cm} 0\leq r \leq n-1,$$ luego $y = x^{qn+r}= (x^{n})^{q}x^{r} = 1^{q}x^{r} = x^{r}, \hspace{0.1cm}  0\leq r \leq n-1.$ Por último, si existieran $0\leq r < s \leq n-1$ tales que $x^{r} = x^{s},$ sería $x^{s-r} = x^{s}x^{-r} = x^{r}x^{-r} = x^{0} = 1, \hspace{0.1cm} s-r \leq n-1 < n,$ pero esto es absurdo porque $n$ es el menor entero positivo tal que $x^{n} = 1$.
\item Llamaremos $d = mcd(n,m)$ y veamos que $n/d$ es el menor entero positivo tal que $(x^{m})^{n/d} = 1$.

Para comenzar, $$(x^{m})^{n/d} = (x^{n})^{m/d} = 1^{m/d} = 1$$ ya que $d$ divide a $m$ por ser $d = mcd(n,m)$ y que el orden de $x$ es $n$.

Por otra parte, si $t$ es un entero positivo tal que $(x^{m})^{t} = 1$, entonces $mt$ es múltiplo de $n$, es decir que existe un $t'$ entero positivo tal que $mt = nt'$. De aquí, puesto que $d$ divide a $m$  y a $n$, $$\left( \dfrac{m}{d}\right)t =\left( \dfrac{n}{d}\right) t',$$ luego $\left( \dfrac{n}{d}\right) $ divide a $\left( \dfrac{m}{d}\right) t$. Pero como $n/d$ y $m/d$ son primos entre sí, necesariamente $(n/d)$ divide a $t$, como queríamos demostrar. ($n/d$ es el menor entero positivo tal que $(x^{m})^{n/d} = 1$).
\item Si $d$ divide a $n$, tenemos que $\langle x^{n/d} \rangle$ es un subgrupo de orden $d$ por los apartados anteriores. Supongamos ahora que $H \leq \langle x \rangle $ tiene orden $d$. Entonces $H$ es cíclico por~\ref{eq:subciclico} y deducimos que existe un entero $s$ tal que $H = \langle x^s \rangle$. Ahora, por el apartado $2.$ tenemos que $$1 = (x^s)^{o(x^s)} = (x^s)^{|H|} = (x^s)^d = x^{sd},$$ y por tanto $n$ divide a $sd$ por el apartado $1.$ Se sigue que $n/d$ divide a $s$. Por tanto, $x^s \in \langle x^{n/d} \rangle$ y así, $H = \langle x^s \rangle \subseteq \langle x^{n/d} \rangle$. Como ambos conjuntos tienen el mismo número de elementos, deben coincidir.
\end{enumerate}

$\hfill \square$

\begin{corolario}\label{eq:abSimple} Sea $G \neq \lbrace 1 \rbrace$ un grupo finito. Entonces $G$ no tiene subgrupos propios si y sólo si $|G|$ es primo. Por lo tanto, un grupo simple abeliano finito es de orden primo.
\end{corolario}
\emph{Demostración: }Si $|G|$ es primo, entonces $G$ no tiene subgrupos propios por el \textit{Teorema de Lagrange}. Supongamos ahora que $G$ no tiene subgrupos propios. Sea $1 \neq x \in G$, entonces $\langle x \rangle = G$. Si $p$ es un número primo que divide a $|G|$ entonces $G$ tiene un subgrupo $H$ de orden $p$ por~\ref{eq:prelgrupcic}. Luego $G = H$ tiene orden $p$. Por último, como en un grupo abeliano todos sus subgrupos son normales ya está.

$\hfill \square$

Este resultado que acabamos de ver tiene sentido porque el orden de un grupo siempre es un entero positivo, y éstos se pueden descomponer en un producto de factores primos tal y como veremos en la parte de anillos, por lo que siempre habrá un primo que lo divida.



Ya hemos analizado $\mathbb{Z}$ pero no sus cocientes. Si $n$ es un entero, el grupo cociente $\mathbb{Z}/n\mathbb{Z}$ es un objeto matemático de interés. Ya sabemos que si $x,y \in \mathbb{Z}$ entonces $x+n\mathbb{Z} = y + n\mathbb{Z}$ si y sólo si $x-y \in n\mathbb{Z}$ si y sólo si $n$ divide a $x-y$. Esto lo escribiremos como $x \equiv y$ mod $n$ y es la base de la conocida como \textit{aritmética modular}.

\begin{proposition}Si $n \geq 1$, entonces $$\mathbb{Z}_n=\mathbb{Z}/n\mathbb{Z} = \lbrace 0+n\mathbb{Z}, 1+n\mathbb{Z}, \ldots, (n-1)+n\mathbb{Z} \rbrace$$ es un grupo cíclico de orden $n$.
\end{proposition}
\emph{Demostración: }Como $\mathbb{Z}$ es abeliano, $n\mathbb{Z} \unlhd \mathbb{Z}$ y el grupo cociente $\mathbb{Z}/n\mathbb{Z}$ está bien definido. Si $x,y \in \mathbb{Z}$, entonces $x +n\mathbb{Z} = y + n\mathbb{Z}$ si y sólo si $n$ divide a $x-y$. Así, tenemos que las clases $n\mathbb{Z}, 1+n\mathbb{Z}, \ldots, (n-1) +n\mathbb{Z}$ son necesariamente distintas. Como $k(1+n\mathbb{Z}) = k + n\mathbb{Z}$, con $k \in \mathbb{Z}$ deducimos que $o(1+n\mathbb{Z})=n$. Por lo que $|\mathbb{Z}/n\mathbb{Z}| = n$.

$\hfill \square$

\begin{definition}Si $n$ es un entero positivo, llamamos \textbf{función de Euler}, y la denotamos por $\varphi$, a $$\varphi(n)=| \lbrace m \in \mathbb{Z}:1\leq m \leq n, \hspace{0.1cm} mcd(n,m)=1 \rbrace|.$$
\end{definition}

Notar que, por~\ref{eq:prelgrupcic}, $\varphi(n)$ es el número de generadores en un grupo cíclico de orden $n$.

Acabemos este capítulo con un ejemplo:

\begin{example}Como hemos visto al principio, si tenemos $n \in \mathbb{Z}$, con $n>1$ y consideramos el grupo aditivo $\mathbb{Z}_{n}$, tenemos que $\mathbb{Z}_{n} = \langle \left[ 1 \right] \rangle$ (aquí hemos escrito $\left[ 1 \right]$ en lugar de $\left[ 1 \right]_{n}$ por cuestiones estéticas). Esto se comprueba fácilmente ya que 
\begin{center}
$0\left[ 1 \right] = \left[ 0 \right]$, $1\left[ 1 \right] = \left[ 1 \right]$, $2\left[ 1 \right] = \left[ 2 \right]$, $\ldots$ , $(n-1)\left[ 1 \right] = \left[ n-1 \right].$
\end{center}
Y como acabamos de ver, en función del $n$ escogido, $\mathbb{Z}_{n}$ puede estar generado por otros elementos además de $\left[ 1 \right]$. Veamos para $\mathbb{Z}_{8}$.

Ya sabemos que $\mathbb{Z}_{8} = \lbrace \left[ 0 \right], \left[ 1 \right], \left[ 2 \right], \left[ 3 \right], \left[ 4 \right], \left[ 5 \right], \left[ 6 \right], \left[ 7 \right] \rbrace$, y además

$0\left[ 3 \right] = 0(3 + 8\mathbb{Z}) = 0 +8\mathbb{Z} = \left[ 0 \right],1\left[ 3 \right] = 1(3 + 8\mathbb{Z}) = 3 +8\mathbb{Z} = \left[ 3 \right],2\left[ 3 \right] = 2(3 + 8\mathbb{Z}) = 6 +8\mathbb{Z} = \left[ 6 \right],$

$3\left[ 3 \right] = 3(3 + 8\mathbb{Z}) = 1 +8\mathbb{Z} = \left[ 1 \right],4\left[ 3 \right] = 4(3 + 8\mathbb{Z}) = 4 +8\mathbb{Z} = \left[ 4 \right], 5\left[ 3 \right] = 5(3 + 8\mathbb{Z}) = 7 +8\mathbb{Z} = \left[ 7 \right],$

$6\left[ 3 \right] = 6(3 + 8\mathbb{Z}) = 2 +8\mathbb{Z} = \left[ 2 \right], 7\left[ 3 \right] = 7(3 + 8\mathbb{Z}) = 5 +8\mathbb{Z} = \left[ 5 \right],$

con lo que $\mathbb{Z}_{8} = \langle \left[ 3 \right] \rangle$. 

Por el resultado anterior sabemos que esto ocurre porque $mcd(3,8)=1$, igualmente con $\left[ 5 \right]$ y con $\left[ 7 \right]$ pero sin embargo con $\left[ 2 \right]$:

$0\left[ 2 \right] = 0(2 + 8\mathbb{Z}) = 0 +8\mathbb{Z} = \left[ 0 \right],1\left[ 2 \right] = 1(2 + 8\mathbb{Z}) = 2 +8\mathbb{Z} = \left[ 2 \right],2\left[ 2 \right] = 2(2 + 8\mathbb{Z}) = 4 +8\mathbb{Z} = \left[ 4 \right],$

$3\left[ 2 \right] = 3(2 + 8\mathbb{Z}) = 6 +8\mathbb{Z} = \left[ 2 \right],4\left[ 2 \right] = 4(2 + 8\mathbb{Z}) = 0 +8\mathbb{Z} = \left[ 0 \right], 5\left[ 2 \right] = 5(2 + 8\mathbb{Z}) = 2 +8\mathbb{Z} = \left[ 2 \right],$

$6\left[ 2 \right] = 6(2 + 8\mathbb{Z}) = 4 +8\mathbb{Z} = \left[ 4 \right], 7\left[ 2 \right] = 7(2 + 8\mathbb{Z}) = 6 +8\mathbb{Z} = \left[ 6 \right],$

con lo que $\langle \left[ 2 \right] \rangle = \lbrace \left[ 0 \right], \left[ 2 \right], \left[ 4 \right], \left[ 6 \right] \rbrace \neq \mathbb{Z}_{8}$.
\end{example}

$\hfill \blacksquare$

\subsection{Homomorfismos}

Estudiaremos ahora aquellas aplicaciones \textit{buenas} entre grupos, es decir, aquellas que preservan la estructura de grupo. Esto ocurre en todas las estructuras algebraicas, aplicaciones que envían elementos de una estructura a otro conjunto dotado de esa misma estructura, es decir, conserva todas las propiedades de la propia estructura.

\begin{definition}Dados $G$ y $H$ grupos, una aplicación $f \colon G \longrightarrow H$ es un \textbf{homomorfismo de grupos} si cumple $$f(xy) = f(x)f(y) \quad \forall x,y \in G.$$
\end{definition}

Los homomorfismos son una potente herramienta para analizar los grupos que relaciona. Si estudiamos los homomorfismos de dos de los grupos más importantes: $S_{\Omega}$ y $GL_n(K)$ llegaremos a dos subramas de la teoría de grupos: la teoría de permutaciones para el primero y la de representaciones de grupos para el segundo.

\begin{example}\label{eq:ejsHoms} Algunos ejemplos importantes de homomorfismos:
\begin{enumerate}
\item La aplicación determinante $$\begin{array}{rccl}
&GL_n(K)&\longrightarrow &K^* \\
&A& \longmapsto &det(A)
\end{array}
$$
\item Dado un grupo $G$ y $N \unlhd G$, la aplicación $$\begin{array}{rccl}
&G&\longrightarrow &G/N \\
&g& \longmapsto &gN
\end{array}
$$ que se conoce como \textbf{proyección canónica}.
\item Dado $G = \langle x \rangle$ un grupo cíclico, la aplicación $$\begin{array}{rccl}
&\mathbb{Z}&\longrightarrow &G \\
&m& \longmapsto &x^m
\end{array}
$$
\end{enumerate}
\end{example}

$\hfill \blacksquare$

Más adelante veremos más desarrollados estos homomorfismos. Ahora veamos algunas de las propiedades fundamentales de los homomorfismos:

\begin{properties}\label{eq:propHoms} Consideremos un homomorfismo $f \colon G \longrightarrow H$. Entonces algunas propiedades sobre los homomorfismos de grupos que serán importantes tenerlas en cuenta son las siguientes:
\begin{enumerate}
\item $f(1_{G}) = 1_{H}$ ya que $1_{H}f(1_{G}) = f(1_{G}) = f(1_{G}1_{G}) = f(1_{G})f(1_{G}) \Longrightarrow 1_{H} = f(1_{G}).$
\item $f(a^{-1}) = (f(a))^{-1}$ para cada $a \in G$, puesto que $$f(a)f(a^{-1}) = f(aa^{-1}) = f(1_{G}) = 1_{H},$$ $$f(a^{-1})f(a) = f(a^{-1}a) = f(1_{G}) = 1_{H}.$$
\item $f(x^n) = f(x)^n$. Esto es así ya que $f(x^n) = f(x\overbrace{\cdots}^n x) = f(x) \overbrace{\cdots}^n f(x) = f(x)^n.$
\item $o(f(x))$ divide al orden de $x$. En efecto, si $o(x) = m$ como $x^{m} = 1_{G}$ se tiene que $1_{H} = f(1_{G}) = f(x^{m}) = f(x)^{m}$ y así $o(f(x))$ divide a $m$. 
\item Si $X$ es un subgrupo de $G$, su imagen $f(X)$ es un subgrupo de $H$.

En efecto, ya sabemos que $f(X)$ contiene el elemento neutro, $f(1_G)$. Ahora, sean $f(x), f(y) \in f(X)$, entonces $f(x) f(y)^{-1} = f(x)f(y^{-1}) = f(xy^{-1}) \in f(X)$ al ser $X$ subgrupo de $G$, luego $f(X)$ es subgrupo de $H$.
\item Si $Y$ es un subgrupo de $H$, $$f^{-1}(Y) = \lbrace x \in G : f(x) \in Y\rbrace$$ es un subgrupo de $G$. Además si $Y$ es subgrupo normal de $H$, $f^{-1}(Y)$ lo es de $G$.

En efecto, si $x,y \in f^{-1}(Y)$, entonces $f(x),f(y) \in Y$, de donde $f(xy^{-1}) = f(x)f(y)^{-1} \in Y$, luego $xy^{-1} \in f^{-1}(Y)$ y $f^{-1}(Y)$ es subgrupo. Para probar la normalidad de $f^{-1}(Y)$ tenemos que ver que $[f^{-1}(Y)]^a \subseteq f^{-1}(Y)$, con $a \in G$. Sea $x \in [f^{-1}(Y)]^a$, luego $a^{-1}xa \in f^{-1}(Y)$ y así $f(a^{-1}xa)=f(a)^{-1}f(x)f(a) \in Y$, por lo que $f(x) \in Y^{f(a)}$ y como $f(a)$ es un elemento de $H$ e $Y$ es normal entonces $f(x) \in Y$ y así $x \in f^{-1}(Y)$.
 
\item Si ahora además consideramos otro homomorfismo $g\colon H \longrightarrow  Z$, con $Z$ otro grupo, entonces,
$g \circ f\colon G \longrightarrow  Z$ también es homomorfismo, pues $$ (g \circ f)(xy) = g(f(xy)) = g(f(x)f(y)) = g(f(x))g(f(y)) = (g \circ f)(x) (g \circ f)(y).$$
\end{enumerate}
\end{properties}
$\hfill \blacksquare$

Notar que de lo último se puede ver que la composición de homomorfismos la hemos definido tal que $$(g \circ f)(x) = g(f(x)),$$ con $g,f$ sendos homomorfismos. Es importante aclararlo porque en otros textos es frecuente encontrar que actúan al revés, primero $g$ y luego $f$.

\begin{definition}Si $f \colon G \longrightarrow H$ es un homomorfismo de grupos, llamaremos \textbf{núcleo de $f$} a $$Ker f= \lbrace g \in G: f(g) = 1_H \rbrace.$$

De igual manera, llamaremos \textbf{imagen de $f$} al conjunto $$Im f = \lbrace f(x) : x \in G\rbrace.$$
\end{definition}

De hecho, en el ejemplo~\ref{eq:ejsHoms}($1.$) tenemos que $Ker(det) = SL_n(K)$ es el grupo especial lineal. Y en el ejemplo~\ref{eq:ejsHoms}($2.$) es el propio $N$.

\begin{proposition}Si consideramos $f \colon G \longrightarrow H$ un homomorfismo de grupos cualquiera, entonces $Ker f \unlhd G$. Además, $f$ es inyectiva si y sólo si $Ker f= \lbrace 1 \rbrace.$
\end{proposition}
\emph{Demostración: }Como $Ker f=f^{-1} (1_H)$, por~\ref{eq:propHoms}($4.$) tenemos que $Ker f$ es subgrupo de $G$. Probaremos ahora que, dados $x \in G$ y $z \in Ker f$, $xzx^{-1} \in Ker f$. Esto es claro, ya que $$f(xzx^{-1})=f(x)f(z)f(x)^{-1} = f(x)f(x)^{-1} = 1.$$

Ahora, si $f$ es inyectiva y $x \in Ker f$ entonces $f(x) = 1 = f(1)$, por lo que $x = 1$ y así $Ker f = \lbrace 1 \rbrace$. Recíprocamente, si $Ker f = \lbrace 1 \rbrace$ y $x,y \in G$ son tales que $f(x) = f(y)$, entonces $f(xy^{-1}) = f(x)f(y)^{-1} = 1$, luego $xy^{-1} \in Ker f = \lbrace 1 \rbrace$ y así $x=y$.

$\hfill \square$

De entre todos los homomorfismos que podemos establecer entre dos grupos, son especialmente importantes dos de ellos: 

\begin{itemize}
\item Si $H$ es un subgrupo de un grupo $G$, la \textbf{\textit{inclusión}} $$\begin{array}{rccl}
i \colon &H & \longrightarrow & G\\
&x & \longmapsto &x
\end{array}
$$ es un homomorfismo inyectivo puesto que $i(xy) = xy = i(x)i(y)$ y $x \in Ker f$ implica que $i(x) = 1_{G}$, es decir, $x = 1_{G} = 1_{H}$.
\item Si $H$ es un subgrupo normal de un grupo $G$, la \textbf{\textit{proyección}} $$\begin{array}{rccl}
\pi \colon &G & \longrightarrow & G/H\\
&x & \longmapsto &xH
\end{array}
$$ es un homomorfismo sobreyectivo. La sobreyectividad es obvia y para ver que es homomorfismo: $$\pi (xy) = xyH = (xH)(yH) = \pi (x) \pi (y).$$ Lo llamaremos \textbf{\textit{proyección canónica}} y ya lo habíamos visto antes en los ejemplos.
\end{itemize}

\begin{definition}Sea $
\begin{array}{rccl}
f\colon G_{1} \longrightarrow  G_{2}
\end{array}
$ un homomorfismo entre dos grupos $G_{1}$ y $G_{2}$, diremos que $f$ es un \textbf{monomorfismo} si $f$ es inyectiva y \textbf{epimorfismo} si $f$ es sobreyectiva.
\end{definition}

A partir de lo que ya sabemos de grupos cocientes, subgrupos normales y lo que acabamos de ver del núcleo de un homomorfismo (que es subgrupo normal del grupo de partida) y en concreto estos dos últimos homomorfismos podemos, ahora sí, dar un significado alternativo a lo que conocemos por subgrupo normal. Es decir, veamos una forma alternativa de caracterizarlos, que todo subgrupo normal es el núcleo de algún homomorfismo de grupos:

\begin{proposition} Todo subgrupo normal es el núcleo de un homomorfismo de grupos.
\end{proposition}
\emph{Demostración: } Sea $N$ un subgrupo normal de un grupo $G$. Vamos a construir un homomorfismo $\varphi$ y un grupo $H$ tales que $N = Ker \hspace{0.1cm} \varphi$ y $H = G/N$. Sabemos que $$\forall g \in G, n \in N, \hspace{0.1cm} gng^{-1} \in N \Longleftrightarrow \forall g \in G, \hspace{0.1cm} gN = Ng.$$ Además, como $N$ es subgrupo normal de $G$, podemos definir el grupo cociente $$H = G/N  = \lbrace gN :g \in G \rbrace = \lbrace Ng : g \in G\rbrace,$$ con la operación $$\begin{array}{rccl}
&G/N \times G/N & \longrightarrow & G/N\\
&(gN,hN)& \longmapsto &ghN
\end{array}
$$ que en~\ref{eq:cociente} ya definimos y comprobamos que estaba bien definida, que era cerrada, que cumplía la asociatividad y la existencia del elemento neutro e inverso. Así que si consideramos la aplicación $$\begin{array}{rccl}
\varphi \colon &G & \longrightarrow & H\\
&g & \longmapsto &gN.
\end{array}
$$  entonces es claro que es homomorfismo puesto que es una proyección: $$\varphi(gh) = ghN = (gN)(hN) = \varphi(g) \varphi(h).$$ Entonces $$Ker\hspace{0.1cm} \varphi = \lbrace g \in G : gN = N \rbrace = \lbrace g \in G : g \in N \rbrace = N.$$

$\hfill \square$

\begin{definition}Diremos que un homomorfismo de grupos $f \colon G \longrightarrow H$ es un \textbf{isomorfismo} si la aplicación $f$ es biyectiva. En tal caso diremos que $G$ es \textbf{isomorfo} a $H$ y lo denotaremos por $G \cong H$.
\end{definition}

\begin{observation} Algunas observaciones con respecto al concepto de isomorfismo de grupos:
\begin{enumerate}
\item Si $
\begin{array}{rccl}
f\colon G_{1} \longrightarrow  G_{2}
\end{array}
$es isomorfismo, también lo es $
\begin{array}{rccl}
f^{-1}\colon G_{2} \longrightarrow  G_{1}
\end{array}
$, o, dicho de otra forma, si $G_{1}\cong G_{2}$ entonces $G_{2}\cong G_{1}$.

\emph{Demostración: }Como la inversa de toda aplicación biyectiva es biyectiva, basta comprobar que $f^{-1}$ es homomorfismo de grupos.\vspace{0.2cm}\\
Si $a,b \in G_{2}$, y $f^{-1}(a)= x$, $f^{-1}(b) = y$, entonces $$f(x) = a, \hspace{0.1cm} f(y) = b\Longrightarrow f(xy) = f(x)f(y) = ab,$$ y así, $xy = f^{-1}(ab)$, por lo que $f^{-1}(ab) = f^{-1}(a)f^{-1}(b).$
\item Si $G_{1}\cong G_{2}$ y $G_{1}$ es abeliano, también lo será $G_{2}$

\emph{Demostración: }Sean $x,y \in G_{2}$ y$
\begin{array}{rccl}
f\colon G_{1} \longrightarrow  G_{2}
\end{array}
$ isomorfismo. Como $f$ es sobreyectiva, existirán $a,b \in G$ tales que $x = f(a)$, $y = f(b)$. Entonces $$xy = f(a)f(b) = f(ab) = f(ba) = f(b)f(a) = yx.$$
\end{enumerate}
\end{observation}

Notemos que si $G_{1}$ es un grupo cualquiera, entonces $G_{1} \cong G_{1}$ puesto que que la aplicación identidad$
\begin{array}{rccl}
f\colon G_{1} \longrightarrow  G_{1}
\end{array}
$ es claramente un isomorfismo. Ya sabemos que si $G_{1}\cong G_{2}$, entonces $G_{2} \cong G_{1}$, y además si tenemos un tercer grupo $G_{3}$ y $G_{1} \cong G_{2}$, $G_{2} \cong G_{3}$, entonces $G_{1} \cong G_{3}$ ya que la composición de isomorfismos también es isomorfismo. Por lo tanto, si consideramos el conjunto de todos los grupos, \textit{la relación binaria $\cong$ es de equivalencia}.

Como hemos podido ver, la propiedad de ser abeliano se conserva en isomorfismos. Será común ir viendo más propiedades que se conservan en isomorfismos, y las llamaremos \textit{invariantes bajo isomorfismo}. Es decir, dos grupos isomorfos tienen, por así decirlo, «las mismas propiedades» y lo único en lo que se diferencian será en los símbolos utilizados para representar los elementos y operaciones. Es decir, \textit{en esencia son el mismo grupo}.

Hablaremos así de una serie de resultados conocidos como \textit{Teoremas de Isomorfía}, que los debemos a unos cuantos matemáticos y matemáticas, entra les que destaca la matemática alemana Emmy Noether, de la que también veremos más resultados más adelante.

\begin{theorem}[\textbf{\textit{Primer Teorema de Isomorfía}}]
Sea $f \colon G \longrightarrow H$ un homomorfismo de grupos. Entonces, la aplicación $$\begin{array}{rccl}
\bar{f} &G/Ker f&\longrightarrow &f(G) \\
&xKer f& \longmapsto &f(x)
\end{array}
$$
es un isomorfismo de grupos.
\end{theorem}
\emph{Demostración: }Sea $N = Ker f$. Sabemos por~\ref{eq:partiGrupo} que $xN = yN$ si y sólo si $x^{-1}y \in N$ si y sólo si $f(x^{-1}y)=1$ si y sólo si $f(x)^{-1}f(y) = 1$ si y sólo si $f(x)=f(y)$. Si leemos esto de izquierda a derecha estamos probando que la aplicación $\bar{f}$ está bien definida, es decir, que la imagen por $\bar{f}$ de un elemento $xN \in G/N$ no depende del representante que escojamos. Si lo leemos de derecha a izquierda estaremos probando que $\bar{f}$ es inyectiva. Si $y \in f(G)$ (imagen de $G$ por $f$) entonces $y=f(x)=\bar{f}(xKer f)$ con $x\in G$ y esto prueba la sobreyectividad. Además, es homomorfismo: $$\bar{f}(xNyN)= \bar{f}(xyN)=f(xy)=f(x)f(y) =\bar{f}(xN) \bar{f}(yN).$$ 

$\hfill \square$

Luego, dados dos grupos $G,H$, podemos expresar el \textit{Primer Teorema de Isomorfía} tal que así: $$G/Ker f \cong f(G).$$
Y notar que si $f$ es suprayectiva, entonces: $$G/Ker f \cong H.$$
Es decir, el \textit{Primer Teorema de Isomorfía} hace conmutativo el siguiente diagrama, $$\xymatrix @=2cm {G\ar[r]^{f} \ar[d]_\pi & H \\ G/Ker f \ar[r]^{\bar{f}} & Im f \ar[u]_{i}  }$$
donde $\pi$ e $i$ son los homomorfismos proyección e inclusión presentados antes respectivamente. Es decir, $$f = i \circ \bar{f} \circ \pi.$$

Y a esta expresión la llamaremos \textbf{\textit{descomposición canónica de un homomorfismo}} $f$.

\begin{proposition}\label{eq:lemIsom} Sea $N \unlhd G$ y sea $f \colon G \longrightarrow G/N$ el homomorfismo $f(g) = gN$. Si $H \leq G$, entonces $f(H) = f(NH)=NH/N \leq G/N$.
\end{proposition}
\emph{Demostración: }Si $H \leq G$ sabemos que $NH$ es subgrupo de $G$. Como $N \unlhd G$ y $N \subseteq NH$, tenemos que $N \unlhd NH$. Ahora, $$f(H) = \lbrace hN : h \in H \rbrace = \lbrace nhN :n, \in N, h \in H \rbrace = NH/N.$$ Por~\ref{eq:propHoms}($5.$), $NH/N$ es un subgrupo de $G/N$.

$\hfill \square$

\begin{example}Veamos algunos ejemplos:
\begin{enumerate}
\item Vamos a ver cómo son los homomorfismos de la forma $
\begin{array}{rccl}
f\colon \mathbb{Z} \longrightarrow  \mathbb{Z}.
\end{array}
$

Sea $f$ uno de estos homomorfismos y $f(1) = a$, con $a\in \mathbb{Z}$, entonces tendremos que para cada entero positivo $n$: $$f(n) = f(\underbrace{1+\ldots+1}_n) = f(1)\underbrace{ + \ldots + }_n f(1) = na$$
mientras que si $n$ es negativo, $m = -n$ será positivo y así $f(n) = f(-m) = -f(m) = -(ma) = (-m)a = na.$ Y como $f(0) = 0a$, tenemos que $f(n) = na$ para cada $a\in \mathbb{Z}$.

Esta aplicación es homomorfismo, ya que $$f(n+m) = (n+m)a = na + ma = f(n) + f(m).$$
Así, los homomorfismos de $\mathbb{Z}$ en $\mathbb{Z}$ son las aplicaciones ($a\in \mathbb{Z}$) $$\begin{array}{rccl}
f_{a}\colon &\mathbb{Z} & \longrightarrow & \mathbb{Z}\\
&n& \longmapsto &na
\end{array}
$$
\item La aplicación $$\begin{array}{rccl}
f\colon &(GL_{n}(\mathbb{R}), \cdot) & \longrightarrow & (\mathbb{R}^{\ast}, \cdot)\\
&A& \longmapsto &det A
\end{array}
$$ es un epimorfismo (un homomorfismo sobreyectivo) de grupos con núcleo $SL_{n}(\mathbb{R})$ y así, por el \textit{Primer Teorema de Isomorfía}, $$GL_{n}(\mathbb{R})/SL_{n}(\mathbb{R}) \cong \mathbb{R}^{\ast}.$$
En efecto, $f(AB) = det(AB) = det A \cdot det B = f(A)f(B)$, luego $f$ es homomorfismo. Es evidente que $Ker f = SL_{n}(\mathbb{R})$ por definición. Finalmente, si $a \in \mathbb{R}^{\ast}$, la matriz $$A = (a_{ij} : 1 \leq i \leq n,\hspace{0.1cm} 1\leq j \leq n)$$ definida por  $$a_{ij} = \left\lbrace \begin{array}{cll} 0\hspace{0.1cm} &\text{si} \hspace{0.1cm} &i\neq j\\ a\hspace{0.1cm} &\text{si} \hspace{0.1cm}  &i=j=1\\1\hspace{0.1cm} &\text{si} \hspace{0.1cm}  &i=j>1  \end{array}\right.$$
cumple $det A = a1^{n-1} = a$, probando la sobreyectividad de $f$.
\item Sea $x \in \mathbb{R}$ y  $$\begin{array}{rccl}
f\colon &(\mathbb{R}, +) & \longrightarrow & (\mathbb{C}^{\ast}, \cdot)\\
&x& \longmapsto &e^{2\pi xi},
\end{array}
$$ como $e^{2\pi xi} = \cos 2\pi x + i\sin 2\pi x = 1$ si $x \in \mathbb{Z}$, deducimos que $Ker f = \mathbb{Z}$. Y como, para cualquier $x \in \mathbb{R}$, el valor absoluto o \textit{módulo} del número complejo $e^{2\pi x i} = \cos 2\pi x + i\sin 2\pi x$ es $\sqrt{\cos^{2} 2 \pi x +\sin^{2} 2\pi x} = 1$, tenemos que $Im f = S^{1} = \lbrace z \in \mathbb{C}: |z| = 1\rbrace$ (indicaremos el módulo con $|\cdot |$). Así, por el \textit{Primer Teorema de Isomorfía}: $$(\mathbb{R}/\mathbb{Z},+) \cong (S^{1}, \cdot).$$
\item Sea $G$ un grupo abeliano y $$\begin{array}{rccl}
f\colon &G & \longrightarrow & G\\
&x& \longmapsto &x^{2}
\end{array}
$$ una aplicación, que es homomorfismo ya que $$f(xy) = (xy)^{2} = xyxy = xxyy = x^{2}y^{2} = f(x)f(y).$$
Observar que $$Ker f = \lbrace x \in G : x^{2} = 1\rbrace$$ que estará formado por $1$ y todos los elementos de orden $2$ de $G$, en caso de que existan. Por ejemplo, si $G = \mathbb{R}^{\ast}$, entonces $x^{2} = 1$ equivale a $(x+1)(x-1) = 0$, y así $Ker f = \lbrace +1,-1\rbrace$. A este grupo lo denotaremos $\mathcal{U}_{2}$ y será interesante cuando veamos el \textit{grupo simétrico} y anillos.

Notar que en general $f$ no es inyectiva, sólo lo será si el orden de $G$ es impar.

\emph{Demostración: } Supongamos que $|G| = 2k+1$ impar, sea $x \in Ker f$. Así $x^{2} = 1$ y también $x^{2k+1} = 1$, por ser el orden de $G$ y $2$ coprimo con $2k+1$. Entonces $$x = x1 = x1^{k} = x(x^{2})^{k} = x^{2k+1} = 1$$ y así $f$ es inyectiva.

Recíprocamente, veamos que si $|G| = 2k$ es par, sea o no $G$ abeliano, $f$ no es inyectiva. Para cada $x \in G$ llamaremos $A_{x} = \lbrace x, x^{-1}\rbrace.$ Los $A_{x}$ constituyen una partición de $G$ pues como cada $x \in A_{x}$, la igualdad $$G = \bigcup_{x \in G} A_{x}$$ es obvia, además si $A_{x}\cap A_{y} \neq \emptyset$ entonces $x \in \lbrace y, y^{-1}\rbrace$ ó $x^{-1} \in \lbrace y,y^{-1}\rbrace$.

Para el primer caso, si $x = y$ entonces $x^{-1} = y^{-1}$ y $A_{x} = A_{y}$, y si $x = y^{-1}$ entonces $x^{-1} = y$ y nuevamente $A_{x} = A_{y}$. Análogamente para el segundo caso.

Es claro que $A_{1} = \lbrace 1 \rbrace$, pues $1^{-1} = 1$. Si el resto de los $A_{x}$, supongamos que hay $p$ de ellos, tuviesen dos elementos, entonces $$2k = |G| = card A_{1} + 2p = 2p +1.$$ Y como éste último es impar sería absurdo. Luego ha de existir $1 \neq a \in G$ tal que $card A_{a} = 1$. Esto significaría que $a^{-1} = a$, y así $f(a) = a^{2} = aa^{-1} = 1 = f(1)$. Luego $f$ no es inyectiva.

Esto se puede reformular diciendo que: \textit{«Todo grupo finito de orden par posee algún elemento de orden 2»}. 
\end{enumerate}
\end{example}
$\hfill \blacksquare$

\begin{theorem}[\textbf{\textit{Segundo Teorema de Isomorfía}}]
Sea $N \unlhd G$ y sea $H \leq G$. Entonces $H \cap N \unlhd H$ y $$H/H\cap N \cong NH/N.$$

\end{theorem}
\emph{Demostración: }Consideremos el siguiente homomorfismo de grupos: $$\begin{array}{rccl}
f\colon &G&\longrightarrow &G/N \\
&x& \longmapsto &xN
\end{array}
$$
y sea $g = \left.f \right|_H \colon H \longrightarrow G/N$ la restricción a $H$. Por el resultado anterior tenemos que $g(H) = f(H) = NH/N$. Notar que, como $N \unlhd G$ y $H \leq G$, $NH$ es grupo. El núcleo de $g$ es:
$$Ker g = \lbrace x \in H :xN = N \rbrace = N \cap H.$$ El resultado se sigue de aplicar el \textit{Primer Teorema de Isomorfía}.

$\hfill \square$

\begin{theorem}[\textbf{\textit{Tercer Teorema de Isomorfía}}]
Sea $G$ un grupo. Sean $N,M \unlhd G$ y $N \subseteq M$. Entonces $$G/M \cong (G/N)/(M/N).$$
\end{theorem}
\emph{Demostración: }Consideremos la aplicación suprayectiva $$\begin{array}{rccl}
f \colon &G/N&\longrightarrow &G/M\\
&gN& \longmapsto &gM
\end{array}
$$
Entonces $f$ está bien definida ya que si $gN = hN$ entonces $g^{-1}h \in N \subseteq M$ y así $gM =hM$. Es claro que es homomorfismo y el núcleo es $$Ker f = \lbrace gN \in G/N : gM = M \rbrace = \lbrace gN \in G/N : g \in M \rbrace = M/N.$$
El resultado se sigue de aplicar el \textit{Primer Teorema de Isomorfía}.

$\hfill \square$

También podemos estudiar los subgrupos de un grupo cociente $G/N$:

\begin{theorem}[\textbf{\textit{Teorema de la correspondencia}}]
Sea $N \unlhd G$. La aplicación $K \longrightarrow G/N$ es una biyección entre el conjunto $\lbrace K: N \subseteq K \leq G \rbrace$ y los subgrupos de $G/N$.
\end{theorem}
\emph{Demostración: }Sea $f \colon G \longrightarrow G/N$ el homomorfismo dado por $f(g) = gN$. Supongamos que $K$ es un subgrupo de $G$ que contiene a $N$. Por~\ref{eq:lemIsom}, $K/N = f(K)$ es un subgrupo de $G/N$. Supongamos que $J$ es otro subgrupo de $G$ que contiene a $N$ con $K/N = J/N$. Si $k \in K$, entonces $kN \in K/N = J/N$, por lo que existirá $j \in J$ tal que $kN = jN$. Así, $k \in jN \subseteq J$. Esto prueba que $K \subseteq J$. Análogamente, $J \subseteq K$ y tenemos que $K=J$. Esto prueba que la aplicación $K \longrightarrow K/N$ es inyectiva. Si $X \leq G/N$, entonces $f(f^{-1}(X)) = X$ pues $f$ es suprayectiva. Sea $K = f^{-1}(X)$. Sabemos que $K \leq G$ por~\ref{eq:propHoms}. Está claro que $N \subseteq K$ pues $f(n) = N \subseteq X$ para cada $n \in N$. Ahora, $X=f(K) = K/N$ y ya está.

$\hfill \square$

\begin{proposition}\label{eq:ej32} K es subgrupo normal de $G$ si y sólo si $K/H$ es subgrupo normal de $G/H$.\end{proposition}

\emph{Demostración: }Sea $K \unlhd G$. Veamos que $(K/H)^x \subseteq K/H$ para todo $x \in G/H$ ($x$ será de la forma $x=gH$). Sea $aH \in (K/H)^x$, entonces $aH = x(kH)x^{-1} = (gH)kH(g^{-1})H = gkg^{-1}H$, y como $K$ es normal $gkg^{-1} \in K$ y así $aH \in K/H$.

Recíprocamente, sea $K/H \unlhd G/H$, es decir, $xK/H = K/Hx$ para todo $x \in G/H$ (que será de la forma $x =gH$). Así, $(gH)(kH) = (k'H)(gH)$, para algunos $k,k' \in K$ y $g\in G$, luego $gk = k'g$ y así $gkg^{-1} = k' \in K$, es decir, $K^g \subseteq K$ y $K$ es normal. 

$\hfill \square$

\begin{definition}Un \textbf{automorfismo} $\alpha$ de $G$ es un isomorfismo $\alpha \colon G \longrightarrow G$. Denotaremos por $Aut(G)$ el conjunto de los automorfismos de $G$. Es claro que $Aut(G)$ es grupo con la operación composición de aplicaciones: $$\alpha \circ \beta = \alpha \beta.$$
\end{definition}

Aunque en general no es sencillo calcular el grupo de automorfismos de un grupo $G$, nosotros estudiaremos un caso más simple, para ello tenemos que:

\begin{definition} Dado $G$ un grupo y $x,g \in G$ tenemos que $$x^g=gxg^{-1}.$$ A este $x^g$ lo denominaremos \textbf{conjugado} de $x$ por $g$. Igualmente para conjuntos, que ya lo habíamos definido al principio para presentar el normalizador, si $X \subseteq G$ y $g \in G$ escribiremos $$X^g = \lbrace x^g:x \in X \rbrace.$$ También definimos la \textbf{aplicación conjugación por $g$} como $$\begin{array}{rccl}
\alpha_g \colon &G&\longrightarrow &G \\
&x& \longmapsto &x^g = gxg^{-1}
\end{array}
$$
\end{definition}

Notar que la conjugación la hemos definido para subconjuntos en general.

\begin{proposition}Sea $G$ un grupo y $g \in G$. Entonces:
\begin{enumerate}
\item La aplicación $\alpha_g$ es un automorfismo de $G$. En particular, si $x,y \in G$ entonces $(xy)^g = x^gy^g.$
\item Si $h \in G$, entonces $\alpha_h \alpha_g = \alpha_{hg}$. En particular, si $x \in G$ entonces $(x^g)^h = x^{hg}$.
\end{enumerate}
\end{proposition}
\emph{Demostración: }Veamos:
\begin{enumerate}
\item 
Sean $x,y \in G$, entonces: $$\alpha_g(xy) = (xy)^g = g(xy)g^{-1} = gxg^{-1}gyg^{-1} = x^gy^g = \alpha_g(x) \alpha_g(y).$$ Luego $\alpha_g$ es un homomorfismo, y notar que $\alpha_1$ es la identidad. Además, $\alpha_g \alpha_{g^{-1}} = \alpha_{g^{-1}} \alpha_g = id$, luego $(\alpha_g)^{-1}=\alpha_{g^{-1}}$ y así $\alpha_g$ es biyectiva.
\item Sea $h \in G$, entonces: $$(x^g)^h=h(gxg^{-1})h^{-1} = (hg)x(g^{-1}h^{-1}) = (hg)x(hg)^{-1} = x^{hg}.$$ Luego, $\alpha_h\alpha_g(x) =\alpha_h(\alpha_g(x)) = (x^g)^h = x^{hg} = \alpha_{hg}(x).$ Así, $\alpha_h\alpha_g = \alpha_{hg}$. 
\end{enumerate}

$\hfill \square$

Notar que cuando hacemos $(x^g)^h$ primero actúa $g$ y luego $h$, por eso $(x^g)^h = x^{hg}.$

Resulta que estos automorfismos especiales, las conjugaciones, forman un grupo y tienen características interesantes.

\begin{definition}Definimos $$Int (G) = \lbrace \alpha_g :g \in G \rbrace$$ como el conjunto de los \textbf{automorfismos internos} de $G$.
\end{definition}

Para el siguiente resultado conviene repasar el concepto de centro de un grupo, que vimos en~\ref{eq:centro}.

\begin{proposition}Si $G$ es un grupo, entonces $Int(G) \unlhd Aut(G)$. Además, $$Int(G) \cong G/Z(G).$$
\end{proposition}
\emph{Demostración: }Sabemos que $\alpha_g\alpha_h = \alpha_{gh}$ y que $(\alpha_g)^{-1} = \alpha_{g^{-1}}$ por el resultado anterior. Así, tenemos que $Int(G) \leq Aut(G)$. Si $f \in Aut(G)$, veamos que $(\alpha_g)^f=\alpha_{f(g)}$: (recordar que $f$ es un automorfismo y $g \in G$) \begin{center}$((\alpha_g)^f)(x) = (f\alpha_g f^{-1})(x) = f(\alpha_g(f^{-1}(x))) = f(g(f^{-1}(x))g^{-1}) = f(g)xf(g^{-1}) =f(g)x(f(g))^{-1} =\alpha_{f(g)}(x) = x^{f(g)}.$\end{center}
Esto demuestra que $Int(G) \unlhd Aut(G)$. 

Ahora, si consideramos la aplicación $G \longrightarrow Int(G)$ dada por $g \longmapsto \alpha_g$, es evidentemente suprayectiva y homomorfismo. El núcleo de esta aplicación será el conjunto $\lbrace g \in G : \alpha_g = id \rbrace = \lbrace g \in G: gxg^{-1}=x\hspace{0.1cm} \forall x \in G \rbrace = \lbrace g \in G : gx = xg\hspace{0.1cm} \forall x \in G \rbrace$, y este conjunto es el centro $Z(G)$. El resultado se sigue de aplicar el \textit{Primer Teorema de Isomorfía}. 

$\hfill \square$

Finalmente, calculemos el grupo de automorfismos de un grupo cíclico. Será muy útil saber más adelante que este grupo es abeliano, veámoslo: si $G = \langle x \rangle $ y $\alpha, \beta \in Aut(G)$, entonces $\alpha (x) = x^d$ y $\beta(x) = x^e$ para algunos enteros $d,e$. Ahora, $\alpha\beta(x)=x^{de} = x^{ed}=\beta \alpha (x)$ y así $\alpha \beta = \beta \alpha$ (esto es así porque todos los elementos de $G$ son potencias de $x$). Ahora examinaremos exactamente cómo es este grupo de automorfismos: 

Si $n \in \mathbb{Z}$, consideramos el grupo abeliano $\mathbb{Z}/n\mathbb{Z}$. En $\mathbb{Z}/n\mathbb{Z}$ también se pueden multiplicar elementos: si $x+n\mathbb{Z}=x'+n\mathbb{Z}$, $y +n\mathbb{Z}=y'+n\mathbb{Z}$ tenemos que $$xy-x'y' = xy-xy'+xy'-x'y'= x(y-y')+y'(x-x') \in n\mathbb{Z},$$ luego es divisible por $n$. Luego $xy + n\mathbb{Z} = x'y' +n\mathbb{Z}$ y la multiplicación $$(x+n\mathbb{Z})(y+n\mathbb{Z})=xy+n\mathbb{Z},$$ está bien definida. Esta multiplicación es asociativa, por serlo la de $\mathbb{Z}$, y tiene elemento neutro $1 + n\mathbb{Z}$. Llamaremos \textbf{$\mathcal{U}_n$} al conjunto de los elementos de $\mathbb{Z}/n\mathbb{Z}$ para los que existe un inverso respecto a la multiplicación.

\begin{proposition}Sea $n \geq 1$ y sea $0 \neq u \in \mathbb{Z}$, entonces $u + n\mathbb{Z}$ es invertible en $\mathbb{Z}/n\mathbb{Z}$ para la multiplicación si y sólo si $mcd(u,n)=1.$ En particular $|\mathcal{U}_n| = \varphi(n)$.
\end{proposition}
\emph{Demostración: }Se tiene que $u + n\mathbb{Z}$ es invertible en $\mathbb{Z}/n\mathbb{Z}$ si y sólo si existe $v \in \mathbb{Z}$ tal que $(u +n\mathbb{Z})(v+n\mathbb{Z})=1+n\mathbb{Z}$. Por lo que $u +n\mathbb{Z}$ es invertible si y sólo si existe $v \in \mathbb{Z}$ tal que $uv-1$ es divisible por $n$. Si esto ocurre, entonces $uv-1 = kn$ para cierto $k$. Ahora, si $d$ divide a $u$ y a $n$, entonces $d$ divide a $uv-kn = 1$, por lo que $mcd(u,n)=1$. Recíprocamente, supongamos que $mcd(u,n)=1$. Por la identidad de Bézout sabemos que existen $a,b \in \mathbb{Z}$ tales que $au+bn = 1$. Luego, $au-1$ es divisible por $n$ y así $u+n\mathbb{Z}$ tiene inverso.

$\hfill \square$

Así, es claro que $$\mathcal{U}_n = \lbrace u \in \mathbb{Z}/n\mathbb{Z}:mcd(u,n)=1 \rbrace.$$

\begin{proposition}Si $C_n$ es un grupo cíclico de orden $n$, entonces $Aut(C_n) \cong \mathcal{U}_n$. En particular, $Aut(C_n)$ es abeliano.
\end{proposition}
\emph{Demostración: }Sea $C_n = \langle x \rangle$, con $o(x)=n$. Si $n = 1$ el resultado está claro. Sea $n \geq 2$. Sea $d$ un entero cualquiera y definimos $$\begin{array}{rccl}
f_d \colon &C_n&\longrightarrow &C_n \\
&x^s& \longmapsto &x^{ds}
\end{array}
$$
con $s \in \mathbb{Z}$. Esta aplicación está bien definida, ya que si $x^s = x^t$, entonces $x^{ds}= (x^s)^d=(x^t)^d= x^{dt}$. Observamos que $$f_d(x^sx^r)=f_d(x^{s+r})=x^{d(s+r)} = x^{ds}x^{dr} = f_d(x^s)f_d(x^r),$$ con lo que $f_d$ es homomomorfismo de grupos. Recíprocamente, si $f \colon C_n \longrightarrow C_n$ es un homomorfismo y escribimos $f(x)=x^d$, entonces para cada entero $s$ tenemos que $f(x^s) = x^{ds}$ por~\ref{eq:propHoms} y deducimos que $f=f_d$. Notar también que claramente la aplicación es inyectiva y sobreyectiva, luego un isomorfismo y, en concreto, automorfismo.

Notamos también que $f_d \circ f_e = f_{ed} = f_e \circ f_d$ y que $f_e = f_d$ si y sólo si $x^d = x^e$ si y sólo si $x^{d-e}=1$ si y sólo si $n$ divide a $d-e$ si y sólo si $e+n\mathbb{Z} = d+n\mathbb{Z}.$

Ahora, $f_d( \langle x \rangle ) = \langle x^d \rangle$ por~\ref{eq:propHoms}. Si $d = 0$, entonces la aplicación $f_d$ no es biyectiva (pues $n\geq 2$). Si $d \neq 0$, tenemos que $f_d$ es biyectiva si y sólo si $f_d$ es suprayectiva si y sólo si $\langle x^d \rangle = \langle x \rangle$ si y sólo si $mcd(d,n)=1$, por~\ref{eq:prelgrupcic}.

Queda probado así que la aplicación$$\begin{array}{rccl}
\phi \colon &\mathcal{U}_n&\longrightarrow &Aut(C_n) \\
&d+n\mathbb{Z}& \longmapsto &f_d
\end{array}
$$ está bien definida y es un isomorfismo de grupos.

$\hfill \square$

Gracias a estos dos últimos resultados concluimos que $|Aut(C_p)| = p-1$. De hecho, este grupo es cíclico. 

Ahora volveremos brevemente a los grupos cíclicos para presentar un resultado que es ciertamente interesante e importante, y que necesitaba de los teoremas de isomorfía para verlo:

Ya hemos visto a lo largo de las páginas anteriores que el conjunto de los enteros y los enteros módulo $n$, $\mathbb{Z}$ y $\mathbb{Z}_{n}$, son grupos, y en concreto grupos cíclicos. Que se haya hecho un inciso especial en estos dos grupos no es casualidad, vamos a ver a continuación que son, por así decirlo, los «únicos» grupos cíclicos que existen. Es decir, que dado un grupo cíclico, o es equivalente a $\mathbb{Z}$ o a $\mathbb{Z}_{n}$, y ya hemos visto en este capítulo que cuando hablamos de «igualdad» o «equivalencia» en \textit{Teoría de Grupos} en realidad estamos hablando de isomorfismos. Básicamente todo grupo cíclico es isomorfo a $\mathbb{Z}$ o a $\mathbb{Z}_{n}$.

\begin{theorem}
Sea $G$ un grupo cíclico. Se verifica:
\begin{enumerate}
\item Si $G$ es infinito, entonces es isomorfo a $(\mathbb{Z},+)$.
\item Si $G$ es finito de orden $n$, entonces es isomorfo a $(\mathbb{Z}_{n},+)$.
\end{enumerate}
\end{theorem}
\emph{Demostración: }(Notar que hemos especificado que la operación en ambos grupos, $\mathbb{Z}$ y $\mathbb{Z}_{n}$, sea la adición, puesto que su elemento neutro será el $0$ y no el $1$)
Sea $G = \langle x \rangle$ y consideremos el homomorfismo $$\begin{array}{rccl}
f\colon &\mathbb{Z}& \longrightarrow &G\\
&k& \longmapsto &x^{k},
\end{array}
$$ que es claramente sobreyectivo ($Im f = G$). Veamos los dos casos: 

\begin{enumerate}
\item Basta comprobar que $f$ es inyectiva. Para ello supongamos por reducción al absurdo que $Ker f \neq \lbrace 0\rbrace$. Entonces, por ser $Ker f$ un subgrupo de $\mathbb{Z}$ no trivial, será de la forma $n\mathbb{Z}$ para algún $n \in \mathbb{N}$ no nulo. Ahora, el \textit{Primer Teorema de Isomorfía} nos asegura que $\mathbb{Z}_{n} = \mathbb{Z}/n\mathbb{Z} \cong G$, así $G$ tendría $n$ elementos, lo cual contradice la hipótesis de que sea infinito.
\item Si $G$ es finito de orden $n$, no puede ser $Ker f = \lbrace 0 \rbrace$, puesto que en ese caso $f$ sería  inyectiva y entonces $G$ infinito. Así pues $Ker f = m\mathbb{Z}$ para algún $m \in \mathbb{N}$ no nulo, usando de nuevo el \textit{Primer Teorema de Isomorfía} $\mathbb{Z}_{m} = \mathbb{Z}/m\mathbb{Z} \cong G$. Como $\mathbb{Z}_{m}$ y $G$ han de tener el mismo orden, $m=n$.
\end{enumerate}

$\hfill \square$

Como consecuencia interesante tenemos:

\begin{corolario}
Supongamos que $G = \langle a \rangle$ es un grupo cíclico. Entonces:
\begin{enumerate}
\item Si $o(a) = \infty$, entonces $$\begin{array}{rccl}
f\colon &\mathbb{Z}& \longrightarrow &G\\
&k& \longmapsto &a^{k},
\end{array}
$$ es un isomorfismo.
\item Si $o(a)= n$, entonces $$\begin{array}{rccl}
f\colon &\mathbb{Z}_{n}& \longrightarrow &G\\
&\left[ k \right]& \longmapsto &a^{k},
\end{array}
$$ es un isomorfismo.
\end{enumerate} 
\end{corolario}

Finalmente, veamos el producto directo y semidirecto:

\begin{proposition}Sean $G_{1}$ y $G_{2}$ grupos. Dado el producto cartesiano $G_{1} \times G_{2}$, entonces podemos convertirlo en un grupo con la siguiente operación: $$\cdot \colon (g_{1},g_{2})(g'_{1},g'_{2})=(g_{1}g'_{1},g_{2},g'_{2}).$$
Además, dado un grupo $G$ y $N_{1},N_{2} \unlhd G$ subgrupos normales tales que $G=N_{1}N_{2}$ y $N_{1}\cap N_{2}=\lbrace 1_{G} \rbrace$. Entonces $$N_{1} \times N_{2} \cong G.$$
\end{proposition}
\emph{Demostración: }Para ver que es grupo con $\cdot$ basta con una simple comprobación. Para la segunda parte definimos la siguiente aplicación: 
$$\begin{array}{rccl}
f\colon &N_{1}\times N_{2} & \longrightarrow & G\\
&(n_{1},n_{2})& \longmapsto &n_{1}n_{2}
\end{array}
$$ 

Para ver que $f$ es homomorfismo: $$f((n_{1},n_{2})(n'_{1},n'_{2}))=f((n_{1}n'_{1},n_{2}n'_{2}))=n_{1}n'_{1}n_{2}n'_{2}.$$
$$f((n_{1},n_{2}))f((n'_{1},n'_{2}))=n_{1}n_{2}n'_{1}n'_{2}.$$
Para comprobar que son iguales bastará probar que $xy=yx$ para todo $x\in N_{1}$, $y\in N_{2}$. Sea $x^{-1}y^{-1}xy=x^{-1}(y^{-1}xy)\in N_{1}$, como también $x^{-1}y^{-1}xy=(x^{-1}y^{-1}x)y \in N_{2}$ y por hipótesis tenemos que $N_{1}\cap N_{2} = \lbrace 1_{G}\rbrace$, entonces será que $x^{-1}y^{-1}xy=1$, luego $xy=yx$. 

Ahora, como $G=N_{1}N_{2}$, $f$ es suprayectiva. $Ker f = \lbrace (n_{1},n_{2}) \in N_{1}\times N_{2}:n_{1}n_{2}=1 \rbrace$. Si $n_{1}n_{2}=1$, entonces $n_{2}=n_{1}^{-1}\in N_{1}\cap N_{2}=\lbrace 1_{G}\rbrace$. Así, $n_{1}=n_{2}=1_{G}$ y $Ker f=\lbrace 1_{G} \rbrace$ y $f$ es inyectiva. El resultado se sigue del \textit{Primer Teorema de Isomorfía}.

$\hfill \square$

\begin{definition}El producto cartesiano en el que hemos descompuesto $G$ antes, $N_{1}\times N_{2}$ con $N_{1}, N_{2}\unlhd G$ tales que con $G=N_{1}N_{2}$ y $N_{1}\cap N_{2}= \lbrace 1_{G} \rbrace$, es un \textbf{producto directo}. 
\end{definition}

\begin{example}Un ejemplo de producto directo bastante conocido es el \textbf{grupo de Klein}, $V_4$. Formalmente, es el producto directo $\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}$, es decir, el producto directo de dos grupos cíclicos de orden $2$. Se llama así en honor al matemático alemán Felix Klein y se denota por la letra $V$, del alemán Vierergruppe, que significa algo así como "grupo de cuatro". 

Evidentemente este grupo tiene $4$ elementos, y veremos que cada uno de ellos es inverso de sí mismo, es decir, cada elemento tiene orden $2$. Como ya sabemos $$\mathbb{Z}/2\mathbb{Z} = \lbrace 0 + 2\mathbb{Z}, 1 + \mathbb{Z} \rbrace.$$ Y esto se podría interpretar como, por un lado $0+2\mathbb{Z}$ la clase de todos aquellos enteros que divididos entre $2$ dan $0$, es decir, los enteros pares, y $1+2\mathbb{Z}$ como la clase formada por todos aquellos cuyo resto de dividirlos entre $2$ sea $1$, es decir, los enteros impares. Como también sabemos, éste es un grupo cíclico de orden $2$, por lo que el orden de sus dos elementos es $2$ y así otra forma de interpretar a este grupo es verlo como aquel formado por $1$ y $-1$, y así $$\mathbb{Z}/2\mathbb{Z} = \lbrace 1, -1 \rbrace.$$

Así, $$V_4 = \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z},$$ es un grupo de $4$ elementos que podríamos representarlos como $(1,1), (1,-1), (-1,1)$ y $(-1,-1)$. Su tabla:
\begin{center}
\begin{tabular}{c|c c c c c}
&$(1,1)$&$(1,-1)$&$(-1,1)$&$(-1,-1)$&\\ \hline
$(1,1)$&$(1,1) $&$(1,-1)$&$(-1,1)$&$(-1,-1)$& \\ 
$(1,-1)$&$(1,-1)$&$(1,1)$&$(-1,-1)$&$(-1,1)$& \\ 
$(-1,1)$&$(-1,1)$&$(-1,-1)$&$(1,1)$&$(1,-1)$& \\ 
$(-1,-1)$&$(-1,-1)$&$(-1,1)$&$(1,-1)$&$(1,1)$& \\												\end{tabular}
\end{center}
Donde vemos que todos sus elementos tienen orden $2$.
\end{example}
$\hfill \blacksquare$

\begin{proposition}Sean $N$ y $H$ grupos. Sea $\varphi \colon H \longrightarrow Aut(N)$ un homomorfismo entre $H$ y el grupo de los automorfismos de $N$. En el producto cartesiano $N \times H$ podemos definir una estructura de grupo, conocida como \textbf{producto semidirecto de $H$ por $N$ vía $\varphi$} y denotada por $N\times_{\varphi} H$, de la siguiente manera:$$(n_{1},h_{1})(n_{2},h_{2}) = (n_{1}\varphi(h_{1})(n_{2}),h_{1}h_{2}),$$ donde $\varphi(h_{1})(n_{2}) = n_{2}^{h_{1}}$ normalmente, es decir, que el automorfismo en cuestión será la conjugación por un elemento de $H$.

Ahora, sea $G$ un grupo, $N \unlhd G$ y $H \leq G$. Supongamos que $G = NH$ y $N \cap H = \lbrace 1_{G}\rbrace$. Dado un $$\begin{array}{rccl}
\varphi\colon &H & \longrightarrow & Aut(N)\\
&h& \longmapsto &n \longmapsto n^{h} = hnh^{-1}.
\end{array}
$$  Entonces $$N \times_{\varphi} H \cong G.$$
\end{proposition}
\emph{Demostración: }Lo primero de todo, veamos que $\varphi$ está bien definida: como $N \unlhd G$, si $n \in N$ y $h \in H$, $hnh^{-1} \in N$. Ya sabemos que la conjugación es un automorfismo. Además $\varphi$ es homorfismo: $$\varphi(h_{1}h_{2})(n)=h_{1}h_{2}nh_{2}^{-1}h_{1}^{-1}=(\varphi(h_{1}) \circ \varphi(h_{2}))(n).$$

Ahora veamos que es grupo. Cumple con la propiedad asociativa: \begin{center}$(n_{1},h_{1})((n_{2},h_{2})(n_{3},h_{3}))=(n_{1},h_{1})(n_{2}\varphi(h_{2})(n_{3}),h_{2}h_{3})=(n_{1}\varphi(h_{1})(n_{2}\varphi(h_{2})(n_{3})),h_{1}h_{2}h_{3})=(n_{1}\varphi(h_{1})(n_{2})\varphi(h_{1}h_{2})(n_{3}),h_{1}h_{2}h_{3}).$

$((n_{1},h_{1})(n_{2},h_{2}))(n_{3},h_{3})=(n_{1}\varphi(h_{1})(n_{2}),h_{1}h_{2})(n_{3},h_{3})=(n_{1}\varphi(h_{1})(n_{2})\varphi(h_{1}h_{2})(n_{3}),h_{1}h_{2}h_{3}).$
\end{center}
Tiene elemento neutro: 
$$(n,h)(1,1)=(n\varphi(h)(1),h)=(n,h) = (1\varphi(1)(n),h)=(1,1)(n,h).$$

Cada elemento $(n,h)$ tiene un inverso $(n,h)^{-1}=(\varphi(h^{-1})(n^{-1}),h^{-1})$.

\begin{center}$(n,h)(\varphi(h^{-1})(n^{-1}),h^{-1})=(n\varphi(h)(\varphi(h^{-1})(n^{-1})),1)=(n\varphi(hh^{-1})(n^{-1}),1)=(nn^{-1},1)=(1,1).$

$(\varphi(h^{-1})(n^{-1}),h^{-1})(n,h)=(\varphi(h^{-1})(n^{-1})\varphi(h^{-1})(n),1)=(h^{-1}n^{-1}hh^{-1}nh,1)=(h^{-1}h,1)=(1,1).$\end{center}

Ahora, veamos la segunda parte. Sea $G=NH$, con $N \unlhd G$, $H\leq G$ y $N \cap H = \lbrace 1_{G} \rbrace$, y sea 
$$\begin{array}{rccl}
\varphi\colon &H & \longrightarrow & Aut(N)\\
&h& \longmapsto &n \longmapsto n^{h} = hnh^{-1}.
\end{array}
$$

Ya sabemos que $\varphi$ está bien definida y que es un homomorfismo.

Definimos ahora $$\begin{array}{rccl}
f\colon &N \times _{\varphi} H & \longrightarrow & G\\
&(n,h)& \longmapsto &nh.
\end{array}
$$
y veamos que $f$ es homomorfismo: \begin{center}$f((n_{1},h_{1})(n_{2},h_{2}))=f((n_{1}\varphi(h_{1})(n_{2}),h_{1}h_{2})=n_{1}\varphi(h_{1})(n_{2})h_{1}h_{2}=n_{1}(h_{1}n_2h_{1}^{-1})h_{1}h_{2}=n_{1}h_{1}n_{2}h_{2}=f((n_{1},h_{1}))f((n_{2},h_{2})).$\end{center}

Como $G=NH$ entonces $f$ es claramente suprayectiva. Ahora, $Ker f= \lbrace (n,h) \in N\times_{\varphi} H :nh=1 \rbrace$. Y si $nh=1$ entonces $n=h^{-1}\in N \cap H$, pero como $N \cap H = \lbrace 1_{G} \rbrace$ tenemos que $n=h=1_{G}$ y así $f$ es inyectiva y por tanto isomorfismo.

$\hfill \square$

Y con esto finalizamos el capítulo de homomorfismos de grupos habiendo presentado las bases y los principales resultados. A continuación veremos una de las herramientas más poderosas que nos ofrecen los grupos y con la que podremos demostrar importantes resultados.

\subsection{Acciones de grupos}

Los grupos se manifiestan a través de sus acciones sobre espacios vectoriales, sobre otros grupos o, en general, sobre conjuntos. En esta sección veremos las acciones sobre conjuntos, o equivalentemente, los homomorfismos de $G$ sobre grupos simétricos.

\begin{definition}Sea $\Omega$ un conjunto no vacío y sea $G$ un grupo. Diremos que $G$ \textbf{actúa} sobre $\Omega$ si $\forall \alpha \in \Omega$, $\forall g \in G$ tenemos definido un único elemento $g \cdot \alpha$ de tal forma que:
\begin{enumerate}
\item $h \cdot (g \cdot \alpha)=(hg) \cdot \alpha$ $\forall \alpha \in \Omega$, $g,h \in G$.
\item $1 \cdot \alpha =\alpha$ $\forall \alpha \in \Omega$.
\end{enumerate}

En este caso, diremos que $\cdot$ define una \textbf{acción} de $G$ sobre $\Omega$.
\end{definition}

\begin{example}\label{eq:ejcorazon}Los siguientes ejemplos son acciones de grupos sobre conjuntos:
\begin{enumerate}
\item Sea $G$ un grupo y $H \leq G$. Sea $\Omega = \lbrace xH : x \in G \rbrace$. Si $g \in G$ y $\alpha \in \Omega$, definimos $g \cdot \alpha = g\alpha$, es decir: $$g \cdot(xH) = gxH, \quad \forall x,g \in G.$$ Esta es la acción de $G$ sobre el conjunto de las coclases a izquierda de $H$ en $G$.
\item Sea $G$ un grupo y $\Omega = G$. Dado un $\alpha \in \Omega, g \in G$ definimos $$g \cdot \alpha= \alpha^g=g\alpha g^{-1}.$$ Esta es la \textbf{acción de $G$ sobre $G$ por conjugación} y ya la conocemos de haberla estudiado en los capítulos anteriores.
\item Sea $\Omega = \lbrace H : H \leq G \rbrace$ el conjunto de los subgrupos de $G$. Si $H \in \Omega$, $g \in G$ definimos $$ g \cdot H = H ^g.$$ Esta es la acción de $G$ sobre los subgrupos de $G$ por conjugación.
\item Sea $\Omega$ un conjunto no vacío y sea $G \leq S_{\Omega}$. Si $g \in G$, $\alpha \in \Omega$ definimos $$g \cdot \alpha = g(\alpha).$$ Esta es la \textbf{acción natural de $G$ sobre $\Omega$}. La llamamos así porque, como veremos más adelante, siempre va a existir una para cada grupo $G$ sobre un conjunto cualquiera $\Omega$ al ser todo grupo finito $G$ isomorfo a un subgrupo del grupo de permutaciones.
\end{enumerate}
\end{example}
$\hfill \blacksquare$

Como se verá ahora, una acción de un grupo $G$ sobre un conjunto $\Omega$ no es más que un homomorfismo de grupos $G \longrightarrow S_{\Omega}$.

\begin{theorem} \label{eq:princAcci}
Sea $G$ un grupo y $\Omega$ un conjunto no vacío. Entonces: 
\begin{enumerate}
\item Supongamos que $G$ actúa sobre $\Omega$. Para cada $g \in G$ consideremos la aplicación $$\begin{array}{rccl}
\rho_g \colon &\Omega&\longrightarrow &\Omega \\
&\alpha& \longmapsto &g \cdot \alpha
\end{array}
$$
Tenemos que $\rho_g$ es biyectiva y además la aplicación 
$$\begin{array}{rccl}
\rho \colon &G&\longrightarrow &S_{\Omega} \\
&g& \longmapsto &\rho_g
\end{array}
$$ es un homomorfismo de grupos.
\item Sea $\rho \colon G \longrightarrow S_{\Omega}$ homomorfismo de grupos. Para cada $g \in G$ y $\alpha \in \Omega$ definimos $g \cdot \alpha = \rho(g)(\alpha)$. Entonces $\cdot$ define una acción de $G$ sobre $\Omega$.
\end{enumerate}
\end{theorem}
\emph{Demostración: }
\begin{enumerate}
\item Sea $g \in G$, veamos que $\rho_g$ es inyectiva. Si $\rho_g(\alpha)=\rho_g(\beta)$, con $\alpha, \beta \in \Omega$ entonces $g \cdot \alpha = g \cdot \beta$, por lo que $g^{-1} \cdot (g\cdot \alpha) = g^{-1}  \cdot (g \cdot \beta$) y aplicando las condiciones de las acciones tenemos que $ (g^{-1}g) \cdot \alpha = (g^{-1}g) \cdot \beta \Rightarrow 1 \cdot \alpha = 1 \cdot \beta \Rightarrow \alpha = \beta$. Para la sobreyectividad consideremos $\beta \in \Omega$, entonces $ g^{-1} \cdot \beta \in \Omega$ y $\rho_g(g^{-1}\cdot \beta)= g \cdot (g^{-1} \cdot \beta )= \beta$. Luego $\rho_g$ es biyectiva.
\item Como $\rho (1)$ es la identidad tenemos que $1 \cdot \alpha = \alpha$, $\forall \alpha \in \Omega$. Ahora, si $g,h \in G$ y $\alpha \in \Omega$ tenemos que $$(\rho(g)\rho(h))(\alpha) = \rho(g)(\rho(h)(\alpha)) = g \cdot(h \cdot \alpha ) = (gh) \cdot \alpha = \rho_{gh}(\alpha) = \rho(gh)(\alpha).$$
\end{enumerate}

$\hfill \square$

\begin{definition}Si un grupo $G$ actúa sobre un conjunto $\Omega$, entonces podemos definir el siguiente conjunto. $$K = \lbrace g \in G : g\cdot \alpha = \alpha \hspace{0.1cm} \forall \alpha \in \Omega \rbrace,$$ como el \textbf{núcleo} de la acción. Notar que $K = Ker(\rho) \unlhd G$. Diremos que la acción de $G$ sobre $\Omega$ es \textbf{fiel} si $K = \lbrace 1 \rbrace.$
\end{definition}

De hecho, el núcleo de la acción (que veremos más adelante en profundidad) de $G$ sobre $G$ por conjugación es $$K = \lbrace g \in G : x^g =x \hspace{0.1cm} \forall x \in G \rbrace = \lbrace g \in G:gx=xg \hspace{0.1cm} \forall x \in G \rbrace = Z(G).$$

Veamos ahora cuál es el núcleo de la acción del primer ejemplo:

\begin{proposition}Sea $H \leq G$ y sea $K = \cap_{x \in G} H^x$. Entonces $K$ es el núcleo de la acción de $G$ sobre $\Omega = \lbrace xH :x \in G \rbrace$ por multiplicación a izquierda.
\end{proposition}
\emph{Demostración: }Sea $g \in G$, entonces $g \in Ker (\rho)$ si y sólo si $gxH = xH$ $\forall x \in G$ si y sólo si $x^{-1}gx H = H$  $\forall x \in G$ si y sólo si $x^{-1}gx \in H$ $\forall x \in G$ si y sólo si $g \in H^x$ $\forall x \in G$ si y sólo si $g \in K$.

$\hfill \square$

Notar que el núcleo de la acción que acabamos de describir, la de $G$ sobre el conjunto de las clases izquierda módulo $H$ (un subgrupo suyo), es lo que habíamos definido en el primer capítulo como el corazón de $H$, $K(H)$.

Tal y como habíamos dicho cuando presentamos el ejemplo de la acción natural veamos que todo grupo finito es subgrupo de un grupo simétrico.

\begin{theorem}[\textbf{\textit{Teorema de Cayley}}]
Sea $H \leq G$, con $[G:H] = n$. Entonces, existe $K \unlhd G$ contenido en $H$ tal que $G/K$ es isomorfo a un subgrupo de $S_n$. En particular, si $G$ tiene orden $n$, entonces $G$ es isomorfo a un subgrupo de $S_n$.
\end{theorem}
\emph{Demostración: }Sea $\Omega$ el conjunto de las clases a izquierda de $H$ en $G$. Luego, $|\Omega | = n$. Sea $K \unlhd G$ el núcleo de la acción de $G$ sobre $\Omega$ Por el resultado anterior tenemos que $K \subseteq H$. Por la primera parte de~\ref{eq:princAcci} existe un homomorfismo de grupos $G \longrightarrow S_{\Omega}$ de núcleo $K$. Por el \textit{Primer Teorema de Isomorfía}, tenemos que $G/K$ es isomorfo a un subgrupo de $S_{\Omega} = S_n$. Para lo segundo tomar simplemente $H = \lbrace 1 \rbrace$.

$\hfill \square$

De este resultado podemos sacar algo de información para los grupos finitos simples:

\begin{corolario}Sea $G$ un grupo finito simple y supongamos que $H \leq G$ es un subgrupo de índice $n > 1$. Entonces $G$ es isomorfo a un subgrupo de $S_n$. En particular, $|G|$ divide a $n!$.
\end{corolario}
\emph{Demostración: }Teniendo en cuenta lo que hemos visto en el resultado anterior tenemos que $K$ es un subgrupo normal de $G$ contenido en $H\leq G$, por lo que $K = 1$. Así, $G$ es isomorfo a un subgrupo de $S_n$ por el resultado anterior. Para lo segundo basta aplicar el \textit{Teorema de Lagrange}.

$\hfill \square$

Ahora veremos que una acción de $G$ puede definir una relación de equivalencia en $\Omega$. En efecto, si $\alpha, \beta \in \Omega$ escribiremos $\alpha \sim \beta $ si existe $g \in G$ tal que $g \cdot \alpha = \beta$. Es decir, $\alpha$ y $\beta$ van a estar relacionados si existe un elemento de $G$ que actuando sobre $\alpha$ dé como resultado $\beta$. Esta relación va a dar mucho de que hablar, veamos que es de equivalencia:

$$g^{-1} \cdot \beta = g^{-1} \cdot (g \cdot \alpha ) = (g^{-1}g) \cdot \alpha = \alpha, $$ luego si $\alpha \sim \beta$ entonces $\beta \sim \alpha$ y tenemos que esta relación es simétrica. Además es claro que $1 \cdot \alpha = \alpha$, luego $\alpha \sim \alpha$ y esta relación es reflexiva. Finalmente, si $g \cdot \alpha = \beta$ ($\alpha \sim \beta$) y $h \cdot \beta = \gamma$ ($\beta \sim \gamma$), con $g, h \in G$, entonces $$\gamma = h \cdot (g \cdot \alpha) = (hg) \cdot \alpha,$$ y como $hg \in G$ por ser $G$ grupo entonces $\alpha \sim \gamma$ y esta relación es transitiva.

\begin{definition}Dado un grupo $G$ actuando sobre un conjunto $\Omega$, $\alpha \in \Omega$ y considerando la relación de equivalencia $\sim$ que acabamos de ver, entonces la clase de equivalencia de $\alpha$ es $$O_{\alpha} = \lbrace g\cdot \alpha : g \in G \rbrace.$$ A este conjunto lo llamamos \textbf{órbita} de $\alpha$ por $G$ ó \textbf{$G$-órbita} de $\alpha$. Notar que su \textbf{longitud} es $|O_{\alpha}|$.
\end{definition}

Notar que al tratarse las órbitas de clases de equivalencia para la relación de equivalencia $\sim$ entre elementos de $\Omega$ antes vista, entonces van a formar una partición de $\Omega.$ Es decir, que su unión disjunta forman la totalidad de $\Omega$. Así, si $R$ es un conjunto de representantes de estas clases de equivalencia (órbitas de la acción), tenemos que $$\Omega = \bigsqcup_{x\in R} O_x.$$ Como la unión es disjunta y $\Omega$ finito tenemos que $$|\Omega | = \sum_{x\in R} |O_x|.$$ A estas dos fórmulas equivalentes se las conoce como \textbf{\textit{fórmula de las órbitas}}. (Se ha empleado $|\cdot|$ para hablar de cardinal de un conjunto, lo cuál podría considerarse abuso de notación).

\begin{definition}Dado un grupo $G$ actuando sobre un conjunto $\Omega$, si $\alpha \in \Omega$ entonces definimos el \textbf{estabilizador} de $\alpha$ en $G$ como $$G_\alpha = \lbrace g \in G : g\cdot \alpha = \alpha \rbrace.$$
\end{definition}

Qué es el \textit{estabilizador} con respecto a $G$ y una propiedad fundamental del mismo nos lo dice el siguiente resultado:

\begin{proposition}\label{eq:coest}
Sea $G \longrightarrow S_\Omega$ una acción de un grupo $G$ sobre un conjunto $\Omega$, y $\alpha \in \Omega$. Entonces:

\begin{enumerate}
\item $G_{\alpha}$ es un subgrupo de $G$.
\item Si $g \in G$, entonces $(G_{\alpha})^{g} = gG_{\alpha}g^{-1} = G_{g \cdot \alpha}$. Es decir, \textbf{el conjugado de un estabilizador es un estabilizador}.
\end{enumerate}
\end{proposition}
\emph{Demostración: }Veamos:
\begin{enumerate}
\item Primero de todo, $1_{G} \in G_{\alpha}$ por la segunda condición a cumplir de las acciones de grupos, así que $G_{\alpha}$ es no vacío. Ahora, sean $g,h \in G_{\alpha}$. Está claro que $g \cdot \alpha = h \cdot \alpha = \alpha$, además $$h^{-1} \cdot \alpha = h^{-1}\cdot(h \cdot \alpha) = (h^{-1}h)\cdot \alpha = 1_{G} \alpha = \alpha.$$ Por lo que $(gh^{-1})\cdot \alpha= g\cdot(h^{-1}\cdot \alpha) = g\cdot \alpha= \alpha,$ luego $gh^{-1} \in G_{\alpha}.$
\item Sea $h \in G_{\alpha}$. Como  $$(ghg^{-1})\cdot(g\cdot \alpha) = g\cdot(h1_{G}\cdot \alpha)= g\cdot(h\cdot \alpha) = g\cdot \alpha,$$ tenemos que $ghg^{-1} \in G_{g\cdot \alpha}$, así que $(G_{\alpha})^{g} \subseteq G_{g\cdot \alpha}$.

Recíprocamente, si $h \in G_{g \cdot \alpha}$, entonces $h\cdot(g \cdot \alpha) = g \cdot \alpha$, y así $(g^{-1}hg)\cdot \alpha = \alpha$, y $(g^{-1}hg) \in G_{\alpha}$, luego $h \in (G_{\alpha})^{g}.$
\end{enumerate}

$\hfill \square$

De aquí es importante quedarse con que \textbf{\textit{si dos elementos de un conjunto cuaquiera $\Omega$ están en la misma órbita entonces sus estabilizadores son conjugados.}}

\begin{theorem}[\textbf{\textit{Teorema de la órbita-estabilizadora}}] \label{eq:torest}
Sea $G$ un grupo que actúa sobre un conjunto $\Omega$ y sea $\alpha \in \Omega$. Entonces $G_\alpha \leq G$ y $$|O_\alpha| = [G:G_\alpha].$$
\end{theorem}
\emph{Demostración: }Lo primero ya lo sabemos del resultado anterior.

Para lo segundo, busquemos una aplicación biyectiva $f \colon \lbrace gG_\alpha : g \in G \rbrace \longrightarrow O_\alpha$. Definimos $f(gG_\alpha) = g\cdot \alpha$. Ahora, $gG_\alpha = h G_\alpha$ si y sólo si $g^{-1}h \in G_\alpha$ si y sólo si $(g^{-1}h) \cdot \alpha = \alpha$ si y sólo si $g \cdot ((g^{-1}h) \cdot \alpha) = g \cdot \alpha$ si y sólo si $h \cdot \alpha = g \cdot \alpha$, luego $f$ está bien definida y si lo leemos al revés podremos comprobar que también es inyectiva. Al ser $f$ claramente suprayectiva, ya está.

$\hfill \square$

Cuando un grupo $G$ actúa sobre un conjunto $\Omega$, de entre todos los elementos de $\Omega$ destacamos aquellos que son fijados por todos los elementos de $G$:

\begin{definition}Dado un grupo $G$ actuando sobre un conjunto $\Omega$, y dado un $\alpha \in \Omega$ decimos que $\alpha$ es un \textbf{punto fijo} de $\Omega$ si $g \cdot \alpha = \alpha$ $\forall g \in G$, es decir aquellos $\alpha \in \Omega$ tales que $O_\alpha = \lbrace \alpha \rbrace$. Igualmente escribimos $$\Omega_0 = \lbrace \alpha \in \Omega : |O_\alpha | = 1. \rbrace$$ para referirnos al conjunto de los puntos fijos de $\Omega$.
\end{definition}

\begin{proposition}Sea un grupo $G$ actuando sobre un conjunto $\Omega$. Si $g \in G$, definimos $Fi(g) = \lbrace i \in \Omega: g \cdot i = i \rbrace$. Entonces, el número de órbitas de $\Omega$ bajo la acción de $G$ es $$\dfrac{1}{|G|} \sum_{g \in G} |Fi(g)|.$$
\end{proposition}
\emph{Demostración: }Hallaremos $|\lbrace (g,i) \in G \times \Omega : g \cdot i = i\rbrace |$. Contamos sus elementos de dos formas y tenemos que $$\sum_{g\in G} |Fi(g)| = \sum_{i\in \Omega}|G_i|.$$ Además, por~\ref{eq:coest} si dos elementos de $\Omega$ pertenecen a la misma órbita entonces sus estabilizadores son conjugados, luego tienen el mismo orden. Sean $O_{i_1}, \ldots, O_{i_r}$ las $r$ órbitas, entonces, teniendo en cuenta el \textit{Teorema de la órbita estabilizadora}, $$\sum_{i\in \Omega} |G_i| = \sum_{k=1}^r[G:G_{i_k}]|G_{i_k}| = \sum_{k=1}^r|G| = r|G|\Rightarrow r|G| = \sum_{g\in G} |Fi(g)|,$$ donde $[G:G_{i_k}]$ es el número de elementos de la órbita de $i_k$ y $|G_{i_k}|$ es el número de elementos $g\in G$ tales que $g\cdot i_k = i_k$ (además está claro que el cardinal del conjunto que hemos escrito al principio es la suma de los $[G:G_{i_k}]|G_{i_k}|$ para cada $k=1,\ldots, r$, aquí cada $i_k$ es un elemento de $\Omega$). Y de aquí, $$r = \dfrac{1}{|G|}\sum_{g\in G} |Fi(g)|.$$

$\hfill \square$

\begin{definition}Sea $p$ un número primo. Un grupo $G$ es un \textbf{$p$-grupo finito} si $G$ es finito y $|G|$ es una potencia de $p$.
\end{definition}

\begin{theorem}\label{eq:ecClasesp}
Sea $G$ un grupo actuando sobre un conjunto finito $\Omega$. Escogemos $\alpha_1, \ldots, \alpha_s$ representantes de las órbitas de longitud mayor que 1. Entonces $$|\Omega| = |\Omega_0| + \sum_{j=1}^s |O_{\alpha_j}|.$$ En particular, si $G$ es un $p$-grupo finito, entonces $$|\Omega| \equiv |\Omega_0|\hspace{0.1cm} \text{mod}\hspace{0.1cm} p.$$
\end{theorem}
\emph{Demostración: }La primera parte se deduce de la fórmula de las órbitas y del teorema de la órbita estabilizadora. Sea ahora $G$ un grupo tal que $|G| = p^n$. Por~\ref{eq:torest}, tendremos que $|O_{\alpha_j}| = [G:G_{\alpha_j}] > 1$, con $j = 1, \ldots , s$. Como cada $[G:G_{\alpha_j}]$ divide a $|G| = p^n$, ya está.

$\hfill \square$

La descomposición del conjunto $\Omega$ en unión de las diferentes órbitas tiene especial interés cuando la acción es la conjugación de un grupo $G$ sobre sí mismo. En este caso consideraremos: 

\begin{definition}\label{eq:accConj} Consideremos la acción de un grupo $G$ sobre sí mismo, $\Omega = G$, $$\begin{array}{rccl}
\rho\colon &G& \longrightarrow &S_G\\
&g& \longmapsto &\alpha_{g}
\end{array}
$$
donde ya sabemos que $\alpha_{g}(x) = x^{g}=gxg^{-1}$ con $x \in G$. Notar que en este caso el conjunto sobre el que consideramos la acción es $G$, y que también la hemos presentado antes, al comienzo del capítulo concretamente, como la \textbf{acción conjugación}.

Como $\alpha_{g} \in Aut(G)$ tenemos que en particular es biyectiva. Además es claro que $\alpha_{gh}=\alpha_{g}\alpha_{h}$, luego $\rho$ es homomorfismo.

El núcleo de $\rho$ es $Ker \hspace{0.1cm} \rho = \lbrace g \in G: \alpha_{g} = id \rbrace = \lbrace g \in G: gxg^{-1} = x \hspace{0.15cm} \forall x \in G \rbrace =  \lbrace g \in G: gx = xg \hspace{0.1cm} \forall x \in G \rbrace$ y es el \textbf{centro de $G$}, que se escribe \textbf{$Z(G)$}.

El estabilizador de un $x \in G$, $G_{x}= \lbrace g \in G: gxg^{-1} = x \rbrace = \lbrace g \in G: gx=xg \rbrace$ también se presentó en el primer capítulo y lo denominamos \textbf{centralizador de $x$ en $G$} y se escribe como \textbf{$C_{G}(x)$}. Además, como $G_{x} \leq G$ entonces también $C_{G}(x) \leq G$.

Por último, si $x \in G$, su órbita $O_{x}$ será $O_{x} = \lbrace gxg^{-1}:g \in G \rbrace$. La denominaremos \textbf{clase de conjugación de $x$ en $G$}. Y, siguiendo el teorema de la órbita estabilizadora vemos que tiene $$[G:C_{G}(x)] = \dfrac{|G|}{|C_{G}(x)|}$$ elementos. La denotaremos por $Cl_{G}(x)$, es decir, tendremos: $$Cl_{G}(x) = \lbrace gxg^{-1} : g \in G \rbrace$$ $$|Cl_{G}(x)| = [G :C_G(x)] = \dfrac{|G|}{|C_G(x)|}.$$
\end{definition}

Notar que $|Cl_G(x) | = 1$ si y sólo si $gx = xg$ $\forall g \in G$, es decir, si y sólo si $x \in Z(G)$. Luego, en este caso $\Omega_0 = Z(G).$

Todos estos conceptos ya los habíamos visto en el primer capítulo.

\begin{theorem}[\textit{\textbf{Ecuación de las clases de conjugación de un grupo}}] \label{eq:ecClases}
Sea $G$ un grupo finito. Sean $K_{1}, \ldots, K_{s}$ las clases de conjugación de $G$ de longitud mayor que $1$. Entonces $$|G| = |Z(G)| + \sum_{j=1}^{s} |K_{j}|.$$ Esta fórmula recibe el nombre de \textbf{ecuación de clases de conjugación de un grupo finito}.
\end{theorem} 
\emph{Demostración: } Se sigue inmediatamente a partir de lo discutido anteriormente (en este caso $\Omega_0 = Z(G)$) y del teorema~\ref{eq:ecClasesp}. Notar que, por el teorema de la órbita estabilizadora, $|K_{j}| = |O_{\alpha_{j}}| = [G:G_{\alpha_{j}}] = [G:C_{G}(\alpha_{j})]$ para $j=1, \ldots, s$, con los $\alpha_{j}$ representantes de las clases de conjugación (órbitas) de longitud mayor que $1$.   ($G = C_{G}(x) \Longleftrightarrow x \in Z(G)$, entonces $\left[ G:C_{G}(x) \right] > 1$ si y sólo si $x \notin Z(G)$.)

$\hfill \square$

Se desprende de aquí claramente que $$|G| \equiv |Z(G)| \hspace{0.2cm}  \text{mod} \hspace{0.1cm} p.$$

\begin{proposition}Sea $G \neq \lbrace 1 \rbrace$ un $p$-grupo finito. Entonces tenemos que $Z(G) \neq \lbrace 1 \rbrace$.
\end{proposition}
\emph{Demostración: }Por~\ref{eq:ecClasesp} y~\ref{eq:ecClases} tenemos que $|G| \equiv |Z(G)|\hspace{0.1cm}\text{mod}\hspace{0.1cm} p$. Como $|G| = p^n$ y $p^n \not\equiv 1 \hspace{0.1cm}\text{mod}\hspace{0.1cm}p$ ya está.

$\hfill \square$

\begin{corolario}Sea $G$ un $p$-grupo finito simple. Entonces $|G| = p$.
\end{corolario}
\emph{Demostración: }Si $G$ es simple entonces $Z(G) = G$, ya que sabemos por el resultado anterior que $Z(G) \neq \lbrace 1 \rbrace$, y como el centro es un subgrupo normal y $G$ es simple entonces necesariamente $Z(G) = G$. Luego $G$ es abeliano y el resultado se sigue de~\ref{eq:abSimple}.

$\hfill \square$

Es decir, \textbf{\textit{todo $p$-grupo finito simple es abeliano}}.

Recordemos que si $H \leq G$ definíamos el \textbf{normalizador} de $H$ en $G$ como $$N_G(H) = \lbrace g \in G : H^g = H \rbrace.$$

Notar que $N_G(H)$ es el estabilizador de $H$ en la acción de $G$ sobre sus subgrupos por conjugación:
 $$\begin{array}{rccl}
\rho\colon &G& \longrightarrow &S_{\Omega}\\
&g& \longmapsto &\rho_{g}(H) = H^{g}.
\end{array}
$$
donde $\Omega$ es el conjunto de subgrupos de $G$.

Es claro que $H \unlhd N_G(H)$ y que $H \unlhd G$ si y sólo si $N_G(H) =G$. Por el \textit{Teorema de la órbita estabilizadora} tenemos que el número de subgrupos distintos de la forma $H^g$, con $g \in G$, es $[G:N_G(H)]$. Es decir, que el número de conjugados distintos de un subgrupo $H$ de $G$ viene dado por $[G:N_G(H)]$. Esto ya lo vimos en~\ref{eq:conjug}

\begin{proposition}Sea $G$ un grupo finito y $H \leq G$ con $|H| = p^a$ para cierto primo $p$ y $a \in \mathbb{N}$. Entonces $$[G:H] \equiv [N_G(H):H] \hspace{0.1cm}\text{mod} \hspace{0.1cm} p.$$
\end{proposition}
\emph{Demostración: }Consideremos el conjunto $\Omega = \lbrace xH : x \in G \rbrace$. Tenemos que $H$ actúa sobre $\Omega$ por multiplicación a izquierda. Calculamos el número de puntos fijos, es decir $\Omega_0$. Se tiene que $hxH = xH$ $\forall h \in H$ si y sólo si $x^{-1}hx \in H$ $\forall h \in H$ si y sólo si $H^{x^{-1}} \subseteq H$ si y sólo si $H \subseteq H ^x$ si y sólo si $H = H^x$ (ya que $|H| = |H^x|$) si y sólo si $x\in N_G(H)$. El resultado se sigue de la segunda parte de~\ref{eq:ecClasesp}.

$\hfill \square$

\begin{corolario}\label{eq:cor411} Sea $G$ un $p$-grupo finito. Si $H \leq G$ entonces $H \leq N_G(H)$.
\end{corolario}
\emph{Demostración: }Como $p^a \not\equiv 1 \hspace{0.1cm}\text{mod} \hspace{0.1cm} p$ si $a \geq 1$, aplicando el resultado anterior ya está.

$\hfill \square$

Es decir, en los $p$-grupos los normalizadores crecen. El siguiente resultado es un caso particular del conocido \textit{Teorema de Cauchy}.

\begin{corolario}\label{eq:cor412} Sea $G$ un $p$-grupo finito. Si $p^a$ divide a $|G|$, entonces $G$ tiene un subgrupo de orden $p^a$.
\end{corolario}
\emph{Demostración: }Lo haremos por inducción sobre el orden de $G$. Podemos suponer que $G \neq \lbrace 1 \rbrace$ y que $p^a < |G|$. Entre los subgrupos propios de $G$ elegimos el de mayor orden posible, $H$. Por el corolario anterior sabemos que $H \unlhd G$. Por el \textit{Teorema de correspondencia} tenemos que $G/H$ no tiene subgrupos propios. Por~\ref{eq:abSimple}, se tiene que $[G:H] = p$. Ahora, $p^a$ divide a $|H|$ y el resultado se sigue por inducción.

$\hfill \square$

Finalmente, hablaremos de las acciones transitivas.

\begin{definition}Diremos que una acción de un grupo $G$ sobre un conjunto $\Omega$ es \textbf{transitiva} si sólo hay una órbita, es decir, si $\Omega$ es una $G$-órbita. Dicho de otra manera: la acción de $G$ sobre $\Omega$ es transitiva si para cualesquiera $\alpha, \beta \in \Omega$ existe un $g \in G$ tal que $g \cdot \alpha = \beta$.
\end{definition}

\begin{proposition}Sea $G$ un grupo actuando sobre un conjunto $\Omega$. Dados $\alpha \in \Omega$ y $g \in G$, entonces $$(G_\alpha)^g = G_{g\cdot \alpha}.$$ En particular, si la acción de $G$ sobre $\Omega$ es transitiva, entonces todos los estabilizadores son conjugados.
\end{proposition}
\emph{Demostración: }Lo primero ya se ha visto en el segundo apartado de~\ref{eq:coest}.

Supongamos ahora que la acción de $G$ sobre $\Omega$ es transitiva y sean $\alpha, \beta \in \Omega$. Entonces existe $g \in G$ tal que $g \cdot \alpha = \beta$ y $$(G_\alpha)^g = G_\beta.$$

$\hfill \square$

\subsection{Grupos de permutaciones}

Partimos de un conjunto finito $\Omega$. Una \textbf{\textit{permutación}} de $\Omega$ es una aplicación biyectiva $f \colon \Omega \longrightarrow \Omega$. A lo largo de esta sección estudiaremos el grupo $S_\Omega$ de permutaciones de $\Omega$ con la operación composición (producto) $g \circ f = gf$, con $g,f \in S_\Omega$. Recordemos que $$|S_\Omega| = |\Omega|!.$$

\begin{definition}Dados $\alpha_1, \ldots, \alpha_n$ $n$ elementos distintos de $\Omega$, entonces designaremos por $(\alpha_1, \ldots, \alpha_n)$ a la única permutación $\sigma \in S_\Omega$ tal que $\sigma (\alpha) = \alpha$ si $\alpha \in \Omega \setminus \lbrace \alpha_1, \ldots, \alpha_n \rbrace$, $\sigma (\alpha_1)=\alpha_2$, $\sigma (\alpha_2) = \alpha_3$, $\ldots$, $\sigma(\alpha_{n-1}) = \alpha_n$ y $\sigma(\alpha_n) = \alpha_1$. A la permutación $\sigma = (\alpha_1, \ldots, \alpha_n ) \in S_\Omega$ la denominamos \textbf{$n$-ciclo} o \textbf{ciclo de longitud $n$}.

Notar que los $1$-ciclos son la aplicación identidad. A los $2$-ciclos, dada la importancia especial que tienen y que iremos viendo, los llamaremos \textbf{trasposiciones}. Notar que si $t$ es una transposición entonces $o(t)=2$ y $t=t^{-1}$.
\end{definition}

\begin{definition}Dada una permutación $\sigma \in S_n$, diremos que $\sigma$ \textbf{mueve} un $\alpha_i \in \Omega$ si $\sigma( \alpha_i) = \alpha_j$, con $i\neq j$. Por el contrario, diremos que $\sigma$ \textbf{fija} un $\alpha_i \in \Omega$ si $\sigma (\alpha_i ) = \alpha_i$.
\end{definition}

Del conjunto $\Omega$ realmente lo que nos interesa desde el punto de vista de las permutaciones no es la naturaleza propia del conjunto o los elementos que la forman, sino que contiene un número $n$ de elementos cualesquiera, por lo que podríamos simplemente escribir $S_n$ para referirnos al grupo de permutaciones de un conjunto finito cualquiera $\Omega$ de $n$ elementos en lugar de $S_\Omega$. Veámoslo también así:

\begin{observation}\label{eq:obsabel} Veamos algunas observaciones interesantes:
\begin{enumerate}
\item Dados enteros $2 \leq n \leq m$, podemos ver a $S_{n}$ como subgrupo de $S_{m}$. En efecto, para todo $\sigma \in S_{n}$ denotamos por $\sigma' \in S_{m}$ a la biyección de $\lbrace 1, \ldots, m \rbrace$ en sí mismo que actúa como $\sigma$ sobre los primeros $n$ enteros positivos y fija los comprendidos entre $n+1$ y $m$. Es decir, la aplicación $$\begin{array}{rccl}
&S_{n}& \longrightarrow &S_{m}\\
&\sigma& \longmapsto &\sigma'
\end{array}
$$ es un homomorfismo inyectivo de grupos y, por el \textit{Primer Teorema de Isomorfía}, $S_{n}$ es isomorfo a su imagen, que es un subgrupo de $S_{m}$.

De aquí se desprende que, dado $H = \lbrace \sigma \in S_{n} : \sigma(n) = n \rbrace \leq S_{n}$ el estabilizador de $n$ en $S_{n}$ en su acción sobre $\Omega$, si $\sigma \in H$ y definimos un $\bar{\sigma} \in S_{n-1}$ como $\bar{\sigma}(i) = \sigma(i)$ para $i=1, \ldots, n-1$, entonces la aplicación $$\begin{array}{rccl}
&H& \longrightarrow &S_{n-1}\\
&\sigma& \longmapsto &\bar{\sigma}
\end{array}
$$ 
es un isomorfismo de grupos.
\item Como hemos dicho antes, lo realmente importante del conjunto $\Omega$ es que tenga $n$ elementos. Así, si $I_{n}$ es otro conjunto con $n$ elementos, el grupo $Biy(I_{n})$ de biyecciones de $I_{n}$ en sí mismo es isomorfo a $S_{n}$, y no distinguiremos entre ambos. Para verlo, fijada una biyección cualquiera $\alpha \colon \Omega \longrightarrow I_{n}$ se comprueba inmediatamente que la aplicación  $$\begin{array}{rccl}
&Biy(I_{n})& \longrightarrow &S_{n}\\
&\beta& \longmapsto &\alpha\circ \beta \circ \alpha^{-1}
\end{array}
$$ es un isomorfismo de grupos. Es por esta razón por la que hemos introducido la notación de $\Omega$ simplemente para hablar de un conjunto finito de $n$ elementos cualquiera.
\end{enumerate}
\end{observation}

Se denotará indistintamente tanto $S_n$ como $S_\Omega$.

Cada elemento de $S_n$ lo escribiremos en ocasiones de una forma un tanto especial, como sigue: 
$$\sigma = \left(
\begin{matrix}
1 & 2 & \ldots & n \\
\sigma(1) & \sigma(2) & \ldots & \sigma(n)
\end{matrix}
\right).
$$

Esta notación nos ahorrará confusiones, ya que muestra el número $n$ de elementos del que partimos, cosa que no aparece en la notación de ciclos. Es decir, si hablamos de la permutación $(1,2,3)$ no sabemos si estamos en $S_3$ o en $S_5$ o en cualquier $S_n$ con $n>3$, porque los elementos fijados no aparecen. En cambio, en la segunda notación sí apreciamos de que $n$ partimos, por lo que sí sabemos en qué $S_n$ nos encontramos.

Observar también que $$(\alpha_1, \ldots, \alpha_n) = (\alpha_n, \alpha_1, \ldots, \alpha_{n-1}) = \ldots = (\alpha_2, \alpha_3, \ldots, \alpha_n, \alpha_1),$$ luego cada $n$-ciclo se puede escribir de $n$ maneras distintas.

Para estudiar los grupos de permutaciones podemos usar las acciones de grupos sobre conjuntos, en concreto vemos que $S_\Omega$ actúa sobre $\Omega$ mediante $\sigma \cdot \alpha = \sigma(\alpha)$ (la acción natural), con $\sigma \in S_\Omega$, $\alpha \in \Omega$.

\begin{definition}Decimos que dos ciclos $(\alpha_1, \ldots, \alpha_m)$, $(\beta_1, \ldots, \beta_n)$ son \textbf{disjuntos} si los conjuntos $\lbrace \alpha_1, \ldots, \alpha_m \rbrace$ y $\lbrace \beta_1, \ldots, \beta_n \rbrace$ son disjuntos.
\end{definition}

\begin{proposition}\label{eq:permCo} Dado $\Omega$ un conjunto. Entonces:
\begin{enumerate}
\item Sea $\sigma = (\alpha_1, \ldots, \alpha_m) \in S_\Omega$. Entonces $\sigma^i(\alpha_1) = \alpha_{i+1}$, con $1 \leq i \leq m-1$ y $\sigma^m(\alpha_1)=\alpha_1$. En particular, $o(\sigma) = m$.
\item Si $\gamma = (\beta_1, \ldots, \beta_n) \in S_\Omega$ es disjunto con $\sigma = (\alpha_1, \ldots, \alpha_m) \in S_\Omega$, entonces $\gamma \sigma = \sigma \gamma$.
\item Sea un producto de ciclos disjuntos dos a dos $$\sigma= (a_{1}, \ldots, a_{m}) \cdots (b_{1}, \ldots, b_{n}),$$ y sea $G =\langle \sigma \rangle \leq S_{n}$. Entonces $\sigma^{i}(a_{1}) = a_{i+1}$ para $1 \leq i \leq m-1$, $\sigma^{m}(a_{1})=a_{1}, \ldots, \sigma^{j}(b_{1})=b_{j+1}$ para $1 \leq j \leq n-1$ y $\sigma^{n}(b_{1})=b_{1}$. Como consecuencia, los conjuntos $\lbrace a_{1}, \ldots, a_{m} \rbrace, \ldots, \lbrace b_{1}, \ldots, b_{n}\rbrace$ son órbitas de la acción de $G$ sobre $\Omega$ y las demás órbitas tienen longitud uno.
\end{enumerate}
\end{proposition}
\emph{Demostración: }
\begin{enumerate}
\item Es inmediato a partir de la definición de ciclo. 
\item Comprobemos que $(\gamma \sigma) \cdot w = (\sigma \gamma) \cdot w$, $\forall w \in \Omega$. Si $w \neq \alpha_i$ y $w \neq \beta_j$, entonces es claro que $(\gamma \sigma) \cdot w = (\sigma \gamma) \cdot w$. Ahora, si $w \in \lbrace \alpha_1, \ldots, \alpha_m \rbrace$ entonces $\sigma \cdot w \in \lbrace \alpha_1, \ldots, \alpha_m \rbrace$, luego $\gamma \cdot w = w$, y también $\gamma \cdot (\sigma \cdot w) = \sigma \cdot w$, y así $$(\gamma \sigma) \cdot w = \gamma \cdot (\sigma \cdot w) = \sigma \cdot w = \sigma \cdot (\gamma \cdot w) = (\sigma \gamma) \cdot w.$$

Y se razonaría de forma análoga si $w \in \lbrace \beta_1, \ldots, \beta_n \rbrace$.
\item La primera parte es consecuencia directa de lo visto en los apartados anteriores. Así, $\lbrace a_{1}, \ldots, a_{m} \rbrace = \lbrace \sigma^{r}(a_{1}) : r \geq 0 \rbrace, \ldots, \lbrace b_{1}, \ldots, b_{n} \rbrace = \lbrace \sigma^{r}(b_{1}) : r \geq 0 \rbrace.$
\end{enumerate}

$\hfill \square$

\begin{proposition}\label{eq:ciclosdis} Sea $n$ un entero positivo. Entonces cada elemento de $S_{n}$ se puede escribir como composición de ciclos disjuntos dos a dos. Dicha descomposición es además única salvo en el orden de los factores. En particular, los ciclos de $S_{n}$ constituyen un sistema generador de $S_{n}$.
\end{proposition}
\emph{Demostración: } 
Sea $\sigma \in S_{n}$ y $G= \langle \sigma \rangle$. Supongamos $O$ una $G$-órbita. Si $|O| = m$ y $a \in O$ vamos a probar que $O = \lbrace a, \sigma(a), \ldots, \sigma^{m-1}(a) \rbrace$. Por el \textit{Teorema de la órbita estabilizadora} tenemos que $[G:G_{a}] = m$. Así, $G/G_{a}$ es un grupo cíclico de orden $m$ generado por $\sigma G_{a}$. Luego, para cualquier entero $n$ tenemos que $\sigma^{n}(a) = a$ si y sólo si $\sigma^{n}\in G_{a}$ si y sólo si $(\sigma G_{a})^{n} = G_{a}$ si y sólo si $m \mid n$. Esto quiere decir que los elementos $a, \sigma(a), \ldots, \sigma^{m-1}(a)$ de la $G$-órbita de $a$ son distintos y que no puede haber más.

Supongamos ahora que $\lbrace a, \sigma(a), \ldots, \sigma^{m-1}(a) \rbrace, \ldots, \lbrace b, \sigma(b), \ldots, \sigma^{n-1}(b) \rbrace$ son todas las distintas $G$-órbitas. Entonces tenemos que $$\sigma = (a, \sigma(a), \ldots, \sigma^{m-1}(a))\cdots (b, \sigma(b), \ldots, \sigma^{n-1}(b)),$$ puesto que la aplicación de la derecha actúa sobre cada elemento de $\Omega$ de la misma forma que $\sigma$.

Por último, si $\sigma = (a_{1}, \ldots, a_{m}) \cdots(b_{1}, \ldots, b_{n})$ se escribe como producto de ciclos disjuntos, entonces por el resultado inmediatamente anterior tenemos que $\sigma$ determina unívocamente los ciclos $(a_{1}, \ldots, a_{m}), \ldots, (b_{1}, \ldots, b_{n})$, quedando así probada la unicidad.

$\hfill \square$

\begin{example}\label{eq:excidis} Consideremos $\sigma \in S_{9}$ dado por $$\sigma:= \left(\begin{matrix}
1 &2 &3 &4 &5 &6 &7 &8 &9 \\
3 &6 &5 &9 &1 &2 &8 &7 &4
\end{matrix}
\right)$$ Entonces es claro que la órbita de $1$ bajo la acción anterior es $$O_{1} = \lbrace 1, \sigma(1)=3, \sigma^{2}(1) = 5 \rbrace$$ y análogamente $$O_{2} = \lbrace 2,6 \rbrace, \hspace{0.2cm} O_{4} = \lbrace 4,9 \rbrace, \hspace{0.2cm} O_{7} = \lbrace 7,8 \rbrace.$$ Así, los ciclos disjuntos $$\tau_{1} = (1,3,5), \hspace{0.2cm} \tau_{2} = (2,6), \hspace{0.2cm} \tau_{3} = (4,9), \hspace{0.2cm} \tau_{4} = (7,8)$$ cumplen $\sigma = \tau_{1} \circ \tau_{2} \circ \tau_{3} \circ \tau_{4}$.

\end{example}

$\hfill \blacksquare$

Como una consecuencia de esta descomposición en ciclos disjuntos vamos a ver que cualquier $k$-ciclo se puede expresar como producto de los ciclos más simples que existen: las transposiciones.

\begin{corolario} Todo $k$-ciclo es producto de $k-1$ transposiciones. Luego, toda permutación $g\in S_{n}$ es producto de transposiciones (aunque no de forma única).
\end{corolario}
\emph{Demostración: }
Hacemos $g = (a_{1}, \ldots, a_{m})=(a_{1},a_{2}) (a_{2},a_{3}) \cdots (a_{k-1},a_{k}).$

$\hfill \square$

\begin{corolario} 
Sean $\sigma \in S_{n}$ y $\tau_{1}, \ldots, \tau_{k} \in S_{n}$ ciclos disjuntos tales que $\sigma = \tau_{1} \circ \ldots \circ \tau_{k}$. Entonces el orden de $\sigma$ como elemento de $S_{n}$ es el mínimo común múltiplo de las longitudes de los ciclos $\tau_{1}, \ldots, \tau_{k}$.
\end{corolario} 
\emph{Demostración: }Sea $h$ el mínimo común múltiplo de los números $o(\tau_i)$ para $1 \leq i \leq m$. Es decir, tenemos que $o(\tau_i)$ divide a $h$ $\forall i$ y que si $o(\tau_i)$ divide a un entero $m$ $\forall i$, entonces $h$ divide a $m$.

Como $\tau_i\tau_j = \tau_j \tau_i$ $\forall i,j$ por el punto $2$ de~\ref{eq:permCo} tenemos que $(\tau_1 \ldots \tau_k)^n= (\tau_1)^n \ldots (\tau_k)^n$ para todo entero $n$. Así, observamos que $\sigma^h = 1$ y se deduce que $o(\sigma)$ divide a $h$.

Si $o(\sigma) = r$, entonces $(\tau_1)^r\ldots (\tau_k)^r = 1$. Probaremos que $(\tau_i)^r=1$ para todo $1 \leq i \leq k$. Para ello, basta probar que $(\tau_i)^r$ fija todos los elementos de $\Omega$. Dado un $\alpha \in \Omega$, si $\alpha$ es fijado por $\tau_i$, entonces $\alpha$ es fijado por $(\tau_i)^r$. Si $\tau_i$ mueve $\alpha$, entonces $\alpha$ es fijado por $\tau_j$ para todo $j \neq i$, en particular por $(\tau_j)^r$. Por tanto $\alpha = (\tau_k)^r \ldots (\tau_1)^r \cdot \alpha = (\tau_i)^r \cdot \alpha$ y deducimos que $(\tau_i)^r$ fija $\alpha$. Concluimos que $(\tau_i)^r = 1$. Por lo tanto, $o(\tau_i)$ divide a $r$ para todo $i$ y tenemos que $h$ divide a $r = o(\sigma).$ Luego $o(\sigma) = h$.


$\hfill \square$

\begin{proposition}Sea $\sigma = (\alpha_1, \ldots, \alpha_k)$ un $k$-ciclo de $S_n$ y sea $\gamma \in S_n$. Entonces $\sigma^\gamma = (\gamma(\alpha_1), \ldots, \gamma(\alpha_k))$.
\end{proposition}
\emph{Demostración: }Sabemos que $\sigma(\alpha_i) = \alpha_{i+1}$, con $i=1, \ldots, k-1$ y $\sigma(\alpha_k)= \alpha_1$ (recordemos que la acción es $\sigma \cdot \alpha = \sigma(\alpha)$). Así, $(\gamma \sigma \gamma^{-1}) (\gamma(\alpha_i)) = \gamma(\alpha_{i+1})$, con $i=1, \ldots, k-1$ y $(\gamma \sigma \gamma^{-1}) (\gamma(\alpha_k)) = \gamma(\alpha_{1})$. Finalmente, si $\beta \in \Omega \setminus \lbrace \sigma(\alpha_1), \ldots, \sigma(\alpha_k) \rbrace$ entonces $\gamma^{-1}(\beta) \in \Omega \setminus \lbrace \alpha_1, \ldots, \alpha_k \rbrace$. Por lo que $\sigma \cdot (\gamma^{-1} (\beta)) = \gamma^{-1}(\beta)$ y así $\sigma^\gamma$ fija $\beta$. Luego $\sigma^\gamma$ y $(\gamma(\alpha_1), \ldots, \gamma(\alpha_k))$ actúan igual sobre cada elemento de $\Omega$ y así son iguales.

$\hfill \square$

Una consecuencia muy útil de~\ref{eq:ciclosdis} es que vamos a poder clasificar cada permutación según la longitud de los ciclos disjuntos en los que se descomponga, lo cual nos permitirá estudiarlos con mayor profundidad a través de dichas longitudes. Llamaremos así al \textbf{\textit{tipo de una permutación}} a la sucesión en orden descendente de las longitudes de los ciclos disjuntos en los que se descompone. En ocasiones también será conocido como \textbf{estructura de ciclos}, y habrá tantas distintas como particiones del número $|\Omega|$.

\begin{proposition}Dos permutaciones $\gamma, \tau \in S_{n}$ son conjugadas en $S_{n}$ si y sólo si tienen el mismo tipo.
\end{proposition}
\emph{Demostración: }
Si $\tau =(a_{1}, \ldots, a_{m})\cdots(b_{1}, \ldots, b_{n})$ es una descomposición de $\tau$ en ciclos disjuntos y $\gamma \in S_{n}$ es tal que $\sigma = \tau^\gamma$, entonces por el resultado anterior tenemos que $$\sigma = \tau^{\gamma}=(\gamma(a_{1}), \ldots, \gamma(a_{m})) \cdots (\gamma(b_{1}), \ldots, \gamma(b_{n}))$$ es una descomposición en ciclos disjuntos de $\sigma (=\tau^{\gamma})$. Por lo que dos permutaciones conjugadas tienen el mismo tipo.

Recíprocamente, supongamos que $\tau =(a_{1}, \ldots, a_{m}) \cdots(b_{1}, \ldots, b_{n})$ y también $\gamma = (a'_{1}, \ldots, a'_{m})\cdots(b'_{1}, \ldots, b'_{n})$ tienen el mismo tipo, veamos que son conjugadas (en estas expresiones se han incluido los $1$-ciclos también). Tenemos que $$\Omega = \lbrace a_{1}, \ldots, a_{m} \rbrace \cup \cdots \cup \lbrace b_{1}, \ldots, b_{n} \rbrace = \lbrace a'_{1}, \ldots, a'_{m} \rbrace \cup \cdots \cup \lbrace b'_{1}, \ldots, b'_{n} \rbrace$$
son dos particiones de $\Omega$. Por lo que existe una única $\sigma \in S_{n}$ tal que $\sigma(a_{i})=a'_{i}, \ldots, \sigma(b_{j})=b'_{j}$ para $1\leq i \leq m, \ldots, 1 \leq j \leq n$. Luego, por el resultado anterior tenemos que $\tau^{\sigma} = \gamma.$

$\hfill \square$

De este resultado tenemos una importante consecuencia, y es que dado un $\sigma \in S_{n}$, entonces \textbf{\textit{la clase de conjugación de $\sigma$}} (ver~\ref{eq:accConj}) \textbf{\textit{está formada por todas las permutaciones del mismo tipo que $\sigma$}}.

\begin{observation} Sea $k>1$, entonces el número de $k$-ciclos que mueven $k$ elementos distintos $a_{1}, \ldots, a_{k} \in \Omega$ es $(k-1)!$. Si $|\Omega| = n$, el número de $k$-ciclos de $S_{n}$ es ${n \choose k} (k-1)!$.

Esto se puede generalizar a permutaciones de determinados tipos: es decir, si queremos saber el número de permutaciones de $S_{n}$ con $b_{j}$ ciclos de longitud $j$ tendremos $$ \dfrac{n!}{1^{b_{1}}2^{b_{2}} \cdots n^{b_{n}}b_{1}!b_{2}!\cdots b_{n}!}.$$(odio la combinatoria)
\end{observation}

\begin{example}
Veamos las distintas clases de conjugación en $S_{5}$. Sabemos que hay 10 $2$-ciclos, 20 $3$-ciclos, 30 $4$-ciclos y 24 $5$-ciclos. Ciclos de tipo $[2,2]$ tenemos 15 ciclos. Ciclos de tipo $[3,2]$ tenemos 20 ciclos, y añadiendo la identidad tenemos: $10+20+30+24+15+20+1 = 120.$
\end{example}

$\hfill \blacksquare$

\begin{example}\label{eq:excentra} Sea $G = S_{5}$.
\begin{enumerate}
\item Sea $\tau = (1,2,3)$. Sabemos que $|Cl_{G}(\tau)| = 20$. Entonces $C_{G}(\tau) = \langle \tau \rangle \langle (4,5) \rangle$.

Por un lado, como $|Cl_{G}(\tau)| = 20$, entonces $|C_{G}(\tau)| = \dfrac{|G|}{20} = \dfrac{120}{20} = 6$. Por otro lado, $\langle (1,2,3) \rangle = \lbrace id, (1,2,3), (1,3,2) \rbrace,$ y $\langle (4,5)\rangle = \lbrace id, (4,5) \rbrace $ (simple comprobación). 

$\langle (1,2,3) \rangle \cap \langle (4,5) \rangle = id$ y así $|\langle (1,2,3) \rangle \langle (4,5) \rangle| = \dfrac{|\langle (1,2,3) \rangle||\langle (4,5) \rangle|}{1} = 3 \cdot 2 = 6.$ Como $(4,5)$ es disjunta con $(1,2,3)$, entonces conmutan y así $\langle (4,5) \rangle \leq C_{G}(\tau)$, y también $\langle (1,2,3) \rangle \langle (4,5) \rangle \leq C_{G}(\tau)$ y como tienen el mismo orden se da la igualdad.
\item Sea $\gamma$ un $5$-ciclo de $G$. Entonces $C_{G}(\gamma) = \langle \gamma \rangle$. 

Como $\langle \gamma \rangle$ es un grupo cíclico, luego abeliano, entonces todos sus elementos formarán parte de $C_{G}(\gamma)$, luego $\langle \gamma \rangle \leq C_{G}(\gamma)$. Y, como $|Cl_{G}(\gamma)| = 24$, entonces $|C_{G}(\gamma)| = \dfrac{|G|}{|Cl_{G}(\gamma)|} = \dfrac{120}{24} = 5 = |\langle \gamma \rangle |$, luego se tiene la igualdad. 
\item Sea $\sigma = (1,2)(3,4)$. Entonces $C_{G}(\sigma) = \langle (1,3,2,4),(1,3)(2,4)\rangle$. Además, este grupo es isomorfo a $\mathcal{D}_{8}$. 

Por un lado, sabemos que hay $15$ ciclos de tipo $[2,2]$, luego $|Cl_{G}(\sigma)|=15 = \dfrac{|G|}{|C_{G}(\sigma)|} = \dfrac{120}{|C_{G}(\sigma)|}$, por lo que $|C_{G}(\sigma)| = \dfrac{120}{15}=8.$

Por otro lado, llamemos $a = (1,3,2,4)$ y $b = (1,3)(2,4)$. Es claro que $o(a) = 4$ y $o(b)=2$ (simple comprobación). Entonces $$\langle a \rangle = \lbrace id, (1,3,2,4), (1,2)(3,4), (1,4,2,3) \rbrace,$$ y $$\langle b \rangle = \lbrace id, (1,3)(2,4) \rbrace.$$

Luego $\langle a \rangle \cap \langle b \rangle = id$, y así $|\langle a \rangle \langle b \rangle | = |\langle a \rangle| |\langle b \rangle| = 4\cdot 2 = 8$. Sólo quedaría ver que $\langle (1,3,2,4),(1,3)(2,4)\rangle \leq C_{G}(\sigma)$, pero esto se desprende del hecho de que $\sigma \in \langle a \rangle$ (que es un grupo cíclico, luego abeliano) y de que $\sigma \cdot b = b \cdot \sigma = (1,4)(2,3)$ (simple comprobación). Así, tenemos un subgrupo del mismo orden que el centralizador, luego son lo mismo.
\end{enumerate}
\end{example}

$\hfill \blacksquare$


\begin{proposition} Sea $n \geq 3$. Entonces $Z(S_{n}) =1$.
\end{proposition}
\emph{Demostración: }
Sea $1 \neq \sigma \in Z(S_{n})$. Entonces va a existir un $a \in \Omega$ tal que $\sigma (a)= b \neq a$, con $b \in \Omega$. Sea ahora $c \in \Omega \setminus \lbrace a,b \rbrace$ y sea $\tau =(b,c)$. Entonces $\tau\sigma \tau^{-1} (a)= \tau \sigma (a) =\tau (b) = c \neq b$ $(=\sigma(a))$. Luego, $\sigma^{\tau} \neq \sigma$, lo cual es absurdo puesto que $\sigma \in Z(S_{n})$.

$\hfill \square$

Ahora, estudiaremos el conocido como \textit{grupo alternado}, pero antes veamos qué son las permutaciones pares e impares.

Sea $\Omega = \lbrace 1, 2, \ldots, n \rbrace$, ya sabemos que en este caso hablaremos de $S_n$ en lugar de $S_\Omega$. Ahora, consideremos el conjunto $\mathcal{C}$ de los subconjuntos de $\Omega$ que tienen dos elementos, es decir, $$\mathcal{C} = \lbrace X \subseteq \Omega : |X| = 2 \rbrace.$$

Sea ahora un $\sigma \in S_n$, y sea $X = \lbrace i,j \rbrace \in \mathcal{C}$. Puede pasar que el signo del entero $i-j$ sea el mismo que el signo del entero $\sigma(i)-\sigma(j)$. En este caso, el signo de $j-i$ también es el signo de $\sigma(j) - \sigma(i)$, por lo que no importa si $i<j$ ó $j<i$. En este caso, escribiremos $$inv_\sigma(X)=0$$ y diremos que $\sigma$ \textbf{\textit{no invierte}} $X$. También puede ocurrir que los enteros $i-j$ y $\sigma(i)-\sigma(j)$ tengan signos opuestos. En este caso también lo tendrán $j-i$ y $\sigma(j) -\sigma(i)$ y escribiremos $$inv_\sigma(X) = 1$$ y diremos que $\sigma$ \textbf{\textit{invierte}} $X$. 

Así, definimos:

\begin{definition}Dado un $\sigma \in S_n$, su \textbf{signatura} es $$sig(\sigma) = (-1)^{\sum_{X\in \mathcal{C}}inv_\sigma(X)}.$$
Diremos que $\sigma$ es \textbf{par} si $sig(\sigma)=1$ y que $\sigma$ es \textbf{impar} si $sig(\sigma)=-1$.
\end{definition}

Otra forma de definirla es:

\begin{definition}Para cada $\sigma \in S_{n}$ consideramos el endomorfismo $$\begin{array}{rccl}
f_{\sigma} \colon &\mathbb{R}^{n}& \longrightarrow &\mathbb{R}^{n}\\
&e_{j}& \longmapsto &e_{\sigma(j)}
\end{array}
$$ con $e_{j}$ un  vector de la base $B = \lbrace e_{1}, \ldots, e_{n} \rbrace$ de $\mathbb{R}^{n}$. La aplicación $$\begin{array}{rccl}
\psi \colon &S_{n}& \longrightarrow &Aut(\mathbb{R}^{n})\\
&\sigma& \longmapsto &f_{\sigma}
\end{array}
$$  es un homomorfismo de grupos, puesto que dados $\sigma, \tau \in S_{n}$ y $j = 1, \ldots, n$ se tiene que $$f_{\sigma \cdot \tau} = e_{(\sigma \cdot \tau)(j)}= e_{\sigma(\tau(j))} = f_{\sigma}(e_{\tau(j)}) = f_{\sigma}(f_{\tau}(e_{j})) = (f_{\sigma} \circ f_{\tau})(e_{j}),$$ 

es decir, $\psi(\sigma \cdot \tau) = f_{\sigma \cdot \tau} = f_{\sigma} \circ f_{\tau} = \psi(\sigma) \circ \psi(\tau)$.

Ahora, observar que la matriz $M_{f_{\sigma}}(B)$ de $f_{\sigma}$ respecto de la base estándar se obtiene a partir de la matriz identidad desordenando las columnas de ésta. Del \textit{Álgebra Lineal} sabemos que si intercambiamos dos columnas de una matriz obtenemos otra con el determinante opuesto a la de la matriz de partida, deducimos así que $det(f_{\sigma}) \in \mathcal{U}_{2} = \lbrace +1, -1 \rbrace$. Se define entonces el  \textbf{homomorfismo índice ó signatura de una permutación} como $$\begin{array}{rccl}
\varepsilon = det \circ \psi \colon S_{n} \longrightarrow \mathcal{U}_{2} = \lbrace +1, -1 \rbrace\\
\end{array}
$$ donde $det \colon Aut(\mathbb{R}^{n}) \longrightarrow \mathbb{R}$ es el homomorfismo determinante. Además el homomorfismo índice es sobreyectivo pues $$\varepsilon(id) = det(f_{id}) = det (id_{\mathbb{R}^{n}}) = +1$$ y si $\sigma$ es una transposición cualquiera, la matriz $M_{f_{\sigma}}(B)$ es aquella en la que se han intercambiado dos columnas de la matriz identidad, y así $$\varepsilon(\sigma) = det(f_{\sigma}) = det(M_{f_{\sigma}}(B)) = -det (id_{\mathbb{R}^{n}}) = -1.$$
\end{definition}

Así, a partir de la construcción de este \textit{homomorfismo índice} como composición del homomorfismo determinante con el homomorfismo $\psi$ antes definido, podemos dar una definición formal de lo que es el \textit{grupo alternado}:

\begin{definition}El núcleo de $\varepsilon$ lo denotaremos $\mathcal{A}_{n}$ y lo llamaremos \textbf{$n$-ésimo grupo alternado}. Las permutaciones $\sigma \in \mathcal{A}_{n}$ se denominan \textbf{pares}, y las que pertenecen a $S_{n} \setminus \mathcal{A}_{n}$ se denominan \textbf{impares}. Al ser el homomorfismo índice $\varepsilon$ sobreyectivo, tenemos que $|\mathcal{A}_{n}| = n!/2$. Las permutaciones pares son aquellas que pueden escribirse como producto de un número par de transposiciones y tienen signatura $1$, y las impares aquellas que pueden escribirse como producto de un número impar de transposiciones y tiene signatura $-1$. Esto se puede comprobar con el siguiente resultado:
\end{definition}

\begin{proposition}\label{eq:cicimpar} Sea $\sigma = (a_{1}, \ldots, a_{k}) \in S_{n}$. Las transposiciones $\tau_{j} = (a_{j-1}, a_{j})$, donde $2\leq j \leq k$, cumplen $\sigma = \tau_{k} \cdot \tau_{k-1} \ldots \tau_{2}.$ En particular $\sigma \in \mathcal{A}_{n}$ si y sólo si $k$ es impar.
\end{proposition}
\emph{Demostración: }La igualdad $\sigma = \tau_{k} \cdot \tau_{k-1} \ldots \tau_{2}$ se comprueba directamente. Además, como cada $\varepsilon(\tau_{i}) = -1$ resulta que $$\varepsilon(\sigma) = \prod_{i=2}^{k}\varepsilon(\tau_{i}) = (-1)^{k-1},$$ luego $\sigma \in \mathcal{A}_{n}$ si y sólo si $1 = (-1)^{k-1}$, esto es, si $k$ es impar.

$\hfill \square$

Del resultado que acabamos de ver se tiene que, dado un $k$-ciclo $(a_{1}, \ldots, a_{k}) \in S_{n}$, entonces su signatura es $(-1)^{k-1}$.

Con todo esto podemos resumir el grupo alternado mediante el siguiente homomorfismo:
\begin{proposition}La aplicación signatura $$\begin{array}{rccl}
sig \colon &S_{n}& \longrightarrow &\lbrace -1, 1\rbrace\\
&\sigma& \longmapsto &sig(\sigma)
\end{array}
$$
es un homomorfismo de grupos. Su núcleo, que está formado por las permutaciones pares, es un subgrupo de índice $2$, el \textbf{grupo alternado $\mathcal{A}_{n}$}. Además, $$S_{n}/\mathcal{A}_{n} \cong C_{2}.$$
\end{proposition}

\begin{observation} Para $n \geq 4$ el grupo alternado $\mathcal{A}_{n}$ no es abeliano puesto que las permutaciones $\sigma = (1,2,3) \in \mathcal{A}_{n}$ y $\tau = (1,2)(3,4) \in \mathcal{A}_{n}$, por la proposición anterior y que $\sigma\tau(1) = 1 \neq 3 = \tau\sigma(1)$.

Además, a partir de la proposición anterior y de~\ref{eq:ciclosdis}, podemos afirmar que las transposiciones generan el grupo $S_{n}$, o sea que cada permutación es producto de transposiciones.
\end{observation}

\begin{example} El grupo $\mathcal{A}_{4}$ tiene $12$ elementos, que son los elementos de $$K = \lbrace 1,(1,2)(3,4),(1,3)(2,4),(1,4)(2,3) \rbrace$$ y los $8$ $3$-ciclos de $S_{4}$. Además $K \unlhd \mathcal{A}_{4}$ y así $\mathcal{A}_{4}$ no es simple, de hecho es el único subgrupo normal propio de $\mathcal{A}_{4}$.
\end{example}

$\hfill \blacksquare$

Una vez visto las primeras definiciones y propiedades de los grupos de permutaciones demostraremos uno de los resultados más importantes en \textit{Teoría de Grupos}: que $\mathcal{A}_{n}$ es simple si $n \geq 5$, también conocido como el \textit{Teorema de Abel}, en honor al matemático noruego Niels Henrik Abel. Así, tal y como hemos visto en el ejemplo anterior, $\mathcal{A}_4$ es el último grupo alternado que no es simple, a partir de ahí $\mathcal{A}_n$ es simple para $n>4$.

\begin{proposition}\label{eq:preabel} Si $n \geq 3$, entonces $\mathcal{A}_{n}$ es transitivo sobre $\Omega =\lbrace 1, \ldots, n \rbrace$
\end{proposition}
\emph{Demostración: } Si $1 \leq i <j \leq n$, elegimos un $k \neq i,j$ y tenemos que $(i,j,k)(i) = j$ (la permutación $(i,j,k)$ sobre $i$). Claramente $(i,j,k) \in \mathcal{A}_{n}$.

$\hfill \square$

\begin{theorem}[\textbf{\textit{Teorema de Abel}}] Si $n \geq 5$, entonces $\mathcal{A}_{n}$ es simple.
\end{theorem}
\emph{Demostración: }\textbf{\textit{Primero demostraremos que $\mathcal{A}_{5}$ es simple}}. En $\mathcal{A}_{5}$ tenemos $20$ $3$-ciclos, $24$ $5$-ciclos y $15$ elementos del tipo $(a,b)(c,d)$. Veamos que los $3$-ciclos son conjugados en $\mathcal{A}_{5}$. Sea $g = (1,2,3)$. Sabemos de~\ref{eq:excentra} que $C_{S_{5}}(g)= \langle g\rangle \langle(4,5) \rangle$. Ahora, $$\langle g \rangle \subseteq C_{\mathcal{A}_{5}}(g) \leq C_{S_{5}}(g)$$ puesto que $(4,5) \in C_{S_{5}}(g) \setminus \mathcal{A}_{5}$. Como $|C_{S_{5}}(g)| = 6$, concluimos que $C_{\mathcal{A}_{5}}(g) = \langle g \rangle$. Por lo tanto, $|Cl_{\mathcal{A}_{5}}(g)| = 60/3 = 20.$ 

Veamos ahora que los $15$ elementos del tipo $(a,b)(c,d)$ son conjugados en $\mathcal{A}_{5}$. Nuevamente por~\ref{eq:excentra} tenemos que $$\langle (1,2)(3,4),(1,3)(2,4) \rangle \subseteq C_{\mathcal{A}_{5}}((1,2)(3,4)) \leq C_{S_{5}}((1,2)(3,4))$$ puesto que $(1,3,2,4) \in C_{S_{5}}((1,2)(3,4)) \setminus \mathcal{A}_{5}$. Como $|C_{S_{5}}((1,2)(3,4))| = 8$, concluimos que $|C_{\mathcal{A}_{5}}((1,2)(3,4))| = 4$ y así la clase de conjugación de $(1,2)(3,4)$ en $\mathcal{A}_{5}$ tiene $15$ elementos. (Esto también se puede ver teniendo en cuenta que todas las permutaciones de tipo $[2,2]$ son pares, es decir, que todas forman parte del grupo alternado).

Finalmente, notamos que hay dos clases de conjugación en $\mathcal{A}_{5}$ de $5$-ciclos. En efecto, sabemos que si $g$ es un $5$-ciclo, entonces $C_{S_{5}}(g) = \langle g \rangle = C_{\mathcal{A}_{5}}(g)$. Así, $|Cl_{\mathcal{A}_{5}}(g)| = 12$. Por tanto, las longitudes de las clases de conjugación de $\mathcal{A}_{5}$ son $1,12,12,15$ y $20$.

Sea ahora $N$ un subgrupo normal propio de $\mathcal{A}_{5}$. Tenemos que $N$ es una unión disjunta de clases de conjugación de $\mathcal{A}_{5}$ (siendo una de ellas el $1$) y que $1 < |N| < 60$ es un divisor de $60$. Por lo tanto, $$|N| = 1 + 12a + 12b + 15c + 20d,$$ con $a,b,c,d \in \lbrace 0, 1 \rbrace$. Pero no hay ningún divisor de $60$ de esta forma quitando el $1$ y el propio $60$. Luego no existe $N$ subgrupo normal propio y así $\mathcal{A}_{5}$ es simple.

\textbf{\textit{Probaremos ahora que $\mathcal{A}_{n}$ es simple}} para $n \geq 6$ por inducción sobre $n$. Supongamos que $n \geq 6$ y que $\mathcal{A}_{n-1}$ es simple. Sabemos que $\mathcal{A}_{n}$ actúa sobre $\lbrace 1,2, \ldots, n \rbrace$. Sea $K$ el estabilizador de $n$ en $\mathcal{A}_{n}$. Sea $K$ el estabilizador de $n$ en $\mathcal{A}_{n}$. Como hicimos en~\ref{eq:obsabel} para cada $\sigma \in K$, tenemos definido un $\bar{\sigma} \in S_{n-1}$. Como la descomposición de $\sigma$ y $\bar{\sigma}$ como producto de ciclos disjuntos es la misma entonces $\sigma$ es par si y sólo si $\bar{\sigma}$ lo es. Por lo tanto $K \cong \mathcal{A}_{n-1}$ es simple.

Por el resultado anterior $\mathcal{A}_{n}$ actúa transitivamente sobre $\lbrace 1, 2, \ldots, n \rbrace$ y por~~sabemos que todos los estabilizadores son conjugados en $\mathcal{A}_{n}$. Por lo tanto, si $\sigma \in \mathcal{A}_{n}$ fija algún elemento, entonces $\sigma \in K^{\tau}$ para cierto $\tau \in \mathcal{A}_{n}$.

Sea ahora $N\unlhd \mathcal{A}_{n}$. Entonces $K \cap N \unlhd K$ y por la simplicidad de $K$ concluimos que $K \subseteq N$ ó $K \cap N = 1$. En el primer caso tenemos que $K^{\tau} \subseteq N$ para todo $\tau \in \mathcal{A}_{n}$. Por lo tanto, si una permutación $\sigma \in \mathcal{A}_{n}$ fija un elemento, entonces $\sigma \in N$. En particular, $N$ contiene todos los productos $(a,b)(c,d)$. Como toda permutación par es producto de un número par de transposiciones tenemos entonces que $N = \mathcal{A}_{n}$ en este caso.

En el segundo caso, $K \cap N = 1$. Por lo tanto, $K^{\tau} \cap N = (K \cap N)^{\tau} = 1$ para todo $\tau \in \mathcal{A}_{n}$. Es decir, si $1 \neq \sigma \in \mathcal{A}_{n}$ fija algún elemento, entonces $\sigma$ no está en $N$. 

Supongamos que $N > 1$ y sea $1 \neq \sigma \in N$. Supongamos primero que en la descomposición de $\sigma$ como producto de ciclos disjuntos solo aparecen transposiciones. Tenemos que $\sigma = (a,b)(c,d) \cdots$. Sea $e$ una cifra distinta de $a,b,c,d$. Entonces $$\gamma = \sigma^{(a,b)(d,e)}=(b,a)(c,e) \cdots \in N.$$
Ahora $\sigma \gamma \in N$, $\sigma \gamma$ fija $a$ y $1 \neq \sigma \gamma$ (ya que manda $d$ a $e$). Esto es una contradicción. Finalmente, supongamos que en la descomposición de $\sigma$ como producto de ciclos disjuntos tenemos un $m$-ciclo con $m \geq 3$. Podemos escribir $\sigma (a,b,c, \ldots) \cdots$. Elegimos ahora dos cifras $d,e$ distintas de $a,b,c$ y escribimos $$\gamma = \sigma^{(c,d,e)} = (a,b,d, \ldots) \cdots \in N.$$ Tenemos que $\gamma \neq \sigma$ y $1 \neq \sigma \gamma^{-1} \in N$ fija $a$. Esta contradicción final prueba el teorema.

$\hfill \square$

\subsection{Teoremas de Sylow}

Empezaremos con un resultado que es consecuencia de lo visto ahora y que básicamente nos dice que si tenemos un grupo de orden primo o múltiplo entonces contendrá un elemento de orden ese primo. Es el conocido como \textit{Teorema de Cauchy}, que lo probaremos primero para grupos abelianos y más tarde generalizaremos a todos.

\begin{theorem}[\textit{\textbf{Teorema de Cauchy para grupos abelianos.}}]
Sea $G$ un grupo abeliano finito, y $p$ un número primo que divide al orden de $G$. Entonces existirá un $x \in G$ tal que $o(x) = p$.
\end{theorem}
\emph{Demostración: } Lo haremos por inducción sobre $|G|$. Sea $H$ un subgrupo propio de $G$ de orden lo mayor posible. Si $p \mid |H|$, por hipótesis de inducción existirá un $x \in H \subset G$ tal que $o(x) = p$. Por lo tanto podemos suponer que $ p \nmid |H|$. Como $p \mid |G| = |G/H| |H|$ por el \textit{Teorema de Lagrange} (además podemos hacer el cociente porque al ser $G$ abeliano todo subgrupo es normal), y esto quiere decir que $p \mid |G/H|$. Además, como $H$ es de orden lo mayor posible entre los subgrupos de $G$, por el \textit{Teorema de la correspondencia} $G/H$ no tiene subgrupos propios no triviales y por tanto es simple.

Así, ahora partimos de que $G/H$ es simple y abeliano y que  $p \mid |G/H|$. Como los grupos simples abelianos son cíclicos de orden primo tenemos que $$G/H \cong C_{p}.$$ Sea $H \neq xH \in G/H$. Entonces es claro que $o(xH) = p$. Tenemos un elemento de orden $p$ dentro del cociente y queremos encontrar un elemento de orden $p$ dentro del grupo. Para ello construiremos el homomorfismo sobreyectivo que ya conocemos $$\begin{array}{rccl}
\pi \colon &G & \longrightarrow & G/H\\
&x & \longmapsto &xH
\end{array}
$$ y de las propiedades de los homomorfismos sabemos que $p = o(xH) = o(\pi(x)) \mid o(x)$. Esto quiere decir que $p \mid o(x)$ y así $x^{o(x)/p} \in G$ de orden $p$, ese es el elemento que buscábamos.

$\hfill \square$

Ahora, el resultado general:

\begin{theorem}[\textbf{\textit{Teorema de Cauchy.}}]
Sea $G$ un grupo finito y $p$ un número primo que divide al orden de $G$. Entonces existirá un $x \in G$ tal que $o(x) = p$.
\end{theorem}
\emph{Demostración: } Lo haremos nuevamente por inducción sobre $|G|$. Si existe un subgrupo propio $H$ de $G$ tal que $p \mid |H|$ ya hemos terminado, puesto que existirá un $x \in H \subset G$ tal que $o(x) = p$. Así, podemos suponer que $p \nmid |H|$ para todo $H$ subgrupo propio de $G$. Ahora, de la ecuación de clases: $$|G| = |Z(G)| + \sum_{i = 1}^{t}  \left[ G:C_{G}(x_{i}) \right]$$ sabemos que como $\left[ G:C_{G}(x_{i}) \right]>1$ entonces $p \nmid |C_{G}(x_{i})|$ $\forall i$, pero a la vez también $p \mid |G|$, esto quiere decir que $p \mid  \left[ G:C_{G}(x_{i}) \right]$ $\forall i$.

Como $p \mid |G|$ y $p \mid  \left[ G:C_{G}(x_{i}) \right]$ entonces necesariamente $p \mid |Z(G)|$, pero como $p$ no divide al cardinal de ningún subgrupo propio tenemos que $Z(G) = G$ y así $G$ es abeliano. Por el resultado para grupos abelianos tenemos éste.

$\hfill \square$

De aquí podemos sacar la siguiente conclusión interesante: \textbf{\textit{dado un grupo finito $G$ y $p$ un número primo, si $p$ no divide al orden de ningún subgrupo propio de $G$ entonces éste será abeliano.}}

Pasemos ya con las definiciones que emplearemos y con las que trabajaremos a partir de ahora:

\begin{definition} Sea $G$ un grupo finito, y $p$ un número primo que divide al orden de $G$. Por tanto $|G| = p^{n}m$, con $m$ y $n$ enteros positivos tales que $p$ no divide a $m$, es decir, $mcd(p,m)=1$. Notar que $n\neq0$. Sea $H$ subgrupo de $G$. Entonces:
\begin{enumerate}
\item Diremos que $H$ es un \textbf{$p$-subgrupo} de $G$ si el orden de $H$ es potencia de $p$, es decir, $|H| = p^{r}$ con $r \geq 0.$
\item Diremos que $H$ es un \textbf{$p$-subgrupo de Sylow} de $G$ si $H$ es un $p$-subgrupo de $G$ y $\left[ G:H \right]$ no es múltiplo de $p$, es decir, $|H| = p^{n}$ (la máxima potencia de $p$ que divide al orden de $G$). Al conjunto de todos los $p$-subgrupos de Sylow de $G$ los denotaremos por $$Syl_{p}(G) = \lbrace H \leq G : |H| = p^{n} \rbrace.$$
\end{enumerate}
\end{definition}

El objetivo fundamental de esta sección es demostrar que los subgrupos de Sylow siempre existen ($Syl_{p}(G) \neq \lbrace \emptyset \rbrace$, $\forall p$) y que son conjugados entre sí. 

\begin{theorem}[\textit{\textbf{Primer Teorema de Sylow}}]
Sea $G$ un grupo finito y $p$ un número primo, entonces $G$ tiene un $p$-subgrupo de Sylow.
\end{theorem}
\emph{Demostración: }Lo haremos por inducción sobre el orden de $G$. Si $|G| = 1$, entonces es evidente. Supongamos ahora que todos los grupos de orden menor que $|G|$ tienen $p$-subgrupos de Sylow y veamos que $G$ también los tiene.
Si $p \nmid |G|$ entonces el subgrupo trivial es un $p$-subgrupo de Sylow de $G$. Por lo que supongamos que $p \mid |G|$, así $|G| = p^{n}m$ con $p$ no dividiendo a $m$ ($mcd(p,m)=1$). Entonces, podemos distinguir dos casos: 

Primero, que exista un subgrupo $H \leq G$ tal que $p \nmid [G:H]$. Entonces es claro que $p^{n} \mid |H|$ y por hipótesis de inducción se tiene que $H$ tiene un $p$-subgrupo de Sylow de orden $p^{n}$, que llamaremos $P$ y que también será $p$-subgrupo de Sylow de $G$ .

Segundo, que para todo subgrupo $H$ de $G$, $p \mid [G:H]$. Entonces, por la ecuación de clases~\ref{eq:ecClases} tenemos que $p \mid |Z(G)|$, y como éste es un grupo abeliano entonces tiene un elemento de orden $p$, ó equivalentemente tiene un subgrupo $H \leq Z(G)$ de orden $p$. Como todos los elementos de $H$ conmutan con todos los elementos de $G$ entonces es claro que $H^{g} = H$ para todo $g \in G$, es decir, $H \unlhd G$. Se cumple que $[G:H] = p^{n-1}m$ y tiene un subgrupo de Sylow $P/H$ que cumplirá $[P:H] = p^{n-1}$, por lo que $|P| = p^{n}$ y así $P$ es un $p$-subgrupo de Sylow de $G$.

$\hfill \square$

\begin{theorem}[\textbf{\textit{Segundo Teorema de Sylow}}]Si $G$ es un grupo finito, entonces todo $p$-subgrupo de $G$ está contenido en un $p$-subgrupo de Sylow y dos $p$-subgrupos de Sylow cualesquiera son conjugados.

\end{theorem}
\emph{Demostración: }Sea $P$ un $p$-subgrupo de Sylow de $G$ y sea $H$ un $p$-subgrupo arbitrario. Entonces $H$ actúa sobre $\Omega= G/\sim_{P}$ por multiplicación a izquierda como vimos en el primer ejemplo de~\ref{eq:ejcorazon}. Por el teorema de la órbita estabilizadora tenemos que las órbitas de $\Omega$ tienen cardinal potencia de $p$ (incluyendo $p^{0}=1$). De hecho, alguna órbita ha de tener cardinal $1$, pues de lo contrario el cardinal de $\Omega$, que es $[G:P]$, sería suma de potencias (no triviales) de $p$, así sería múltiplo de $p$.

Por lo tanto, existirá un $g \in G$ tal que la clase de conjugación $x = gP$ formará una órbita trivial, con $x$ como único elemento. Concretamente $hgP = gP$ para todo $h \in H$. En particular $hg \in gP$ y así $h \in P^{g}$ para todo $h \in H$. De aquí $H \leq P^{g}$ y así $P^{g}$ es también $p$-subgrupo de Sylow.

En caso de que $H$ sea un $p$-subgrupo de Sylow de $G$, entonces ha de darse la igualdad $H = P^{g}$, puesto que tenemos una inclusión y ambos tienen el mismo orden.

$\hfill \square$

Por lo tanto, queda claro que los $p$-subgrupos de Sylow forman una órbita en la acción de $G$ sobre el conjunto de todos sus subgrupos por conjugación. Luego, \textbf{\textit{si $P$ es un $p$-subgrupo de Sylow entonces el número total de $p$-subgrupos de Sylow es $[G: N_{G}(P)]$. Éste número es un divisor del orden de $G$ y también de $[G:P]$.}}

\begin{corolario}Sean $p$ un número primo y $G$ un grupo finito cuyo orden es $|G| = p^{n}m$, donde $m$ y $n$ son enteros positivos y $p$ no divide a $m$. Sea $H$ un $p$-subgrupo de Sylow de $G$. Entonces $H$ es subgrupo normal si y sólo si es el único $p$-subgrupo de Sylow de $G$.
\end{corolario}
\emph{Demostración: }Los $p$-subgrupos de Sylow de $G$ son, por el \textit{Segundo Teorema de Sylow}, los subgrupos de $G$ conjugados de $H$, y coinciden todos con $H$ si y sólo si éste es normal. Es, por tanto, consecuencia inmediata de la definición de subgrupo normal y del \textit{Segundo Teorema de Sylow}.

$\hfill \square$

\begin{definition}Los grupos finitos con un único $p$-Sylow para cada divisor primo $p$ de $|G|$ se llaman \textbf{grupos nilpotentes finitos}.
\end{definition}

Finalmente veremos el último de los teoremas de Sylow:

\begin{theorem}[\textit{\textbf{Tercer Teorema de Sylow}}]
El número $v_{p}$ de $p$-subgrupos de Sylow de un grupo finito cumple que $v_{p} \equiv 1$ mod $p$.
\end{theorem}
\emph{Demostración: }Sea $G$ un grupo finito y $\Omega$ el conjunto de sus $p$-subgrupos de Sylow. Sea un $P \in \Omega$ y consideremos la acción de $P$ sobre $\Omega$ por conjugación. Ya sabemos que $v_p = [G:N_G(P)]$. Es claro que $P^{g}=P$ para todo $g \in P$, luego la órbita de $P$ es trivial. Veamos que es la única. Si $Q \in \Omega$ cumple que $Q^{g} = Q$ para todo $g \in P$, entonces $P \leq N_{G}(Q)$ y así $P$ y $Q$ son $p$-subgrupos de Sylow de $N_{G}(Q)$, luego son conjugados en $N_{G}(Q)$. Así, existe un $g \in N_{G}(Q)$ tal que $P = Q^{g}= Q$.

Las órbitas que la acción de $P$ forma en $\Omega$ tienen cardinal potencia de $p$, y se ha visto que la única que tiene cardinal $1$ es la de $P$, luego $v_{p}=|\Omega| \equiv 1$ mod $p$.

$\hfill \square$

La última de las consecuencias es equivalente a decir que $\left[ G:N_{G}(P) \right] \equiv 1$ $mod$ $p$, con $P$ un $p$-subgrupo de Sylow de $G$.

\subsection{Resolubilidad}

\begin{definition}Un grupo $G$ se dice \textbf{resoluble} si existen subgrupos $$1 = G_0 \unlhd G_1 \unlhd \ldots \unlhd G_{k-1} \unlhd G_{k} = G$$ tales que $G_{i+1}/G_i$ es abeliano para todo $i= 0, \ldots, k-1$. Como $G_{i+1}/G_i$ es abeliano si y sólo si $$xG_iyG_i = yG_ixG_i$$ para todo $x,y \in G_{i+1}$, concluimos que $G_{i+1}/G_i$ es abeliano si y sólo $xyx^{-1}y^{-1} \in G_i$ para todo $x,y \in G_{i+1}$.
\end{definition}

La importancia de este concepto es fundamental en álgebra abstracta, ya que a cada \textit{ecuación polinómica} de la forma $$a_{n}x^{n} + \ldots + a_{1}x + a_{0} = 0, \hspace{0.2cm} a_{0}, \ldots , a_{n} \in \mathbb{Q}$$ se le puede asociar un grupo, y que dicho grupo sea resoluble es condición necesaria y suficiente para que las soluciones de la ecuación polinómica anterior se puedan expresar mediante sumas, restas, multiplicaciones, divisiones y extracción de raíces de números racionales. A esto se le conoce como \textit{ser resoluble por radicales}, y es ésta la razón de llamar así a estos grupos, porque podríamos resumirlo en: \textit{ecuación resoluble por radicales} $\Longleftrightarrow$ \textit{grupo asociado resoluble}. Esto es lo que se desarolla y estudia en el seno de la \textit{Teoría de Galois}. Podríamos considerar los grupos y su teoría como un ¿ingrediente? más, bastante potente y uno de los pilares, pero no el único. Como acabamos de ver los polinomios también juegan un papel central, y para poder relacionarlo con todo lo visto necesitaremos entender qué son y sobre qué estructuras se definen, pero eso lo veremos en la sección de anillos.

\begin{proposition} \label{eq:reso1} Sea $G$ un grupo.
\begin{enumerate}
\item Si $H \leq G$ y $G$ es resoluble, entonces $H$ es resoluble.
\item Supongamos que $N \unlhd G$. Entonces $G$ es resoluble si y sólo si $N$ y $G/N$ son resolubles.
\end{enumerate}
\end{proposition}
\emph{Demostración: }Supongamos que $$1 = G_0 \unlhd G_1 \unlhd \ldots \unlhd G_{k-1} \unlhd G_k = G$$ son tales que $G_{i+1}/G_i$ es abeliano para todo $i = 0, \ldots, k-1$. Por tanto, $xyx^{-1}y^{-1} \in G_i$ para todos $x,y \in G_{i+1}$ y para todo $i = 0, \ldots, k -1$.

Supongamos ahora que $H \leq G$. Sea $H_i = H \cap G_i$ para $i = 0, \ldots, k$. Tenemos que $H \cap G_{i+1} \leq G_{i+1}$ y $G_i \unlhd G_{i+1}$. Por el \textit{Segundo Teorema de Isomorfía}, tenemos que $H_i = H \cap G_i \unlhd H \cap G_{i+1} = H_{i+1}$ y $$H_{i+1}G_i/G_i \cong H_{i+1}/H_{i}.$$

Este grupo es abeliano ya que es isomorfo a un subgrupo de $G_{i+1}/G_i$. Tenemos que la serie $1 = H_0 \unlhd H_1 \unlhd \ldots \unlhd H_{k-1} \unlhd H_k = H,$ es tal que $H_{i+1}/H_{i}$ es abeliano. 

Supongamos ahora que $N \unlhd G$. Como $G_i \unlhd G_{i+1}$, se tiene que $NG_i \unlhd NG_{i+1}$ por~\ref{eq:ej218}. Por tanto, $NG_i/N \unlhd NG_{i+1}/N$ por~\ref{eq:ej32}. Así, tenemos una serie $$N = NG_0/N \unlhd NG_1/N \unlhd \ldots \unlhd NG_{k-1}/N \unlhd NG_k/N = G/N.$$ Notar que $NG_{i+1}/N = \lbrace Nx : x \in G_{i+1} \rbrace$. Ahora, $$(Nx)(Ny)(Nx)^{-1}(Ny)^{-1} = Nxyx^{-1}y^{-1} \in NG_i/N, \quad \forall x,y \in G_{i+1}.$$ Esto prueba que $G/N$ es resoluble. 

Supongamos finalmente que $N$ y $G/N$ son resolubles. Entonces existen series $$1 = N_0 \unlhd N_1 \unlhd \ldots \unlhd N_k = N$$ $$N = G_0 \unlhd G_1/N \unlhd \ldots \unlhd G_n/N = G/N$$ tales que $N_{i+1}/N_i$ y $(G_{j+1}/N)/(G_j/N)$ son abelianos para $i = 0, \ldots, k-1$ y $j = 0, \ldots, n-1$. Como $G_{j+1}/G_j \cong (G_{j+1}/N)/(G_j/N)$ por el \textit{Tercer Teorema de Isomorfía} la serie $$1 = N_0 \unlhd \ldots \unlhd N_k = N = G_0 \unlhd G_1 \unlhd \ldots \unlhd G_n = G$$ prueba que $G$ es resoluble.

$\hfill \square$

\begin{proposition}Si $G$ es un grupo nilpotente finito, entonces $G$ es resoluble.
\end{proposition}
\emph{Demostración: }Por inducción sobre $|G|$. Sea $p$ un divisor primo de $|G|$. Si $G$ es un $p$-grupo, por~\ref{eq:cor412} podemos hallar subgrupos $$1 = G_0 \leq G_1 \leq\ldots \leq G_k = G$$ tales que $[G_{i+1}:G_i] = p$, con $i=0, \ldots, k-1$. Por~\ref{eq:cor411}, tenemos que $G_i \unlhd G_{i+1}$. Por tanto, $G_{i+1}/G_i$ es cíclico de orden $p$ y $G$ es resoluble. 

Por tanto, podemos suponer que $G$ no es un $p$-grupo. Sea $P \in Syl_p(G)$. Tenemos que $G/P$ es nilpotente. Por inducción, $G/P$ es resoluble. Como ya sabemos que $P$ es resoluble, el resultado queda demostrado aplicando el segundo apartado del resultado anterior. 

$\hfill \square$

Ahora podemos redefinir la caracterización de los grupos resolubles: 

\begin{theorem}
Un grupo finito $G$ es resoluble si y sólo si $G$ tiene una serie $$1 = G_0 \unlhd G_1 \unlhd \ldots \unlhd G_k =G,$$ donde $G_{i+1}/G_i$ es cíclico de orden primo, con $i= 0, \ldots, k-1$.
\end{theorem}
\emph{Demostración: }Si $G$ tiene tal serie está claro que es resoluble. Para ver el recíproco, lo probaremos por inducción sobre $|G|$. Por ser $G$ resoluble, existe $N \unlhd G$ de orden más pequeño que el orden de $G$ tal que $G/N$ es abeliano. Sea $M/N$ un subgrupo propio de $G/N$ de orden el más mayor posible. Por el \textit{Teorema de la correspondencia} y de~\ref{eq:abSimple} tenemos que $G/M$ es cíclico de orden primo. Ahora, por la primera parte de~\ref{eq:reso1}, $M$ es resoluble y aplicamos la hipótesis de inducción.

$\hfill \square$

\begin{proposition}Si $n\geq 5$, entonces $S_n$ no es resoluble.
\end{proposition}
\emph{Demostración: }Si $S_n$ es resoluble, entonces $A_n$ es resoluble aplicando la primera parte de~\ref{eq:reso1}. Por tanto, existe $N \unlhd A_n$, tal que $A_n/N$ es abeliano. Como $A_n$ es simple, tenemos que $N = 1$. Pero $A_n$ no es abeliano, contradicción

$\hfill \square$

\newpage
\section{Anillos}
\subsection{Generalidades}

\begin{definition} Decimos que un \textbf{conjunto $A$} dotado de dos operaciones, que usualmente denominaremos suma y producto, $$\begin{array}{rccl}
+ \colon &A \times A & \longrightarrow & A\\
&(a,b) & \longmapsto &a+b
\end{array}
$$
$$\begin{array}{rccl}
\cdot \colon &A \times A & \longrightarrow & A\\
&(a,b) & \longmapsto &ab
\end{array}
$$
es un \textbf{anillo} si cumple que \begin{enumerate}
\renewcommand{\theenumi}{\roman{enumi}}
\item $A$ dotado de la suma es un \textbf{grupo conmutativo}, es decir, \begin{itemize}
\item La suma cumple las propiedades asociativa y conmutativa.
\item Existe un único elemento $0 \in A$ tal que $a + 0 = 0 + a = a\hspace{0.2cm} \forall a \in A$, que denominaremos \textbf{elemento neutro ó cero}.
\item Para todo $a \in A$ existe un único elemento $b$ tal que $a + b = b +a = 0$, que denominaremos \textbf{elemento opuesto} y denotaremos por $-a$.
\end{itemize}
\item $A$ dotado del producto es un \textbf{semigrupo}, es decir, que el producto cumple la propiedad \textbf{asociativa}. Dados $a, b, c \in A$, entonces se tiene que $$a(bc)= (ab)c.$$
\item La propiedad \textbf{distributiva} del producto con respecto a la suma, es decir que dados $a,b,c \in A$, tenemos que $$(a+b)c = ac+bc, \hspace{0.3cm} a(b+c) = ab+ac.$$
\end{enumerate}
Además es importante matizar que el elemento neutro para la suma, el cero, podrá escribirse como $0_{A}$ o simplemente $0$. Denotaremos por $A^{\ast} = A\setminus \lbrace 0 \rbrace.$ Y, como en grupos, la operación conocida como producto podrá denotarse con un $\cdot$ en ocasiones o con simple yuxtaposición.

Finalmente, una notación usual para los anillos será ($A$, $+$, $\cdot$), que incluye el conjunto y las dos operaciones dotadas.
\end{definition}

\begin{definition} Llamaremos \textbf{anillo unitario} a un anillo $A$ que posea \textbf{elemento unidad}, es decir,si existe $1_{A} = 1 \in A$ tal que $1 \cdot a = a \cdot 1 = a$ \hspace{0.1cm} $\forall a \in A$. También se puede denominar uno.
\end{definition}

Aclaremos algo desde el principio: si tenemos un anillo $A$, utilizaremos la notación aditiva en el grupo abeliano, es decir hablaremos de $(A,+)$, $0$ será el neutro y $-r$ el opuesto de un $r \in A$ cualquiera. Dado un $n \in \mathbb{Z}$ también tendremos definido $nr$.

\begin{observation} Notar que podría ocurrir que $1 = 0$, y entonces $A = \lbrace 0 \rbrace$ ya que si $x \in A$ entonces $0 =  0 \cdot x = 1 \cdot x = x$. Así que para evitar este tipo de confusiones supondremos que $0 \neq 1$.
\end{observation}

A lo largo de las siguiente páginas siempre trabajaremos con anillos unitarios, y en este tipo de anillos podremos distinguir un tipo especial de elementos: 

\begin{definition}Sea $A$ un anillo unitario. Una \textbf{unidad} de $A$ es un elemento $a \in A$ para el que existe un $b \in A$ tal que $$ab = ba = 1.$$ Es decir, $b$ será el \textbf{inverso} de $a$ con respecto al producto. Lo denotaremos por $a^{-1}$, y observar que si ciertos $a, b, c \in A$ verifican $ab = ca = 1$, entonces $$c = c(ab) = (ca)b = b.$$ Por lo que, de existir el inverso, será único. El conjunto de todas las unidades de $A$ lo denotaremos por $\mathcal{U}(A)$, que es un grupo con la operación producto. En efecto, dados $a,b \in \mathcal{U}(A)$, entonces $$(ab)(b^{-1}a^{-1}) = a(bb^{-1})a^{-1} = aa^{-1} = 1 = b^{-1}b = b^{-1}(a^{-1}a)b = (b^{-1}a^{-1})(ab).$$ De aquí deducimos que $(ab)^{-1} = b^{-1}a^{-1}$ y así $ab$ es invertible, luego $ab \in \mathcal{U}(A)$. Como es evidente que si $a \in \mathcal{U}(A)$ entonces $a^{-1} \in \mathcal{U}(A)$ entonces es claro que $\mathcal{U}(A)$ es grupo.

Finalmente, diremos que un anillo es \textbf{conmutativo} si se cumple, para cualesquiera $a,b \in A$ que $$ab = ba.$$
\end{definition}

\begin{observation}Es importante tener en cuenta que a lo largo de las siguientes páginas en ocasiones podremos escribir $x/y$ en vez de $xy^{-1}$, siempre que $x \in A$ e $y \in \mathcal{U}(A)$.
\end{observation}

\begin{definition} Llamaremos \textbf{cuerpo} a un anillo $K$ tal que $K^{\ast} = K \setminus \lbrace 0 \rbrace$ forma un grupo con la multiplicación. Dicho de otra forma, en todo anillo unitario vamos a tener que $\mathcal{U}(A) \subseteq A^{\ast}$, y los cuerpos son aquellos anillos unitarios $K$ tales que $\mathcal{U}(A) = K^{\ast}$. De igual manera que para anillos, también podremos definir los \textbf{cuerpos conmutativos} como aquellos que, para cualesquiera $a,b \in K$ se tiene que $$ab = ba.$$
Además, un elemento $a \in A$ diremos que es \textbf{idempotente} si $a^{2} = a$. Y diremos que es \textbf{nilpotente} si existe un entero positivo $n$ tal que $a^{n} = 0$. Un anillo cuyo único elemento nilpotente sea el $0$ se dirá \textbf{reducido}.
\end{definition}

Más adelante veremos un ejemplo bastante interesante de anillo en el que todos sus elementos son idempotentes.

\begin{properties}Algunas propiedades básicas: \begin{enumerate}
\item Para cada $a \in A$ y $n,m$ enteros, podremos definir $$na = \overbrace{a+ \ldots +a}^{n}$$ $$a^{n} = \overbrace{a \cdots a}^{n}$$ y se cumplirán las siguientes propiedades: $$a^{n+m} = a^{n}a^{m}$$ $$a^{nm} = (a^{n})^{m}.$$
\item Si $a,b \in A$ y tenemos que $ab = ba$, entonces se cumplirá la conocida como \textbf{Fórmula de Newton}:
$$(a+b)^{n} = \sum_{k=0}^{n} {n \choose k}a^{n-k}b^{k}.$$ Y esto es así ya que, como $ab = ba$, el producto $(a+b)\cdots(a+b)$ es, por la propiedad distributiva, una suma de productos de la forma $a^{k}b^{n-k}$, con $0 \leq k \leq n$, cada uno de ellos obtenido al seleccionar un $a$ en $k$ de los factores $(a+b)$ y un $b$ en los restantes. Y el número de sumandos de esta forma es igual al número de maneras de elegir los $k$ factores, de entre los $n$ dados, en los que el elemento seleccionado es $a$, es decir ${n \choose k}$.
\end{enumerate} 
\end{properties}

Una vez vistas las primeras definiciones, veamos algunos ejemplos clásicos de anillos:

\begin{example}\label{eq:ejemploAnillos} Algunos de estos ejemplos ya los conocemos, de hecho algunos son bastante familiares: \begin{enumerate}
\item El conjunto $\mathbb{Z}$ de los números enteros, dotado con la suma y producto habituales, es un anillo conmutativo y unitario. Sus únicas unidades son $1$ y $-1$, por lo que no es un cuerpo.
\item Los números pares, $2\mathbb{Z}$, constituyen un anillo conmutativo pero no unitario, puesto que no existe ningún elemento $u \in 2\mathbb{Z}$ de la forma $2z$ con $z$ algún entero, tal que $2z \cdot 2a = 2a$ con $a \in \mathbb{Z}$.
\item Los cocientes de $\mathbb{Z}$, $\mathbb{Z}/n\mathbb{Z}$, con $n \in \mathbb{N}$, también forman un anillo cuyas unidades serán todos los elementos $a+n\mathbb{Z}$ tales que $mcd(a,n)=1$. Más adelante veremos detalladamente este anillo, que es bastante interesante. De hecho si $n$ es primo también será un cuerpo.
\item Los conjuntos $\mathbb{Q}, \mathbb{R}$ y $\mathbb{C}$ de los números racionales, reales y complejos respectivamente son cuerpos conmutativos.
\item Sea $A$ el conjunto de los números complejos $a +bi$, con $a,b \in \mathbb{Z}$. Como $i^{2} = -1$, este conjunto $A$ es un anillo con las operaciones heredadas de $\mathbb{C}$. Tenemos que $$(a+bi)(c+di) = ac + adi + bci + bdi^{2} = (ac-bd) + (ad+bc)i \in A.$$ A este anillo se le denota $\mathbb{Z}[i]$ y a estos números se les conocen como \textbf{enteros de Gauss}.
$$\mathbb{Z}[i]=\lbrace a+bi, a,b \in \mathbb{Z} \rbrace.$$
\item Sean $A$ un anillo y $M_{2} = M_{2}(A)$ el conjunto de las matrices cuadradas de orden $2$ de elementos de $A$. Este conjunto es un anillo con la suma y producto como siguen:  $$\left(
\begin{matrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{matrix}
\right) + \left(
\begin{matrix}
b_{11} & b_{12} \\
b_{21} & b_{22}
\end{matrix}
\right) = \left(
\begin{matrix}
a_{11} + b_{11} & a_{12} + b_{12}\\
a_{21} +b_{21} & a_{22} + b_{22}
\end{matrix}
\right)$$ 

$$\left(
\begin{matrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{matrix}
\right) \cdot \left(
\begin{matrix}
b_{11} & b_{12} \\
b_{21} & b_{22}
\end{matrix}
\right) = \left(
\begin{matrix}
a_{11}b_{11} + a_{12}b_{21} & a_{11}b_{12} + a_{12}b_{22}\\
a_{21}b_{11} + a_{22}b_{21} & a_{21}b_{12} + a_{22}b_{22}
\end{matrix}
\right).$$
Además este anillo será unitario si y sólo si $A$ lo es. En cuyo caso, el elemento unidad ó uno será $$1_{M_{2}} =  \left(
\begin{matrix}
1 & 0 \\
0 & 1
\end{matrix} 
\right).$$ A partir de aquí, calculemos las unidades. Para esto, vamos a considerar el \textbf{determinante} de una matriz $a =\left(
\begin{matrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{matrix}
\right) \in M_{2}$ cualquiera, que ya conocemos, y en este caso lo vamos a definir como sigue: $$\delta = det(a) =a_{11}a_{22} -a_{12}a_{21}$$ y consideremos $$b = \left(
\begin{matrix}
a_{22} & -a_{12} \\
-a_{21} & a_{11}
\end{matrix}
\right).$$ Entonces, por como hemos elegido las matrices, tenemos fácilmente que $$a\cdot b = \left(
\begin{matrix}
\delta & 0 \\
0 & \delta
\end{matrix}
\right).$$ Así, si $\delta \in \mathcal{U}(A)$, entonces $a$ será una unidad y tendremos que $$a^{-1} = \left(
\begin{matrix}
a_{22}/\delta & -a_{12}/\delta \\
-a_{21}\delta & a_{11}/\delta
\end{matrix}
\right).$$ Recíprocamente, si existe $c = a^{-1}$, también existirá $d = b^{-1}$, que se  obtiene de igual forma. Entonces, $$\left(
\begin{matrix}
1 & 0 \\
0 & 1
\end{matrix} 
\right) = d(ca)b = (dc)(ab) = \left( \begin{matrix}
e_{11} & e_{12} \\
e_{21} & e_{22}
\end{matrix}
\right) \left( \begin{matrix}
\delta & 0 \\
0 & \delta
\end{matrix}
\right) = \left( \begin{matrix}
e_{11}\delta & e_{12}\delta \\
e_{21}\delta & e_{22}\delta
\end{matrix}
\right)$$ y, por tanto, $e_{11}\delta = e_{22}\delta = 1$, y así $\delta \in \mathcal{U}(A).$

En resumen, $a \in \mathcal{U}(M_{2})$ si y sólo si $det(a) \in \mathcal{U}(A)$. Por ejemplo, si $A = \mathbb{Z}$, los enteros, $a$ será unidad si y sólo si $det(a) = \pm 1$. Pero si $A = \mathbb{Q}$ (ó cualquier cuerpo), $a$ será unidad si y sólo si $det(a) \neq 0$, ya que en un cuerpo todos los elementos a excepción del $0$ son unidades.

De todo esto podemos decir que el \textbf{determinante} nos puede caracterizar las unidades y nos permite, como ya sabemos del álgebra lineal, el cálculo de inversos. Si lo vemos como un homomorfismo de grupos, es fácil demostrar que, dados $a,b \in M_{2}$ $$det(ab) = det(a)det(b).$$ Finalmente apuntar que todo lo visto en este ejemplo es aplicable para matrices de un orden $n \geq 2$ cualquiera.
\item Denotaremos por $M_n(K)$ al conjunto de las matrices cuadradas de orden $n$ con coeficientes en un cuerpo $K = \mathbb{Q}, \mathbb{R}, \mathbb{C}$. Entonces el conjunto de sus unidades (que de hecho será un grupo) es $GL_n(K)$.  
\item Sea $A = \mathcal{C}(\mathbb{R}, \mathbb{R})$ el conjunto de las funciones continuas reales de variable real. En este caso, dicho conjunto es un anillo; en efecto dados $t \in \mathbb{R}$ y $f,g \in A$, podemos definir las operaciones $$(f+g)(t) = f(t) + g(t)$$ $$(f \cdot g)(t) = f(t) \cdot g(t)$$
Además, es conmutativo y unitario, con el elemento neutro la función constante $$c_{1}(t) = 1.$$
\item Si $A$ es un anillo, podemos construir el \textbf{anillo de polinomios} $A[x]$ sobre $A$. Más adelante detallaremos en una sección propia este particular anillo, pero ahora podemos presentarlo en líneas generales para poder ver algunos resultados referentes a él en las siguientes páginas. 

Un polinomio $p \in A[x]$ es una suma de la forma $$p = \sum_n a_nx^n,$$ con $a_n \in A$ para todo $n$ y donde existe un $m$ tal que $a_n=0$ si $n>m$. En ocasiones también podremos escribir estos elementos como $p(x)$. Si tenemos que $p=a_mx^m+\ldots+a_1x+a_0,$ y $a_m\neq 0$ entonces podremos decir que el \textbf{grado} de $p$, $\delta(p)$, es $m$. También diremos que los términos $a_m,\ldots, a_1, a_0$ son los \textbf{coeficientes} de $p$ y concretamente que $a_m$ es el \textbf{coeficiente director} de $p$. Si este coeficiente director $a_m$ cumple que $a_m =1$ diremos que $p$ es \textbf{mónico}. El polinomio $0$ se suele convenir que tiene grado $-\infty$.

Diremos que dos polinomios $p = \sum_n a_nx^n$, $q = \sum	_n b_nx^n$ son iguales si y sólo si $a_n = b_n$ para todo $n$. También los podremos sumar y multiplicar: $$p+q= \sum_n(a_n+b_n)x^n,$$ $$pq = \sum_n\left(\sum_{i+j=n \atop i,j\geq 0} a_ib_j \right) x^n.$$
\end{enumerate}
\end{example}

$\hfill \blacksquare$

Un anillo clásico muy interesante es el siguiente:

\begin{example}Sea $X$ un conjunto, si consideramos el conjunto de las partes de $X$ $$\mathcal{P}(X) = \lbrace A : A \subseteq X \rbrace,$$ junto con las dos operaciones $$A+B = (A \setminus B) \cup (B \setminus A), \quad \forall A,B \in \mathcal{P}(X),$$ $$A \cdot B = A \cap B, \quad \forall A,B \in \mathcal{P}(X).$$ Entonces $(\mathcal{P}(X), +, \cdot)$ es un anillo conmutativo pero no unitario. A la operación $+$ la denominaremos \textbf{diferencia simétrica}, y se suele representar por $\Delta$.

Veámoslo, para ello definamos la \textbf{función característica de un conjunto}: dado dos conjuntos cualesquiera $A,X$ tales que $A \subseteq X$, 
$$\begin{array}{rccl}
\mathcal{X}_A \colon &X&\longrightarrow &\lbrace 1, 0\rbrace \\
&x& \longmapsto &\mathcal{X}_A(x) = \left\lbrace\begin{array}{c} 1~si~x \in A \\ 0~si~x \notin A \end{array}\right.
\end{array}
$$

Esta función cumple: 
\begin{enumerate}
\item $\mathcal{X}_A = \mathcal{X}_B \Leftrightarrow A = B$. 

En efecto, si $x \in A$, entonces $\mathcal{X}_A(x)=1$. Por hiótesis $\mathcal{X}_A=\mathcal{X}_B$, luego $\mathcal{X}_B(x)=1$, y $x \in B$ y así $A \subseteq B$. Para el otro contenido es análogo. Reciprocamente, por hipótesis $A = B$ y si $x \in A =B$ entonces $\mathcal{X}_A(x) = \mathcal{X}_B(x)=1$. Si $x \notin A = B$ entonces $\mathcal{X}_A(x) = \mathcal{X}_B(x) = 0$. Como $\mathcal{X}_A(x) = \mathcal{X}_B(x) $ para todo $x \in X$ concluimos que $\mathcal{X}_A = \mathcal{X}_B$.
\item $\mathcal{X}_{A^c} = 1- \mathcal{X}_A$.

Si $x \in A$, entonces $x \notin A^c$, luego $\mathcal{X}_A(x)=1$ y $\mathcal{X}_{A^c}(x)=0$, así que $\mathcal{X}_{A^c}(x) =1 - \mathcal{X}_A(x)$. Si $x \notin A$, entonces $x \in A^c$, luego $\mathcal{X}_A(x)=0$ y $\mathcal{X}_{A^c}(x)=1$, así que $\mathcal{X}_{A^c}(x) =1 - \mathcal{X}_A(x)$. Como esto se tiene para todo $x \in X$, concluimos que $\mathcal{X}_{A^c} = 1 - \mathcal{X}_A$.
\item $\mathcal{X}_{A \cap B} = \mathcal{X}_A \cdot \mathcal{X}_B$.

Si $x \in A \cap B$ entonces $x \in A$ y $x \in B$, luego $\mathcal{X}_{A\cap B} = 1$, y $\mathcal{X}_A = 1$, $\mathcal{X}_B=1$. Es decir, si $x \in A \cap B$ entonces $\mathcal{X}_{A\cap B}(x) = \mathcal{X}_A(x) \cdot \mathcal{X}_B(x)$. Por otra parte, si $x \notin \mathcal{X}_{A\cap B}$ entonces $x \notin A$ ó $x \notin B$, luego $\mathcal{X}_{A\cap B}(x)=0$ y ó $\mathcal{X}_A(x)=0$ ó $\mathcal{X}_B(x)=0$. Por lo tanto, si $x \notin A \cap B$ entonces también se tiene que $\mathcal{X}_{A\cap B}(x) = \mathcal{X}_A(x) \cdot \mathcal{X}_B(x)$. Concluimos que $\mathcal{X}_{A\cap B} = \mathcal{X}_A \cdot \mathcal{X}_B$.
\item $\mathcal{X}_{A\cup B} = \mathcal{X}_A + \mathcal{X}_B - \mathcal{X}_A \cdot \mathcal{X}_B$.

Si $x \in A \cup B$ entonces $\mathcal{X}_{A\cup B}(x) = 1$. Según los distintos casos tenemos: si $x \in A \cap B$ entonces $\mathcal{X}_A(x)+ \mathcal{X}_B(x)-\mathcal{X}_A(x) \cdot \mathcal{X}_B(x) = 1+1-1\cdot 1 = 1.$ Si $x \in A$ y $x\notin B$ entonces $\mathcal{X}_A(x)+ \mathcal{X}_B(x)-\mathcal{X}_A(x) \cdot \mathcal{X}_B(x) =1+0 - 1 \cdot 0 = 1$. Si $x \notin A$ y $x \in B$ entonces $\mathcal{X}_A(x)+ \mathcal{X}_B(x)-\mathcal{X}_A(x) \cdot \mathcal{X}_B(x) = 0 + 1 -0 \cdot 1 = 1.$ Si $x \notin A \cup B$, entonces $\mathcal{X}_{A\cup B}(x)=0$, y como $x \notin A$, $x \notin B$: $\mathcal{X}_A(x)+ \mathcal{X}_B(x)-\mathcal{X}_A(x) \cdot \mathcal{X}_B(x) = 0 + 0 - 0 \cdot 0 =0$. Por lo tanto, para todo $x \in X$ se tiene que $\mathcal{X}_{A\cup B}(x)= \mathcal{X}_A(x)+ \mathcal{X}_B(x)-\mathcal{X}_A(x) \cdot \mathcal{X}_B(x)$, luego concluimos que $\mathcal{X}_{A\cup B} = \mathcal{X}_A+ \mathcal{X}_B-\mathcal{X}_A \cdot \mathcal{X}_B$.
\item $\mathcal{X}_{A \Delta B} = \mathcal{X}_A + \mathcal{X}_B - 2 \cdot \mathcal{X}_A \cdot \mathcal{X}_B.$

Para todo $x \in X$ se tiene que $\mathcal{X}_\emptyset(x) = 0$ ya que $ x\notin \emptyset$. Es decir, $\mathcal{X}_\emptyset = 0$. Por los dos apartados anteriores tenemos que $\mathcal{X}_{A\cup B} = \mathcal{X}_A + \mathcal{X}_B - \mathcal{X}_{A\cap B}$ y si $A \cap B = \emptyset$ entonces $\mathcal{X}_{A\cup B} = \mathcal{X}_A + \mathcal{X}_B$. La diferencia simétrica sabemos que la podemos expresar como $(A \setminus B) \cup (B \setminus A)$, siendo esta unión disjunta, luego $\mathcal{X}_{A\Delta B} = \mathbb{X}_{A \setminus B} + \mathcal{X}_{B\setminus A} = \mathcal{X}_{A\cap B^c} + \mathcal{X}_{B\cap A^c} = \mathcal{X}_A \cdot \mathcal{X}_{B^c} + \mathcal{X}_B \cdot \mathcal{X}_{A^c} = \mathcal{X}_A \cdot(1 - \mathcal{X}_B) + \mathcal{X}_B \cdot (1- \mathcal{X}_A) = \mathcal{X}_A + \mathcal{X}_B -2 \cdot \mathcal{X}_A \cdot \mathcal{X}_B$.
\end{enumerate}

Comprobemos ahora que es un anillo: 
\begin{enumerate}
\item La propiedad más costosa de ver es la asociativa para $+$, que sabemos que es la diferencia simétrica $\Delta$, así que todo se reduce a ver que, dados $A,B,C \in \mathcal{P}(X)$, $(A+B)+C = A+(B+C)$ ó dicho de otra forma: $(A \Delta B) \Delta C = A \Delta(B \Delta C)$. Usaremos las propiedades que hemos visto de la función característica, ya que sabemos que dos subconjuntos $A = B$ son iguales si y sólo si sus funciones características coinciden. 

$\mathcal{X}_{(A\Delta B) \Delta C} = \mathcal{X}_{A\Delta B} + \mathcal{X}_C - 2 \cdot \mathcal{X}_{A\Delta B} \cdot \mathcal{X}_C = \mathcal{X}_A + \mathcal{X}_B -2 \cdot \mathcal{X}_A \cdot \mathcal{X}_B + \mathcal{X}_C -2 \cdot(\mathcal{X}_A+\mathcal{X}_B-2\cdot\mathcal{X}_A \cdot\mathcal{X}_B) \cdot \mathcal{X}_C = \mathcal{X}_A + \mathcal{X}_B -2 \cdot \mathcal{X}_A \cdot \mathcal{X}_B + \mathcal{X}_C - 2 \cdot \mathcal{X}_A \cdot \mathcal{X}_C - 2\cdot \mathcal{X}_B \cdot \mathcal{X}_C +4 \cdot \mathcal{X}_A \cdot \mathcal{X}_B \cdot \mathcal{X}_C.$ 

$\mathcal{X}_{A\Delta(B\Delta C)} = \mathcal{X}_A + \mathcal{X}_{B \Delta C} - 2 \cdot \mathcal{X}_A \cdot \mathcal{X}_{B \Delta C} = \mathcal{X}_A + \mathcal{X}_B + \mathcal{X}_C - 2 \cdot \mathcal{X}_B \cdot \mathcal{X}_C - 2 \cdot \mathcal{X}_A \cdot (\mathcal{X}_B + \mathcal{X}_C -2 \cdot \mathcal{X}_A \cdot \mathcal{X}_C) = \mathcal{X}_A + \mathcal{X}_B + \mathcal{X}_C - 2 \cdot \mathcal{X}_A \cdot \mathcal{X}_B - 2 \cdot \mathcal{X}_A \cdot \mathcal{X}_C - 2 \cdot \mathcal{X}_B \cdot \mathcal{X}_C + 4 \cdot \mathcal{X}_A \cdot \mathcal{X}_B \cdot \mathcal{X}_C.$

Y se tiene la igualdad, luego se tiene que $(A \Delta B ) \Delta C = A \Delta (B \Delta C)$.
\item Para el elemento neutro, notar que $A\Delta \emptyset = \emptyset \Delta A = A$ para todo $A \in \mathcal{P}(X)$.
\item Cada elemento es inverso de sí mismo, ya que $A \Delta A = \emptyset$ para todo $A \in \mathcal{P}(X)$.
\item La operación $\Delta$ es conmutativa, ya que $A \Delta B = B \Delta A$ para cualesquiera $A, B \in \mathcal{P}(X)$.
\item La operación $\cdot$ es asociativa, ya que $(A \cap B) \cap C = A \cap (B \cap C)$ para cualesquiera $A,B,C \in \mathcal{P}(X)$. Notar que también es conmutativa.
\item Veamos la propiedad distributiva de $\cdot$ respecto de $\Delta$. Dados $A,B,C \in \mathcal{P}(X)$, entonces $(A\Delta B) \cdot C = ((A \setminus B) \cup (B \setminus A)) \cdot C = ((A \setminus B) \cup (B \setminus A)) \cap C = ((A \setminus B) \cap C) \cup ((B \setminus A) \cap C) = ((A \cap C)\setminus B) \cup ((B \cap C) \setminus A) = ((A \cap C)\setminus (B \cap C)) \cup ((B \cap C) \setminus (A\cap C)) = (A \cap C) \Delta (B \cap C) = (A\cdot C) \Delta (B \cdot C)$.
\item Notar que no existe elemento $1$ ya que el único elemento $B \in \mathcal{P}(X)$ que cumple que para cualquier subconjunto $A \in \mathcal{P}(X)$, $A \cdot B = A$ es el propio $A$.
\end{enumerate}

Así, queda probad que $(\mathcal{P}(X), \Delta, \cdot)$ es un anillo conmutativo, en el que además se tiene que $A^2 = A$ para cualquier $A \in \mathcal{P}(X)$.
\end{example}
$\hfill \blacksquare$

Los anillos $A$ como el anterior que cumplan que para todo elemento $a \in A$ se tiene $a^2 = a$, que todo elemento sea idempotente, se denominan \textbf{\textit{anillo de Boole}}.

Una vez vistos estos ejemplos y definiciones vamos a definir unos elementos que son de gran importancia en un anillo, y que nos abrirán las puertas a otra estructura algebraica.

\begin{definition}Sea $A$ un anillo. Llamaremos \textbf{divisor de cero} a un elemento $a \in A$ no nulo tal que $ab = 0$ para algún $b \in A$ no nulo.
\end{definition}

\begin{observation}Hay ejemplos de anillos que sí tienen divisores de cero, como es el último ejemplo anterior, $\mathcal{C}(\mathbb{R}, \mathbb{R})$, ya que si consideramos las funciones $$\begin{array}{rccl}
f \colon t \longrightarrow t - \abs{t} \\
\end{array}
$$
$$\begin{array}{rccl}
g \colon t \longrightarrow t + \abs{t} \\
\end{array}
$$ Entonces $(fg)(t) = (t - \abs{t})(t + \abs{t}) = t^{2} -\abs{t}^{2} = 0.$
\end{observation}

\begin{example}Otros ejemplos de divisores de cero son:
\begin{enumerate}
\item En el anillo de las matrices cuadradas de orden $2$ con coeficientes en $\mathbb{Z}$, $M_2(\mathbb{Z})$ tenemos: $$\left( \begin{matrix}
1 & 1 \\
2 & 2
\end{matrix} \right)\left(
\begin{matrix}
1 & 1 \\
-1 & -1
\end{matrix}\right) =\left( \begin{matrix}
0 & 0\\
0 & 0
\end{matrix}\right)$$

\item En el anillo $\mathbb{Z}/n\mathbb{Z}$, si dos enteros $a,b$ son tales que $ab=n$, entonces $a+n\mathbb{Z}$ y $b+n\mathbb{Z}$ son divisores de cero. 
\end{enumerate}
\end{example}

Es claro además que los cuerpos no tienen divisores de cero, ya que si tenemos que $ab =0 $, con $a$ y $b$ no nulos, entonces $$a = a(bb^{-1}) = (ab)b^{-1} = 0b^{-1} = 0.$$ Pero el no tener divisores de cero tampoco hace a un anillo un cuerpo, por ejemplo $\mathbb{Z}$ no los tiene, pero sin embargo tampoco es un cuerpo. Por lo tanto, se ha de introducir una clase de anillos más fuerte que se encuentre entre ambas estructuras, es de aquí de dónde surge la siguiente definición:

\begin{definition} Llamaremos \textbf{dominio de integridad}, ó D.I, a un anillo unitario y conmutativo sin divisores de cero.

Importante remarcar una propiedad fundamental de los dominios de integridad, y también de los cuerpos: se pueden simplificar factores comunes en las igualdades. Si tenemos $ab = ac$, con $a \neq 0$, entonces $a(b-c) = 0$, y al no ser $a$ un divisor de cero, tenemos que $b-c = 0$ y de aquí $b = c$. Esto se conoce como \textbf{ley cancelativa} y también puede darse en estructuras de anillos, siempre y cuando los elementos implicados no sean divisores de cero. 
\end{definition}

Y aunque no sean cuerpos, podremos asociarles de forma natural uno con la construcción del llamado \textbf{\textit{cuerpo de fracciones de un dominio de integridad}}. Veámoslo.

\begin{definition}[\textbf{\textit{Cuerpo de fracciones de un dominio de integridad.}}] Sean $A$ un dominio de integridad y $T = A \times A^{\ast}$. En $T$ podremos definir una relación de equivalencia como sigue: $$(a,b)\sim (a',b') \Leftrightarrow ab' = ba'.$$ A la clase de $(a,b)$ la denotaremos por $[a,b]$. Así, el conjunto cociente $T/ \sim$ para esta relación, que denotaremos $K$, es un anillo con las operaciones suma y producto como sigue: $$[a,b]+[a',b'] = [ab' + ba', bb']$$
$$[a,b]\cdot[a',b'] = [aa', bb'].$$
Y, efectivamente, $K$ también será un cuerpo ya que su elemento neutro para la suma (cero) es $[0,1]$ y para todo $[a,b] \in K$ tal que $[a,b] \neq [0,1]$ existirá un $[b,a] \in K$ que cumplirá $$[a,b] \cdot [b,a] = [ab, ab] = [1,1],$$ siendo éste último el elemento neutro para el producto en $K$.

A este cuerpo $K = T/\sim$ lo denominaremos \textbf{cuerpo de fracciones de $A$}, y representaremos a sus elementos por $a/b$ en lugar de $[a,b]$. Al verlos de esta forma se puede entender mejor el por qué de operarlos así. Además, podremos identificar a $A$ con el subconjunto de $K$ de los elementos $a/1$, con $a \in A.$
\end{definition}

Notar que si $A$ no es conmutativo, entonces su cuerpo de fracciones tampoco lo será.

Así, si $A = \mathbb{Z}$, entonces la anterior construcción nos devolverá el cuerpo $\mathbb{Q}$ de los números racionales.

Presentamos ahora la noción de característica de un anillo, que más adelante la detallaremos y analizaremos con más profundidad:

\begin{definition}[\textbf{\textit{Característica de un anillo}}]
Llamaremos \textbf{característica} de un anillo $A$ al menor natural no nulo $n$ tal que $n\cdot 1=n1 = 0$. En caso de que no exista diremos que $A$ tiene característica $0$.
\end{definition}

Es decir, la característica de un anillo es el mínimo número de veces que hay que sumar $1$ consigo mismo para obtener $0$, y si no existe dicho número entonces diremos que será $0$.

Claramente los anillos $\mathbb{Z}$ y $\mathbb{Q}$ tienen característica $0$, mientras que los cocientes de $\mathbb{Z}$, $\mathbb{Z}/n\mathbb{Z}$ tienen característica $n$. 

Aunque no hemos dado una definición formal de qué es un número primo (y resultará importante darla para los objetivos de esta parte del texto) en la siguiente proposición nos bastará con emplear la que nos viene dada directamente de la aritmética: aquel que no puede descomponerse en un producto de otros números que no sean él mismo y el $1$.

\begin{proposition}La característica de un dominio de integridad $A$ es $0$ o $p$, con $p$ primo.
\end{proposition}
\emph{Demostración: }Supongamos que $A$ es un dominio de integridad cuya característica no es $0$. Sea $p$ la característica de $A$ y supongamos que no es primo, luego $p = nm$, con $n,m>1$ enteros, y $m 1 \neq 0 \neq n  1$ pero $(m 1)(n 1 ) = (n m)1 = 0$, contradiciendo que $A$ sea dominio de integridad.

$\hfill \square$

Ahora un concepto que es propio de los anillos en general, análogo al de los subgrupos en  los grupos. Y es que, como ya se dijo entonces para los grupos, dada una estructura algebraica cualquiera siempre es natural preguntarse si van a poder definirse subconjuntos que mantengan esa estructura. 

\begin{definition} Sea $B$ un anillo conmutativo y unitario, $A \subseteq B$ un subconjunto que, con las operaciones inducidas por $B$, es a su vez un anillo unitario tal que $1_{B} =1_{A}.$ Diremos que $A$ es un \textbf{subanillo} de $B$, y ya sabemos que la aplicación
$$\begin{array}{rccl}
&A&\longrightarrow &B \\
&x& \longmapsto &x
\end{array}
$$  es un monomorfismo, la inclusión canónica. Si $A$ y $B$ son cuerpos diremos que $A$ es un \textbf{subcuerpo} de $B$. Además, todo dominio de integridad es subanillo de su cuerpo de fracciones, vía el monomorfismo $x \longrightarrow x/1$.
\end{definition}

Es decir, diremos que un subconjunto $A$ de un anillo $R$ es \textbf{subanillo} de $R$ si $s-t, st \in A$ $\forall st, \in A$. En particular, $A$ es subgrupo de $R$.

\begin{definition}Llamaremos \textbf{cuerpo primo}, o también \textbf{subcuerpo primo}, de un cuerpo $K$ a la intersección de todos los subcuerpos de $K$. Es decir, el subcuerpo primo de un cuerpo es el menor subcuerpo que contiene.
\end{definition}

Los denominamos cuerpos primos porque, tal y como veremos más adelante, serán de la forma $\mathbb{Z}_p$ con $p$ primo, o $\mathbb{Q}$, es decir, el cuerpo de los racionales.

Además, resulta que la interseccion es cerrada para los subanillos: 

\begin{observation} Si $\lbrace A_{i}: i \in I\rbrace$, con $I$ una colección finita de índices, es una familia de subanillos (subcuerpos respectivamente) de un anillo $B$, entonces su intersección $$A = \bigcap_{i \in I} A_{i}$$ es también un subanillo (subcuerpo) de $B$.
\end{observation}

\begin{example} Veamos algunos ejemplos de dominios de integridad: \begin{enumerate}
\item Sea $A$ un anillo, el anillo de matrices $M_{2}$ con elementos de $A$ nunca es dominio de integridad, ya que por ejemplo dado un $x \in A$ tenemos $$\left( \begin{matrix}
x & 0 \\
0 & 0
\end{matrix}
\right) \left( \begin{matrix}
0 & 0 \\
0 & x
\end{matrix}
\right) = \left( \begin{matrix}
0 & 0 \\
0 & 0
\end{matrix}
\right)$$
\item Al hacer un \textbf{producto de anillos} siempre obtenemos otro anillo que sí contiene divisores de cero. Sean $A$ y $B$ dos anillos unitarios y conmutativos. Entonces $C = A \times B$ es un anillo unitario y conmutativo con las operaciones $$(a_{1},b_{1}) + (a_{2},b_{2}) = (a_{1}+a_{2}, b_{1}+b_{2})$$ $$(a_{1},b_{1}) \cdot (a_{2},b_{2}) = (a_{1}a_{2},b_{1}b_{2}).$$ Es claro que $0_{A\times B} = (0_{A},0_{B})$ y que $1_{A \times B} = (1_{A},1_{B})$. Y como divisores de cero tendremos a aquellos elementos que sean de la forma $(0,b)$ ó $(a,0)$ ya que $$(0,b)(a,0) = (0 \cdot a, b \cdot 0) = (0_{A}, 0_{B}).$$ Y esto ocurrirá aunque $A$ y $B$ sean dominios de integridad. Además, igualmente podremos construir de forma análoga un \textbf{producto de una colección finita de anillos}.
\end{enumerate}
\end{example}
$\hfill \blacksquare$

\begin{observation}A propósito del producto de anillos, se puede comprobar fácilmente que $$\mathcal{U}(A \times B) = \mathcal{U}(A) \times \mathcal{U}(B).$$
\end{observation}

Ahora introduciremos uno de los conceptos más importantes que veremos a lo largo de este capítulo y que será de todavía mayor importancia en lo sucesivo. Es algo así como la extensión del concepto de subgrupo normal para los anillos: 

\begin{definition}Sea $A$ un anillo conmutativo y unitario. Llamaremos \textbf{ideal} a un subconjunto $I \subseteq A$ que cumplirá las siguientes condiciones: \renewcommand{\labelenumi}{\arabic{enumi}.}
\begin{enumerate}
\item $I$ es un subgrupo de $A$ para la suma, así habrá de incluir el elemento neutro, es decir, $0 \in I$.
\item $\forall x \in I, a \in A$ tenemos que $ax \in I$.
\end{enumerate}
Aunque la primera condición es también equivalente a: \begin{enumerate}
\item $\forall x,y \in I$, se tiene que $x+y \in I$. 
\end{enumerate}
Y esto es así ya que, al cumplirse $2.$ y esta nueva condición, tendremos que dados $x,y \in I$ $$x-y = x +(-1)y \in I$$ (ya que $(-1)y \in I$ por $2.$). Así, $I$ será subgrupo para la suma. Estas dos últimas condiciones son las que dió en su momento el matemático Richard Dedekind cuando definió el concepto de ideal (la primera es de Kummer).
\end{definition}

Es inmediato comprobar que, por ejemplo, los múltiplos de un número entero, es decir, conjuntos de la forma $n\mathbb{Z}$ con $n$ un entero cualquiera, forman un ideal del anillo de los números enteros $\mathbb{Z}$.

\begin{definition} Algunas definiciones de especial interés: \renewcommand{\labelenumi}{\arabic{enumi}.} \begin{enumerate}
\item El conjunto $\lbrace 0 \rbrace$ es un ideal de $A$, denominado \textbf{ideal nulo}. También $A$ cumple con las condiciones, así que también es ideal de $A$, y tanto este como el ideal nulo son los llamados \textbf{ideales impropios} de $A$. Esto sirve para distinguirlos de aquellos ideales $\lbrace 0 \rbrace \neq I \neq A$, a los que llamaremos \textbf{ideales propios} de $A$. Notar que si $1 \in I$, entonces por la segunda condición tenemos que $x = x \cdot 1 \in I$ para cualquier $x \in A$ y así $I = A$. Por lo tanto será importante tener en cuenta que \textbf{$I$ es propio si y sólo si $1 \notin I$.}
\item Si $x \in A$, entonces el conjunto $$xA = \lbrace xa : \hspace{0.1cm} a \in A \rbrace$$ es un ideal de $A$, denominado \textbf{ideal principal generado por $x$} y lo denotaremos por $(x)$. Un ejemplo de esto podrían ser los ideales de $\mathbb{Z}$ mencionados anteriormente, los conjuntos $n\mathbb{Z}$. Más adelante veremos esta expresión generalizada para hablar de ideales generados por conjuntos.
\end{enumerate}
\end{definition}

Con esto, podemos enunciar el siguiente resultado, que define los cuerpos a partir de los ideales:

\begin{proposition}\label{eq:idK}Un anillo $A$ es un cuerpo si y sólo si sus únicos ideales son los impropios, es decir, el mismo $A$ y $\lbrace 0 \rbrace$.
\end{proposition}
\emph{Demostración: } Si $A$ es un cuerpo e $I$ un ideal no nulo de $A$ entonces $I$ contendrá algún elemento $a \neq 0$ y así $aa^{-1} = 1 \in I$, por lo que $I = A$. Recíprocamente, supongamos que los únicos ideales de $A$ son los impropios. Sea un $0 \neq a \in A$ y consideremos el ideal que genera, $I=(a)$. Como $a$ es no nulo $I$ no es trivial, y así $I=A$, luego $1 \in I$ y esto quiere decir que existe un $b \in A$ tal que $ab = 1$. Por lo tanto, $a \in \mathcal{U}(A)$ y como esto es así para cualquier $a \in A$ no nulo, se tiene que $A$ es un cuerpo.

$\hfill \square$

Es decir: en un cuerpo $K$ no hay más ideales que $\lbrace 0 \rbrace$ y el propio $K$. 

Con todo esto, sería normal preguntarse para qué hemos definido este concepto, el de ideal. Y es que la noción de ideal, como ya se ha dicho, es de gran importancia principalmente porque nos va a permitir definir relaciones de equivalencia en un anillo de tal forma que el conjunto cociente podrá heredar la estructura de anillo. Es algo similar a lo que pasa con los \textit{subgrupos normales} en \textit{Teoría de Grupos}.
 
\begin{definition}\label{eq:ancoci} \textbf{\textit{Anillos cociente.}} Sea $A$ un anillo conmutativo y unitario e $I \subset A$ un ideal propio. Definiremos la siguiente relación de equivalencia: \begin{center}
$x \sim y$ si $x-y \in I$, con $x,y \in A$.
\end{center}
Es evidente que es una relación de equivalencia (cumple las propiedades reflexiva, simétrica y transitiva) ya que $I$ tiene estructura de subgrupo.

El conjunto cociente de $A$ para esta relación lo denotaremos $A/I$ y la clase de equivalencia de un elemento $x \in A$ será: $$x + I = \lbrace x + a  : \hspace{0.1cm} a \in I \rbrace.$$
Que un elemento $y$ esté en la clase de equivalencia de $x$ significa que existirá un elemento $a \in I$ de la forma $a = y-x$. Además,\begin{center}
$x + I = y + I  \Leftrightarrow x \equiv y$ $mod$ $I$, es decir, que $x-y,y-x \in I$.
\end{center} 
Ahora, dotaremos a $A/I$ de dos operaciones que lo convertirán en un anillo, dados $x,y \in A$: 
$$\begin{array}{rccl}
+ \colon &A/I \times A/I&\longrightarrow & A/I\\
&((x + I),(y + I)) & \longmapsto &(x + I) + (y + I) = (x + y) + I,
\end{array}
$$ que le confiere a $A/I$ estructura de grupo abeliano (conmutativo), y
$$\begin{array}{rccl}
\cdot \colon &A/I \times A/I&\longrightarrow & A/I\\
&((x + I),(y + I)) & \longmapsto &(x + I)\cdot(y + I) = xy + I.
\end{array}
$$ Esta última operación además no depende de los representantes elegidos. Supongamos que $x + I = x' + I$ (es decir, $x-x' \in I$) y que $y + I = y' + I$ ($y-y' \in I$). Entonces $xy + I = x'y' + I$, ya que $$xy -x'y' = xy - x'y + x'y - x'y' = (x-x')y + x'(y-y') \in I$$ esto último es así por la segunda condición que deben cumplir los ideales.\vspace{0.2cm}\\
Una vez visto esto, las propiedades  asociativa y conmutativa del producto, así como la distributiva, son inmediatas. El \textbf{elemento neutro} de $A/I$ será $1 + I$. Así, $A/I$ dotado con las dos operaciones, suma y producto respectivamente, y las demás propiedades enunciadas tiene estructura de anillo conmutativo unitario, que denominaremos \textbf{anillo cociente ó anillo de clases de restos módulo $I$}.

Finalmente, los ideales del cociente $A/I$ serán aquellos ideales de $A$ que contengan a $I$, de hecho se puede establecer fácilmente una biyección entre ambos conjuntos. Sea $L$ un ideal del anillo cociente y consideremos el conjunto $$J = \lbrace x \in A : x + I \in L \rbrace.$$ Entonces es claro que $J$ es un ideal de $A$ y que contiene a $I$, puesto que si $x \in I$ entonces $x + I = 0 + I \in L.$ Luego la biyección se establece entre los conjuntos de la forma $L$ y de la forma $J$, es decir, entre los ideales de $A/I$ y los ideales de $A$ que contienen a $I$ respectivamente.
\end{definition}

En el siguiente capítulo desarrollaremos adecuadamente este último resultado.

\begin{observation} Notar que si $x \in I$, entonces $x + I$ será el conjunto de los $x+a$ con $a \in I$, pero como $x \in I$ entonces $x+a \in I$ y así $x + I = 0 + I = I$.
\end{observation}

En resumen, llamaremos anillo cociente al conjunto $A/I$ de las clases de equivalencia de un anillo respecto a la relación de equivalencia $x \sim y$ si $x-y \in I$, con $I$ un ideal propio de $A$, y dotado con las operaciones antes definidas y que le confieren una estructura de anillo conmutativo unitario.

A continuación desarrollaremos la idea de subconjuntos que generan ideales. Anteriormente vimos cuando un ideal es generado por un sólo elemento, denominado ideal principal generado por ese elemento, y ahora generalizaremos ese concepto. Definiremos ideal generado por un subconjunto a través de la siguiente proposición:

\begin{proposition}[\textbf{\textit{Ideales generados por un subconjunto}}]
Sea $A$ un anillo conmutativo y unitario, y $L$ un subconjunto de $A$, que carece de estructura algebraica. Consideremos el conjunto $I \subseteq A$ de todas las sumas finitas de la forma $$a_{1}x_{1} + \ldots + a_{r}x_{r}, \hspace{0.2cm} a_{1}, \ldots, a_{r} \in A, \hspace{0.2cm} x_{1}, \ldots, x_{r} \in L, \hspace{0.2cm} r \geq 1.$$ Entonces tenemos que \begin{enumerate}
\item $I$ es un ideal.
\item $I$ es el mínimo ideal que contiene a $L$, es decir, si $\mathcal{L}$ es la colección de todos los ideales $J \subseteq A$ tales que $ L \subseteq J$, se verifica que $$I = \bigcap_{J \in \mathcal{L}} J.$$
\end{enumerate}
\end{proposition}
\emph{Demostración: } Veamos $1.$. Comprobemos , para ello sean $$a = \sum_{k =1}^{r}a_{k}x_{k}, \hspace{0.2cm} b= \sum_{l=1}^{s} b_{l}y_{l} \in I, \hspace{0.3cm} c \in A.$$ Entonces es evidente que $$a+b = a_{1}x_{1} + \ldots + a_{r}x_{r} + b_{1}y_{1} + \ldots + b_{s}y_{s} \in I$$ $$c \cdot a = c(a_{1}x_{1} + \ldots + a_{r}x_{r}) =(ca_{1})x_{1} + \ldots + (ca_{r})x_{r} \in I.$$ Para probar $2.$ observar que $I \in \mathcal{L}$, puesto que $I$ es un ideal que contiene a $L$, luego $$\bigcap_{J \in \mathcal{L}} J \subseteq I.$$ Pero, por otra parte, si $J \in \mathcal{L}$, $a_{1}, \ldots, a_{r} \in A$, $x_{1}, \ldots, x_{r} \in L$, tenemos $a_{1}x_{1}, \ldots, a_{r}x_{r} \in J$ y $a_{1}x_{1}+ \ldots + a_{r}x_{r} \in J$ por ser $J$ un ideal de $A$ que contiene a $L$. Esto demuestra que todos los elementos de $I$ están también en $J$, así $I \subseteq J$. Siendo esto igual para todo ideal $J$ de $\mathcal{L}$, tenemos que $$I \subseteq \bigcap_{J \in \mathcal{L}} J.$$ Por tanto, la igualdad.

Este ideal $I$ que acabamos de construir es lo que conoceremos como \textbf{\textit{ideal generado por $L$}}.

$\hfill \square$

\begin{definition} Sea $A$ un anillo conmutativo y unitario. Un ideal $I \subseteq A$ se llama \textbf{finitamente generado} si es un ideal generado por un subconjunto finito $L = \lbrace x_{1}, \ldots, x_{r}\rbrace \subseteq A.$ En dicho caso, $$I = Ax_{1} + \ldots + Ax_{r} = \left\lbrace \sum_{k=1}^{r}a_{k}x_{k} : \hspace{0.1cm} a_{1}, \ldots, a_{r} \in A \right\rbrace.$$ Lo denotaremos $I = (x_{1}, \ldots, x_{r}).$ Y recordar que si $r=1$, es decir, si el ideal está generado por un solo elemento, entonces $I$ se llama \textbf{ideal principal}.
\end{definition}

\begin{definition}
Un anillo $A$ se dirá \textbf{noetheriano}, en honor a la gran matemática alemana Emmy Noether, si todos sus ideales son finitamente generados.
\end{definition}

Los anillos noetherianos cumplen la siguiente condición:

\begin{theorem}[\textbf{\textit{Condición de cadena ascendente}}]
Sea $A$ un dominio de integridad. Entonces son equivalentes:
\begin{enumerate}
\item $A$ es un anillo noetheriano.
\item Para toda cadena ascendente de ideales de $A$ $$I_0 \subseteq I_1 \subseteq I_2 \subseteq I_3 \subseteq \ldots $$ existe un número natural $n$ tal que $I_n = I_m$ para todo $m \geq n$.
\item Toda familia no vacía de ideales de $A$ tiene un maximal
\end{enumerate}
\end{theorem}
\emph{Demostración: }Si $I_0 \subseteq I_1 \subseteq I_2 \subseteq I_3 \subseteq \ldots$ es una cadena ascendente de ideales de $A$, es fácil ver que la unión $I = \bigcup_{i=0} I_i$ es también un ideal de $A$. Si $A$ es noetheriano entonces $I$ ha de tener un generador finito $X$. Cada elemento de $X$ está en uno de los ideales $I_i$, y como $X$ es finito y los ideales forman una cadena, existirá un natural $n$ tal que $X \subseteq I_n$, pero entonces $\bigcup _{i=0} I_i = (X) \subseteq I_n$, lo que implica que $I_i = I_n$ para todo $i \geq n$. Por tanto $1$ implica $2$.

Si una familia no vacía de ideales de $A$ no tuviera maximal, se podría extraer una cadena ascendente de ideales que contradijera $2$, luego $2$ implica $3$.

Si $A$ tuviera un ideal $I$ que no admitiera un generador finito, entonces, dado cualquier elemento $a_0$ de $I$, se cumple que $(a_0) \neq I$, luego existe un elemento $a_1 \in I \setminus (a_0)$, luego $(a_0) \subseteq (a_0,a_1) \neq I$ y de esta forma podemos conseguir una cadena de ideales $(a_0) \subseteq (a_0,a_1) \subseteq (a_0,a_1,a_2) \subseteq \ldots$ sin que ninguno de ellos sea maximal. Luego $3$ implica $1.$

$\hfill \square$

Es claro que todo cuerpo $K$ es un anillo noetheriano.

\begin{definition}[\textbf{\textit{Operaciones con ideales.}}] Sean $I$, $J$ ideales de un anillo unitario y conmutativo $A$. Veamos las operaciones que se pueden realizar con ellos:\begin{enumerate}
\item \textbf{Suma}. La denotaremos $I + J$, y consiste en todos los elementos de la forma $x+ y$, con $x \in I$, $y \in J$. Coincide con el ideal generado por $I \cup J$. En efecto, dados $a_{1}, \ldots, a_{r}, b_{1}, \ldots, b_{s} \in A$, $x_{1}, \ldots, x_{r} \in I$, $y_{1}, \ldots, y_{s} \in J,$ podremos escribir $a_{1}x_{1} + \ldots + a_{r}x_{r} + b_{1}y_{1} + \ldots + b_{s}y_{s} = x + y$, con $x = a_{1}x_{1} + \ldots + a_{r}x_{r} \in I$, e $y= b_{1}y_{1} + \ldots + b_{s}y_{s} \in J$.
\item \textbf{Producto}. Se denota por $I \cdot J$ ó también $IJ$, y es el ideal generado por todos los productos $xy$, con $x \in I$, $y \in J$. Consiste en el siguiente conjunto: $$IJ = \lbrace x_{1}y_{1} + \ldots + x_{r}y_{r} : \hspace{0.1cm} x_{1}, \ldots, x_{r} \in I, \hspace{0.1cm} y_{1}, \ldots, y_{r} \in J, \hspace{0.1cm} r \geq 1 \rbrace.$$
\item \textbf{Intersección}. La denotaremos por $I \cap J$, y es, de forma inmediata, un ideal de $A$. De hecho, también es un ideal de $A$ la intersección de una colección infinita de ideales.
\end{enumerate}
\end{definition}

De estas definiciones deducimos el siguiente resultado:

\begin{proposition} Dado un anillo conmutativo y unitario $A$, y dos ideales $I$, $J$ de $A$, entonces tendremos: \begin{enumerate}
\item $IJ \subseteq I \cap J.$
\item En general $IJ$ y $I \cap J$ no coincidirán.
\item Dada una colección finita de ideales $I_{1}, \ldots, I_{r}$ de $A$, con $r \geq 1$, entonces $$I_{1} \cdots I_{r} \subseteq I_{1} \cap \cdots \cap I_{r}.$$
\end{enumerate} 
\end{proposition}
\emph{Demostración: }Para probar $1.$ simplemente hay que tener en cuenta que, como $IJ =  \lbrace x_{1}y_{1} + \ldots + x_{r}y_{r} : \hspace{0.1cm} x_{1}, \ldots, x_{r} \in I, \hspace{0.1cm} y_{1}, \ldots, y_{r} \in J, \hspace{0.1cm} r \geq 1 \rbrace$, entonces cada $x_{i}y_{i} \in I$ puesto que cada $x_{i} \in I$ y cada $y_{i} \in A$ al pertenecer a $J$, y análogamente $x_{i}y_{i} \in J$, así que $x_{i}y_{i} \in I \cap J$. Y como $I \cap J$ es ideal, entonces las sumas también pertenecerán. La comprobación de que $IJ$ es ideal es también directa.

Para ver $2.$ daremos un contraejemlo. Consideremos $A = \mathbb{Z}$, $I = 4\mathbb{Z}$ y $J = 6\mathbb{Z}$, respectivamente los múltiplos de $4$ y de $6$. Entonces la $I \cap J$ estará formado por aquellos elementos que sean múltiplos de $4$ y de $6$, es decir múltiplos de $12$, luego $I \cap J = 12\mathbb{Z}$. Sin embargo, $IJ = 24\mathbb{Z}$, luego el contenido de $IJ$ en la intersección es estricto.

$3.$ es evidente por recurrencia ya que $$I_{1} \cdots I_{r} \subseteq (I_{1} \cdots I_{r-1} ) I_{r} \subseteq (I_{1} \cdots I_{r-1} ) \cap I_{r} \subseteq (I_{1} \cap \cdots \cap I_{r-1} ) \cap I_{r} \subseteq I_{1} \cap \cdots \cap I_{r}.$$

$\hfill \square$

\begin{definition} \label{eq:comax} Sea un anillo conmutativo y unitario $A$ y dos ideales $I$, $J$ de $A$. Entonces diremos que $I$ y $J$ son \textbf{comaximales} si $I + J = A$. Además, en tal caso se tendrá que $IJ = I \cap J$.
\end{definition}

\begin{observation} Efectivamente, se tiene la igualdad $IJ = I \cap J$ ya que al ser comaximales existirán $x \in I$ e $y \in J$ tales que $x +y = 1$. Y ahora, dado un $a \in I \cap J$, $a,x \in I$ y también $a, y \in J$, así que $ax \in J$, $ay \in I$ y se tendrá: $$a = a1 = a(x+y) = ax + ay \in IJ.$$
\end{observation}

Ahora se introducirá dos clases muy importantes de ideales, que serán esenciales en lo que sigue. 

\begin{definition}Sea $A$ un anillo no necesariamente conmutativo ni unitario e $I$ un ideal de $A$. Diremos que $I$ es \textbf{maximal} si lo es, respecto de la inclusión, en la familia de todos los ideales propios de $A$, es decir, si no existe ningún ideal propio  $J$ de $A$ que lo contenga estrictamente ($I \subsetneq J$).
\end{definition}

A continuación daremos una caracterización de estos ideales:

\begin{proposition} Sea $A$ un anillo conmutativo y unitario e $I$ un ideal de $A$. Entonces $I$ será \textbf{maximal} si se cumple algunas  de las siguientes condiciones equivalentes: \begin{enumerate}
\item El anillo cociente $A/I$ es un cuerpo.
\item $I$ es un ideal propio y ningún otro ideal propio lo contiene estrictamente.
\end{enumerate}
\end{proposition}
\emph{Demostración: } Sea $A/I$ un cuerpo y supongamos que $I$ no es maximal. Entonces existirá un ideal $J$ de $A$ tal que $I \subsetneq J \subsetneq A$. Sea $x \in J \setminus I$ un elemento de $J$ que no pertenece a $I$. Entonces $x + I$ es un elemento no nulo del cuerpo $A/I$ ya que $x \notin I$, por lo que tendrá inverso, es decir, existirá $y \in A$ tal que $$1 + I = (x + I)(y + I)= xy + I,$$ y en consecuencia $1 -xy \in I \subseteq J$. Ahora como $xy \in J$, por ser $J$ un ideal, tendremos que $1 = (1- xy) + xy \in J$ y así $J = A$, lo cual es absurdo.

Recíprocamente, sea $x + I$ un elemento no nulo de $A/I$. Entonces $x \in A \setminus I$, es decir, será un elemento de $A$ que no estará en $I$, por lo que el ideal $I + (x)$ contiene estrictamente a $I$. Como este último es maximal tendremos que $I + (x) = A$, es decir que existirá $b \in I$ e $y \in A$ tal que $b + xy = 1$. Así que $1 - xy \in I$, es decir, $$xy + I = (x + I)(y + I ) = 1 + I,$$ por lo que $A/I$ es un cuerpo.

$\hfill \square$

La siguiente proposición caracterizará a la otra clase de ideales que veremos, los ideales \textbf{\textit{primos}}:

\begin{proposition} Sea $A$ un anillo conmutativo y unitario e $I$ un ideal de $A$. Diremos que $I$ es \textbf{primo} si se verifica alguna de las siguientes condiciones: \begin{enumerate}
\item El anillo cociente $A/I$ es un dominio de integridad.
\item $I$ es un ideal propio y para cualesquiera $x, y \in A$, si $xy \in I$, entonces $x \in I$ ó $y \in I.$
\end{enumerate}
\end{proposition}
\emph{Demostración: } Si $xy \in I$, entonces $0 + I = xy + I = (x + I)(y + I),$ y como $A/I$ es dominio de integridad ó $x + I = 0 + I$ y $x \in I$ ó $y + I = 0 + I$ y así $y \in I$.

Recíprocamente, $0 + I = xy + I = (x+ I)( y + I)$ ya que $xy \in I$, y como ó $x \in I$ ó $y \in I$, entonces ó $(x + I)=  0 + I$ ó $(y + I) = 0 + I$ respectivamente. Así $A/I$ es dominio de integridad.

$\hfill \square$

El por qué del término ideal primo se debe a que los ideales primos no nulos del anillo de los enteros $\mathbb{Z}$ son precisamente los generados por los números primos, aunque esto lo veremos más adelante.

\begin{observation} Todo ideal maximal es primo, ya que todo cuerpo es dominio de integridad.
\end{observation}

\begin{observation} Notar que $A = A/(0)$, con $A$ un anillo cualquiera. Luego $A$ es un dominio de integridad si y sólo si $(0)$ es primo y $A$ es cuerpo si y sólo si $(0)$ es maximal.
\end{observation}

Finalmente, estudiaremos dos clases concretas de ideales bastante interesantes: 

\begin{definition}Sea $A$ un anillo conmutativo y unitario, se dice que un ideal $I$ de $A$ es \textbf{radical} si para todo $x \in A$ tal que $x^n \in I$, con $n$ un entero positivo, se cumple que $x \in I$.
\end{definition}

\begin{proposition}Todo ideal primo $I$ de un anillo conmutativo y unitario $A$ es radical.
\end{proposition}
\emph{Demostración: }Tenemos que ver que si $x \in A$ y $n>0$ es un entero tal que $x^n \in I$ entonces $x \in I$. Lo haremos por inducción sobre $n$: es evidente para $n=1$. Ahora, si $n>1$ y $x^n \in I$ entonces $x \cdot x^{n-1} \in I$ y por ser $I$ primo entonces ó $x \in I$ y ya hemos terminado, ó $x^{n-1} \in I$. En el segundo caso la hipótesis de inducción asegura que $x \in I$.

$\hfill \square$

\begin{proposition}Sean $A$ un anillo e $I$ un ideal propio de $A$. Entonces:
\begin{enumerate}
\item Existe un ideal maximal $M$ de $A$ que contiene a $I$.
\item El anillo $A$ posee algún ideal maximal.
\item Para cada $x \in A \setminus \mathcal{U}(A)$ existe un ideal maximal $M$ de $A$ tal que $x \in M$.
\end{enumerate} 
\end{proposition}
\emph{Demostración: }\begin{enumerate}
\item La familia de ideales $$\mathcal{F} = \lbrace J \subseteq A~ideal~de~A~:I \subset J \rbrace,$$  es no vacía pues contiene al ideal $I$ y está parcialmente ordenada con respecto a la inclusión. Toda cadena de ideales $\mathcal{C} = \lbrace J_l \rbrace_{l \in L}$ de $\mathcal{F}$ está acotada superiormente ya que $J = \cup_l J_l \in \mathcal{F}$ es una cota superior suya. Por el \textit{Lema de Zorn} existe un elemento maximal $M \in \mathcal{F}$. Veamos que $M$ es un ideal maximal de $A$ que contiene a $I$:

La inclusión $I \subseteq M$ se deduce de que $M \in \mathcal{F}$. Por otro lado, si $M$ no es un ideal maximal de $A$, existe un ideal $J$ tal que $M \subset J \subset A$. Pero entoncces $I \subseteq M \subset J \subset A$ y así $J \in \mathcal{F}$, y esto contradice la maximalidad de $M$.
\item Basta aplicar el apartado anterior al ideal $I = \lbrace 0 \rbrace$.
\item Como $x$ no es unidad, se tiene que el ideal $(x) \neq A$, luego por $1.$ existe un ideal maximal $M$ de $A$ que contiene a $(x)$, y así $x \in M$.
\end{enumerate}

$\hfill \square$

\begin{definition} Llamaremos \textbf{radical de Jacobson} $I$ de $A$, con $A$ un anillo conmutativo y unitario, a la intersección de todos los ideales maximales de $A$. Lo denotaremos por $\mathcal{R}$.
\end{definition}

Además, los podemos caracterizar de la siguiente forma:

\begin{proposition}Dado $A$ un anillo conmutativo y unitario, $x \in \mathcal{R}$ si y sólo si $1-xy$ es una unidad en $A$ para todo $y \in A$.
\end{proposition}
\emph{Demostración: }Sea $x \in \mathcal{R}$ y supongamos que $1-xy$ no es unidad. Entonces, por el resultado anterior, $1-xy$ pertenece a un ideal maximal $M$, pero $x \in \mathcal{R} \subseteq M$, por lo que $xy \in M$ y así $1 \in M$, absurdo. 

Recíprocamente, supongamos que $x \notin M$ para todo ideal maximal $M$. Entonces $M$ y $x$ generan el ideal $(1)$, luego $u +xy = 1$ para algún $u \in M$ y algún $y \in A$. Por lo tanto, $1-xy \in M$ y esto implicaría que $1-xy$ no es una unidad, contradiciendo la hipótesis.

$\hfill \square$

\subsection{Homomorfismos}

Ahora, al igual que con pasaba con grupos, introduciremos las aplicaciones que conservan la estructura de anillo, para a partir de ellas estudiar lo que resta.

\begin{definition} Sean $A$ y $B$ dos anillos conmutativos y unitarios. Definiremos un \textbf{homomorfismo de anillos} de $A$ en $B$ como una aplicación $$f \colon A \longrightarrow B$$ tal que: \begin{enumerate}
\item $f(x + y) = f(x) + f(y)$, $\forall x,y \in A$.
\item $f(xy) = f(x)f(y)$, $\forall x,y \in A.$
\item $f(1_{A}) = 1_{B}.$
\end{enumerate}

\end{definition}
\begin{observation} La última condición es muy importante y de no darse no podrían excluirse algunas aplicaciones que, aunque conserven las operaciones, podrían ser contraproducentes. Ya que, si $x \in A$ $$f(x) \cdot (f(1_{A}) - 1_{B}) = f(x) f(1_{A}) - f(x)1_{B} = f(x \cdot 1_{A}) - f(x) = 0.$$ Así, si $f(1_{A}) \neq 1_{B}$, todos los elementos de $f(A)$ serían divisores de cero. 
\end{observation}

\begin{example} Veamos dos ejemplos de homomorfismos: \begin{enumerate}
\item La conjugación $$\begin{array}{rccl}
f \colon &\mathbb{Z}[i]&\longrightarrow &\mathbb{Z}[i] \\
&x = a + bi& \longmapsto &\bar{x} = a-bi,
\end{array}
$$ es un homomorfismo. Evidentemente $f(1) = 1$ ya que es real, sea $x = a +bi$ e $y = c +di$, entonces \begin{center}$f(x+y) = \overline{x + y} = \overline{(a+bi) + (c + di)} = \overline{(a+c) + (b + d)i} = (a+c) - (b+d)i = (a-bi) + (c -di) = \overline{x} + \overline{y} = f(x) + f(y),$\end{center}\begin{center} $f(xy) = \overline{xy} = \overline{(a+bi)(c+di)} = \overline{(ac-bd) + (ad +bc)i} = (ac-bd) -(ad +bc)i = (a-bi)(c-di) = \bar{x}\bar{y} = f(x)f(y).$\end{center}
\item Sea $A = \mathcal{C} (\mathbb{R}, \mathbb{R})$ el anillo de las funciones continuas reales de variable real definido en~\ref{eq:ejemploAnillos}. Podemos ver la composición como el siguiente homomorfismo: $$\begin{array}{rccl}
\phi \colon &A&\longrightarrow &A \\
&g& \longmapsto &g \circ f.
\end{array}
$$ Entonces 
\begin{center}
$\phi(g + h)(t) = ((g+h) \circ f)(t) = (g+h)(f(t)) = g(f(t)) + h(f(t)) = (g \circ f)(t) + (h \circ f)(t)  = ((g \circ f) + (h \circ f))(t) = (\phi(g) + \phi(h))(t),$ \end{center}
y como esto es para todo $t \in \mathbb{R}$ tenemos que $$\phi(g + h) = \phi(g) + \phi(h).$$ Igualmente para el resto de condiciones.
\end{enumerate}
\end{example}

$\hfill \blacksquare$

Veamos ahora las definiciones esenciales para homomorfismos, igual que en grupos pero en anillos: 

\begin{definition} Sea $f \colon A \longrightarrow B$ un homomorfismo de anillos conmutativos y unitarios. Entonces: \begin{enumerate}
\item Llamaremos \textbf{núcleo} de $f$ y lo denotaremos \textbf{$ker f$} al ideal $$ker f = \lbrace x \in A:  f(x) = 0 \rbrace.$$ Es un ideal ya que, si $x,y \in ker f$, $a \in A$, tenemos que $$f(x+y) = f(x) + f(y) = 0 +0 = 0,$$ $$f(ax)=f(a) f(x) = f(a) \cdot 0 = 0.$$
\item Llamaremos \textbf{imagen} de $f$ y la denotaremos \textbf{$Im f$} al anillo $$Im f = \lbrace y \in B: \hspace{0.1cm} \exists x \in A, \hspace{0.1cm} y = f(x) \rbrace.$$
Es un anillo conmutativo y unitario con las operaciones heredadas de $B$, ya que si $y = f(x)$, $v = f(u)$, $x, u \in A$, tenemos que $$y-v = f(x) - f(u) = f(x-u) \in im f,$$ $$y \cdot v = f(x)f(u) = f(x u) \in im f,$$ $$1_{B} = f(1_{A}) \in imf.$$
\end{enumerate}
\end{definition}

Un homomorfismo muy importante es el conocido como \textit{homomorfismo evaluación}, que involucra anillos de polinomios. Si $p(x) = a_kx^k + \ldots + a_1x+a_0 \in A[x]$ y $a \in A$, con $A$ un anillo conmutativo y unitario, entonces definimos $p(b)=a_kb^k + \ldots + a_1b +a_0$. Es decir, tratamos a $x$ como una variable que puede ser evaluada en distintos \textit{valores} $b$. Esto lo veremos más adelante.

\begin{proposition}[\textbf{\textit{Homomorfismo evaluación}}]
Sean $A$ y $B$ anillos conmutativos y unitarios tales que $A \subseteq B$ ($A$ subanillo de $B$), y supongamos que $b \in A$. Entonces, la aplicación $$\begin{array}{rccl}
ev_b \colon &A[x]&\longrightarrow &B \\
&p=\sum_ia_ix^i& \longmapsto &p(b)=\sum_i a_ib^i
\end{array}
$$ es un homomorfismo de anillos.
\end{proposition}
\emph{Demostración: }Observar que $ev_b(1) = 1$. Si $p(x) = \sum_i a_ix^i$ y $q(x) = \sum_i c_ix^i$ hay que comprobar que $(p+q)(b)=p(b)+q(b)$ y que $pq(b) = p(b)q(b)$. Es un simple ejercicio.

$\hfill \square$

Notar que el \textit{\textbf{núcleo del homomorfismo evaluación}} en $b$ estará formado por todos los polinomios que anulen $b$, ó dicho de otra manera: que tengan a $b$ por raíz (más adelante definiremos raíz de un polinomio de manera formal). Además, la \textbf{\textit{imagen del homomorfismo evaluación}} en $b$ será el menor subanillo de $B$ que contiene a $A$ y a $b$, que denotaremos por $A[b]$.

\begin{proposition} Sea $f \colon A \longrightarrow B$ un homomorfismo de anillos conmutativos y unitarios. Como $f(1_{A}) = 1_{B} \neq 0$, $ker f$ es un ideal propio de $A$. Además, $f$ es inyectiva si y sólo si $ker f = \lbrace 0 \rbrace.$
\end{proposition}
\emph{Demostración: } Sea $f$ inyectiva, como $f(0) = 0$, entonces el núcleo ha de reducirse al elemento neutro $0$. Recíprocamente, supongamos que $ker f = \lbrace 0 \rbrace$. Si $x,y \in A$ y tenemos que $f(x) = f(y)$, entonces $f(x-y)= 0$. Esto quiere decir que $x-y \in ker f$, pero $ker f = \lbrace 0 \rbrace$ luego $x-y = 0$ y finalmente $x = y$. Y así, $f$ es inyectiva.

$\hfill \square$

\begin{proposition} Sea $I$ es un ideal primo de un anillo unitario y conmutativo $A$ tal que el anillo cociente $A/I$ es finito, entonces $I$ es un ideal maximal.
\end{proposition}
\emph{Demostración: } Tenemos que ver que $ B = A/I$ es un cuerpo. Sea $x \in B$ un elemento no nulo, entonces la aplicación $$\begin{array}{rccl}
h \colon &B^{\ast}&\longrightarrow &B^{\ast} \\
&y& \longmapsto &xy,
\end{array}
$$ es inyectiva, puesto que $xy = xy'$ implica que $x(y-y') =0$ y como $B$ no tiene divisores de cero, por ser $A/I$ dominio de integridad, $y = y'$. Y como $B$ es finito la aplicación $h$ ha de ser necesariamente suprayectiva y así $1_{B} = xy$ para algún $y \in B^{\ast}$, luego $x$ es unidad. Como esto se puede hacer para cualquier $x \in B$ no nulo, $B$ es un cuerpo.

$\hfill \square$

Como si $I$ es primo el cociente $A/I$ es dominio de integridad, de este resultado deducimos que \textbf{\textit{todo dominio de integridad finito es un cuerpo}}.

\begin{observation} Si $f \colon K \longrightarrow B$ es un homomorfismo de anillos conmutativos y unitarios, y $K$ es un cuerpo, entonces $f$ ha de ser inyectiva. Observar que esto es así ya que al ser $ker f$ un ideal de $K$ distinto de $K$ (ya que $f(1_{K}) = 1_{B}$), por~\ref{eq:idK} sólo puede ser $\lbrace 0 \rbrace$, y así $f$ es inyectiva.
\end{observation}

Notar que, dado un homomorfismo de anillos $f \colon A \longrightarrow B$, si $I \subseteq A$ es un ideal de $A$, entonces $f(I)$ no tiene por qué ser necesariamente un ideal de $B$. Por ejemplo, si consideramos la inclusión $i \colon \mathbb{Z} \longrightarrow \mathbb{Q}$ y un ideal $I$ de $\mathbb{Z}$, y $f(I)$ no es ideal de $\mathbb{Q}$ ya que $\mathbb{Q}$ es un cuerpo y sus únicos ideales son él mismo y el trivial. Sin embargo, 

\begin{proposition}Dado un homomorfismo de anillos sobreyectivo $f \colon A \longrightarrow B$ e $I$ un ideal de $A$, entonces $f(I)$ es un ideal de $B$.
\end{proposition}
\emph{Demostración: }Si $b_1, b_2 \in f(I)$ existen $a_1,a_2 \in I$ tales que $f(a_i)=b_i$, y como $a_1+a_2 \in I$ entonces $b_1+b_2 =f(a_1)+f(a_2)=f(a_1+a_2)\in f(I)$. Además, dados $b \in B$ e $y \in f(I)$ existen, por ser $f$ sobreyectiva, $a \in A, x \in I$ tal que $f(a)=b$ y $f(x)=y$. Como $ax \in I$, se tiene que $by = f(a)f(x) = f(ax) \in f(I)$.

$\hfill \square$

Además, 

\begin{proposition}\label{eq:idif} Dado un homomorfismo de anillos $f \colon A \longrightarrow B$ y $J$ un ideal de $B$. Entonces $I = f^{-1}(J)$ es un ideal de $A$. Además, si $J \neq B$ entonces $I \neq A$.
\end{proposition}
\emph{Demostración: }Dados $a_1, a_2 \in I$, sus imágenes $f(a_1), f(a_2) \in J$, luego $f(a_1+a_2)  = f(a_1)+f(a_2) \in J$, es decir, $a_1+a_2 \in I$. Además, si $a \in A$ y $x \in I$ se tiene que $f(a) \in B$, $f(x) \in J$, por lo que $f(ax)=f(a)f(x) \in J$ y así $ax \in I$.

Para lo último, notar que si $I = A$ entonces $1 \in I$, por lo que $1 = f(1) \in J$ y así $J=B$.

$\hfill \square$

Si tenemos un homomorfismo de anillos $f \colon A\longrightarrow B$ como en la proposición anterior diremos que $I$ es el \textbf{\textit{contraído}} de $J$ mediante $f$. Notar que $ker f = f^{-1}(0)$, luego $ker f \subseteq f^{-1}(J)$, con $J$ un ideal cualquiera de $B$.

Notar también que, dado un homomorfismo de anillos conmutativos y unitarios $f \colon A \longrightarrow B$ y $M$ un ideal maximal de $B$, no siempre se va a tener que $f^{-1}(M)$ sea un ideal maximal de $A$. Por ejemplo, en la inclusión $i \colon \mathbb{Z} \longrightarrow \mathbb{Q}$, $M = ( 0 )$ es un ideal maximal en $\mathbb{Q}$, ya que $\mathbb{Q}$ es un cuerpo, pero $( 0 ) = i^{-1}(M)$ no es un ideal maximal de $\mathbb{Z}$. 

Sin embargo, sí va a ocurrir con los ideales primos. Es decir, dado un homomorfismo de anillos $f \colon A \longrightarrow B$, si $J$ es un ideal primo de $B$, entonces $I = f^{-1}(J)$ va a ser un ideal primo de $A$. Sean $a,x \in A$ tales que $ax \in I$. Así, $f(ax)=f(a)f(x) \in J$ y como $J$ es primo entonces ó $f(a) \in J$ ó $f(x) \in J$. Si $f(a) \in J$ entonces $a \in I$ y si $f(x) \in J$ entonces $x \in I$, luego $I$ es primo. 

Ahora, al igual que con grupos, veremos los \textit{Teoremas de Isomorfía}, que funcionan de forma análoga a los de grupos y que también nos serán muy útiles. Antes de eso definamos brevemente los distintos homomorfismos de anillos, también de forma análoga a los de los grupos.

\begin{definition} Sea $f \colon A \longrightarrow B$ un homomorfismo de anillos conmutativos y unitarios. Entonces diremos que: \begin{enumerate}
\item $f$ es un \textbf{epimorfismo}, si es una aplicación suprayectiva.
\item $f$ es un \textbf{monomorfismo}, si es una aplicación inyectiva.
\item $f$ es un \textbf{isomorfismo}, si es una aplicación biyectiva.
\end{enumerate}
\end{definition}

\begin{example} En el anillo $\mathbb{Z}$ de los números enteros todos los ideales son principales, tal y como veremos más adelante. Así, para cada número entero $k$ se tiene el ideal $$(k) = I_{k} = k\mathbb{Z} = \lbrace pk : \hspace{0.1cm} p \in \mathbb{Z} \rbrace.$$ Y es claro que tanto $k$ como $-k$ generan el mismo ideal, así que tomaremos $k \geq 0$. Esto establece una biyección entre el conjunto de los ideales de $\mathbb{Z}$, $\mathcal{I}$, y los enteros no negativos, $\mathbb{Z}^+$, con $(0) = 0\mathbb{Z} = \lbrace 0 \rbrace$ y $1\mathbb{Z} = \mathbb{Z}$:

$$\begin{array}{rccl}
&\mathbb{Z}^+&\longrightarrow & \mathcal{I}\\
&k& \longmapsto &(k),
\end{array}
$$ 

Veamoslo:

Supongamos que $(k) = (l)$, con $k, l \geq 0$. Entonces $k \in (l)$ y $l \in (k)$. Si $l=0$, entonces $k \in (l) = (0) = \lbrace 0 \rbrace$, luego $k = l = 0$. Igualmente si $k = 0$. Ahora, sea $k,l > 0$. Entonces $$k = ql, \hspace{0.2cm} l = pk, \hspace{0.2cm} 0 < q, p \in \mathbb{Z}.$$ Y, por lo tanto, $k \geq l$ y $l \geq k$, y de aquí la igualdad.
\end{example}

$\hfill \blacksquare$

Vamos a desarrollar un poco el concepto de \textit{anillos isomorfos} para entender mejor qué significa que dos anillos lo sean. Ya sabemos que, en álgebra, el hecho de que dos objetos sean isomorfos quiere decir que esencialmente son el mismo, sólo cambian los nombres de sus elementos. Luego, dados dos anillos conmutativos y unitarios $A$ y $B$, diremos que son \textit{isomorfos} cuando exista un isomorfismo $f \colon A \longrightarrow B$. Esto implica inmediatamente que existe la aplicación inversa $f^{-1} \colon B \longrightarrow A$ y que es también un homomorfismo. Por tanto, si tenemos dos elementos $u,v \in B$, entonces $u=f(x)$, $v=f(y)$ para ciertos $x,y \in A$, éstos son únicos (por ser biyectiva) y así, tenemos que $$f(x+y)= f(x) + f(y) = u + v.$$ $$f^{-1}(u+v) = f^{-1}(u) + f^{-1}(v)= x + y.$$

Además, cuando dos anillos cualesquiera $A$ y $B$ sean isomorfos, escribiremos $A\cong B$. También es inmediato comprobar que un isomorfismo $f$ entre dos anillos conmutativos y unitarios $A$ y $B$ induce un isomorfismo de grupos entre $\mathcal{U}(A)$ y $\mathcal{U}(B)$.

\begin{theorem}[\textbf{\textit{Primer Teorema de Isomorfía}}]\label{eq:1ti} Sea $f \colon A \longrightarrow B$ un homomorfismo de anillos conmutativos y unitarios. Consideremos el diagrama siguiente:
$$\xymatrix @=2cm {A\ar[r]^{f} \ar[d]_\pi & B  \\ A/Ker f \ar[r]^{\bar{f}} & Im f \ar[u]_{i}  }$$

con $A/Ker f$ el anillo de clases módulo $Ker f$ y $$\begin{array}{rccl}
\pi \colon &A&\longrightarrow &A/Ker f \\
&x& \longmapsto &x + Ker f,
\end{array}
$$ 
la proyección canónica, que es suprayectiva.
$$\begin{array}{rccl}
\bar{f} \colon &A/Ker f&\longrightarrow &Im f \\
&x + Ker f& \longmapsto &f(x),
\end{array}
$$ 
la aplicación que nos induce, que será biyectiva, es decir, un isomorfismo: 

$$A/Ker f \cong Imf.$$

y
$$\begin{array}{rccl}
i \colon &Im f&\longrightarrow &B \\
&f(x)& \longmapsto &f(x) =y,
\end{array}
$$ 
la inclusión canónica, que será inyectiva. 

Así, en estas condiciones, todas las aplicaciones son homomorfismos y el diagrama es conmutativo, es decir, $$f = i \circ \bar{f} \circ \pi.$$
\end{theorem}
\emph{Demostración: }Veamos que $\bar{f}$ \begin{enumerate}
\item está bien definida, y es que si $x + Ker f = y + Ker f$ entonces tenemos que $x-y \in Ker f$ y así $f(x-y) = 0$, pero $f(x-y)= f(x) -f(y)$ y de aquí deducimos que $$f(x) = f(y),$$ y así $\bar{f}(x + Kerf) = \bar{f}(y+ Kerf)$, es decir, $\bar{f}$ no depende del representante que escojamos de la clase.
\item es inyectiva. Sean $x,y \in A$ tales que $\bar{f}(x + Kerf) = \bar{f}(y + Kerf)$. Esto quiere decir que $f(x) = f(y)$, y así $f(x) - f(y) = f(x-y) = 0$, luego $x-y \in Kerf$. Así, $x + Kerf = y + Kerf$ y $\bar{f}$ es inyectiva.
\item es suprayectiva. Sea $y \in Imf$, entonces $y = f(x)$ para algún $x \in A$ y así, $$y = \bar{f}(x + Kerf),$$ y $\bar{f}$ es suprayectiva, es decir, $\forall y \in Imf$ existe un $x + Kef \in A/Kerf$ tal que $\bar{f}(x + Kerf) = y$.
\end{enumerate}
Lo último es claro ya que, dado un $x \in A$, tenemos que $$f(x) = (i \circ \bar{f} \circ \pi) (x) = i(\bar{f}(\pi(x))) = i(\bar{f}(x + Kerf)) = i(f(x)) = f(x).$$

$\hfill \square$

\begin{observation}Notar que si aplicamos el \textit{Primer Teorema de Isomorfía} al homomorfismo evaluación ev un $b \in A$ cualquiera, tenemos que $$A[x]/ker \hspace{0.1cm} ev_b \cong A[b].$$
\end{observation}

\begin{corolario}$\mathbb{R}[x]/(x^2+1) \cong \mathbb{C}$.
\end{corolario}
\emph{Demostración: }Consideremos el homomorfismo $f \colon \mathbb{R}[x] \longrightarrow \mathbb{C}$ definido por la inclusión $\mathbb{R} \subseteq \mathbb{C}$ y tal que $f(x) = i$. Este homomorfismo es sobreyectivo ya que, dado $a+bi \in \mathbb{C}$, $f(a+bx)=a+ib$, por tanto $Imf = \mathbb{C}$. Basta ahora ver que $Kerf =(x^2+1)$. Como $\mathbb{R}$ es un cuerpo, todo ideal no trivial de $\mathbb{R}[x]$ está generado por cualquiera de sus elementos no nulos de grado mínimo. Por tanto, es suficiente comprobar que $x^2+1 \in Kerf$ y que $Ker f$ no posee ningún polinomio no trivial de grado menor que $2$. Claramente $f(x^2+1)=i^2+1 = 0$. Si $a+bx \in \mathbb{R}[x]$ es un polinomio no trivial entonces $f(a+bx) = a+ib$ es un número complejo no trivial, con lo que queda demostrado.

$\hfill \square$

\begin{definition}[\textbf{\textit{Anillos $\mathbb{Z}[\sqrt{n}]$}}] \label{def:ard}

Sea $n \in \mathbb{Z}$ que no es cuadrado de ningún entero. Entonces $\sqrt{n} \in \mathbb{C} \setminus \mathbb{Q}.$

Esto es así ya que por el \textit{Teorema fundamental de la aritmética} $n = p_1^{m_1}\ldots p_r^{m_r}$, con $p_1, \ldots, p_r$ primos distinto y $m_1, \ldots, _r$ enteros positivos tales que $m_1$ es impar. Si $\sqrt{n}$ fuese racional entonces existirían enteros positivos y primos entre sí $a,b$ tales que $\sqrt{n} = a/b$, por lo que $a^2 = nb^2$. Pero esto es imposible porque la mayor potencia de $p_1$ que divide al antero $a^2$ es par, mientras que la mayor potencia de $p_1$ que divide a $nb^2$ es impar.

Veamos que $\mathbb{Z}[\sqrt{n}] = \lbrace a + b\sqrt{n}:a,b \in \mathbb{Z}\rbrace$ es subanillo de $\mathbb{C}$ para cualquier $n \in \mathbb{Z}$ no cuadrado de ningún otro entero. Sean $a+b\sqrt{n}, a'+b'\sqrt{n} \in  \mathbb{Z}[\sqrt{n}]$, entonces $$(a+b\sqrt{n})- (a'+b'\sqrt{n}) = (a-a') + (b-b')\sqrt{n} \in \mathbb{Z}[\sqrt{n}],$$ ya que $(a-a')$ y $(b-b')$ son enteros. Por otro lado, $$(a+b\sqrt{n})(a'+b'\sqrt{n}) = (aa') + (bb')n +(ab'+a'b)\sqrt{n} \in \mathbb{Z}[\sqrt{n}],$$  ya que $(aa'),(bb')n,(ab'+a'b)$ son enteros.

Sin embargo, también podemos verlo de la siguiente forma: si $n \in \mathbb{Z}$ no es un cuadrado en $\mathbb{Z}$ entonces el conjunto $\mathbb{Z}[\sqrt{n}]=\lbrace a + b \sqrt{n}:a,b \in \mathbb{Z} \rbrace $ es un subanillo de $\mathbb{C}$ por ser la imagen del homomorfismo evaluación $$\begin{array}{rccl}
ev_{\sqrt{n}} \colon &\mathbb{Z}[x]&\longrightarrow &\mathbb{C} \\
&f& \longmapsto &f(\sqrt{n})
\end{array}
$$
y de hecho es el menor subanillo de $\mathbb{C}$ que contiene a $\mathbb{Z}$ y a $\sqrt{n}$. El núcleo de este homomorfismo es $ker \hspace{0.1cm} ev_{\sqrt{n}} = (x^2-n) \in \mathbb{Z}[x]$, luego, por el \textit{Primer Teorema de Isomorfía}, $$\mathbb{Z}[x]/(x^2-n) \cong \mathbb{Z}[\sqrt{n}].$$

Esto es así ya que es evidente que $x^2-n \in ker \hspace{0.1cm} ev_{\sqrt{n}}$. Recíprocamente, sea $f \in ker \hspace{0.1cm} ev_{\sqrt{n}}$, y supongamos que es de grado menor que $2$, es decir, de la forma $a+bx$ con $a,b \in \mathbb{Z}$, tal que $ev_{\sqrt{n}}(f)=0$. Así, $ev_{\sqrt{n}}(f)=a+b\sqrt{n} = 0$, de lo que deducimos que $\sqrt{n} = -a/b \in \mathbb{Q}$, lo cuál es absurdo por lo primero que hemos visto. Así, el polinomio mónico de menor grado es $x^2-n$, luego $ker \hspace{0.1cm} ev_{\sqrt{n}} = (x^2-n)$.

Para todo $\alpha = a + b\sqrt{n} \in \mathbb{Z}[\sqrt{n}]$ definimos el \textbf{conjugado} de $\alpha$ como $\overline{\alpha} = a-b\sqrt{n}$. Veamos que para cualesquiera $\alpha, \beta \in \mathbb{Z}[\sqrt{n}]$ se verifica que $\overline{\alpha\beta} = \overline{\alpha}\overline{\beta}$.

Si $\alpha = a + b\sqrt{n}$, $\beta = a'+b'\sqrt{n}$, entonces: \begin{center}$\overline{\alpha}\overline{\beta} = (a-b\sqrt{n})(a'-b'\sqrt{n})=aa'-ab'\sqrt{n}-a'b\sqrt{n}+bb'n = (aa'+bb'n)-(ab'+a'b)\sqrt{n},$\end{center} \begin{center}$\overline{\alpha\beta} = \overline{aa'+ab'\sqrt{n}+a'b\sqrt{n}+bb'n} = (aa'+bb'n)-(ab'+a'b)\sqrt{n}.$\end{center}
Además, notar que evidentemente $\alpha \overline{\alpha} = \overline{\alpha} \alpha$ para cualquier $\alpha \in \mathbb{Z}[\sqrt{n}]$.

De hecho, para todo $\alpha \in \mathbb{Z}[\sqrt{n}]$ definimos la \textbf{norma} de $\alpha$ como $N(\alpha) = \alpha \overline{\alpha}$. Notar que, dado un $\alpha = a + b \sqrt{n}$, entonces $N(\alpha) = \alpha \overline{\alpha} = (a+b\sqrt{n})(a-b\sqrt{n}) = a^2 - nb^2 \in \mathbb{Z}$. Por otra parte, para todo $\alpha, \beta \in \mathbb{Z}[\sqrt{n}]$ tenemos que $$N (\alpha \beta) = (\alpha \beta)(\overline{\alpha\beta}) = \alpha\beta \overline{\alpha}\overline{\beta} = \alpha\overline{\alpha} \beta \overline{\beta} = N(\alpha)N(\beta).$$

Veamos que, dado un $\alpha \in \mathbb{Z}[\sqrt{n}]$, $N(\alpha) = \pm 1 \Leftrightarrow$ $\alpha$ es unidad en $\mathbb{Z}[\sqrt{n}]$.

Si $N(\alpha) = 1$, entonces $\alpha \overline{\alpha} = 1$ y así $\alpha$ es unidad en $\mathbb{Z}[\sqrt{n}]$. Si $N(\alpha) = -1$, entonces $\alpha(-\overline{\alpha}) = 1$ y así $\alpha$ es nuevamente unidad en $\mathbb{Z}[\sqrt{n}]$. Recíprocamente, si $\alpha \in \mathbb{Z}[\sqrt{n}]$ es unidad, existirá un $\beta \in \mathbb{Z}[\sqrt{n}]$ tal que $\alpha \beta = 1$. Tomando normas: $$1 = N(1) = N(\alpha \beta) = N(\alpha)N(\beta),$$ pero la norma es un número entero, luego $N(\alpha)$ sólo puede ser $1$ o $-1$.
\end{definition}

\begin{theorem}[\textbf{\textit{Segundo Teorema de Isomorfía}}]
Sean $A \subseteq B$ dos anillos conmutativos y unitarios, e $I$ un ideal de $B$. Entonces $A + I$ es un subanillo de $B$ que contiene a $I$. Además, los anillos $(A+ I)/I$ y $A/(A \cap I)$ son isomorfos.
\end{theorem}
\emph{Demostración: } Que $A + I$ es subanillo de $B$ es inmediato. Para ver lo segundo consideremos el siguiente homomorfismo: $$\begin{array}{rccl}
f \colon &A&\longrightarrow &(A + I)/I \\
&x& \longmapsto &x + I.
\end{array}
$$ Su núcleo estará formado por todos los elementos $x \in A$ que también estén en $I$, es decir, $Ker f = A \cap I$. Además $f$ es suprayectiva, ya que para todo $y \in (A+ I)/I$ existen $x \in A$ y $b \in I$ tales que $y = (x +b) + I = x + I = f(x)$. Entonces, por el \textit{Primer Teorema de Isomorfía}~\ref{eq:1ti}, los anillos $A/(A \cap I)$ y $(A+I)/I$ son isomorfos.

$\hfill \square$

\begin{theorem}[\textbf{\textit{Tercer Teorema de Isomorfía}}]
Sean $A$ un anillo conmutativo y unitario, y $J, I$ ideales de $A$ tales que $J \subseteq I$. Entonces los anillos $(A/J)/(I/J)$ y $A/I$ son isomorfos.
\end{theorem}
\emph{Demostración: }En este caso consideraremos el siguiente homomorfismo de anillos conmutativos y unitarios: $$\begin{array}{rccl}
f \colon &A/J&\longrightarrow &A/I \\
&x+ J& \longmapsto &x + I.
\end{array}
$$ Evidentemente es suprayectivo y está bien definido, pues $J \subseteq I$. Ahora, $Ker f = \lbrace a + J: a \in I \rbrace = I/J$. De nuevo, por el \textit{Primer Teorema de Isomorfía}~\ref{eq:1ti} tenemos que $(A/J)/(I/J) \cong A/I$.

$\hfill \square$

\begin{example} Dos ejemplos conocidos: \begin{enumerate}
\item Sea $A$ un anillo conmutativo y unitario, e $I$ un ideal propio de $A$. Entonces podemos definir una aplicación $$\begin{array}{rccl}
p \colon &A&\longrightarrow &A/I \\
&x& \longmapsto &x + I,
\end{array}
$$ que será siempre un epimorfismo, es decir, suprayectiva.
\item La conjugación del \textbf{anillo de los enteros de Gauss}: $$\begin{array}{rccl}
f \colon &\mathbb{Z}[i]&\longrightarrow &\mathbb{Z}[i] \\
&x& \longmapsto &\bar{x}
\end{array}
$$ es un isomorfismo. De hecho, su inversa es ella misma, ya que $$f^{2}(a+bi)= (f \circ f)(a+bi)= f(a-bi)= a+bi.$$
También lo será cuando nos encontremos en el cuerpo de los complejos $\mathbb{C}$.
\end{enumerate}
\end{example}
$\hfill \blacksquare$

\begin{theorem}[\textbf{\textit{Teorema de la Correspondencia}}]Sean $A$ un anillo e $I$ un ideal de $A$. Sea $\mathcal{I}$ el conjunto de los ideales de $A$ que contienen al ideal $I$ y $\mathcal{J}$ el conjunto de los ideales de $A/I$. Entonces la aplicación $$\begin{array}{rccl}
f \colon &\mathcal{I}&\longrightarrow &\mathcal{J} \\
&T& \longmapsto &T/I = \lbrace x+I : x\in T \rbrace
\end{array}
$$ 
es biyectiva.
\end{theorem}
\emph{Demostración: }Consideramos la proyección canónica $\pi \colon A \longrightarrow A/I$, que sabemos es un epimorfismo. Como la aplicación es sobreyectiva sabemos que para un ideal $T \in \mathcal{I}$ su imagen $T/I \in A/I$ es también un ideal de $A/I$, luego $f$ está bien definida. 

Veamos ahora que es biyectiva, para lo cuál construiremos su inversa. Por~\ref{eq:idif}, si $J$ es un ideal de $A/I$ se tiene que $\pi^{-1}(J)=T$ es un ideal de $A$ que contiene a $ker \hspace{0.1cm} \pi = I$, es decir, $T \in \mathcal{I}$. Así, obtenemos una aplicación 
$$\begin{array}{rccl}
h \colon &\mathcal{J}&\longrightarrow &\mathcal{I} \\
&J& \longmapsto &\pi^{-1}(J)
\end{array}
$$ 
tal que $f \circ h = id_{\mathcal{J}}$ y $h \circ f = id_{\mathcal{I}}$.

$\hfill \square$

Es decir, los ideales de $A/I$ serán aquellos ideales de $A$ que contengan al ideal $I$, tal y como vimos en el capítulo anterior.

\begin{proposition}Sea $A$ un anillo e $I$ un ideal de $A$. Consideremos el anillo cociente $A/I$ e $\mathcal{I}$ el conjunto de los ideales de $A$ que contienen a $I$. Entonces: 
\begin{enumerate}
\item Un ideal $P \in \mathcal{I}$ es primo si y sólo si $P/I$ es un ideal primo de $A/I$.
\item Un ideal $M \in \mathcal{I}$ es maximal si y sólo si $M/I$ es un ideal maximal de $A/I$.
\end{enumerate}
\end{proposition}
\emph{Demostración: }Veamos el primer resultado. Si consideramos la proyección canónica $\pi \colon A \longrightarrow A/I$, sabemos que si $\pi (P) = P/I$ es un ideal primo entonces $P = \pi^{-1} (P/I)$ es también primo. Recíprocamente, supongamos que $P$ es un ideal primo de $A$ que contiene a $I$ y veamos que $P/I$ es primo. Sean $a,b \in A/I$ tales que $ab \in P/I$. Entonces existen $c,d \in A$ tales que $a = c + I$ y $b = d + I$, por lo que $cd + I = ab \in P/I$, luego $cd \in P$. Como $P$ es un ideal primo podemos suponer que $c \in P$, por lo que $a = c+ I \in P/I$, luego $P/I$ es primo.

Veamos ahora la segunda parte. Supongamos que $M$ es un ideal maximal de $A$ que contiene a $I$ pero $M/I$ no es un ideal maximal de $A/I$. Entonces existe un ideal $(b) \subset A$ que contiene a $I$ tal que $M/I \subset (b)/I$, luego $M = \pi^{-1}(M/I) \subset \pi^{-1}((b)/I) = (b)$. Esto implica, por ser $M$ maximal, que $M = (b)$, luego $M/I = (b) /I$, que es una contradicción. Recíprocamente, supongamos que $(c)$ es un ideal no maximal de $A$ tal que $J = (c)/I$ es un ideal maximal de $A/I$. Existe por tanto un ideal propio $M$ de $A$ tal que $(c) \subset M$. En particular, $J = (c)/I \subset M/I$ y como $J$ es maximal tendremos la igualdad $J = M/I$. Esto implica que $(c) = \pi^{-1}(J) = \pi^{-1}(M/I) = M$, que de nuevo es una contradicción.

$\hfill \square$

Finalmente, terminaremos estas generalidades de anillos enunciando y demostrando un resultado más que interesante que se conoce ya de aritmética. Es el \textit{Teorema chino de los restos}. Necesitaremos recordar la noción de ideales comaximales, presentada en~\ref{eq:comax}.

\begin{theorem}[\textbf{\textit{Teorema chino de los restos}}]
Sea $A$ un anillo, $r \geq 2$ un número entero e $I_{1}, \cdots, I_{r}$ ideales de $A$ comaximales dos a dos, es decir, $I_{i} + I_{j} = A$ si $i \neq j$. Entonces, se tiene: \begin{enumerate}
\item $I_{1} + (I_{2} \cdots I_{r}) = A.$
\item $I = I_{1} \cap \cdots \cap I_{r} = I_{1} \ldots I_{r}.$
\item El homomorfismo $$\begin{array}{rccl}
f \colon &A&\longrightarrow &A/I_{1}\times \cdots \times A/I_{r} \\
&x& \longmapsto &(x + I_{1}, \ldots, x+ I_{r}),
\end{array}
$$ es sobreyectivo.
\item Los anillos $A/I$ y $A/I_{1}\times \cdots \times A/I_{r}$ son isomorfos.
\end{enumerate} 
\end{theorem}
\emph{Demostración: } Veámoslo punto por punto: \begin{enumerate}
\item Lo demostraremos por inducción sobre $r$, siendo obvio para $r = 2$. Sea $r \geq 3$ y supondremos probado que $I_{1} + (I_{2} \cdots I_{r-1}) = A$, como $I_{1} + I_{r} = A$ existirán $x_{1},y_{1} \in I_{1}$, $x \in I_{2} \cdots I_{r-1}$, $y \in I_{r}$ tales que $1 = x_{1} + x$ y $1 = y_{1} + y$. Por lo que $$1 = (x_{1} +x)(y_{1} + y)=(x_{1}y_{1} + x_{1}y + xy_{1}) + xy \in I_{1} + (I_{2} \cdots I_{r-1}I_{r}),$$ y así $I_{1} + (I_{2} \cdots I_{r}) = A.$
\item En el anterior apartado se ha visto que $I_{1}$ y $J= I_{2} \cdots I_{r}$ son comaximales, y de~\ref{eq:comax} deducimos que $$I = I_{1} \cap \ldots \cap I_{r} = I_{1} \cap J = I_{1}J = I_{1} \cdot (I_{2} \cdots I_{r}) = I_{1} \cdots I_{r}.$$
\item Deducimos de $1.$ que para cada índice $1 \leq i \leq r$, $I_{i} +I_{1}\cdots I_{i-1}\cdot I_{i+1} \cdots I_{r} = A.$ Por lo tanto, existen $u_{i} \in I_{i}$ y $v_{i} \in I_{1}\cdots I_{i-1}\cdot I_{i+1} \cdots I_{r}$ tales que $u_{i} + v_{i} = 1$, para cada $i = 1, \ldots, r$. Así, dados $x_{1}, \ldots, x_{r} \in A$, elegimos $x = x_{1}v_{1} + \ldots + x_{r}v_{r} \in A$ y tenemos que $$x + I_{i} = x_{1}v_{1} + \ldots + x_{r}v_{r} + I_{i} = x_{i}v_{i} + I_{i} =  x_{i}v_{i} +x_{i}u_{i} + I_{i} = x_{i}(v_{i} + u_{i}) + I_{i} = x_{i} + I_{i},$$ donde al pasar a la tercera igualdad $x_{i}u_{i}$ aparece porque $u_{i} \in I_{i}$. Así, $f(x) = x_{1} + I_{1}, \ldots, x_{r} + I_{r}$ y $f$ es sobreyectiva. 
\item Se deduce fácilmente que $Ker f = I_{1} \cap \cdots \cap I_{r} = I$, con $f$ el homomorfismo del apartado anterior, y aplicando el \textit{Primer Teorema de Isomorfía}~\ref{eq:1ti} ya está.
\end{enumerate}
$\hfill \square$


\subsection{Divisibilidad}

Durante esta sección consideraremos a $A$ como un dominio de integridad. Empezaremos dando unas definiciones:

\begin{definition} Sean $a, b$ elementos de $A$ con $a \neq 0$. Se dice que \textbf{$a$ divide a $b$, que $a$ es un divisor de $b$, que $b$ es divisible por $a$ o que $b$ es un múltiplo de $a$} si existe un $c \in A$ tal que $b = ac$. Se escribe $a \mid b$. Si $a$ no divide a $b$ se escribe $a \nmid b$.

En otras palabras, $a \mid b \Leftrightarrow a \in (b)$, ó equivalentemente $(b) \subseteq (a)$.
\end{definition}

Esto nos presenta la divisibilidad como una relación de orden parcial que será inmediata para ideales pero que para entenderla entre elementos habrá que describir la relación de igualdad asociada: 

\begin{center}
$a$ está relacionado con $b$ si $a \mid b$ y $b \mid a$, o sea si $(a) = (b).$
\end{center} 

Esto es equivalente a: 

Existe una unidad $u \in \mathcal{U}(A)$ tal que $b = ua$. Esto es así ya que si $(b) = (a)$ tendremos que $b \in (a), a \in (b)$, luego $b = ac$ y $a = bd$, con $c, d \in A$. Luego $b = bdc$ y como $A$ es un dominio de integridad podremos simplificar y obtener $1 = dc$, y así $c$ es unidad.

Y de aquí llegamos a la definición de \textit{elementos asociados}.

\begin{definition}Dos elemento $a,b \in A$ se dirán \textbf{asociados} en $A$ si $a \mid b$ y $b \mid a$. Por ejemplo, en $\mathbb{Z}$ $n$ y $-n$ lo son. Ser asociados es una relación de equivalencia en $A$, en la que la clase de un $a$ cualquiera (sus asociados) estará formada por elementos de la forma $ua$, con $u \in \mathcal{U}(A)$. 
\end{definition}

Lo podemos resumir diciendo que dos elementos $a,b \in A$ son asociados si y sólo si $(a) = (b)$. De igual forma diremos que $b$ es un asociado de $a$ si $a = ub$, con $u \in \mathcal{U}(A)$.

Estos elementos son distintos, pero se comportan de forma análoga desde el punto de vista de la divisibilidad, es decir, tienen los mismos múltiplos y los mismos divisores.

\begin{definition} Dado $A$ un dominio de integridad, y $a \in A$ no nulo. Diremos que $a$ es \textbf{primo} si el ideal que genera, $I=aA = (a)$, es primo. Diremos que $a$ es \textbf{reducible} en $A$ si existen $b,c \in A \setminus \mathcal{U}(A)$ tales que $a =bc$. Si $a$ no es reducible ni unidad se dice que es \textbf{irreducible} en $A$.
\end{definition}

Alternativamente, podemos definir elementos irreducibles así: 

Si $y \in A^{\ast}$ no es unidad, denotaremos $div(y)$ el conjunto de todos los divisores de $y$. Es claro que los conjuntos $y \cdot \mathcal{U}(A)$ y $\mathcal{U}(A)$ están contenidos en $div(y)$. Así, si $y$ no tiene más divisores que las unidades y los productos del propio $y$ por unidades diremos que $y$ es \textbf{\textit{irreducible}}.

Así, hablaremos de \textbf{\textit{elementos irreducibles}} cuando sus únicos divisores sean unidades y asociados.

\begin{proposition}\label{eq:eirr} Sea $A$ un anillo y $a \in A \setminus \mathcal{U}(A)$ un elemento no nulo. 
\begin{enumerate}
\item El elemento $a$ es primo si y sólo si para cada par de elementos $b, c \in A$ tales que $a \mid bc$ se cumple que $a \mid b$ ó $a\mid c$.
\item Si $A$ es dominio de integridad y $a \neq 0$ es primo, entonces $a$ es irreducible.
\item Sea $A$ un dominio de integridad. Entonces, un elemento no nulo $a \in A$ es irreducible si y sólo si $I=(a)$ es un ideal maximal entre los ideales principales propios de $A$.
\end{enumerate}
\end{proposition}
\emph{Demostración: }\begin{enumerate}
\item Supongamos que $a$ es primo, luego $I=(a)$ es primo, y sean $b,c \in A$ tales que $a \mid bc$. Entonces $bc \in I$, y como $I$ es primo entonces $b \in I$ o $c \in I$. En el primer caso $a \mid b$ y en el segundo caso $a \mid c$.

Recíprocamente, sean $a,b,c \in A$, $I = (a)$, tales que $a \mid bc$ y así $bc \in I$, si $a \mid b$ entonces $b \in I$ y si $a \mid c$ entonces $c \in I$. Así $I$ es primo.
\item Sea $a$ primo e $I=(a)$, supongamos que $a$ es reducible. Entonces $a = bc$, con $b,c \in A \setminus \mathcal{U}(A)$. Como $bc \ I$ y este ideal es primo, podemos suponer que $b \in I$, luego existe $u \in A$ tal que $b = au$. Así, $a = bc = auc$, luego, como $a \neq 0$ y A es dominio de integridad, $1 = uc$. Esto querría decir que $c \in \mathcal{U}(A)$, absurdo.
\item Supongamos que el ideal $I$ no es maximal entre los ideales principales propios de $A$. Entonces, existe un $b \in A$ tal que $(a) = I \subset (b) = J \neq A$. En particular, ni $a$ ni $b$ son unidades de $A$ y existe un $c \in A$ tal que $a = bc$. Tampoco $c$ es unidad en $A$ porque la inclusión $I \subset J$ es estricta. Por lo tanto $a$ es reducible.

Recíprocamente, si $a$ es reducible existen $b, c \in A \setminus \mathcal{U}(A)$ tales que $a = bc$. Por lo tanto, $(a) = I \subset (b) = J \neq A$ ya que $b$ no es unidad en $A$. Veamos que la inclusión es estricta, y es que si no lo fuera entonces $a$ y $b$ serían asociados. Así, existiría una unidad $u \in A$ tal que $a = bu$. Por lo tanto, $b(c-u) = bc-bu = a-a = 0$ y como $A$ es dominio de integridad, $b = 0$ ó $c = u$. Lo primero implicaría que $a = 0$, lo cual es falso. Así, $c = u \in \mathcal{U}(A)$, que también es falso.
\end{enumerate}

$\hfill \square$

El recíproco de $2.$ en general no se cumple, para que lo haga se tendrá que cumplir que todos los ideales de $A$ sean principales aunque esto lo desarrollaremos más adelante.

Una clase importante de dominios de integridad, en la que la relación de divisibilidad puede ser estudiada con ventaja, es:

\subsubsection{Dominios euclídeos}
\begin{definition} \label{eq:de} Diremos que $A$ es un \textbf{dominio euclídeo}, escrito $DE$, si existe una aplicación $$\begin{array}{rccl}
\norm{\cdot}\colon A\longrightarrow \mathbb{N}
\end{array}
$$
que cumpla: \begin{enumerate}
\item $\norm{x} = 0$ si y sólo si $x = 0$.
\item $\norm{xy} = \norm{x} \cdot \norm{y}.$
\item Si $x, y \in A^{\ast}$, existe $r \in A$ tal que $y \mid (x-r)$ y $\norm{r} < \norm{y}$. Esto no viene a ser más que la división de los enteros, donde $r$ es el resto y el elemento $q \in A$ tal que $x-r = qy$ el cociente. 
\end{enumerate}
A esta aplicación la denominaremos \textbf{norma euclídea}.
\end{definition}

La última condición puede ser reformulada tal que así: dados $x,y \in A$ no nulos (en realidad bastaría con que sólo lo fuera $y$) existen $r$ y $q$ tales que $x=qy+r$, con $r=0$ ó bien $\norm{r} < \norm{y}$.

Notar que el anillo de los enteros $\mathbb{Z}$ es un dominio eculídeo tomando como aplicación el módulo $|\cdot |$.

En un dominio euclídeo se cumple la siguiente propiedad, que ya vimos por encima cuando hablamos de los anillos $\mathbb{Z}[\sqrt{n}]$ en~\ref{def:ard}.

\begin{proposition} Sea $A$ un dominio euclídeo. Entonces: $$\mathcal{U}(A) = \lbrace x \in A : \norm{x} = 1 \rbrace.$$
\end{proposition}
\emph{Demostración: } Lo primero notar que $\norm{1_{A}} = 1$, puesto que $\norm{1_{A}} = \norm{1_{A}\cdot 1_{A}} = \norm{1_{A}}^{2}$ y como $\norm{1_{A}} \neq 0$, tenemos que $\norm{1_{A}} = 1$.

Veamos que $\mathcal{U}(A) \subseteq \lbrace x \in A : \norm{x} = 1 \rbrace$. Si $x \in A$ tiene inverso $x^{-1}$, resulta que $\norm{x} \cdot \norm{x^{-1}} = \norm{x\cdot x^{-1}} = \norm{1_{A}} = 1.$ Luego necesariamente $\norm{x} = 1$ (recordar que son naturales).

Recíprocamente, sea $x \in A$ con $\norm{x} = 1$. Entonces $x \neq 0$ y por definición se tiene que $x \mid (1_{A}-r)$ para un cierto $r \in A$, con $\norm{r} < \norm{x}.$ Como $\norm{x} = 1$, sólo puede ser $\norm{r} = 0$, luego $r = 0$. Así $x \mid 1_{A}$ y por tanto se trata de una unidad. 
 
$\hfill \square$

Por ejemplo, en el caso de $\mathbb{Z}[i]$, si definimos el módulo de un elemento $z = a+bi \in \mathbb{Z}[i]$ como $\norm{z} = a^{2} + b^{2}$ y para calcular sus unidades veamos aquellos que cumplen que $a^{2} + b^{2} = 1$. Como $a,b \in \mathbb{Z}$, tenemos que uno de ellos es $0$ y el otro es $\pm 1$. Por lo que $$\mathcal{U}(\mathbb{Z}[i]) = \lbrace 1, -1, i, -i \rbrace.$$

\begin{example}Sea $A = \lbrace a + b \sqrt{-2}: a, b \in \mathbb{Z} \rbrace $. La aplicación 

$$\begin{array}{rccl}
\varphi \colon &A \setminus \lbrace 0 \rbrace &\longrightarrow &\mathbb{N} \\
&x = a+b\sqrt{-2}& \longmapsto &x\bar{x} = a^2 + 2b^2
\end{array}
$$ 
dota al anillo $A$ de estructura de dominio euclídeo, cuyas unidades son $1$ y $-1$. Tal y como vimos en~\ref{def:ard}, como $-2$ es un entero que es no cuadrado de ningún otro entero, sabemos que $A$ es un subanillo de $\mathbb{C}$. De~\ref{def:ard} también vemos fácilmente que $A$ cumple con las dos primeras propiedades de los $DE$ y también que sus unidades son $1$ y $-1$.

Veamos ahora que existe división euclídea con respecto a $\varphi$. Sean $x = a+b\sqrt{-2}$, $y = c+d\sqrt{-2} \in A$ con $y \neq 0$. Dividiendo, $$\dfrac{x}{y} = \dfrac{x\bar{y}}{y\bar{y}} = \dfrac{(u+v\sqrt{-2})}{\norm{y}},$$ con $u,v \in \mathbb{Z}$, $\norm{y}>0$. Los números $q_1 = u/\norm{y}$, $q_2 = v/\norm{y}$ son reales, por lo que existirán enteros $\alpha, \beta$ tales que $|q_1 - \alpha| \leq 1/2$, $|q_2 - \beta | \leq 1/2$. Si denotamos por $r_1 = q_1 - \alpha$ y $r_2 = q_2 - \beta$ tenemos $$x = (q_1 + q_2\sqrt{-2})y, \quad q_1 + q_2\sqrt{-2} = \alpha + r_1 + (\beta + r_2)\sqrt{-2} = \alpha + \beta\sqrt{-2} + (r_1 + r_2\sqrt{-2}),$$ con $|r_1|, |r_2| \leq 1/2$. Así, $x = (\alpha + \beta \sqrt{-2})y + (r_1+r_2\sqrt{-2})y$, por lo que sólo tenemos que comprobar que $\norm{(r_1+r_2\sqrt{-2})y}< \norm{y}$. $\norm{(r_1+r_2\sqrt{-2})y} = (r_1+r_2\sqrt{-2})y\overline{(r_1+r_2\sqrt{-2})y} = y\bar{y}(r_1+r_2\sqrt{-2})\overline{(r_1+r_2\sqrt{-2})} = \norm{y}(r_1^2+2r_2^2 )\leq (1/4+2/4)\norm{y} < \norm{y}$.
\end{example}

$\hfill \blacksquare$

\begin{proposition}\label{eq:dedip} En un dominio euclídeo todos los ideales son principales.
\end{proposition}
\emph{Demostración: } Sea $I$ un ideal no nulo de un dominio euclídeo $A$. Elijamos un $x \in I$ tal que $$\norm{x} = \min \lbrace \norm{y} :0 \neq y \in I \rbrace.$$ Este mínimo existe y es $>0$, puesto que es el mínimo de un conjunto no vacío de números naturales positivos. Afirmamos que $I$ está generado por $x$.\vspace{0.2cm}\\
En efecto, sea $y \in I$, $y \neq 0$. Entonces como $x \in A^{\ast}$, existirá $r \in A$ tal que $x \mid (y-r)$ y con $\norm{r} < \norm{x}$. De esto deducimos que $y-r \in (x) \subseteq I$, y como $y \in I$ e $I$ es ideal, $r \in I$. Pero la minimalidad de $\norm{x}$ y la condición de que $\norm{r} < \norm{x}$ implican que $r = 0$. Así, $y = y-r$ está en $(x)$, y por lo tanto $I = (x)$.

$\hfill \square$

Este resultado que acabamos de ver nos dice que en los dominios euclídeos todos los ideales son generados por un sólo elemento, luego principales, y si definimos a éstos como una nueva clase de dominios habremos encontrado otra estructura que nos facilitará mucho el trabajo con ideales. 

\subsubsection{Dominios de ideales principales}

\begin{definition} Llamaremos \textbf{dominio de ideales principales}, escrito como $DIP$, a un dominio de integridad en el que todos sus ideales son principales. Todo $DE$ es un $DIP$.
\end{definition} 

Aunque ya sabemos que $\mathbb{Z}$, como es dominio euclídeo, es un $DIP$, es interesante notar que no haría falta que pudiese definirse el módulo para que fuera un $DIP$:

\begin{proposition}$\mathbb{Z}$ es un $DIP$.
\end{proposition}
\emph{Demostración: }Si $I \subseteq \mathbb{Z}$ es un ideal, en particular es subgrupo, y como $\mathbb{Z}$ es cíclico todos sus subgrupos lo son, es decir, $I = \langle n \rangle = (n)$, para algún entero $n$. 

$\hfill \square$

De la demostración también vemos que $\mathbb{Z}$ es un anillo noetheriano. De hecho, como en un dominio de ideales principales todos los ideales son finitamente generados, \textbf{\textit{todos los $DIP$ son anillos noetherianos}}.

En concreto ya sabemos que todos los ideales de $\mathbb{Z}$ son de la forma $n\mathbb{Z}$.

\begin{proposition} Sea $A$ un $DIP$. Entonces todo elemento irreducible $a \in A^{\ast}$ genera un ideal maximal.
\end{proposition}
\emph{Demostración: }Sabemos de~\ref{eq:eirr} que un elemento irreducible genera un ideal maximal entre los ideales principales propios de $A$, pero como $A$ es $DIP$ todos sus ideales son principales, luego el ideal que genera $a$ será maximal.

$\hfill \square$

De este resultado se desprende de forma clara que en un dominio de ideales principales todos los ideales primos son maximales.

Anteriormente vimos que todo elemento primo es irreducible, ahora veremos que dadas unas condiciones también se cumple el recíproco.

\begin{proposition}\label{pregauss0} Sea $A$ un $DIP$. Entonces todo elemento irreducible de $A$ es primo.
\end{proposition}
\emph{Demostración: }Por el resultado anterior sabemos que todo elemento irreducible genera un ideal maximal, y como todo ideal maximal es primo, llegamos a la conclusión de que ese elemento es primo.

$\hfill \square$


A continuación desarrollaremos una definición que ya vimos anteriormente, tanto para anillos como para cuerpos, y que nos habla sobre el menor entero tal que multiplicado por el neutro de un anillo/cuerpo nos da el cero. 

\begin{definition}[\textbf{\textit{Característica de un dominio de integridad.}}] Consideremos de nuevo un dominio $A$. Si $k \in \mathbb{Z}$, definimos un elemento $k \cdot 1_{A} \in A$: $$k \cdot 1_{A} = 1_{A} + \cdots + 1_{A} \hspace{0.1cm} \text{si $k>0$}$$ $$k \cdot 1_{A} = 0 \hspace{0.1cm} \text{si k = 0}$$ $$k \cdot 1_{A} = -((-k) \cdot 1_{A}) \hspace{0.1cm} \text{si $k<0$}.$$
Entonces, $$\begin{array}{rccl}
\phi \colon &\mathbb{Z}&\longrightarrow &A \\
&k& \longmapsto &k\cdot 1_{A}
\end{array}
$$ es un homomorfismo de anillos. Consideremos su núcleo $Ker \hspace{0.1cm} \phi$. Entonces pueden darse dos casos: \begin{enumerate}
\item $Ker \hspace{0.1cm} \phi = \lbrace 0 \rbrace$. Entonces $\mathbb{Z} \subseteq A$ vía $\phi$, y diremos que $A$ tiene \textbf{característica $0$}. Esto ocurre, por ejemplo para $A = \mathbb{Z}, \mathbb{Q}, \mathbb{R}, \mathbb{C}$ ó $\mathbb{Z}[i]$. En este caso el menor entero $k$ tal que $k \cdot 1_{A} = 0$, es el $0$.
\item $Ker \hspace{0.1cm} \phi \neq \lbrace 0 \rbrace$. Como $\mathbb{Z}/Ker \hspace{0.1cm} \phi \cong Im \hspace{0.1cm} \phi \subseteq A$ y $A$ es dominio de integridad, $\mathbb{Z}/Ker \hspace{0.1cm} \phi$ también lo será, y así $Ker \hspace{0.1cm} \phi$ será un ideal primo. Como $\mathbb{Z}$ es un $DIP$, $Ker \hspace{0.1cm} \phi = (p)$, con $p$ primo. Diremos entonces que $A$ tiene \textbf{característica $p$}. De hecho, por el resultado anterior, $\mathbb{Z}/(p)$ es un cuerpo. Además, todo anillo finito tiene característica positiva.
\end{enumerate}
\end{definition}

Es decir, la característica de un anillo $A$ es el núcleo del homomorfismo anterior.

\begin{definition} Sean $x,y \in A\setminus \lbrace 0 \rbrace$. Diremos que $z \in A$ es: \begin{enumerate}
\item Un \textbf{máximo común divisor} (mcd) de $x,y$ si $z$ divide tanto a $x$ como a $y$, y es múltiplo de cualquier otro divisor de ambos.
\item Un \textbf{mínimo común múltiplo} (mcm) de$x,y$ si $z$ es múltiplo de $x$ y de $y$, y además divide a cualquier otro múltiplo de ambos.
\end{enumerate}
\end{definition}

\begin{observation}\label{eq:obs} Algunas observaciones respecto a estas definiciones: \begin{enumerate}
\item Si $z, z'$ son dos mcd de $x,y$ entonces $z \mid z'$ y $z' \mid z$, luego los elementos difieren en una unidad, es decir, $(z) = (z')$. En este sentido se tiene la unicidad del mcd. Igualmente para el mcm.
\item Podemos expresar el mcd en términos de ideales así: $$(x) + (y) \subseteq (z) \subseteq \bigcap \lbrace I : I\supseteq (x) +(y), \hspace{0.1cm} I \hspace{0.1cm} \text{principal}\rbrace.$$
\item La descripción del mcm mediante ideales es: $z$ es mcm de $x,y$ si y sólo si $$(x) \cap (y) = (z).$$ En efecto, si $z$ es el mcm, $z \subseteq (x)$ y $z \subseteq (y)$, luego se tiene el contenido $(x) \cap (y) \supseteq (z)$. Pero si $t \in (x) \cap (y)$, entonces $t$ e múltiplo de $x$ y de $y$, luego $z \mid t$ y $t \in (z)$. Esto da la igualdad. Recíprocamente, si $(x) \cap (y) = (z)$, entonces $x \mid z$, $y \mid z$, y si $t$ es otro múltiplo común, entonces $t \in (x) \cap (y) = (z)$ y $z \mid t$.
\item En general, el mcd puede no existir, y esto estará relacionado con las propiedades de los elementos irreducibles de $A$.
\end{enumerate} 
\end{observation}

\begin{proposition} \label{eq:lemdiv} Sean $x, y \in A\setminus \lbrace 0 \rbrace$, y supongamos que tienen un $mcm$ $z$. Entonces $t = xy/z \in A$ y $t$ es un $mcd$ de $x,y$.
\end{proposition}
\emph{Demostración: } Por definición de $mcm$, $z$ divide a $xy$, luego $t$ es un elemento de $A$ bien definido. Por otra parte, $x \mid z$ e $y\mid z$, luego $z = ax$, $z =by,$ con $a,b \in A.$ \vspace{0.2cm}\\
Se tiene $zx =byx = btz$, y como $A$ es dominio $x = bt$ y $t \mid x$. Análogamente, $t \mid y$. Por otra parte, si $u$ es un divisor común de $x$ e $y$, entonces $x = cu, y = du$, con $c,d \in A$. Observamos que  $$xy/u = (x/u)y = cy, \hspace{0.2cm} xy/u = (y/u)x = dx,$$ luego $xy/u$ es múltiplo común de $x$ e $y$, con lo que $z$ divide a $xy/u$, y en consecuencia, $u$ divide a $xy/z = t$. Esto prueba que $t$ es múltiplo de cualquier divisor común $u$ de $x$ e $y$.

$\hfill \square$

\begin{proposition} \label{eq:mcmd} Sea $A$ un dominio de integridad, entonces son equivalentes:
\begin{enumerate}
\item Todo par de elementos no nulos tienen $mcm$.
\item Todo par de elementos no nulos tienen $mcd$.
\end{enumerate}
Y se cumple que, si $x,y \in A^{\ast}$, entonces $$mcm(x,y) \cdot mcd(x,y) = xy.$$
\end{proposition}
\emph{Demostración: } Que el primero implica el segundo es claro por el resultado anterior. Veamos el recíproco. Sean $x,y \in A$, $t = mcd(x,y)$. Entonces $$z = xy/t = (x/t)y = x(y/t)$$ es múltiplo de $x$ y de $y$. Consideremos otro múltiplo común $u$. Entonces $$tu = mcd(xu,yu) \hspace{0.2cm} (\ast).$$ En efecto, sea $d = mcd(xu,yu)$. Evidentemente $tu \mid d$ y así $d = tuv$. Entonces $tuv$ divide a $xu$ y a $yu$, de donde $tv$ divide a $x$ e $y$, luego $tv$ divide a $t$ y $v$ es unidad. Así, tenemos $(\ast)$.\vspace{0.2cm}\\
Claramente $xy \mid xu$ y $xy \mid tu$, esto es, $xy / t$ divide a $u$. Así $z = xy/t = mcm(x,y)$, y multiplicando esta igualdad por $t$ queda $zt = xy$.

$\hfill \square$

\begin{corolario} Sea $A$ un dominio de ideales principales. Entonces el mcd y el mcm de dos elementos no nulos cualesquiera de $A$ siempre existe, y se tiene que: \begin{enumerate}
\item $(x) + (y) = (mcd).$
\item $(x) \cap (y) = (mcm).$
\item $xy = mcd \cdot mcm.$
\end{enumerate}
\end{corolario}
\emph{Demostración: }Por la hipótesis sobre $A$, $(x) \cap (y)$ es principal, luego por ~\ref{eq:obs} (3) existe el mcm y se cumple $2.$. Ahora, por~\ref{eq:lemdiv} existe el mcd y se cumple $3.$ Finalmente, de nuevo por ser $A$ un $DIP$, $(x) + (y)$ es principal, y de~\ref{eq:obs} (2) se sigue $1.$

$\hfill \square$

\begin{proposition}[\textbf{\textit{Identidad de Bézout}}] Sean $x, y \in A^{\ast}$, y supongamos que generan un ideal principal. Entonces existen $z = mcd(x,y)$, $a,b \in A$ tales que $$z = ax + by.$$
\end{proposition}
\emph{Demostración: }Sea $z \in A$ un generador de $(x) + (y)$. Entonces: \begin{enumerate}
\item $x,y \in (z)$, luego $z$ es un divisor común de $x$ e $y$.
\item $z = ax + by$ para ciertos $a,b \in A$.
\end{enumerate}
Por último, además, si $t \mid x$ y $t \mid y$, es claro que $t \mid z$. Por lo que tendremos que $z = mcd(x,y).$

$\hfill \square$

\begin{definition} Dos elementos $x,y \in A^{\ast}$ se denominan \textbf{primos entre sí} cuando no comparten más divisores comunes que las unidades, es decir, cuando $mcd(x,y) = 1$.
\end{definition}

Por ejemplo, si tenemos que $1 = ax+by$, con $a,b \in A$, entonces $x$ e $y$ son primos entre sí, pues la condición impuesta significa $1 \in (x)+(y)$ y por~\ref{eq:obs} (2) se tiene $1 = mcd(x,y)$.

Finalmente daremos un criterio que nos asegurará cuándo los ideales de un dominio son principales: 

\begin{proposition}[\textbf{\textit{Criterio de Hasse}}] Sea $A$ un dominio de integridad y supongamos que existe una función $\varphi \colon A \longrightarrow \mathbb{N}$ tal que $\varphi^{-1}(0) = \lbrace 0 \rbrace$ y cumple: para cada par de elementos $a,b \in A$ tales que $b \neq 0$, $a \notin (b)$ y $\varphi(b) \leq \varphi(a)$ entonces existen $c,d \in A$ tales que $0 < \varphi(ac-bd) < \varphi (b)$. Entonces $A$ es un dominio de ideales principales.
\end{proposition}
\emph{Demostración: }Sea $I$ un ideal no nulo de $A$ y sea $M = \lbrace \varphi(x) : x \in I \setminus \lbrace 0 \rbrace \rbrace \subseteq \mathbb{N}$. Como $\mathbb{N}$ está bien ordenado existirá un $b \in I \setminus \lbrace 0 \rbrace$ tal que $\varphi(b) \leq \varphi(x)$ para cada $x \in I \setminus \lbrace 0 \rbrace$, y veamos que $I = (b)$. Está claro que $(b) \subseteq I$, y supongamos, por reducción al absurdo, que existe un $a \in I \setminus (b)$. Como $b \neq 0$ y $\varphi(b) \leq \varphi(a)$ existen $c,d \in A$ tales que $0 < \varphi(ac-bd) < \varphi(b)$. Así, $e = ac-bd \in I \setminus \lbrace 0 \rbrace$ y $\varphi (e) < \varphi(b)$, en contra de la elección de $b$.

$\hfill \square$

Con todo esto, hemos visto las nociones básicas de divisibilidad y también se ha podido comprobar que en los dominios de ideales principales se cumple: 

\begin{enumerate}
\item (P) Todo elemento irreducible es primo.
\item (MC) Siempre existen mcd y mcm.
\item (B) La identidad de Bézout.
\end{enumerate}

A partir de aquí y con esto, vamos a poder definir una nueva estructura algebraica, que presentaremos más adelante, aunque necesitaremos añadir otra propiedad a estas 3 ya conocidas.

\subsubsection{Dominios de factorización única}

\begin{definition}\label{eq:defdfu} Un \textbf{dominio de factorización única} (o simplemente \textbf{dominio factorial}), escrito $DFU$, es un dominio de integridad en el que se cumple: \begin{enumerate}
\item Todo elemento irreducible es primo.
\item Todo elemento no nulo que no sea unidad es producto de elementos irreducibles.
\end{enumerate}
\end{definition}

A ese producto de elementos irreducibles la denominaremos también \textbf{\textit{factorización única}}. Existen entonces elementos irreducibles $a_{1}, \ldots, a_{r}$ dos a dos primos entre sí, enteros $\alpha_{1}, \ldots, \alpha_{r} > 0$ y $u \in \mathcal{U}(A)$ tales que $$x = ua_{1}^{\alpha_{1}}\ldots a_{r}^{\alpha_{r}}.$$ Estos $a_{i}$ se llaman \textbf{factores irreducibles} de $x$.

Que todo elemento irreducible sea primo se cumple siempre que nos encontremos en un dominio de ideales principales, tal y como vimos anteriormente. También se puede ver como una consecuencia de la \textit{Identidad de Bézout}: supongamos que tenemos un elemento irreducible $p$ tal que $p \mid ab$, para ciertos $a,b \in A$, con $A$ un $DIP$. Entonces, si $p \nmid a$, $mcd(p,a)=1$ y por la \textit{Identidad de Bézout} existirán $x,y \in A$ tales que $1 = xp + ya$, luego $b = bxp + yab$, y como $p \mid ab$ (y evidentemente $p \mid p$) entonces $p \mid b$. Análogo en caso de que $p \nmid b$.

\begin{proposition}Sea $A$ un dominio de ideales principales. Entonces $A$ es un dominio de factorización única.
\end{proposition}
\emph{Demostración: } Veamos primero que todo elemento no nulo de $A$ tiene una factorización en elementos irreducibles. Sea $S$ el conjunto de los ideales principales no nulos cuyos generadores no tienen una factorización en elementos irreducibles, y supongamos que $S$ es no vacío. Sea $(a_1) \in S$. Consideremos la siguiente cadena ascendente: 
$$(a_1) \subset (a_2) \subset \ldots \subset (a_n) \subset \ldots$$ de ideales en $S$. Podemos suponer que esta cadena no es infinita. De hecho, la unión de todos los ideales de esa cadena es un ideal de $A$, y por tanto principal, digamos $(a)$. Este generador $a$ tiene que pertenecer a algún elemento de la cadena, digamos $(a_n)$, luego podemos observar que $(a_n) \subset (a) \subset (a_n)$, por lo que la cadena se estabiliza en $(a_n)$. Así, $S$ está ordenado y tiene un elemento maximal, $(a)$. Por lo tanto, todo ideal de $A$ que contenga a $(a)$ y sea distinto de $(a)$ tiene un generador que admite una factorizacón en elementos irreducibles. 

Observar que $a$ no puede ser irreducible, de lo contrario tendría una factorización, por lo que podemos escribirlo como $a=bc$, con $b,c \in A \setminus \mathcal{U}(A)$. Pero entonces $(b) \neq (a)$, $(c) \neq (a)$ y $(a) \subset (b)$, $(a) \subset (c)$. Así, $b,c$ admiten factorizaciones en elementos irreducibles. El producto de esas factorizaciones es una factorización en elementos irreducibles de $a$, lo cuál es absurdo.

Para probar la unicidad, supongamos que $a$ tiene dos factorizaciones en elementos irreducibles $$a = p_1\ldots p_r = q_1 \ldots q_s.$$ Como $p_1$ divide al producto de la derecha y es irreducible entonces necesariamente divide a uno de los factores, que podemos asumir que es $q_1$ tras una reordenación. Así, existirá una unidad $u_1$ tal que $q_1 = up_1$ (ya que $q_1$ es irreducible). Ahora podemos cancelar $p_1$ en ambas factorizaciones, quedando $$p_2 \ldots p_r = u_1q_2 \ldots q_s.$$ El resultado se tiene por inducción.

$\hfill \square$

\begin{example}Veamos que $\mathbb{Z}[\sqrt{5}i] = \lbrace a + b\sqrt{5}i: a,b \in \mathbb{Z} \rbrace$ es dominio de integridad con las operaciones habituales de suma y producto de complejos:

Como $\mathbb{Z}[\sqrt{5}i]\subseteq \mathbb{C}$ bastará demostrar que $\mathbb{Z}[\sqrt{5}i]$ es subanillo de $\mathbb{C}$. Usamos el conocido teorema de caracterización de subanillos. Claramente, $\mathbb{Z}[\sqrt{5}i] \neq 0$. Para cada par de elementos $a+b \sqrt{5}i, c+d\sqrt{5}i \in \mathbb{Z}[\sqrt{5}i]$ tenemos $$(a+b\sqrt{5}i)-(c+d\sqrt{5}i) = (a-c)+(b-d)\sqrt{5}i\in \mathbb{Z}[\sqrt{5}i]$$ $$(a+b\sqrt{5}i)(c+d\sqrt{5}i) = (ac-5bd)+(ad+bc)\sqrt{5}i\in \mathbb{Z}[\sqrt{5}i].$$ Así, $\mathbb{Z}[\sqrt{5}i]$ es subanillo, y como $\mathbb{C}$ es conmutativo, también lo será $\mathbb{Z}[\sqrt{5}i]$. Además, $1 = 1+0 \sqrt{5}i \in \mathbb{Z}[\sqrt{5}i]$, luego es unitario. Como $(\mathbb{C}, +, \cdot)$ es dominio de integridad, también lo será $\mathbb{Z}[\sqrt{5}i]$.
\end{example}

$\hfill \blacksquare$

Notar que de la proposición anterior tenemos que los DFU satisfacen la condición de cadena ascendente para ideales principales.

\begin{observation} Algunas observaciones:\begin{enumerate}
\item Que todo elemento no nulo que no sea unidad sea producto de elementos irreducibles no garantiza la unicidad de dicha factorización. Es necesaria también la primera condición, ya que la unicidad se desprende de que ésta se cumple sobre un dominio de ideales principales.
\item En un DFU siempre existen mcd y mcm. Efectivamente, puesto que el mcd es el producto de los factores irreducibles comunes elevados al menor exponente y el mcm es el producto de todos los factores irreducibles (comunes y no comunes) elevados al mayor exponente.
\item Las relaciones entre las distintas estructuras algebraicas estudiadas se puede resumir en: $$Cuerpos \subseteq DE \subseteq DIP \subseteq DFU 	\subseteq DI \subseteq Anillo.$$
Por ejemplo, las matrices constituyen un anillo pero no un DI, $\mathbb{Z}[\sqrt{-3}]$ es un DI que no es DFU (puesto que $(1+\sqrt{-3})(1-\sqrt{-3}) = 4 = 2 \cdot 2$), el anillo de los polinomios con coeficientes enteros $\mathbb{Z}[X]$ es un DFU que no es DIP o $\mathbb{Z}$ es un DE que no es un cuerpo. 

Los anillos $\mathbb{Z}$ y $\mathbb{Z}[i]$ son DE y por tanto DFU. Es precisamente en $\mathbb{Z}$ donde éste resultado se manifiesta como el \textbf{\textit{teorema fundamental de la Aritmética}}: \textit{todo número entero positivo $n$ se escribe de modo único como producto de números primos positivos $p_{1}, \ldots, p_{r}$ de la forma $n = p_{1}^{\alpha_{1}} \ldots p_{r}^{\alpha_{r}}.$}
\end{enumerate}
\end{observation}

A continuación veremos todas las propiedades vistas hasta ahora a través de un ejemplo bastante completo, se trata de $\mathbb{Z}[\sqrt{-5}] =\mathbb{Z}[\sqrt{5}i]$, que ya habíamos probado que era subanillo:

\begin{example} Nos situaremos en el subanillo $A \subseteq \mathbb{C}$ de los números complejos de la forma $a +b\sqrt{-5}$, $a,b \in \mathbb{Z}$. Lo denotaremos $A = \mathbb{Z}[\sqrt{-5}]$ y efectivamente $$\mathbb{Z}[\sqrt{-5}] = \lbrace a + b\sqrt{-5} : a,b \in \mathbb{Z} \rbrace.$$ A lo largo del ejemplo se usará indistintamente tanto $A$ como $\mathbb{Z}[\sqrt{-5}]$. 

Estudiaremos primero las unidades. Sea un elemento $a +b\sqrt{-5} \in \mathbb{Z}[\sqrt{-5}]$, entonces $a +b\sqrt{-5} \in \mathcal{U}(\mathbb{Z}[\sqrt{-5}])$ si y sólo si existen $c,d \in \mathbb{Z}$ tales que $$1 = (c + d\sqrt{-5})(a +b\sqrt{-5}) = (ca-5db) + (cb + da)\sqrt{-5}.$$ Y esto quiere decir que $ca-5db = 1$ y $cb + da = 0$. De lo que se obtiene las siguientes soluciones $$c = \dfrac{a}{a^{2}+5b^{2}}, \hspace{0.2cm} d = \dfrac{-b}{a^{2}+5b^{2}}.$$ Esto quiere decir que $(a^{2}+5b^{2}) \mid a$ y que $(a^{2} + 5b^{2}) \mid b$; por lo que $|b| \geq a^{2}+5b^{2}$ y de esto $|b| = 0$ ya que de lo contrario tendríamos que $a^{2} + 5b^{2} \geq 5b^{2} > b^{2} \geq |b|$, que es una contradicción. Así $|b| = 0$ y $b = 0$, y como nuevamente $|a| \geq a^{2} + 5b^{2} = a^{2}$ entonces $|a| \leq 1$. Pero $a$ no puede ser $0$ porque sino también lo sería $a + b\sqrt{-5}$, luego $a = \pm 1$. Esto deja como posibles soluciones $(a,b) = (\pm 1, 0).$ Así, $\mathcal{U} (\mathbb{Z}[\sqrt{-5}]) = \lbrace 1, -1 \rbrace$.\vspace{0.3cm}\\
 
Por lo tanto, las unidades de $\mathbb{Z}[\sqrt{-5}]$ son los elementos $a + b\sqrt{-5}$ tales que $a^{2} + 5b^{2} = 1$. Ahora, definamos una aplicación $$\begin{array}{rccl}
\phi \colon &A&\longrightarrow &\mathbb{N} \\
&a+b\sqrt{-5}& \longmapsto &a^{2}+ 5b^{2}.
\end{array}
$$ El haber definido una aplicación así nos puede sugerir que, entonces, $A$ sea un $DE$, sin embargo no va a ser el caso puesto que no va a cumplir la última de las condiciones vistas cuando definimos los $DE$ en~\ref{eq:de}. Esto tiene todo el sentido del mundo ya que, de ser un $DE$, entonces todo elemento irreducible sería primo y veremos más adelante que esto no es así.

Aunque esta última condición no se cumpla sí lo hace la otra de los $DFU$, es decir, todo elemento no nulo que no sea unidad es producto de elementos irreducibles. Para ver esto es suficiente con ver que $A$ no contiene sucesiones infinitas de la forma $$(x_{0}) \subseteq (x_{1}) \subseteq (x_{2}) \subseteq \ldots \subseteq (x_{n}) \subseteq \ldots.$$ Y efectivamente así es, de no serlo tendríamos $x_{i} = a_{i+1}x_{i+1}$, con $a_{i+1} \notin  \mathcal{U}(A)$ y por tanto $\phi (a_{i+}) > 1$, luego $\phi (x_{i}) > \phi (x_{i+1}).$ Y como está claro que no puede existir la sucesión de números naturales $$\phi(x_{0}) > \phi (x_{1}) > \ldots > \phi(x_{n}) > \ldots, $$ entonces tampoco lo hará $$(x_{0}) \subseteq (x_{1}) \subseteq (x_{2}) \subseteq \ldots \subseteq (x_{n}) \subseteq \ldots.$$ 

Además, en $\mathbb{Z}[\sqrt{-5}]$ no hay unicidad de factorización: $$3 \cdot 2 = (1 + \sqrt{-5}) (1- \sqrt{-5}),$$ y los elementos $2,3, 1+ \sqrt{-5}, 1 - \sqrt{-5}$ son irreducibles. De lo contrario, si alguno de estos elementos, que denotaremos por $x$, fuera reducible tendríamos $x = x_{1}x_{2},  x_{i} \notin \mathcal{U}(A)$, luego $\phi(x) = \phi(x_{1}) \phi(x_{2})$ con $\phi(x_{i}) >1$, donde $\phi(x) = 4,9,6,6$ respectivamente. Sea $\phi(x_{i}) = a_{i}^{2} + 5b_{i}^{2}$. En $\mathbb{Z}$ sí hay unicidad de factorización, luego en cualquiera de los casos $a_{i}^{2}+5b_{i}^{2} = 2$ ó $3$ para $i = 1,2$, lo cual es imposible.

Por todo esto, $A$ no es un $DFU$, sin embargo hemos visto que sí cumple con la condición de que todo elemento no nulo que no sea unidad es producto de elementos irreducibles, así que entonces debe fallar la otra condición: hay elementos irreducibles que no son primos. Esto es así, por ejemplo $1+\sqrt{-5}$.

Por lo que acabamos de ver es claro que habrá al menos dos elementos $x,y \in A$ que no tienen $mcd$, y tiene sentido porque no es $DFU$. Busquemos un par que lo cumpla: para eso sean $$x = 2 \cdot 3 = (1 + \sqrt{-5})\cdot(1- \sqrt{-5})$$ $$y = 2 \cdot (1 + \sqrt{-5}).$$ Supongamos que existe $z = mcd(xy)$. Al ser $2$ y $1 + \sqrt{-5}$ divisores tanto de $x$ como de $y$ existirán entonces $u,v \in A$ tales que $z = 2u = (1 + \sqrt{-5})v.$ Como $2$ y $1+ \sqrt{-5}$ son primos entre sí, $u$ no puede ser unidad, así que $$\phi(u) > 1.$$ También tenemos que $z \mid x$, $z \mid y$, luego $x = zx_{1}$, $y = zy_{1}$ con $x_{1}, y_{1} \in A$. Conocemos los valores de $\phi(x)$ y $\phi(y)$ de antes, luego $$4 \cdot 9 = \phi(x) = \phi(z) \phi (x_{1}) = 4\phi(u) \phi(x_{1}).$$ $$4 \cdot 6 = \phi(y) = \phi(z) \phi(y_{1}) = 4 \phi(u) \phi(y_{1}).$$ De aquí sacamos que $9 = \phi(u) \phi(x_{1})$, $ 6 = \phi(u) \phi(y_{1})$ y como $\phi(u) >1$, necesariamente $$3 = \phi(u) = a^{2} + 5b^{2}, \hspace{0.2cm} u = a+b\sqrt{-5}.$$ Esto es absurdo.

Veamos ahora que la identidad de Bézout no se cumple en $\mathbb{Z}[\sqrt{-5}]$. Por ejemplo, si tomamos $x = 2$, $y = 1-\sqrt{-5}$ entonces $x$ e $y$ son primos entre sí luego $1 = mcd(x,y)$. Sin embargo, vamos a comprobar que no existen $u,v \in A$ tales que $1 = ux + vy$. Supongamos lo contrario y lleguemos a una contradicción: sean $u = a+b\sqrt{-5}$, $v = c + d\sqrt{-5}$ entonces $$1 = 2a + c+ 5d,$$ $$0 = 2b - c + d$$ y de aquí sumándolas $$1 = 2a + 2b + 6d = 2(a + b + 3d).$$ Esto último es imposible ya que $a,b,d \in \mathbb{Z}$.

Por último veamos que no todo par de elementos de $A$ tienen mínimo común múltiplo. Por ejemplo, si escogemos nuevamente el mismo par de antes $x = 2$, $y = 1- \sqrt{-5}$ ya sabemos entonces que su $mcd$ es $1$, luego por~\ref{eq:mcmd} su $mcm$ ha de ser $xy$. Pero claro, $$6 = 3 \cdot 2 = 3x, $$ $$6 = (1 + \sqrt{-5}) \cdot (1 - \sqrt{-5}) = (1 + \sqrt{-5})y,$$ luego el $mcm$ dividirá a $6$. Luego existirá un $u \in A$ tal que $6 = uxy = (a+ b\sqrt{-5}) \cdot 2 \cdot (1- \sqrt{-5})$. Operando, obtenemos $$6 = 2a + 10b,$$ $$0 = -2a + 2b.$$ De esto deducimos que $6 = 12b$, que es imposible teniendo en cuenta que $b \in \mathbb{Z}$, luego no tienen solución entera.

\end{example}
$\hfill \blacksquare$

\subsubsection{Anillos de restos}

A lo largo de la presente sección se llevará a cabo el estudio de los cocientes del anillo de los números enteros $\mathbb{Z}$. Pero antes de eso veamos algunas propiedades del anillo en el que nos encontramos y que ya conocemos gracias a todo lo visto en las secciones anteriores: 

Primero, el resultado central de la sección, y a partir del cual desarrollaremos el resto.

\begin{proposition}Sea $n$ un entero positivo. El anillo $\mathbb{Z}/n\mathbb{Z}$ es un cuerpo si y sólo si $n$ es primo.
\end{proposition}
\emph{Demostración: }Está claro que podemos suponer que $n \geq 2$. Supongamos que $n=ab$, con $1 <a,b<n$ y que $\mathbb{Z}/n\mathbb{Z}$ es cuerpo. Entonces $(a+n\mathbb{Z})(b+n\mathbb{Z}) = 0$ pero esto sería absurdo si $a+n\mathbb{Z},b+n\mathbb{Z}\neq 0$ puesto que un $\mathbb{Z}/n\mathbb{Z}$ es cuerpo y no tiene divisores de cero, así que necesariamente $n$ es primo.

Recíprocamente, supongamos que $n$ es primo, y sea $1 \leq m < n$, entonces se tiene que $mcd(n,m)=1$.  En este caso, sabemos que van a existir $a,b \in \mathbb{Z}$ tales que $an+bm = 1$ por la identidad de Bézout. Por lo tanto, $$(m+n\mathbb{Z})(b+n\mathbb{Z}) = 1+n\mathbb{Z},$$ y tenemos que $m+n\mathbb{Z}$ es invertible.

$\hfill \square$

A este anillo lo podremos denotar indistintamente tanto $\mathbb{Z}/n\mathbb{Z}$ como $\mathbb{Z}/(n)$ tal y como iremos viendo.

\begin{enumerate}
\item Un número entero $p$ es \textit{irreducible} si y solo si es primo, si y sólo si genera un ideal maximal y si y sólo si $\mathbb{Z}/(p)$ es un cuerpo.
\item El anillo $\mathbb{Z}$ es un \textit{dominio de factorización única} (en particular es un $DE$). Todo entero $n >1$ se escribe de manera única como sigue: $$n = p_{1}^{\alpha_{1}} \ldots p_{s}^{\alpha_{s}},$$ con $p_{i}$ números primos conocidos como factores primos de $n$.
\item El conjunto de los números primos es infinito. Para verlo, dado un primo $p$, si definimos el número $n = p!+1$ y consideramos un factor primo cualquiera $p'$ de $n$, entonces $p'$ es estrictamente mayor que $p$ (y así sucesivamente). Si no lo fuera, entonces necesariamente $p' \mid p! = n-1$ y así, como $p'$ divide tanto a $n$ (por ser un factor suyo) y a $n-1$, $p' \mid (n-(n-1)) = 1$, y esto es absurdo.
\end{enumerate}

Con esto ya podemos pasar a describir los cocientes de $\mathbb{Z}$:

\begin{definition} Sea $n$ un número entero. Llamaremos \textbf{anillo de restos módulo n} al cociente $\mathbb{Z}/(n)$. Como $(n) = (-n)$ al ser $-1$ unidad, podremos suponer que $n \geq 0$. Si $n = 0$ el cociente es el propio $\mathbb{Z}$ y si $n=1$ entonces $(n) = \mathbb{Z}$  y no tendría sentido considerar el cociente. Luego $n >1$.

Sea $k \in \mathbb{Z}$. Denotaremos $[k]_{n}$, ó simplemente $[k]$ si no es necesario especificar, la clase de $k$ $$k + (n) = \lbrace k + qn: q \in \mathbb{Z}\rbrace.$$ 
Para obtener otro representante de la clase de $k$, $[k]$, dividiremos por $n$ y tendremos $k = qn + r$. El resto ha de ser positivo o nulo y esto plantea un problema si $k <0$ (porque recordemos que $k$ es un entero), bastará dividir por exceso en vez de por defecto y ya está. Con esto $k -r = qn \in (n)$, por lo tanto $[k] = [r]$. 

Por ejemplo, en $\mathbb{Z}/(3)$ si $k = -8$ tenemos que $-8 = -3 \cdot 3 + 1$, luego $-8$ pertenece a la clase de $[1]$ y así la clase de $[-8] = [1] = \lbrace \ldots, -11, -8, -5, -2, 1, 4, 7, 10, \ldots \rbrace$ (notar que en $\mathbb{Z}/(3)$ la clase de $8$ no es la de $-8$). 

Consideremos ahora dos restos $0 \leq r < s < n$. Si $[r] = [s]$, entonces $s-r \in (n)$, y así $n \mid (s-r)$, y en particular $n  \leq s-r$. Esto es absurdo porque $s-r \leq s < n$. Por lo tanto, en $\mathbb{Z}/(n)$ \textbf{cada clase de equivalencia está determinada por un único representante} $r$ tal que $0 \leq r <n$, es decir, $$\mathbb{Z}/(n) = \lbrace [0], [1], \ldots, [n-1] \rbrace.$$
En particular, $\mathbb{Z}/(n)$ tiene $n$ elementos. $[0]$ y $[1]$ son el cero y el uno de $\mathbb{Z}/(n)$. Es evidente que si sumamos $n$ veces la clase del uno tenemos: $[1] + \ldots +[1] = [n] = [0]$, y que $-[1] = [-1] = [n-1]$. Con esto recordemos que las igualdades entre clases las podemos escribir como $$k \equiv l \hspace{0.1cm}\text{mod}\hspace{0.1cm} n$$ y viene a decir que $[k] = [l]$, es decir, que $k-l = qn$ con un $q \in \mathbb{Z}$. 

Si nos situamos, por ejemplo, en $\mathbb{Z}/(5)$, tenemos que $[3] + [1] = [4]$, que $[2] + [0] = [2]$ y que $[4]+ [3] = [2]$, además $[2] \cdot [2] = [4]$, $[4] \cdot [1] = [4]$ y $[2] \cdot [4] = [3]$; esto por poner sólo unos ejemplos. En $\mathbb{Z}/(6)$, sin embargo, $[2] \cdot [4] = [2]$ y $[4] + [3] = [1]$.
\end{definition}

Pasemos a ver ahora cómo son los ideales de un anillo de restos:

\begin{definition} Sea $n > 1$. Ya vimos en~\ref{eq:ancoci} que los ideales de $\mathbb{Z}/(n)$ están en biyección con los ideales $I \subseteq \mathbb{Z}$ que contienen $(n)$. Sea entonces un ideal $I = (m) \subseteq \mathbb{Z}$ tal que $(m) \supseteq (n)$. Entonces $m \mid n$, y así los ideales de $\mathbb{Z}/(n)$ están en biyección con aquellos ideales generados por los divisores positivos de $n$ (positivos porque $I = (-m) = (m)$).
\end{definition}

Y veamos también los homomorfismos entre anillos de restos:
\begin{definition} Vamos a centrarnos en 5 puntos:\begin{enumerate}
\item No existe ningún homomorfismo de anillos unitarios de la siguiente forma $f \colon \mathbb{Z}/(n) \longrightarrow \mathbb{Z}$ con $n > 0$. De no ser así tendríamos que $$0 = f([0]) = f([1] \overbrace{+ \ldots +}^{n} [1]) = f([1]) \overbrace{+ \ldots +}^{n} f([1])= 1 \overbrace{+ \ldots +}^{n} 1 = n,$$ que es absurdo.
\item La identidad es el único homomorfismo de anillos unitarios $f \colon \mathbb{Z} \longrightarrow \mathbb{Z}.$ En efecto, sea $f \colon \mathbb{Z} \longrightarrow \mathbb{Z}$ uno de ellos, como $f(1) = 1$ entonces, dado un entero $k$, $$f(k) = f(1 \overbrace{+ \ldots +}^{k} 1) = f(1) \overbrace{+ \ldots +}^{k}  f(1) = 1 \overbrace{+ \ldots +}^{k}  1 = k,$$ $$f(-k) = -f(k) = -k.$$ Y este homomorfismo es la identidad: $f = id_{\mathbb{Z}}$.
\item Nos situamos ahora en los homomorfismos de $\mathbb{Z}$ en $\mathbb{Z}/(n)$ con $n>1$. Sea $k$ un entero positivo. Entonces $$f(k) = f(k) = f(1 \overbrace{+ \ldots +}^{k} 1) = f(1) \overbrace{+ \ldots +}^{k}  f(1) = [1]  \overbrace{+ \ldots +}^{k}  [1] = [k],$$ $$f(-k) = -f(k) = -[k] = [-k].$$ Este es el único homomorfismo de anillos unitarios $f \colon \mathbb{Z} \longrightarrow \mathbb{Z}/(n).$
\item Veamos ahora qué ocurre en los homomorfismos del tipo $f \colon \mathbb{Z}/(m) \longrightarrow \mathbb{Z}/(n)$. Sea $f$ uno de ellos, entonces: \begin{center}$[0]_{n} = f([0]_{m}) = f([1]_{m} \overbrace{+ \ldots +}^{m}  [1]_{m}) =   f([1]_{m})  \overbrace{+ \ldots +}^{m}  f([1]_{m}) =  [1]_{n}  \overbrace{+ \ldots +}^{m}  [1]_{n} = [m]_{n}.$\end{center} Y esto quiere decir que $m \equiv 0 \hspace{0.1cm} \text{mod} \hspace{0.1cm} n$, luego $n \mid m$. Por lo tanto, $n$ ha de dividir a $m$.
\item Si $n>1$ y $n\mid m$ entonces existirá un único homomorfismo de anillos unitarios $f \colon \mathbb{Z}/(m) \longrightarrow \mathbb{Z}/(n)$, y además será un epimorfismo. Dicho homomorfismo lo podremos definir como: $$\begin{array}{rccl}
f \colon &\mathbb{Z}/(m)&\longrightarrow &\mathbb{Z}/(n) \\
&[k]_{m}& \longmapsto &[k]_{n}
\end{array}
$$
El cuál ya sabemos que existe por el punto anterior, y está bien definido porque si $k \equiv l \hspace{0.1cm} \text{mod} \hspace{0.1cm} m$ entonces $m \mid (k-l)$, y como $n \mid m$ tendremos entonces que $n \mid (k-l)$, es decir, que $k \equiv l \hspace{0.1cm} \text{mod} \hspace{0.1cm} n$.
\end{enumerate}
\end{definition}

Podemos dar una versión alternativa del teorema chino de los restos:

\begin{theorem}
Si $a,b$ son enteros primos entre sí, entonces se tendrá un isomorfismo de anillos unitarios $$\mathbb{Z}(ab) \cong \mathbb{Z}/(a) \times \mathbb{Z}/(b).$$
\end{theorem}
\emph{Demostración: } Definimos $$\begin{array}{rccl}
f \colon &\mathbb{Z}/(ab)&\longrightarrow &\mathbb{Z}/(a) \times \mathbb{Z}/(b)\\
&[k]_{ab}& \longmapsto &([k]_{a}, [k]_{b}).
\end{array}
$$ Está bien definido, pues si $k \equiv l \hspace{0.1cm} \text{mod} \hspace{0.1cm} ab$ entonces $ab \mid (k-l)$ y así tanto $a$ como $b$ dividen a $k-l$ y tenemos que $k \equiv l \hspace{0.1cm} \text{mod} \hspace{0.1cm} a$ y $k \equiv l \hspace{0.1cm} \text{mod} \hspace{0.1cm} b$. 

Que es homomorfismo es evidente. Es inyectiva, sea $k$ un entero tal que $f([k]_{ab}) = 0$, entonces $([k]_{a}, [k]_{b}) = (0,0)$ y así $$k \equiv 0 \hspace{0.1cm} \text{mod} \hspace{0.1cm} a$$ $$k \equiv 0 \hspace{0.1cm} \text{mod} \hspace{0.1cm} b.$$ Esto quiere decir que $a \mid k$ y $b \mid k$, luego $mcm(a,b) \mid k$, pero como $a$ y $b$ son primos entre sí tenemos que $mcm(a,b) = ab$. Por lo tanto, $ab \mid k$, es decir, $$k \equiv 0 \hspace{0.1cm} \text{mod} \hspace{0.1cm} ab.$$ Luego $ker f = \lbrace 0 \rbrace$ y $f$ es  inyectiva.

Como es una aplicación inyectiva entre dos conjuntos finitos de igual cardinal $ab$ entonces también será biyectiva, y así isomorfismo.

$\hfill \square$

\begin{lemma}Sean $m$ y $n$ enteros positivos tales que $mcd(m,n)=1$. Entonces, dados $a,b \in \mathbb{Z}$, el sistema $$x \equiv a \hspace{0.1cm} \text{mod} \hspace{0.1cm} m$$
$$x \equiv b \hspace{0.1cm} \text{mod} \hspace{0.1cm} n$$ tiene solución. Si $x_1, x_2$ son dos soluciones del sistema, entonces $x_1 \equiv x_2 \hspace{0.1cm} \text{mod} \hspace{0.1cm} mn$.
\end{lemma}
\emph{Demostración: }La ecuación $x \equiv a \hspace{0.1cm} \text{mod} \hspace{0.1cm} m$ tiene solución puesto que $a+km$ satisface la ecuación para cualquier $k \in \mathbb{Z}$. Debemos mostrar que existe un entero $k_1$ tal que $$a+k_1m \equiv b \hspace{0.1cm} \text{mod} \hspace{0.1cm} n.$$ Esto es equivalente a mostrar que $$k_1m \equiv (b-a) \hspace{0.1cm} \text{mod} \hspace{0.1cm} n$$ tiene solución para $k_1$. Como $m$ y $n$ son coprimos, existen enteros $s$ y $t$ tales que $ms+nt=1$. Concluimos que $(b-a)ms=(b-a)-(b-a)nt$ y así $$(b-a)ms \equiv (b-a) \hspace{0.1cm} \text{mod} \hspace{0.1cm} n.$$
Tomamos $k_1=(b-a)s$ y ya está.

Para ver ahora que dos soluciones cualesquiera son congruentes módulo $mn$, sean $c_1$ y $c_2$ dos soluciones del sistema. Es decir, 
$$c_i\equiv a \hspace{0.1cm} \text{mod} \hspace{0.1cm} m$$
$$c_i \equiv b \hspace{0.1cm} \text{mod} \hspace{0.1cm} n$$ para $i=1,2$. Entonces $$c_2 \equiv c_1 \hspace{0.1cm} \text{mod} \hspace{0.1cm} m$$ $$c_2 \equiv c_1 \hspace{0.1cm} \text{mod} \hspace{0.1cm} n$$ por lo que tanto $m$ como $n$ dividen a $c_2-c_1$. Así, $c_2 \equiv c_1 \hspace{0.1cm} \text{mod} \hspace{0.1cm} mn.$

$\hfill \square$

\begin{example}Resolvamos el siguiente sistema: 
$$x \equiv 3 \hspace{0.1cm} \text{mod} \hspace{0.1cm} 4$$
$$x \equiv 4 \hspace{0.1cm} \text{mod} \hspace{0.1cm} 4$$
Usando el algoritmo de Euclides podemos encontrar enteros $s,t$ tales que $4s+5t = 1$. Una posibilidad para tales enteros es $s=4$ y $t=-3$. Tenemos que $a=3$, $b=4$, $m=4$ y $n=5$, luego $k_1 = (4-3)4$ y concluimos así que $$x=a+k_1m=3 +4k_1 = 3+4((4-3)4)=19.$$
\end{example}

Por extensión a $k$ ecuaciones llegamos a:

\begin{theorem}[\textbf{\textit{Teorema Chino de los restos}}]
Sean $n_1, n_2, \ldots, n_k$ enteros positivos tales que $mcd(n_i,n_j)=1$ con $i \neq j$, es decir, coprimos dos a dos. Entonces para enteros cualesquiera $a_1, \ldots, a_k$ el sistema 
$$x \equiv a_1 \hspace{0.1cm} \text{mod} \hspace{0.1cm} n_1$$
$$x \equiv a_2 \hspace{0.1cm} \text{mod} \hspace{0.1cm} n_2$$
$$\vdots$$
$$x \equiv a_k \hspace{0.1cm} \text{mod} \hspace{0.1cm} n_k$$
tiene solución. Más aún, dos soluciones cualesquiera de sistema son congruentes módulo $n_1, n_2, \ldots, n_k$.
\end{theorem}
\emph{Demostración: }Lo haremos por inducción sobre el número de ecuaciones en el sistema. Si hay $k=2$ ecuaciones entonces el resultado se da por el lema anterior. Ahora supongamos que el resultado es cierto para un sistema de $k$ o menos ecuaciones y que queremos encontrar una solución de 
$$x \equiv a_1 \hspace{0.1cm} \text{mod} \hspace{0.1cm} n_1$$
$$x \equiv a_2 \hspace{0.1cm} \text{mod} \hspace{0.1cm} n_2$$
$$\vdots$$
$$x \equiv a_{k+1} \hspace{0.1cm} \text{mod} \hspace{0.1cm} n_{k+1}.$$ Considerando las primeras $k$ ecuaciones, existe una solución que es única módulo $n_1 \ldots n_k$, digamos $a$. Como $n_1 \ldots n_k$ y $n_{k+1}$ son coprimos entre sí el sistema
$$x \equiv a \hspace{0.1cm} \text{mod} \hspace{0.1cm} n_1\ldots n_k$$
$$x \equiv a_{k+1} \hspace{0.1cm} \text{mod} \hspace{0.1cm} n_{k+1}$$ tiene una solución que es única módulo $n_1 \ldots n_{k+1}$ por el lema anterior.

$\hfill \square$

Veamos las unidades de los anillos de restos:

\begin{proposition} Sean $n >1$ y $k \in \mathbb{Z}$. Entonces son equivalentes: \begin{enumerate}
\item $[k] \in \mathcal{U}(\mathbb{Z}/(n)).$
\item $mcd (k,n) = 1.$
\item $[k] \neq 0$ y no es divisor de cero en $\mathbb{Z}/(n)$.
\end{enumerate}
\end{proposition}
\emph{Demostración: } Si $[k]$ es unidad, existirá un $l \in \mathbb{Z}$ tal que $$[1] = [l] \cdot [k] = [lk],$$ y así $1-lk \in (n)$, es decir, $1-lk = mn$ para algún $m \in \mathbb{Z}$. Con esto, $$1 = lk  + mn,$$ y por tanto, $mcd(k,n) = 1$. Tenemos así la primera implicación. Haciendo lo mismo al revés tenemos la implicación inversa y en cualquier anillo $1.\Rightarrow 3.$

Veamos ahora que $3. \Rightarrow 2.$, es decir, dado $mcd(k,n) = d>1$ entonces o bien $[k] = [0]$ o bien es un divisor de cero. Como $$n \mid \left( \dfrac{k}{d}\right) n = k\left( \dfrac{n}{d}\right),$$ o bien $[k] = [0]$, ó $[k]$ es divisor de cero, ó $\left[\dfrac{n}{d} \right] = [0]$, pero en este último caso se tendría que $n \mid \dfrac{n}{d}$ luego $d = 1$, lo cuál contradice la hipótesis.

$\hfill \square$

Con este último resultado del capítulo llegamos a un concepto que ya vimos antes:
 
\begin{definition} Dado un $m$ entero positivo. Denotaremos por $\phi (m)$ el número de enteros $k$ que cumplen: \begin{enumerate}
\item $0 < k \leq m$.
\item $mcd(k,m) = 1$.
\end{enumerate}
Esta aplicación $\phi$ ya la conocemos, es la llamada \textbf{función de Euler}.
\end{definition}

Sobre los anillos la \textit{función de Euler} puede tomar una interpretación diferente: si $n>1$, entonces $\phi(n)$ es el número de unidades de $\mathbb{Z}/(n)$. En efecto, por la proposición anterior $$\mathcal{U}(\mathbb{Z}/(n)) = \lbrace [k]: 0 < k < n, \hspace{0.1cm} mcd(k,n) = 1 \rbrace.$$

Ya sabemos que, dado un primo $p>1$, $\phi(p) = p-1$. Esto está relacionado con el hecho de que si $p$ es primo entonces el cociente $\mathbb{Z}/(p)$ es un cuerpo. Entonces: $$\mathcal{U}(\mathbb{Z}/(p)) = \lbrace [1], \ldots, [p-1] \rbrace.$$

\subsection{Anillos de polinomios}

\begin{definition}Sea $A$ un anillo conmutativo y unitario. Diremos que $X$ es una \textbf{indeterminada} ó \textbf{variable} si sus potencias son algebraicamente independientes, es decir, $$\sum_{i=0}^{n} a_{i}X^{i}=0, \hspace{0.2cm} a_{i}\in A \Longleftrightarrow a_0 = \ldots = a_n = 0  \quad\forall n.$$

Un \textbf{polinomio en $X$} con coeficientes en $A$ es una suma finita $$f(X) = a_0+a_1X+\ldots + a_nXn, \hspace{0.1cm} a_0, a_1, \ldots, a_n \in A$$ a la que se puede agregar un número finito y arbitrario de ceros.  
\end{definition}

\begin{definition}Dados polinomios $f(X) = \sum_{i=0}^n a_iX^i$ y $g(X) = \sum_{j=0}^m b_jX^j$ y $s = max\lbrace n,m \rbrace$ definimos su \textbf{suma} por $$f(X) +g(X) = \sum_{k\geq 0}^s(a_k+b_k)X^k = (a_0+b_0)+\ldots + (a_k+b_k)X^k + \ldots + (a_s+b_s)X^s,$$
y su \textbf{producto} como $$f(X)\cdot g(X) = \sum_{k=1}^{n+m}c_k X^k, \hspace{0.2cm} c_k = \sum_{i+j=k}a_ib_j,$$ teniendo en cuenta que si algún coeficiente $a_i$ ó $b_j$ no aparece es $0$.

Así, construimos un nuevo anillo $A[X]$ cuyo \textbf{cero} es $0 = 0X + \ldots + 0X^n$, y cuyo \textbf{uno} es $1 = 1+ 0X + \ldots + 0X^n$. Diremos que $A[X]$ es el \textbf{anillo de polinomios en la variable $X$ con coeficientes en $A$}.
\end{definition}

\begin{observation}Este nuevo anillo, $A[X]$, contiene a $A$ ya que los elementos de $A$ son polinomios de la forma $a = a+0X+\ldots + 0X^n$.
\end{observation}

\begin{definition}Dados dos anillos $A \leq B$, si $f(X) \in A[X]$ y $b \in B$, al elemento $f(b) \in B$ se le suele llamar \textbf{\textit{valor}} de $f(X)$ en $b$.  De igual forma, al conjunto $$A[b]= \lbrace f(b) : f(X) \in A[x] \rbrace,$$ de todos ellos lo llamaremos \textbf{\textit{anillo de valores de $b$}} en $A[X]$. Si el valor $f(b)=0$ se dice que $b$ es una \textbf{raíz} de $f(X)$. 
\end{definition}

Si $X_1, \ldots, X_n$ son variables independientes, el \textbf{anillo de polinomios} $A[X_1, \ldots, X_n]$ en las variables $X_1, \ldots, X_n$ con coeficientes en $A$ se puede definir de manera inductiva $$A[X_1, \ldots, X_n] = (A[X_1, \ldots, X_{n-1}])[X_n].$$

A partir de ahora supondremos que $A$ es un dominio de integridad.

\begin{definition}Si $0 \neq f(X) = \sum_{i=0}^n a_nX^n \in A[X]$, el \textbf{grado} de $f(X)$ es el mayor entero $n \geq 0$ tal que $a_n \neq 0$ y se denota $\delta (f)$. Los polinomios de grados $0,1,2,3,4$ los llamaremos constantes, lineales, cuadráticos, cúbicos y cuárticos respectivamente.

Diremos que un $a_iX^i$ es el término de grado $i$. El de grado $0$ se denomina \textbf{término independiente}. El coeficiente del término de mayor grado lo llamaremos \textbf{coeficiente director de $f(X)$}. Diremos que un $f(X)$ es mónico si su coeficiente director es una unidad del anillo.
\end{definition}

Ahora, dado $0 \neq f(X_1, \ldots, X_n) \in A[X_1,\ldots, X_n]$ el $grado_{X_i}(f)$ ó $\delta_{X_i}(f)$ es el grado de $f$ como polinomio en $X_i$. El \textbf{\textit{grado total}} de $f = \sum a_{i_1\ldots i_n}X^{i_1}_1\cdots X^{i_n}_n$ es el máximo $\lbrace i_1+\ldots+i_n : a_{i_1 \ldots i_n} \neq 0 \rbrace$.

Por convenio asumiremos que el polinomio cero no tiene grado o que tiene grado $- \infty$.

\begin{proposition} Un anillo de polinomios $A[X]$ es dominio de integridad ($DI$) si y sólo si lo es $A$.
\end{proposition}
\emph{Demostración: }  Como $A$ es subanillo de $A[X]$, el sólo si es claro. Supongamos ahora que $A$ es $DI$. Consideremos la indeterminada $X$ y dos polinomios de $A[X]$: $$f = a_{0} + a_{1}X + \ldots + a_{p}X^{p}, \hspace{0.2cm} g = b_{0} + b_{1}X + \ldots + b_{q}X^{q},$$ vemos que $\delta (f) = p$ y que $\delta (g) = q$, lo que significa que $a_{p} \neq 0$, $b_{q} \neq 0$. Hagamos su producto: $$fg = \sum_{r}^{p+q}c_{r}X^{r} = a_{0}b_{0} + \ldots + (a_{p-1}b_{q} + a_{p}b_{q-1})X^{p+q-1} + a_{p}b_{q}X^{p+q}.$$ Por tanto, $c_{p+q} = a_{p}b_{q} \neq 0$ ya que $A$ es $DI$. Pero esto quiere decir que $fg \neq 0$ pues al menos el coeficiente $c_{p+q}$ es no nulo. Quedaría así probado que $A[X]$ es $DI$.

$\hfill \square$

Notar que este resultado se puede extender de forma natural por inducción a varias variables, es decir: $A[X_{1}, \ldots, X_{n}]$ es dominio de integridad ($DI$) si y sólo si lo es $A$.

De esto se deduce que, como hemos considerado que de ahora en adelante $A$ será un dominio de integridad, $A[X]$ va a ser un dominio de integridad.

De hecho, en general vamos a tener que $\delta(f \cdot g ) \leq \delta(f)+\delta(g)$, pero como $A[X]$ es dominio de integridad entonces: $$\delta(f\cdot g) =  \delta(f)+\delta(g).$$
Es decir, 

\begin{proposition}Dado $A[X]$ un dominio de integridad, $f,g \in A[X]$. Entonces: \begin{enumerate}
\item $\delta(f+g) \leq max\lbrace \delta(f), \delta(g) \rbrace$.
\item $\delta(fg) = \delta(f) + \delta(g)$.
\end{enumerate}
\end{proposition}

Además, 

\begin{corolario} Si $A$ es un dominio de integridad, entonces $$\mathcal{U}(A) = \mathcal{U}(A[X]).$$
\end{corolario}
\emph{Demostración: } Si $a \in \mathcal{U}(A)$ existirá $a^{-1} \in A$ y $a^{-1}$ será también el inverso de $a$ en $A[X]$, luego $a \in \mathcal{U}(A[X])$. Recíprocamente, sea $f \in \mathcal{U}(A[X])$. Entonces existe $g \in A[X]$ con $1 = fg$ $(\ast)$. Como $A$ es dominio de integridad, tenemos que $$0 = \delta (1) = \delta (fg) = \delta (f) + \delta (g).$$ Esto sólo puede significar que $\delta (f) = \delta (g) = 0$, es decir, $f \in A$ y $g \in A$. Así, por $(\ast)$ $f$ es unidad en $A$.

$\hfill \square$

Es además una propiedad que se puede extender por inducción a un anillo de polinomios en varias variables: $$\mathcal{U}(A) = \mathcal{U}(A[X_{1}, \ldots, X_{n}]).$$

La división en $A[X]$ está regulada por la conocida como \textbf{\textit{pseudodivisión}}.

\begin{proposition}\label{eq:divPol} Dados $0 \neq f(X), g(X) \in A[X]$, si $a$ es el coeficiente director de $f(X)$, existen un entero $t \geq 0 $ y polinomios $q(X), r(X) \in A[X]$ tales que $a^tg(X) = f(X)q(X)+r(X)$ y ó $r(X) = 0$ ó $\delta (r) < \delta (f)$.
\end{proposition}
\emph{Demostración: }Si $\delta (g) < \delta (f)$,  basta tomar $t = 0$, $q(X) = 0$ y $r(X) = g(X)$. Supongamos $m = \delta(g) \geq \delta(f) = n$ y procedamos por inducción sobre $m$. Sea $b$ el coeficiente director de $g(X)$. Si $m = 0$, se tiene que $g(X) = b$ y $n = 0$. Como $ag(X)=f(X)b$, basta tomar $t=1$, $q(X)=b$ y $r(X)=0$. Si $m >0$, sea $h(X)=ag(X)-bf(X)X^{m-n}$. Como $\delta(h) < \delta(g)=m$, por inducción existen $t'\geq 0$ y $q'(X), r'(X) \in A[X]$ verificando $a^{t'}h(X) = q'(X)f(X) + r'(X)$, donde ó $r'(X) = 0$ ó $\delta(r') < \delta(f)$. Así $a^{t'+1}g(X) = (q'(X)+a^{t'}bX^{m-n})f(X)+r'(X)$ y basta tomar $t = t'+1$, $q(X) = q'(X) + a^{t'}bX^{m-n}$ y $r(X) = r'(X)$.

$\hfill \square$

\begin{proposition}Si $K$ es un cuerpo, entonces $K[X]$ es un $DIP$.
\end{proposition}
\emph{Demostración: }Sea $I$ un ideal de $K[X]$ y supongamos que $I \neq 0$. Sea $g \in I$ del menor grado posible. Sea $f$ un elemento de $I$ cualquiera no nulo. Por el algoritmo de la división, existen $q,r \in K[X]$ tales que $$f=qg+r$$ y se tiene que $\delta(r) < \delta(g)$. Pero $r = f-qg$ y así $r \in I$. Como $g$ es el elemento de $I$ de grado mínimo se sigue que $r=0$ necesariamente. Así, $I$ estará formado por todos los polinomios $f = qg$. Por último, sólo basta comprobar que $f$ es mónico para que se tenga el resultado, pero esto es fácil, si $f$ es mónico ya está, y si no lo es multiplicamos por el inverso del coeficiente director de $f$, que siempre existe por ser $K$ un cuerpo, y ya está. Así $I$ es principal.

$\hfill \square$

De hecho,

\begin{corolario}SI $K$ es un cuerpo, $K[X]$ es un dominio euclídeo.
\end{corolario}
\emph{Demostración: }En este caso, el grado es una función euclídea.

$\hfill \square$

\begin{corolario}[\textbf{\textit{Teorema del resto}}] Si $a \in A$ y $f(X) \in A[X]$, el resto de dividir $f(X)$ por $(X-a)$ es $f(a)$. En particular, $f(a) = 0$ si y sólo si $X-a \mid f(X)$.
\end{corolario}
\emph{Demostración: }Aplicamos~\ref{eq:divPol}, quedando $f(X)= (X-a)g(X)+r(X)$, con $f(X)$ como dividendo, $X-a$ como divisor, $g(X)$ un polinomio cualquiera de $A[X]$ y $r(X)$ el resto. Entonces ó $r(X)=0$, y así está claro que $f(a)$ es el resto (que es $0$), ó $\delta(r) < \delta(X-a)$, y así $r(X)$ sería una constante y $f(a) = (a-a)g(a) + r = r$.

$\hfill \square$

La aplicación reiterada del \textit{Teorema del resto} permite deducir una cierta factorización de un polinomio quitándole sus raíces en $A$. Es decir, si $f(X) \in A[X]$ y $a_1, a_2, \ldots, a_r \in A$ son sus raíces en $A$, cada una de ellas apareciendo $m_1, \ldots, m_r$ veces respectivamente, entonces existe $g(X) \in A[X]$ tal que $$f(X) = (X-a_1)^{m_1}\ldots (X-a_r)^{m_r}g(X),$$ donde $g(a) \neq 0$, para todo $a \in A$. Cada factor $X-a_i$ es irreducible, puesto que es mónico de grado $1$, aunque $g(X)$ no tiene por qué serlo. Se tiene que $\delta(f) = m_1+m_2 + \ldots + m_r+\delta(g)$, luego $\sum_i^r m_i \leq \delta(f)$. 
\begin{itemize}
\item \textit{Raíces} en $A$: la condición necesaria para su existencia es la \textit{regla de Ruffini}: $f(X) = a_nX^n+\ldots+ a_1X+a_0 \in A[X]$, $a \in A$ y $f(a)=0 \Rightarrow a \mid a_0$.
\item \textit{Multiplicidades de raíces}: que se caracterizará usando el criterio de la derivada, para ello recordamos que la derivación de polinomios es una aplicación lineal $$\begin{array}{rccl}
&A[X]&\longrightarrow &A[X] \\
&f(X)=\sum_{i=0}^na_iX^i& \longmapsto &f'(X) = \sum_{i=1}^{n-1} ia_iX
\end{array}
$$
Notar que es una aplicación que se puede aplicar tantas veces como queramos, obteniendo las derivadas sucesivas del polinomio: $f''(X), \ldots, f^{(n}(X), \ldots$, esto lo hacemos de forma inductiva: $f^{(0}(X)=f(X)$ y $f^{(n}(X) = (f^{(n-1}(X))'$, con $n >0$. 

Recordamos también las siguientes propiedades de la derivación de polinomios: 
\renewcommand{\theenumi}{\arabic{enumi}}
\begin{enumerate}
\item Si $a\in A$, $a' = 0$.
\item Si $n\geq 1$, $(X^n)' = nX^{n-1}.$
\item $(f(X) + g(X))' = f'+g'$.
\item $(f(X)g(X))' = f'(X)g(X) +f(X)g'(X)$. (\textit{Regla de Leibniz})
\end{enumerate}
Notar que podría ser $f(X)$ no constante y $f'(X)$ nulo. Esto pasaría si $f(X) \in A[X^n]$, con $n$ la característica de $A$. 
\end{itemize}

\begin{proposition}Si la característica de $A$ no divide al grado de $f(X) \in A[X]$, entonces $a \in A$ es una raíz múltiple de $f(X)$ si y sólo si $f(a) =f'(a)=0$.
\end{proposition}
\emph{Demostración: }En general, tenemos que $f(X) = (X-a)^ng(X)$ con $n \geq 0$ y $g(a)\neq 0$. Así, se tiene que $f'(X) = n(X-a)^{n-1}g(X)+(X-a)^ng'(X)$. El resultado se obtiene aplicando el \textit{Teorema del resto}, teniendo en cuenta que $a$ se repite si y sólo si $n >1$.

$\hfill \square$

\begin{definition}Una raíz $a \in A$ de un polinomio $f(X) \in A[X]$ se dice que es \textbf{simple} si $f'(a) \neq 0$ y \textbf{múltiple} en caso contrario. El menor $n \geq 1$ tal que $f^n(a) \neq 0$ se llama \textbf{multiplicidad de $a$} como raíz de $f(X)$. Así, $a$ será simple si y sólo si $n=1$ y múltiple si y sólo si $n > 1$.
\end{definition}

Diremos que las raíces de multiplicidad $2,3,4, \ldots$ se denominan dobles, triples, cuádruples, $\ldots$, respectivamente.

A partir de ahora consideraremos $A$ como un dominio de factorización única y $K$ como su cuerpo de fracciones.

\begin{definition}Dado $0 \neq f(X) = a_nX^n+ \ldots + a_1X^1+a_0 \in A[X]$, definimos el \textbf{contenido} de $f$, y lo denotamos $c(f)$, como el máximo común divisor de los coeficientes nu nulos de $f(X)$. Igualmente, diremos que $f(X)$ es \textbf{primitivo} si $c(f) \in \mathcal{U}(A)$.
\end{definition}

Dado un $f(X) \in A[X]$ arbitrario, se tiene que $f(X) = c(f)f_1(X)$, con $f_1(X) \in A[X]$ primmitivo. En particular, un polinomio \textit{irreducible} es \textit{primitivo}.

\begin{lemma}[\textbf{\textit{Lema de Gauss}}]El producto de polinomios primitivos es primitivo.
\end{lemma}
\emph{Demostración: }Sean $f(X) = a_nX^n+\ldots+ a_1X+a_0$, $g(X)= b_mX^m+\ldots+b_1X+b_0 \in A[X]$ primitivos. Su producto es $f(X)g(X) = c_{n+m}X^{n+m} + \ldots + c_1X+c_0 \in A[X]$, con $c_k = a_0b_k+ \ldots+ a_ib_{k-i} + \ldots + a_kb_0.$ Si $f(X)g(X)$ no es primitivo, entonces existe un primo $p \in A$ tal que $p \mid c_k$, $\forall k$. Como $f(X)$ y $g(X)$ son primitivos, existen $s,t \geq 0$ tales que $p \mid a_i$ si $i< s$, pero $p \nmid a_s$ y $p \mid b_j$ si $j <t$, pero $p \nmid b_t$. Como $p \ mid c_{s+t}$, se deduce que $p \mid a_sb_t,$ absurdo.

$\hfill \square$

De hecho, tenemos que $c(f\cdot g) \sim c(f)\cdot c(g)$, con $f(X), g(X) \in A[X]$.

\begin{proposition}Sean $f(X), g(X) \in A[X]$ dos polinomios primitivos. Entonces $f(X)$ y $g(X)$ son asociados en $A[X]$ si y sólo si lo son en $K[X]$.
\end{proposition}
\emph{Demostración: } El directo es inmediato, veamos el recíproco. Supongamos que $f(X) = \alpha g(X)$, con $\alpha \in \mathcal{U}(K[X]) = K^*$. Si $\alpha = a/b$, con $a,b \in A$, deducimos que $bf(X) = ag(X)$. Como $f(X)$ y $g(X)$ son primitivos, tomando contenidos, $a\sim b$, luego $\alpha \in \mathcal{U}(A) = \mathcal{U}(A[X])$.


$\hfill \square$

\begin{proposition}Un polinomio no constante primitivo $f(X) \in A[X]$ es irreducible en $A[X]$ si y sólo si lo es en $K[X]$.
\end{proposition}
\emph{Demostración: }Sea $f(X)$ irreducible en $A[X]$ y supongamos que $f(X) = g(X)h(X)$, con $g(X), h(X) \in K[X]$. Al quitar los denominadores de los coeficientes del segundo término, calcular el contenido del polinomio resultante y aplicar el \textit{Lema de Gauss}, queda $f(X) = (a/b)g_1(X)h_1(X)$, con $a,b \in A$ y $g_1(X), h_1(X) \in A[X]$ son primitivos con $\delta (g_1) = \delta (g)$ y $\delta(h_1) = \delta(h)$. Como en el resultado anterior, operando y tomando contenidos, se tiene que $a/b \in \mathcal{U}(A)$. Por lo tanto, $g_1(X)$ ó $h_1(X)$ es constante no nulo, luego unidad de $K$. Así, $f(X)$ es irreducible en $K[X]$.

Recíprocamente, supongamos que $f(X)$ es irreducible en $K[X]$ y que $f(X) = g(X)h(X)$, con $g(X), h(X) \in A[X]$. Leyendo la expresión en $K[X]$ deducimos que uno de sus factores, por ejemplo $g(X)$, debe ser una unidad en $K[X]$, es decir, $g(X) \in K$. Como $g(X) \in A[X]$, esto indica que $g(X) = a \in A$ es constante. Como $f(X)$ es primitivo, el \textit{Lema de Gauss} implica que $a \in \mathcal{U}(A)$. Por lo tanto, $f(X)$ es irreducible en $A[X]$.

$\hfill \square$

\begin{theorem}[\textbf{\textit{Teorema de Gauss}}]
Si $A$ es un $DFU$, entonces también lo es $A[X]$.
\end{theorem}
\emph{Demostración: }Sea $f(X) \in A[X]$ un polinomio no nulo y no unidad. Escribamos $f(X) = c(f)f_1(X)$, con $f_1(X) \in A[X]$ primitivo, y factorizemos $f_1(X)$ en $K[X]$. Si $p(X) \in K[X]$ es uno de sus factores irreducibles, procediendo de modo habitual, podemos escribir $p(X) = (a/b)p'(X)$, con $a,b \in A$ y $p'(X) \in A[X]$ es primitivo. Más aún, como $p(X)$ es irreducible en $K[X]$, $p'(X)$ es irreducible en $K[X]$, luego, por primitividad, $p'(X)$ es irreducible en $A[X]$. Igualmente, otra vez por primitividad, $a/b \in \mathcal{U}(A) = \mathcal{U}(A[X])$. Por lo tanto, factorizando $c(f)$ en $A$, podemos escribir $$f(X) = ua_1 \cdots a_rp_1'(X) \cdots p_n'(X),$$ con $u \in \mathcal{U}(A[X])$, $a_1, \ldots, a_r \in A$ irreducibles en $A$ y $p_1'(X), \ldots, p_n'(X) \in A[X]$ irreducibles en $A[X]$. Notemos que cada $a_i$ es irreducible en $A[X]$ puesto que lo es en $A$. Por lo tanto la factorización existe. 

Veamos ahora que es única. Sea $a_1\cdots a_rp_1(X) \cdots p_n(X)= b_1\cdots b_sq_1(X) \cdots q_m(X)$, donde $a_1, \ldots, a_r, b_1, \ldots, b_s \in A$ son irreducibles en $A[X]$, luego también en $A$, y $p_1(X), \ldots, p_n(X), q_1(X), \ldots, q_m(X) \in A[X]$ son polinomios no constantes irreducibles en $A[X]$. Por primitividad, $a_1 \cdots a_r \sim b_1 \cdots b_s$, luego $r=s$ y, salvo el orden, $a_i \sim b_i$. Así, $p_1(X) \cdots p_n(X)$ y $q_1(X) \cdots q_m(X)$ son asociados en $K[X]$, pues lo son en $A[X]$ y son primitivos. Por lo tanto $n=m$ y, salvo el orden nuevamente, $p_j(X) \sim q_j(X)$ en $A[X]$, pues son polinomios primitivos asociados en $K[X]$. Así, la factorización es única

$\hfill \square$

\begin{theorem}
Sea $A$ un dominio de integridad. Entonces $A[x]$ es $DIP$ si y sólo si $A$ es un cuerpo.
\end{theorem}
\emph{Demostración: }Si $A$ es un cuerpo sabemos que $A[x]$ es un dominio euclídeo, luego un $DIP$. Recíprocamente, si $A[x]$ es $DIP$, sea $a \in A$ un elemento no nulo y veamos que es una unidad en $A$. Para ello consideramos el ideal $(x,a)$ de $A[x]$. Como ha de ser principal existirá un polinomio $p \in A[x]$ tal que $(x,a)=(p)$, luego $a=pq$ para cierto $q \in A[x]$, pero entonces $\delta (p) + \delta (q)= \delta(a)=0$, luego $\delta(p)=0$ y así $p \in A$. Por otra parte, $x =pr$ para cierto $r \in A[x]$, pero entonces el coeficiente director de $x$, que es $1$, es el producto de $p$ por el coeficiente director de $r$, luego $p$ es una unidad y $(p) = A[x]$.

Entoncecs, $1 \in (p) = (x,a)$, luego $1 = ux+va$, para ciertos polinomios $u,v \in A[x]$. Sin embargo, el término independiente de $ux$ es $0$ y el de $va$ es $ba$, donde $b$ es el término independiente de $v$. Resulta así que $1 = ba$ y $a$ es una unidad en $A$.

$\hfill \square$

Finalmente, veamos uno de los criterios de irreducibilidad de polinomios más conocidos y útiles: 

\begin{proposition}[\textbf{\textit{Criterio de Eisenstein}}] Si $f(X) = a_nX^n+ \ldots + a_1X + a_0 \in \mathbb{Z}[X]$ es primitivo y existe un primo $p$ tal que: 
\begin{enumerate}
\item $p \mid a_i$, con $i = 0, \ldots, n-1$.
\item $p \nmid a_n$.
\item $p^2 \nmid a_0$
\end{enumerate}
Entonces $f(X)$ es irreducible en $\mathbb{Z}[X]$ y en $\mathbb{Q}[X]$.
\end{proposition}
\emph{Demostración: }Basta ver que $f(X)$ es irreducible en $\mathbb{Z}[X]$. Si $f(X)$ es reducible, existen $g(X), h(X) \in \mathbb{Z}[X]$ no constantes tales que $f(X) = g(X)h(X)$. Sean $g(X) = b_rX^r+ \ldots + b_1X + b_0 \in \mathbb{Z}[X]$ y $h(X)= c_sX^s+ \ldots + c_1 X + c_0 \in \mathbb{Z}[X]$. Como $a_0 = b_0c_0$, se tiene que $p$ divide sólo a uno de los dos, a $b_0$ ó a $c_0$. Supongamos que $p \mid b_0$ y que $p \nmid c_0$. Como $p$ no puede dividir a todos los coeficientes de $g(X)$, ya que no divide a $a_n$, existe $r \geq m >0$ tal que $p \mid b_i$, si $i = 0, \ldots, m-1$ y $p \nmid b_m$. Como $m \leq r < n$, se deduce que $p \mid a_m = \sum_{i=0}^m b_ic_{m-i}$, lo que fuerza a que $p \mid b_mc_0$, una contradicción.

$\hfill \square$






























\end{document}